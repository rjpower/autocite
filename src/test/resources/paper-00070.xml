<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="0" size="28" family="Times" color="#7f7f7f"/>
	<fontspec id="1" size="23" family="Times" color="#000000"/>
	<fontspec id="2" size="15" family="Times" color="#000000"/>
	<fontspec id="3" size="12" family="Times" color="#000000"/>
	<fontspec id="4" size="19" family="Times" color="#000000"/>
	<fontspec id="5" size="14" family="Times" color="#000000"/>
<text top="784" left="48" width="0" height="27" font="0"><a href="http://arxiv.org/abs/1201.3204v1">arXiv:1201.3204v1  [cs.AI]  16 Jan 2012</a></text>
<text top="259" left="189" width="537" height="23" font="1">Evaluation of a Simple, Scalable, Parallel Best-First</text>
<text top="291" left="376" width="163" height="23" font="1">Search Strategy</text>
<text top="342" left="386" width="142" height="16" font="2">Akihiro Kishimoto</text>
<text top="363" left="342" width="230" height="16" font="2">Tokyo Institute of Technology</text>
<text top="384" left="310" width="296" height="16" font="2">Japan Science and Technology Agency</text>
<text top="405" left="363" width="189" height="16" font="2">kishimoto@is.titech.ac.jp</text>
<text top="435" left="263" width="116" height="16" font="2">Alex Fukunaga</text>
<text top="456" left="223" width="196" height="16" font="2">The University of Tokyko</text>
<text top="477" left="205" width="232" height="16" font="2">fukunaga@idea.c.u-tokyo.ac.jp</text>
<text top="435" left="553" width="78" height="16" font="2">Adi Botea</text>
<text top="456" left="474" width="237" height="16" font="2">IBM Research, Dublin, Ireland</text>
<text top="477" left="511" width="162" height="16" font="2">adibotea@ie.ibm.com</text>
<text top="535" left="425" width="66" height="15" font="3">Abstract</text>
<text top="559" left="252" width="434" height="15" font="3">Large-scale, parallel clusters composed of commodity processors are</text>
<text top="577" left="230" width="456" height="15" font="3">increasingly available, enabling the use of vast processing capabilities</text>
<text top="595" left="230" width="456" height="15" font="3">and distributed RAM to solve hard search problems. We investigate</text>
<text top="613" left="230" width="456" height="15" font="3">Hash-Distributed A* (HDA*), a simple approach to parallel best-ﬁrst</text>
<text top="631" left="230" width="456" height="15" font="3">search that asynchronously distributes and schedules work among pro-</text>
<text top="649" left="230" width="456" height="15" font="3">cessors based on a hash function of the search state. We use this ap-</text>
<text top="667" left="230" width="456" height="15" font="3">proach to parallelize the A* algorithm in an optimal sequential version</text>
<text top="685" left="230" width="456" height="15" font="3">of the Fast Downward planner, as well as a 24-puzzle solver. The scal-</text>
<text top="703" left="230" width="456" height="15" font="3">ing behavior of HDA* is evaluated experimentally on a shared memory,</text>
<text top="721" left="230" width="456" height="15" font="3">multicore machine with 8 cores, a cluster of commodity machines us-</text>
<text top="739" left="230" width="456" height="15" font="3">ing up to 64 cores, and a large-scale high-performance cluster using up</text>
<text top="757" left="230" width="456" height="15" font="3">to 1024 processors. We show that this approach scales well, allowing</text>
<text top="775" left="230" width="456" height="15" font="3">the eﬀective utilization of large amount of distributed memory to opti-</text>
<text top="793" left="230" width="456" height="15" font="3">mally solve problems which require more than a terabyte of RAM. We</text>
<text top="810" left="230" width="456" height="15" font="3">also compare HDA* to Transposition-table Driven Scheduling (TDS), a</text>
<text top="828" left="230" width="456" height="15" font="3">hash-based parallelization of IDA*, and show that, in planning, HDA*</text>
<text top="846" left="230" width="456" height="15" font="3">signiﬁcantly outperforms TDS. A simple hybrid which combines HDA*</text>
<text top="864" left="230" width="363" height="15" font="3">and TDS to exploit both of their strengths is proposed.</text>
<text top="911" left="189" width="12" height="20" font="4">1</text>
<text top="911" left="225" width="133" height="20" font="4">Introduction</text>
<text top="951" left="189" width="538" height="16" font="5">Parallel search is an important research area due to two reasons. First, many</text>
<text top="971" left="189" width="538" height="16" font="5">search problems, including planning instances, continue to be diﬃcult for se-</text>
<text top="991" left="189" width="538" height="16" font="5">quential algorithms. Parallel search on state-of-the-art, parallel clusters has</text>
<text top="1036" left="454" width="8" height="16" font="5">1</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="6" size="9" family="Times" color="#000000"/>
	<fontspec id="7" size="6" family="Times" color="#000000"/>
	<fontspec id="8" size="11" family="Times" color="#000000"/>
<text top="199" left="189" width="538" height="16" font="5">the potential to provide both the memory and the CPU resources required</text>
<text top="219" left="189" width="538" height="16" font="5">to solve challenging problem instances. Second, while multiprocessors were</text>
<text top="240" left="189" width="538" height="16" font="5">previously expensive and rare, multicore machines are now ubiquitous. Fu-</text>
<text top="260" left="189" width="538" height="16" font="5">ture generations of hardware are likely to continue to have an increasing</text>
<text top="280" left="189" width="538" height="16" font="5">number of processors, where the speed of each individual CPU core does</text>
<text top="300" left="189" width="538" height="16" font="5">not increase as rapidly as in past decades. Thus, exploiting parallelism is</text>
<text top="321" left="189" width="433" height="16" font="5">necessary to extract signiﬁcant speedups from the hardware.</text>
<text top="341" left="214" width="513" height="16" font="5">Our work is primarily motivated by domain-independent planning. In</text>
<text top="361" left="189" width="538" height="16" font="5">classical planning, many problem instances continue to pose a challenge for</text>
<text top="382" left="189" width="538" height="16" font="5">state-of-the-art planning systems. Both the memory and the CPU require-</text>
<text top="402" left="189" width="538" height="16" font="5">ments are main causes of performance bottlenecks. The problem is especially</text>
<text top="422" left="189" width="538" height="16" font="5">pressing in sequential optimal planning. Despite signiﬁcant progress in re-</text>
<text top="443" left="189" width="538" height="16" font="5">cent years in developing domain-independent admissible heuristics <a href="pdfxml.html#43">[1, 2, 3]</a>,</text>
<text top="463" left="189" width="538" height="16" font="5">scaling up optimal planning remains a challenge. Multi-processor, paral-</text>
<text top="484" left="189" width="83" height="15" font="5">lel plannin<a href="pdfxml.html#2">g</a></text>
<text top="481" left="274" width="6" height="12" font="6"><a href="pdfxml.html#2">1</a></text>
<text top="483" left="287" width="439" height="16" font="5">has the potential to provide both the memory and the CPU</text>
<text top="504" left="189" width="412" height="16" font="5">resources required to solve challenging problem instances.</text>
<text top="524" left="214" width="512" height="16" font="5">We introduce and evaluate Hash Distributed A* (HDA*), a paralleliza-</text>
<text top="544" left="189" width="538" height="16" font="5">tion of A* <a href="pdfxml.html#43">[4]</a>. HDA* runs A* on every processor, where each processor</text>
<text top="565" left="189" width="538" height="16" font="5">has its own open and closed lists. A hash function assigns each state to a</text>
<text top="585" left="189" width="538" height="16" font="5">unique processor, so that every state has an “owner”. Whenever a state is</text>
<text top="605" left="189" width="538" height="16" font="5">generated, its owner process is computed according to this hash function,</text>
<text top="626" left="189" width="538" height="16" font="5">and the state is sent to its owner. This simple mechanism simultaneously</text>
<text top="646" left="189" width="538" height="16" font="5">performs load balancing as well as duplicate pruning. While the key idea</text>
<text top="666" left="189" width="538" height="16" font="5">of hash-based assignment of states to processors was initially proposed as</text>
<text top="687" left="189" width="538" height="16" font="5">part of the PRA* algorithm by Evett et al. <a href="pdfxml.html#43">[5]</a>, and later extended by Ma-</text>
<text top="707" left="189" width="538" height="16" font="5">hapatra and Dutt <a href="pdfxml.html#43">[6]</a>, the scalability and limitations of hash-based work</text>
<text top="727" left="189" width="538" height="16" font="5">distribution and duplicate pruning have not been previously evaluated in</text>
<text top="748" left="189" width="538" height="16" font="5">depth. In addition, hash-based work distribution has never been applied to</text>
<text top="768" left="189" width="217" height="16" font="5">domain-independent planning.</text>
<text top="788" left="214" width="512" height="16" font="5">HDA* has two key attributes which make it worth examining in detail.</text>
<text top="809" left="189" width="538" height="16" font="5">First, it is inherently scalable on large-scale parallel systems, because it is</text>
<text top="829" left="189" width="538" height="16" font="5">a distributed algorithm with no central bottleneck resources. While there</text>
<text top="849" left="189" width="538" height="16" font="5">has been some recent work in parallel search <a href="pdfxml.html#44">[7, 8, 9]</a>, these approaches</text>
<text top="870" left="189" width="538" height="16" font="5">are multi-threaded, and limited to shared-memory environments <a href="pdfxml.html#44">[10]</a>, which</text>
<text top="890" left="189" width="538" height="16" font="5">typically have a small number of processors. HDA*, on the other hand,</text>
<text top="910" left="189" width="538" height="16" font="5">scales naturally from a single, multi-core desktop machine to a large scale,</text>
<text top="931" left="189" width="538" height="16" font="5">distributed memory cluster. When implemented using the standard MPI</text>
<text top="960" left="207" width="5" height="7" font="7">1</text>
<text top="962" left="214" width="513" height="13" font="8">In this paper, parallel planning refers to computing sequential plans with multi-</text>
<text top="979" left="189" width="504" height="13" font="8">processor planning, as opposed to computing parallel plans with a serial algorithm.</text>
<text top="1036" left="454" width="8" height="16" font="5">2</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">message passing library <a href="pdfxml.html#44">[11]</a>, the exact same code can be executed on a wide</text>
<text top="219" left="189" width="538" height="16" font="5">array of parallel environments, ranging from a standard desktop multicore</text>
<text top="240" left="189" width="538" height="16" font="5">to a massive cluster with thousands of cores, using all of the aggregate CPU</text>
<text top="260" left="189" width="538" height="16" font="5">and memory resources available on the system. Second, it is a very simple</text>
<text top="280" left="189" width="538" height="16" font="5">algorithm – conceptually, the only diﬀerence between HDA* and A* is that</text>
<text top="300" left="189" width="538" height="16" font="5">when a node is generated, we compute its hash value, and send the node</text>
<text top="321" left="189" width="538" height="16" font="5">to the closed list of the processor that “owns” the hash value. Everything</text>
<text top="341" left="189" width="538" height="16" font="5">runs asynchronously, and there is no tricky synchronization. This simplicity</text>
<text top="361" left="189" width="538" height="16" font="5">is extremely valuable in parallel algorithms, as debugging parallel programs</text>
<text top="382" left="189" width="538" height="16" font="5">is notoriously tricky and time-consuming. Thus, the goal of our work is to</text>
<text top="402" left="189" width="391" height="16" font="5">evaluate the performance and the scalability of HDA*.</text>
<text top="422" left="214" width="512" height="16" font="5">HDA* is implemented as an extension of two state-of-the-art solvers.</text>
<text top="443" left="189" width="538" height="16" font="5">The ﬁrst solver is the Fast Downward domain-independent planner. We</text>
<text top="463" left="189" width="538" height="16" font="5">use the cost-optimal version with the explicit (merge-and-shrink) abstrac-</text>
<text top="483" left="189" width="538" height="16" font="5">tion heuristic reported by Helmert, Haslum, and Hoﬀman <a href="pdfxml.html#43">[3]</a>. The sec-</text>
<text top="504" left="189" width="538" height="16" font="5">ond solver is an application-speciﬁc 24-puzzle solver, which uses the pattern</text>
<text top="524" left="189" width="538" height="16" font="5">database heuristic code provided by Korf and Felner <a href="pdfxml.html#44">[12]</a>. A key diﬀerence</text>
<text top="544" left="189" width="538" height="16" font="5">between these is the relative speed of processing an individual state. The</text>
<text top="565" left="189" width="538" height="16" font="5">domain-speciﬁc 24-puzzle solver processes states signiﬁcantly faster than the</text>
<text top="585" left="189" width="538" height="16" font="5">domain-independent Fast Downward planner, expanding 2-5x more states</text>
<text top="605" left="189" width="82" height="16" font="5">per second<a href="pdfxml.html#3">.</a></text>
<text top="603" left="270" width="6" height="12" font="6"><a href="pdfxml.html#3">2</a></text>
<text top="605" left="288" width="439" height="16" font="5">The speed of processing a state can signiﬁcantly impact the</text>
<text top="626" left="189" width="67" height="15" font="5">eﬃciency</text>
<text top="626" left="264" width="463" height="16" font="5">of a parallel search algorithm, which is the speedup relative to</text>
<text top="646" left="189" width="538" height="16" font="5">a serial implementation divided by the number of CPU cores. A larger</text>
<text top="666" left="189" width="538" height="16" font="5">processing cost per state tends to diminish the impact of parallel-speciﬁc</text>
<text top="687" left="189" width="538" height="16" font="5">overheads, such as the communication and the synchronization overhead</text>
<text top="707" left="189" width="538" height="16" font="5">(introduced in Section <a href="pdfxml.html#4">2)</a>. Therefore, integrating our technique into both</text>
<text top="727" left="189" width="538" height="16" font="5">types of solvers helps us get a more complete picture of the eﬃciency of</text>
<text top="748" left="189" width="329" height="16" font="5">HDA* across a range of application problems.</text>
<text top="768" left="214" width="513" height="16" font="5">The scaling behavior of the algorithm is evaluated on a single multicore</text>
<text top="788" left="189" width="538" height="16" font="5">machine, as well as a commodity cluster with a 1Gb(2x, bonded) Ethernet</text>
<text top="809" left="189" width="538" height="16" font="5">network, and on a high-performance computing (HPC) cluster with 1024</text>
<text top="829" left="189" width="538" height="16" font="5">processors, 2TB of RAM and a 20Gb Inﬁniband network. The latter envi-</text>
<text top="849" left="189" width="538" height="16" font="5">ronment takes the scale of our experiments well beyond previous experiments</text>
<text top="870" left="189" width="538" height="16" font="5">in AI planning. We show that this approach scales well, allowing eﬀective</text>
<text top="890" left="189" width="538" height="16" font="5">utilization of a large amount of distributed memory to optimally solve prob-</text>
<text top="910" left="189" width="538" height="16" font="5">lems that require hundreds of gigabytes, or even up to two terabytes of</text>
<text top="931" left="189" width="538" height="16" font="5">RAM. We also show that HDA* works well on a single, multi-core machine,</text>
<text top="960" left="207" width="5" height="7" font="7">2</text>
<text top="962" left="214" width="513" height="13" font="8">Korf and Felner’s code is IDA*, which generates states much faster than this; we only</text>
<text top="979" left="189" width="538" height="13" font="8">use their pattern database heuristic code, adapted for use in a best-ﬁrst search framework.</text>
<text top="1036" left="454" width="8" height="16" font="5">3</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">achieving speedups of up to 6.6 when the same HDA* code used for our</text>
<text top="219" left="189" width="538" height="16" font="5">distributed memory experiments was executed on an 8-core shared memory</text>
<text top="240" left="189" width="63" height="16" font="5">machine.</text>
<text top="260" left="214" width="513" height="16" font="5">The experiments include a comparison with TDS <a href="pdfxml.html#44">[13, 14]</a>, a successful</text>
<text top="280" left="189" width="538" height="16" font="5">parallelization of IDA*. On a commodity cluster with up to 64 processors</text>
<text top="300" left="189" width="538" height="16" font="5">in use, HDA* is shown to be 2x to 65x faster and to solve more instances</text>
<text top="321" left="189" width="538" height="16" font="5">than TDS. We propose a simple, hybrid approach that combines strengths</text>
<text top="341" left="189" width="538" height="16" font="5">of both HDA* and TDS: Run HDA* ﬁrst, and if HDA* succeeds, return the</text>
<text top="361" left="189" width="538" height="16" font="5">solution. Otherwise, start a TDS search where the initial threshold for the</text>
<text top="382" left="189" width="538" height="16" font="5">depth-ﬁrst exploration is provided by the failed HDA* search. Clearly, when</text>
<text top="402" left="189" width="538" height="16" font="5">HDA* succeeds, this hybrid algorithm runs as fast as HDA*. We show that,</text>
<text top="422" left="189" width="538" height="16" font="5">when HDA* fails, the total runtime of the hybrid approach is comparable</text>
<text top="443" left="189" width="203" height="16" font="5">to the running time of TDS.</text>
<text top="463" left="214" width="513" height="16" font="5">Some of the results presented in this article have previously been reported</text>
<text top="483" left="189" width="538" height="16" font="5">in a shorter, conference paper <a href="pdfxml.html#44">[15]</a>. However, that initial work was limited to</text>
<text top="504" left="189" width="538" height="16" font="5">up to 128 CPU cores, contained no results on the 24-puzzle, no comparison</text>
<text top="524" left="189" width="538" height="16" font="5">to TDS, and included a less detailed evaluation and analysis. A summary</text>
<text top="544" left="189" width="538" height="16" font="5">of our results on 1024 cores has previously been presented in a two-page</text>
<text top="565" left="189" width="80" height="16" font="5">report <a href="pdfxml.html#44">[16]</a>.</text>
<text top="585" left="214" width="513" height="16" font="5">The rest of the paper is organized as follows. Section <a href="pdfxml.html#4">2 </a>presents back-</text>
<text top="605" left="189" width="538" height="16" font="5">ground information. The HDA* algorithm is described in Section <a href="pdfxml.html#11">3. </a>We</text>
<text top="626" left="189" width="538" height="16" font="5">then present an empirical evaluation and analysis of the scalability HDA* in</text>
<text top="646" left="189" width="538" height="16" font="5">Section <a href="pdfxml.html#14">4. </a>Hash-based distribution is compared with a simpler, randomized</text>
<text top="666" left="189" width="538" height="16" font="5">work distribution strategy in Section <a href="pdfxml.html#30">5. </a>In Section <a href="pdfxml.html#31">6, </a>we compare HDA*</text>
<text top="687" left="189" width="538" height="16" font="5">with TDS, and propose a hybrid strategy which combines the strengths of</text>
<text top="707" left="189" width="538" height="16" font="5">both algorithms. We review other approaches to parallel search in Section <a href="pdfxml.html#38">7.</a></text>
<text top="727" left="189" width="538" height="16" font="5">This is followed by a summary and discussion of the results, and directions</text>
<text top="748" left="189" width="113" height="16" font="5">for future work.</text>
<text top="795" left="189" width="12" height="20" font="4">2</text>
<text top="795" left="225" width="126" height="20" font="4">Background</text>
<text top="836" left="189" width="538" height="16" font="5">Eﬃcient implementation of parallel search algorithms is challenging largely</text>
<text top="856" left="189" width="538" height="16" font="5">due to several types of overhead. Search overhead occurs when a parallel</text>
<text top="876" left="189" width="538" height="16" font="5">implementation of a search algorithm generates more states than a serial</text>
<text top="897" left="189" width="538" height="16" font="5">implementation. The main cause of search overhead is partitioning of the</text>
<text top="917" left="189" width="538" height="16" font="5">search space among processors, which has the side eﬀect that the access to</text>
<text top="937" left="189" width="538" height="16" font="5">non-local information is restricted. For example, a sequential A* algorithm</text>
<text top="958" left="189" width="538" height="16" font="5">terminates immediately after a solution is found, as it is guaranteed to be</text>
<text top="978" left="189" width="538" height="16" font="5">optimal. In contrast, when a parallel A* algorithm ﬁnds a (ﬁrst) solution,</text>
<text top="1036" left="454" width="8" height="16" font="5">4</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">that is not necessarily an optimal solution. Better solutions might exist in</text>
<text top="219" left="189" width="538" height="16" font="5">non-local portions of the search space. The search overhead can be nega-</text>
<text top="240" left="189" width="538" height="16" font="5">tive, which means that parallel search expands fewer states than sequential</text>
<text top="260" left="189" width="538" height="16" font="5">search. A negative search overhead possibly results in achieving super-linear</text>
<text top="280" left="189" width="538" height="16" font="5">speedup and often indicates an ineﬃciency in the serial implementation or</text>
<text top="300" left="189" width="538" height="16" font="5">algorithm. For example, not following the heuristic can sometimes result in</text>
<text top="321" left="189" width="205" height="16" font="5">ﬁnding a solution faster <a href="pdfxml.html#44">[17]</a>.</text>
<text top="342" left="214" width="185" height="15" font="5">Synchronization overhead</text>
<text top="341" left="408" width="319" height="16" font="5">is the idle time wasted at synchronization</text>
<text top="361" left="189" width="538" height="16" font="5">points, where some processors have to wait for the others to reach the syn-</text>
<text top="382" left="189" width="538" height="16" font="5">chronization point. For example, in a shared-memory environment, the idle</text>
<text top="402" left="189" width="538" height="16" font="5">time can be caused by mutual exclusion (mutex) locks on shared data that</text>
<text top="422" left="189" width="538" height="16" font="5">cannot be accessed by more than one processor at a time. Finally, commu-</text>
<text top="443" left="189" width="126" height="15" font="5">nication overhead</text>
<text top="443" left="322" width="404" height="16" font="5">refers to the cost of inter-process information exchange</text>
<text top="463" left="189" width="538" height="16" font="5">(i.e., the cost of sending a message from one processor to another over a</text>
<text top="483" left="189" width="483" height="16" font="5">network), and mainly occurs in a distributed-memory environment.</text>
<text top="504" left="214" width="513" height="16" font="5">The key to achieving a good speedup in parallel search is to minimize</text>
<text top="524" left="189" width="538" height="16" font="5">such overheads. This is often a diﬃcult task, in part because the overheads</text>
<text top="544" left="189" width="538" height="16" font="5">are interdependent. For example, reducing search overhead usually increases</text>
<text top="565" left="189" width="331" height="16" font="5">synchronization and communication overhead.</text>
<text top="585" left="214" width="512" height="16" font="5">There are several, broad approaches to parallelizing search algorithms.</text>
<text top="605" left="189" width="538" height="16" font="5">This paper focuses on parallelization by partitioning the search space, so we</text>
<text top="626" left="189" width="538" height="16" font="5">review this approach in this section, providing a background for the next</text>
<text top="646" left="189" width="538" height="16" font="5">two sections. Other approaches, including parallelization of the computa-</text>
<text top="666" left="189" width="538" height="16" font="5">tion performed on each state, running a diﬀerent search algorithm on each</text>
<text top="687" left="189" width="464" height="16" font="5">processor, and parallel window search, are reviewed in Section <a href="pdfxml.html#38">7.</a></text>
<text top="707" left="214" width="513" height="16" font="5">There are several approaches for explicitly distributing the search space</text>
<text top="727" left="189" width="181" height="16" font="5">among parallel processes.</text>
<text top="748" left="214" width="100" height="15" font="5">Work stealing</text>
<text top="748" left="321" width="405" height="16" font="5">is a standard approach for parallel search, and is used</text>
<text top="768" left="189" width="538" height="16" font="5">in many applications, particularly in shared-memory environments. Work</text>
<text top="788" left="189" width="538" height="16" font="5">stealing tries to keep all processors busy at all times by moving work among</text>
<text top="809" left="189" width="538" height="16" font="5">processors. In work-stealing, each processor maintains a local work queue.</text>
<text top="829" left="189" width="538" height="16" font="5">When a processor P generates new work (i.e., new states to be expanded)</text>
<text top="849" left="189" width="538" height="16" font="5">w, it places w in P ’s own local queue. When P has no work in its queue, it</text>
<text top="870" left="189" width="340" height="16" font="5">steals work from the queue of a busy processor.</text>
<text top="890" left="214" width="513" height="16" font="5">In this framework, the root process initially generates some seed nodes</text>
<text top="910" left="189" width="538" height="16" font="5">using sequential search, and assigns these seed nodes among the available</text>
<text top="931" left="189" width="538" height="16" font="5">processors. Then, at each processor, a local search algorithm begins to</text>
<text top="951" left="189" width="538" height="16" font="5">explore the descendants of its seed node. These seed nodes become the</text>
<text top="971" left="189" width="538" height="16" font="5">local root nodes for a local, sequential search algorithm. This basic strategy</text>
<text top="991" left="189" width="538" height="16" font="5">can be applied to depth-ﬁrst search algorithms, including simple depth-ﬁrst</text>
<text top="1036" left="454" width="8" height="16" font="5">5</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">search, branch-and-bound, and IDA*, as well as breadth-ﬁrst and best-ﬁrst</text>
<text top="219" left="189" width="213" height="16" font="5">search algorithms such as A*.</text>
<text top="240" left="214" width="513" height="16" font="5">Two key considerations in a particular work-stealing strategy are how to</text>
<text top="260" left="189" width="538" height="16" font="5">decide which processor to steal work from, as well as how to decide which</text>
<text top="280" left="189" width="538" height="16" font="5">and how much work to steal. A number of diﬀerent work-stealing strategies</text>
<text top="300" left="189" width="538" height="16" font="5">for depth-ﬁrst, linear-space algorithms such as depth-ﬁrst branch-and-bound</text>
<text top="321" left="189" width="538" height="16" font="5">IDA*, and minimax search have been studied (e.g. <a href="pdfxml.html#44">[18, </a><a href="pdfxml.html#45">19, 20]</a>). While most</text>
<text top="341" left="189" width="538" height="16" font="5">work on work-stealing has been on MIMD systems, parallelization of IDA*</text>
<text top="361" left="189" width="538" height="16" font="5">on SIMD machines using an alternating, two-phase mechanism, with a search</text>
<text top="382" left="189" width="498" height="16" font="5">phase and a load balancing phase, has also been investigated <a href="pdfxml.html#45">[21, 22]</a><a href="pdfxml.html#6">.</a></text>
<text top="379" left="686" width="6" height="12" font="6"><a href="pdfxml.html#6">3</a></text>
<text top="402" left="214" width="513" height="16" font="5">Another related research direction is addressing memory limitations by</text>
<text top="422" left="189" width="538" height="16" font="5">using a large amount of slower, external memory (such as disks), to store</text>
<text top="443" left="189" width="538" height="16" font="5">states in search <a href="pdfxml.html#45">[23, 24, 25] </a>(external memory was also used speciﬁcally</text>
<text top="463" left="189" width="538" height="16" font="5">for planning <a href="pdfxml.html#45">[26]</a>). An issue with using external memory is the overhead</text>
<text top="483" left="189" width="538" height="16" font="5">of expensive I/O operations, so techniques for structuring the search to</text>
<text top="504" left="189" width="538" height="16" font="5">minimize these overheads has been the focus of work in this area. Korf</text>
<text top="524" left="189" width="538" height="16" font="5">has implemented a multithreaded, breadth-ﬁrst search using a shared work</text>
<text top="544" left="189" width="538" height="16" font="5">queue which uses external memory <a href="pdfxml.html#44">[7, </a><a href="pdfxml.html#45">24]</a>. Interestingly, some solutions</text>
<text top="565" left="189" width="538" height="16" font="5">to reducing the I/O overhead in external memory search could in principle</text>
<text top="585" left="189" width="538" height="16" font="5">be adapted to handle the inter-process communication overhead in parallel</text>
<text top="605" left="189" width="538" height="16" font="5">search. For example, Zhou and Hansen <a href="pdfxml.html#44">[8] </a>and, more recently, Burns et al.</text>
<text top="626" left="189" width="538" height="16" font="5"><a href="pdfxml.html#44">[9] </a>adapt the idea of structured duplicate detection, which was originally</text>
<text top="646" left="189" width="445" height="16" font="5">introduced for external memory search <a href="pdfxml.html#45">[25]</a>, to parallel search.</text>
<text top="666" left="214" width="512" height="16" font="5">Zhou and Hansen <a href="pdfxml.html#44">[8] </a>introduce a parallel, breadth-ﬁrst search algorithm.</text>
<text top="687" left="189" width="538" height="16" font="5">Parallel structured duplicate detection seeks to reduce synchronization over-</text>
<text top="707" left="189" width="538" height="16" font="5">head. The original state space is partitioned into collections of states called</text>
<text top="727" left="189" width="538" height="16" font="5">blocks. The duplicate detection scope of a state contains the blocks that</text>
<text top="748" left="189" width="538" height="16" font="5">correspond to the successors of that state. States whose duplicate detec-</text>
<text top="768" left="189" width="538" height="16" font="5">tion scopes are disjoint can be expanded with no need for synchronization.</text>
<text top="788" left="189" width="538" height="16" font="5">Burns et al. <a href="pdfxml.html#44">[9] </a>have investigated best-ﬁrst search algorithms that include</text>
<text top="809" left="189" width="538" height="16" font="5">enhancements such as structured duplicate detection and speculative search.</text>
<text top="829" left="189" width="538" height="16" font="5">These techniques were shown to be eﬀective in a shared memory machine</text>
<text top="849" left="189" width="135" height="16" font="5">with up to 8 cores.</text>
<text top="870" left="214" width="513" height="16" font="5">Niewiadomski et al. <a href="pdfxml.html#45">[27] </a>introduce PFA*-DDD, a parallel version of</text>
<text top="890" left="189" width="538" height="16" font="5">Frontier A* with Delayed Duplicate Detection. While achieving very good</text>
<text top="910" left="189" width="538" height="16" font="5">speed-up eﬃciency (often superlinear), PFA*-DDD is limited to returning</text>
<text top="941" left="207" width="5" height="7" font="7">3</text>
<text top="943" left="214" width="513" height="13" font="8">In MIMD (Multiple-Instruction, Multiple-Data stream) systems, each processor exe-</text>
<text top="959" left="189" width="538" height="13" font="8">cutes code independently; in SIMD (Single-Instruction, Multiple-Data stream) systems,</text>
<text top="976" left="189" width="378" height="13" font="8">all processors execute the same instruction (on diﬀerent data).</text>
<text top="1036" left="454" width="8" height="16" font="5">6</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">only the cost of a path from start to target, not an actual path. According</text>
<text top="219" left="189" width="538" height="16" font="5">to the authors, adapting that parallel algorithm to return actual paths is</text>
<text top="240" left="189" width="77" height="16" font="5">not trivial.</text>
<text top="260" left="214" width="513" height="16" font="5">We now review the line of work that leads to the work described in this</text>
<text top="280" left="189" width="538" height="16" font="5">paper. Algorithms such as breadth-ﬁrst or best-ﬁrst search (including A*)</text>
<text top="300" left="189" width="538" height="16" font="5">use an open list which stores the set of states that have been generated but</text>
<text top="321" left="189" width="538" height="16" font="5">not yet expanded. Kumar, Ramesh, and Rao <a href="pdfxml.html#45">[28]</a>, in an early study, iden-</text>
<text top="341" left="189" width="538" height="16" font="5">tiﬁed two broad approaches to parallelizing best-ﬁrst search, based on how</text>
<text top="361" left="189" width="538" height="16" font="5">the usage and maintenance of the open list was parallelized. In a centralized</text>
<text top="382" left="189" width="538" height="16" font="5">approach, there is a single open list which is shared among all processes.</text>
<text top="402" left="189" width="538" height="16" font="5">Each process expands one of the current best nodes from the shared open</text>
<text top="422" left="189" width="538" height="16" font="5">list, and generates and evaluates its children. This centralized approach in-</text>
<text top="443" left="189" width="538" height="16" font="5">troduces no or very little search overhead (i.e., extra states processed by a</text>
<text top="463" left="189" width="538" height="16" font="5">parallel search algorithm), and no load balancing among processors is nec-</text>
<text top="483" left="189" width="538" height="16" font="5">essary. Furthermore, this method is especially simple to implement in a</text>
<text top="504" left="189" width="538" height="16" font="5">shared-memory architecture by using a shared data structure for the open</text>
<text top="524" left="189" width="538" height="16" font="5">list. However, the necessity for concurrent access to the shared open list</text>
<text top="544" left="189" width="538" height="16" font="5">becomes a bottleneck and inherently limits the scalability of the centralized</text>
<text top="565" left="189" width="538" height="16" font="5">approach, except in cases where the cost of processing each node (e.g., eval-</text>
<text top="585" left="189" width="538" height="16" font="5">uating the node with a heuristic function) is extremely expensive, in which</text>
<text top="605" left="189" width="538" height="16" font="5">case overheads associated with shared open list access become insigniﬁcant.</text>
<text top="626" left="214" width="512" height="16" font="5">In contrast, in a decentralized approach to parallel best-ﬁrst search, each</text>
<text top="646" left="189" width="538" height="16" font="5">process has its own open list. Initially, the root processor generates and</text>
<text top="666" left="189" width="538" height="16" font="5">distributes some search nodes among the available processes. Then, each</text>
<text top="687" left="189" width="538" height="16" font="5">process starts to locally run best-ﬁrst search using its local open list (as well</text>
<text top="707" left="189" width="538" height="16" font="5">as a closed list, in case of best-ﬁrst algorithms such as A*). Decentralizing</text>
<text top="727" left="189" width="538" height="16" font="5">the open list eliminates the concurrency overheads associated with a shared,</text>
<text top="748" left="189" width="428" height="16" font="5">centralized open list, but load balancing becomes necessary.</text>
<text top="768" left="214" width="512" height="16" font="5">In early work on parallelizing A*, Kumar, Ramesh and Rao <a href="pdfxml.html#45">[28]</a>, as well</text>
<text top="788" left="189" width="538" height="16" font="5">as Karp and Zhang <a href="pdfxml.html#45">[29, </a><a href="pdfxml.html#46">30] </a>proposed a random work allocation strategy,</text>
<text top="809" left="189" width="538" height="16" font="5">where newly generated states were sent to random processors. In parallel</text>
<text top="829" left="189" width="538" height="16" font="5">architectures where communications between processors is non-uniform, a</text>
<text top="849" left="189" width="538" height="16" font="5">straightforward variant of this randomized strategy is to send states to a</text>
<text top="870" left="189" width="538" height="16" font="5">random neighboring processor to avoid the cost of sending to an arbitrary</text>
<text top="890" left="189" width="146" height="16" font="5">processor (c.f., <a href="pdfxml.html#46">[31]</a>).</text>
<text top="910" left="214" width="513" height="16" font="5">In addition to load balancing, another issue that a parallel search al-</text>
<text top="931" left="189" width="538" height="16" font="5">gorithm must address is duplicate detection. In many search applications,</text>
<text top="951" left="189" width="538" height="16" font="5">including planning benchmarks, the search space is a graph rather than a</text>
<text top="971" left="189" width="538" height="16" font="5">tree, and there are multiple paths to the same state. In sequential search,</text>
<text top="991" left="189" width="538" height="16" font="5">duplicates can be detected and pruned by using a closed list (e.g., hash</text>
<text top="1036" left="454" width="8" height="16" font="5">7</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">table) or other duplicate detection techniques (e.g. <a href="pdfxml.html#46">[32, 33]</a>). Eﬃcient du-</text>
<text top="219" left="189" width="538" height="16" font="5">plicate detection is critical for performance, both in serial and parallel search</text>
<text top="240" left="189" width="537" height="16" font="5">algorithms, and can potentially eliminate vast amounts of redundant work.</text>
<text top="260" left="214" width="512" height="16" font="5">In parallel search, performing duplicate state detection incurs several</text>
<text top="280" left="189" width="538" height="16" font="5">overheads. The cause of an overhead depends on the algorithm and the</text>
<text top="300" left="189" width="538" height="16" font="5">machine environment. For instance, in a shared-memory environment, many</text>
<text top="321" left="189" width="538" height="16" font="5">approaches, including work-stealing, need to carefully manage locks on the</text>
<text top="341" left="189" width="538" height="16" font="5">shared open and closed lists, to guarantee that these structures are correctly</text>
<text top="361" left="189" width="63" height="16" font="5">updated.</text>
<text top="382" left="214" width="513" height="16" font="5">Parallel Retracting A* (PRA*) <a href="pdfxml.html#43">[5] </a>simultaneously addresses the problem</text>
<text top="402" left="189" width="538" height="16" font="5">of work distribution and duplicate state detection. In PRA*, each processor</text>
<text top="422" left="189" width="538" height="16" font="5">maintains its own open and closed lists. A hash function maps each state to</text>
<text top="443" left="189" width="538" height="16" font="5">exactly one processor. When generating a state, PRA* distributes it to the</text>
<text top="463" left="189" width="538" height="16" font="5">corresponding processor. If the hash keys are distributed uniformly across</text>
<text top="483" left="189" width="538" height="16" font="5">the processors, load balancing is achieved. After receiving states, PRA* has</text>
<text top="504" left="189" width="538" height="16" font="5">the advantage that duplicate detection can be performed eﬃciently. All the</text>
<text top="524" left="189" width="358" height="16" font="5">checks are done locally at the destination process.</text>
<text top="544" left="214" width="513" height="16" font="5">While PRA* incorporated the idea of hash-based work distribution,</text>
<text top="565" left="189" width="538" height="16" font="5">PRA* diﬀers signiﬁcantly from a parallel A* in that it is a parallel ver-</text>
<text top="585" left="189" width="538" height="16" font="5">sion of RA* <a href="pdfxml.html#43">[5]</a>, a limited memory search algorithm closely related to MA*</text>
<text top="605" left="189" width="538" height="16" font="5"><a href="pdfxml.html#46">[34] </a>and SMA* <a href="pdfxml.html#46">[35]</a>. When a processor’s memory became full, Parallel Re-</text>
<text top="626" left="189" width="538" height="16" font="5">tracting A* retracts states from the search frontier, and their f -values are</text>
<text top="646" left="189" width="538" height="16" font="5">stored in their parents, which frees up memory. Thus, unlike parallel A*,</text>
<text top="666" left="189" width="538" height="16" font="5">PRA* does not store all expanded nodes in memory, and will not terminate</text>
<text top="687" left="189" width="538" height="16" font="5">due to running out of memory in some process. On the other hand, because</text>
<text top="707" left="189" width="538" height="16" font="5">of the way this retraction mechanism was implemented in <a href="pdfxml.html#43">[5]</a>, PRA* incurs a</text>
<text top="727" left="189" width="538" height="16" font="5">signiﬁcant synchronization overhead, as it uses synchronous communication</text>
<text top="748" left="189" width="538" height="16" font="5">to distribute states. When a processor P generates a new state s and sends</text>
<text top="768" left="189" width="538" height="16" font="5">it to the destination processor Q, P blocks and waits for Q to conﬁrm that</text>
<text top="788" left="189" width="538" height="16" font="5">s has successfully been received and stored (or whether the send operation</text>
<text top="809" left="189" width="400" height="16" font="5">failed due to memory exhaustion at the target process).</text>
<text top="829" left="214" width="513" height="16" font="5">Unlike PRA*, HDA* does not incorporate any mechanism for node re-</text>
<text top="849" left="189" width="538" height="16" font="5">traction. Also, unlike the original implementation of PRA*, HDA* is a</text>
<text top="870" left="189" width="538" height="16" font="5">fully asynchronous algorithm, where all messages are sent/received asyn-</text>
<text top="890" left="189" width="538" height="16" font="5">chronously. This results in a simple algorithm which achieves scalability for</text>
<text top="910" left="189" width="223" height="16" font="5">both speed and memory usage.</text>
<text top="931" left="214" width="513" height="16" font="5">The idea of hash-based work distribution was investigated further by</text>
<text top="951" left="189" width="538" height="16" font="5">Mahapatra and Dutt <a href="pdfxml.html#43">[6]</a>, who studied parallel A* on a Hypercube architec-</text>
<text top="971" left="189" width="538" height="16" font="5">ture, where CPUs are connected by a hypercube network, while in current</text>
<text top="991" left="189" width="538" height="16" font="5">standard architectures machines are connected by either a mesh or torus</text>
<text top="1036" left="454" width="8" height="16" font="5">8</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">network. They proposed two alternatives to the simple hash-based work</text>
<text top="219" left="189" width="538" height="16" font="5">distribution in PRA*. The ﬁrst approach by Mahapatra and Dutt, called</text>
<text top="240" left="189" width="538" height="16" font="5">Global Hashing of Nodes and Quality Equalizing (GOHA&amp;QE), decouples</text>
<text top="260" left="189" width="538" height="16" font="5">load balancing and duplicate checking. States are assigned an owner (based</text>
<text top="280" left="189" width="538" height="16" font="5">on hash key) for duplicate checking, and a newly generated state is ﬁrst</text>
<text top="300" left="189" width="538" height="16" font="5">sent to its owner process for duplicate checking. If the state is in the open</text>
<text top="321" left="189" width="538" height="16" font="5">list of the owner process, then it is a duplicate and discarded. Otherwise,</text>
<text top="341" left="189" width="538" height="16" font="5">it is added to the open list of the owner, and then, the state is possibly</text>
<text top="361" left="189" width="538" height="16" font="5">reassigned to another process using Dutt and Mahapatra’s Quality Equaliz-</text>
<text top="382" left="189" width="538" height="16" font="5">ing (QE) strategy <a href="pdfxml.html#46">[31]</a>. In both PRA* and GOHA&amp;QE, the hash function</text>
<text top="402" left="189" width="538" height="16" font="5">is global – a state can be hashed to any of the processors in the system.</text>
<text top="422" left="189" width="538" height="16" font="5">In parallel architectures where communications costs vary among pairs of</text>
<text top="443" left="189" width="538" height="16" font="5">processors, such a global hashing may be suboptimal. Therefore, Mahapa-</text>
<text top="463" left="189" width="538" height="16" font="5">tra and Dutt also proposed Local Hashing of Nodes and QE (LOHA&amp;QE),</text>
<text top="483" left="189" width="538" height="16" font="5">which incorporates a state space partitioning strategy and allocates disjoint</text>
<text top="504" left="189" width="538" height="16" font="5">partitions to disjoint processor groups in order to minimize communication</text>
<text top="524" left="189" width="538" height="16" font="5">costs <a href="pdfxml.html#43">[6]</a>. Mahapatra and Dutt showed that GOHA&amp;QA and LOHA&amp;QE</text>
<text top="544" left="189" width="538" height="16" font="5">outperformed the simpler, global hash-based work distribution method used</text>
<text top="565" left="189" width="399" height="16" font="5">in PRA* on the Travelling Salesperson Problem (TSP).</text>
<text top="585" left="214" width="512" height="16" font="5">Mahapatra and Dutt’s local hashing is based on a number of restrictive</text>
<text top="605" left="189" width="538" height="16" font="5">assumptions that do not allow applying this strategy to planning. Speciﬁ-</text>
<text top="626" left="189" width="538" height="16" font="5">cally, local hashing works in problems with so-called levelized search graphs.</text>
<text top="646" left="189" width="538" height="16" font="5">In a levelized graph, a given state will always have the same depth (distance</text>
<text top="666" left="189" width="538" height="16" font="5">from root node), regardless of the path that connects the root and the state.</text>
<text top="687" left="189" width="538" height="16" font="5">The notion of the levelized graph can sometimes be extended to exploit local</text>
<text top="707" left="189" width="538" height="16" font="5">hashing if the search space has some regularities on depths such as multiple</text>
<text top="727" left="189" width="538" height="16" font="5">sequence alignment <a href="pdfxml.html#46">[36]</a>. However, planning and the sliding-tile puzzle do</text>
<text top="748" left="189" width="538" height="16" font="5">not belong to this class of problems. The reason is that the same state could</text>
<text top="768" left="189" width="538" height="16" font="5">be reached via diﬀerent-length paths. For example, if two cities A and B</text>
<text top="788" left="189" width="538" height="16" font="5">are connected by two routes of diﬀerent lengths, then driving a truck from</text>
<text top="809" left="189" width="538" height="16" font="5">A to B via each route will result in the same state but the paths from the</text>
<text top="829" left="189" width="290" height="16" font="5">starting state will have diﬀerent lengths.</text>
<text top="849" left="214" width="513" height="16" font="5">HDA* is similar to the GOHA approach described by Mahapatra and</text>
<text top="870" left="189" width="538" height="16" font="5">Dutt. However, GOHA is a parallelization of SEQ A*, a variant of A*</text>
<text top="890" left="189" width="537" height="16" font="5">which performs partial expansion of states, while HDA* is a parallelization</text>
<text top="910" left="189" width="112" height="16" font="5">of standard A*.</text>
<text top="931" left="214" width="515" height="16" font="5">Transposition-table driven work scheduling (TDS) <a href="pdfxml.html#44">[13, 14] </a>is a distributed</text>
<text top="951" left="189" width="538" height="16" font="5">memory, parallel IDA* algorithm. Similarly to PRA*, TDS distributes work</text>
<text top="971" left="189" width="538" height="16" font="5">using a state hash function. The transposition table is partitioned over</text>
<text top="991" left="189" width="538" height="16" font="5">processors to be used for detecting and pruning duplicate states that ar-</text>
<text top="1036" left="454" width="8" height="16" font="5">9</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">rive at the processor. Thus, TDS distributes a massive transposition table</text>
<text top="219" left="189" width="538" height="16" font="5">for IDA* among the processing nodes, similarly to how PRA* distributes</text>
<text top="240" left="189" width="538" height="16" font="5">the open and the closed lists for A*. This distributed transposition table</text>
<text top="260" left="189" width="538" height="16" font="5">allows TDS to exhibit a very low (sometimes negative) search overhead,</text>
<text top="280" left="189" width="538" height="16" font="5">compared to a sequential IDA* that runs on a single computational node</text>
<text top="300" left="189" width="538" height="16" font="5">with limited RAM capacity. TDS achieved impressive speedups in applica-</text>
<text top="321" left="189" width="538" height="16" font="5">tions such as the 15-puzzle, the double-blank puzzle, and the Rubik’s cube,</text>
<text top="341" left="189" width="538" height="16" font="5">on a distributed-memory machine. The ideas behind TDS have also been</text>
<text top="361" left="189" width="479" height="16" font="5">successfully integrated in adversarial two-player search <a href="pdfxml.html#46">[37, 38, 39]</a>.</text>
<text top="382" left="214" width="513" height="16" font="5">Thus, the idea of hash-based distribution of work in parallel A* is not</text>
<text top="402" left="189" width="538" height="16" font="5">new, but there are several reasons to revisit the idea and perform an in-depth</text>
<text top="422" left="189" width="538" height="16" font="5">evaluation at this point. First, the primary motivation for this work was to</text>
<text top="443" left="189" width="538" height="16" font="5">advance the state of the art of domain-independent planning by parallelizing</text>
<text top="463" left="189" width="538" height="16" font="5">search. While there has been some previous, smaller-scale work on parallel</text>
<text top="483" left="189" width="538" height="16" font="5">planning, large-scale parallel planning has not been previously attempted</text>
<text top="504" left="189" width="538" height="16" font="5">(to our knowledge), and hash-based work distribution is a natural approach</text>
<text top="524" left="189" width="420" height="16" font="5">for scaling parallel planning to large-scale parallel clusters.</text>
<text top="544" left="214" width="513" height="16" font="5">Second, parallel systems have become much more common today than</text>
<text top="565" left="189" width="538" height="16" font="5">when the earlier work by Evett et al. <a href="pdfxml.html#43">[5] </a>and Mahapatra and Dutt <a href="pdfxml.html#43">[6] </a>was</text>
<text top="585" left="189" width="538" height="16" font="5">done, and the parallel systems which are prevalent today have very diﬀerent</text>
<text top="605" left="189" width="538" height="16" font="5">architectures. The most common parallel architectures today are commod-</text>
<text top="626" left="189" width="538" height="16" font="5">ity, multicore, shared memory machines, as well as distributed memory clus-</text>
<text top="646" left="189" width="538" height="16" font="5">ters which are composed of shared memory multicore nodes. While there</text>
<text top="666" left="189" width="538" height="16" font="5">is still some diversity in parallel architectures today, the situation is much</text>
<text top="687" left="189" width="538" height="16" font="5">more homogeneous than in the past. Hash-based work distribution is a</text>
<text top="707" left="189" width="538" height="16" font="5">simple approach that can potentially scale naturally from single, multi-core</text>
<text top="727" left="189" width="538" height="16" font="5">nodes to large clusters of multi-core nodes, and it is important to evalu-</text>
<text top="748" left="189" width="538" height="16" font="5">ate its performance on current, standard parallel architectures. In addition,</text>
<text top="768" left="189" width="538" height="16" font="5">previous algorithms based on this idea, such as PRA* and Mahapatra and</text>
<text top="788" left="189" width="538" height="16" font="5">Dutt’s method, make some assumptions that are speciﬁc to the hardware</text>
<text top="809" left="189" width="538" height="16" font="5">architecture in use. In contrast, we aim at obtaining an algorithm as general</text>
<text top="829" left="189" width="538" height="16" font="5">as possible, avoiding hardware-speciﬁc assumptions. In fact, as mentioned</text>
<text top="849" left="189" width="538" height="16" font="5">earlier, our MPI-based implementation can be run on a variety of platforms,</text>
<text top="870" left="189" width="465" height="16" font="5">including shared-memory and distributed-memory environments.</text>
<text top="890" left="214" width="513" height="16" font="5">Third, there are some important issues that were not explored in the</text>
<text top="910" left="189" width="538" height="16" font="5">earlier work. For example, the performance impact of using a hash function</text>
<text top="931" left="189" width="538" height="16" font="5">for work distribution, as opposed to a simpler, randomized strategy, has not</text>
<text top="951" left="189" width="206" height="16" font="5">been previously investigated.</text>
<text top="971" left="214" width="513" height="16" font="5">Fourth, while the work on TDS showed the utility of asynchronous, hash-</text>
<text top="991" left="189" width="538" height="16" font="5">based work distribution for IDA*, this previous work was done on 15-puzzle</text>
<text top="1036" left="449" width="16" height="16" font="5">10</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">variants and the Rubik’s cube, which are two domains where the overhead</text>
<text top="219" left="189" width="538" height="16" font="5">incurred by re-exploration of states in IDA* is known to be relatively small.</text>
<text top="240" left="189" width="538" height="16" font="5">In some other domains, this overhead can be quite signiﬁcant, which can</text>
<text top="260" left="189" width="537" height="16" font="5">result in signiﬁcant costs on a cluster environment. Thus, an investigation</text>
<text top="280" left="189" width="538" height="16" font="5">of the scalability of hash-based, parallel A* and a comparison with TDS is</text>
<text top="300" left="189" width="83" height="16" font="5">worthwhile.</text>
<text top="348" left="189" width="12" height="20" font="4">3</text>
<text top="348" left="225" width="222" height="20" font="4">Hash Distributed A*</text>
<text top="388" left="189" width="538" height="16" font="5">We now describe Hash Distributed A* (HDA*), a simple parallelization of</text>
<text top="409" left="189" width="538" height="16" font="5">A* which uses the hash-based work distribution strategy originally proposed</text>
<text top="429" left="189" width="90" height="16" font="5">in PRA* <a href="pdfxml.html#43">[5]</a>.</text>
<text top="449" left="214" width="513" height="16" font="5">In HDA* the closed and open lists are implemented as a distributed</text>
<text top="470" left="189" width="538" height="16" font="5">data structure, where each processor “owns” a partition of the entire search</text>
<text top="490" left="189" width="538" height="16" font="5">space. The partitioning is done via a hash function on the state, and is</text>
<text top="510" left="189" width="110" height="16" font="5">described later.</text>
<text top="531" left="214" width="513" height="16" font="5">The overall HDA* algorithm begins by the expansion of the initial state</text>
<text top="551" left="189" width="538" height="16" font="5">at the head processor. Then, each processor P executes the following loop</text>
<text top="571" left="189" width="245" height="16" font="5">until an optimal solution is found:</text>
<text top="604" left="209" width="518" height="16" font="5">1. First, P checks if one or more new states have been received in its</text>
<text top="624" left="230" width="497" height="16" font="5">message queue. If so, P checks for each new state s in P ’s closed list,</text>
<text top="644" left="230" width="497" height="16" font="5">in order to determine whether s is a duplicate, or whether it should</text>
<text top="665" left="230" width="232" height="16" font="5">be inserted in P ’s local open lis<a href="pdfxml.html#11">t</a></text>
<text top="662" left="462" width="6" height="12" font="6"><a href="pdfxml.html#11">4</a></text>
<text top="665" left="469" width="5" height="16" font="5">.</text>
<text top="698" left="209" width="518" height="16" font="5">2. If the message queue is empty, then P selects a highest priority state</text>
<text top="718" left="230" width="497" height="16" font="5">from its local open list and expands it, resulting in newly generated</text>
<text top="739" left="230" width="497" height="16" font="5">states. For each of the newly generated states s, a hash key K(s) is</text>
<text top="759" left="230" width="497" height="16" font="5">computed based on the state representation, and the generated state is</text>
<text top="779" left="230" width="497" height="16" font="5">then sent to the processor which owns K(s). This send is asynchronous</text>
<text top="799" left="230" width="497" height="16" font="5">and non-blocking. P continues its computation without waiting for a</text>
<text top="820" left="230" width="192" height="16" font="5">reply from the destination.</text>
<text top="852" left="214" width="513" height="16" font="5">In a typical, straightforward implementation of hash-based work distri-</text>
<text top="872" left="189" width="538" height="16" font="5">bution on a shared memory machine, each processing thread owns a local</text>
<text top="893" left="189" width="538" height="16" font="5">open/closed list which is implemented in shared memory, and when a state</text>
<text top="913" left="189" width="538" height="16" font="5">is assigned to some thread, the writer thread obtains a lock on the target</text>
<text top="942" left="207" width="5" height="7" font="7">4</text>
<text top="944" left="214" width="513" height="13" font="8">Even if the heuristic function <a href="pdfxml.html#43">[3] </a>is consistent, parallel A* search may sometimes have</text>
<text top="961" left="189" width="538" height="15" font="8">to re-open the state saved in the closed list. For example, P may receive many identical</text>
<text top="977" left="189" width="538" height="15" font="8">states with various priorities from diﬀerent processors and these states may reach P in</text>
<text top="994" left="189" width="61" height="13" font="8">any order.</text>
<text top="1036" left="449" width="16" height="16" font="5">11</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">shared memory, writes the state, then releases the lock. Note that when-</text>
<text top="219" left="189" width="538" height="16" font="5">ever a processor P “sends” a state s to a destination dest(s), then P must</text>
<text top="240" left="189" width="538" height="16" font="5">wait until the lock for shared open list (or message queue) for dest(s) is</text>
<text top="260" left="189" width="538" height="16" font="5">available and not locked by any other processor. This results in signiﬁ-</text>
<text top="280" left="189" width="538" height="16" font="5">cant synchronization overhead – for example, it was observed in <a href="pdfxml.html#44">[9] </a>that a</text>
<text top="300" left="189" width="538" height="16" font="5">straightforward implementation of PRA* exhibited extremely poor perfor-</text>
<text top="321" left="189" width="538" height="16" font="5">mance on the Grid search problem, where multi-core performance for up to</text>
<text top="341" left="189" width="538" height="16" font="5">8 cores was consistently slower than sequential A*. While it is possible to</text>
<text top="361" left="189" width="538" height="16" font="5">speed up locking operations by using, for example, highly optimized lock</text>
<text top="382" left="189" width="538" height="16" font="5">operations implementations in inline assembly language such as those which</text>
<text top="402" left="189" width="401" height="16" font="5">are commonly used in the two-player game communit<a href="pdfxml.html#12">y</a></text>
<text top="399" left="590" width="6" height="12" font="6"><a href="pdfxml.html#12">5</a></text>
<text top="402" left="597" width="130" height="16" font="5">, the performance</text>
<text top="422" left="189" width="538" height="16" font="5">degradation due to the increase in synchronization points caused by locks</text>
<text top="443" left="189" width="230" height="16" font="5">remains a considerable problem.</text>
<text top="463" left="214" width="513" height="16" font="5">In contrast, the open/closed lists in HDA* are not explicitly shared</text>
<text top="483" left="189" width="538" height="16" font="5">among the processors. Thus, even in a multi-core environment where it</text>
<text top="504" left="189" width="538" height="16" font="5">is possible to share memory, all communications are done between separate</text>
<text top="524" left="189" width="538" height="16" font="5">MPI processes using non-blocking send/receive operations. Our implemen-</text>
<text top="544" left="189" width="538" height="16" font="5">tation implements this by using MPI Bsend and MPI Iprobe. This enables</text>
<text top="565" left="189" width="513" height="16" font="5">HDA* to utilize highly optimized message buﬀers implemented in MPI.</text>
<text top="585" left="214" width="513" height="16" font="5">Additionally, more than one state can be packed to reduce the number</text>
<text top="605" left="189" width="538" height="16" font="5">of MPI communications. A possible concern with HDA* is communication</text>
<text top="626" left="189" width="538" height="16" font="5">overhead, since every state generation can result in a message being sent</text>
<text top="646" left="189" width="538" height="16" font="5">from the processor where the state is generated to another processor which</text>
<text top="666" left="189" width="538" height="16" font="5">is the “owner” of the state. In their work with transposition-table driven</text>
<text top="687" left="189" width="538" height="16" font="5">scheduling for parallel IDA*, Romein et al. <a href="pdfxml.html#44">[13] </a>showed that this communi-</text>
<text top="707" left="189" width="538" height="16" font="5">cation overhead could be overcome by packing multiple states with the same</text>
<text top="727" left="189" width="538" height="16" font="5">destination into a single message. HDA* uses this state packing strategy.</text>
<text top="748" left="189" width="538" height="16" font="5">The relation between performance and message sizes depends on several fac-</text>
<text top="768" left="189" width="538" height="16" font="5">tors such as network conﬁgurations, the number of CPU cores, the speed</text>
<text top="788" left="189" width="538" height="16" font="5">of CPU, and so on. In our experiments, 100 states are packed into each</text>
<text top="809" left="189" width="538" height="16" font="5">message on a commodity cluster using more than 16 CPU cores and a HPC</text>
<text top="829" left="189" width="538" height="16" font="5">cluster, while 10 states are packed on the commodity cluster using less than</text>
<text top="849" left="189" width="62" height="16" font="5">17 cores.</text>
<text top="870" left="214" width="513" height="16" font="5">In a decentralized parallel A* (including HDA*), when a solution is dis-</text>
<text top="890" left="189" width="538" height="16" font="5">covered, there is no guarantee at that time that the solution is optimal <a href="pdfxml.html#45">[28]</a>.</text>
<text top="910" left="189" width="538" height="16" font="5">When a processor discovers a goal state G, the processor broadcasts the</text>
<text top="931" left="189" width="538" height="16" font="5">cost of G to all processors. The search cannot terminate until all processors</text>
<text top="951" left="189" width="538" height="16" font="5">have proved that there is no solution with a cost better than that of G. In</text>
<text top="980" left="207" width="5" height="7" font="7"><a href="http://gps.tanaka.ecc.u-tokyo.ac.jp/osl/osl/doc/html/lightMutex_8h-source.html">5</a></text>
<text top="983" left="214" width="551" height="12" font="8"><a href="http://gps.tanaka.ecc.u-tokyo.ac.jp/osl/osl/doc/html/lightMutex_8h-source.html">http://gps.tanaka.ecc.u-tokyo.ac.jp/osl/osl/doc/html/lightMutex_8h-source.html</a></text>
<text top="1036" left="449" width="16" height="16" font="5">12</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">order to correctly terminate a decentralized parallel A*, it is not suﬃcient</text>
<text top="219" left="189" width="538" height="16" font="5">to check the local open list at every processor. We must also ensure that</text>
<text top="240" left="189" width="538" height="16" font="5">there is no message still travelling from the sender to the receiver that could</text>
<text top="260" left="189" width="538" height="16" font="5">lead to a better solution. Various algorithms to handle termination exist. In</text>
<text top="280" left="189" width="538" height="16" font="5">our implementation of HDA*, we used the time algorithm of Mattern <a href="pdfxml.html#46">[40]</a>,</text>
<text top="300" left="189" width="206" height="16" font="5">which was also used in TDS.</text>
<text top="321" left="214" width="513" height="16" font="5">Mattern’s method is based on counting sent messages and received mes-</text>
<text top="341" left="189" width="538" height="16" font="5">sages. If all processors were able to do the counting at the very same time</text>
<text top="361" left="189" width="538" height="16" font="5">instant, it would be trivial to detect whether a message is still travelling.</text>
<text top="382" left="189" width="291" height="16" font="5">However, in reality, diﬀerent processors P</text>
<text top="389" left="480" width="4" height="8" font="6">i</text>
<text top="382" left="490" width="237" height="16" font="5">will report their sent and received</text>
<text top="402" left="189" width="93" height="16" font="5">counters, S(t</text>
<text top="409" left="282" width="4" height="8" font="6">i</text>
<text top="402" left="287" width="69" height="16" font="5">) and R(t</text>
<text top="409" left="356" width="4" height="8" font="6">i</text>
<text top="402" left="361" width="151" height="16" font="5">), at diﬀerent times t</text>
<text top="409" left="512" width="4" height="8" font="6">i</text>
<text top="402" left="517" width="210" height="16" font="5">. To handle this, Mattern in-</text>
<text top="422" left="189" width="538" height="16" font="5">troduces a basic method where the counters are reported in two diﬀerent</text>
<text top="443" left="189" width="97" height="16" font="5">waves. Let R</text>
<text top="442" left="286" width="6" height="11" font="6">∗</text>
<text top="443" left="298" width="13" height="16" font="5">=</text>
<text top="451" left="332" width="4" height="8" font="6">i</text>
<text top="443" left="340" width="25" height="16" font="5">R(t</text>
<text top="450" left="365" width="4" height="8" font="6">i</text>
<text top="443" left="370" width="357" height="16" font="5">) be the accumulated received counter at the end</text>
<text top="463" left="189" width="175" height="16" font="5">of the ﬁrst wave, and S</text>
<text top="463" left="364" width="10" height="11" font="6">′∗</text>
<text top="463" left="382" width="13" height="16" font="5">=</text>
<text top="472" left="417" width="4" height="8" font="6">i</text>
<text top="463" left="425" width="23" height="16" font="5">S(t</text>
<text top="463" left="448" width="3" height="11" font="6">′</text>
<text top="472" left="448" width="4" height="8" font="6">i</text>
<text top="463" left="453" width="273" height="16" font="5">) be the accumulated sent counter at</text>
<text top="483" left="189" width="406" height="16" font="5">the end of the second wave. Mattern proved that, if S</text>
<text top="483" left="596" width="10" height="11" font="6">′∗</text>
<text top="483" left="614" width="32" height="16" font="5">= R</text>
<text top="483" left="646" width="6" height="11" font="6">∗</text>
<text top="483" left="653" width="74" height="16" font="5">, then the</text>
<text top="504" left="189" width="536" height="16" font="5">termination condition holds (i.e., there are no messages travelling around).</text>
<text top="524" left="214" width="512" height="16" font="5">Mattern’s time algorithm is a variation of the basic method that allows</text>
<text top="544" left="189" width="538" height="16" font="5">checking the termination condition in only one wave. Each work message</text>
<text top="565" left="189" width="538" height="16" font="5">(i.e., containing search states to be processed) has a time stamp, which</text>
<text top="585" left="189" width="538" height="16" font="5">can be implemented as a clock counter maintained locally by each proces-</text>
<text top="605" left="189" width="538" height="16" font="5">sor. Every time a new termination check is started, the initiating processor</text>
<text top="626" left="189" width="538" height="16" font="5">increments its clock counter and sends a control message to another proces-</text>
<text top="646" left="189" width="538" height="16" font="5">sor, starting a chain of control messages that will visit all processors and</text>
<text top="666" left="189" width="538" height="16" font="5">will come back to the ﬁrst one. When receiving a control message, a pro-</text>
<text top="687" left="189" width="538" height="16" font="5">cessor updates its clock counter C to max(C, T ), where T is the maximum</text>
<text top="707" left="189" width="538" height="16" font="5">clock value among processors visited so far in the chain of control messages.</text>
<text top="727" left="189" width="484" height="16" font="5">If a processor contains a received message m with a time stamp t</text>
<text top="734" left="672" width="11" height="8" font="6">m</text>
<text top="727" left="691" width="36" height="16" font="5">≥ T ,</text>
<text top="748" left="189" width="538" height="16" font="5">then the termination check fails. Obviously, if, at the end of the chain of</text>
<text top="768" left="189" width="538" height="16" font="5">messages, the accumulated sent and received counters diﬀer, then the ter-</text>
<text top="788" left="189" width="200" height="16" font="5">mination check fails as well.</text>
<text top="809" left="214" width="513" height="16" font="5">In a hash based work distribution scheme, the choice of the hash func-</text>
<text top="829" left="189" width="538" height="16" font="5">tion is essential for achieving uniform distribution of the keys, which results</text>
<text top="849" left="189" width="538" height="16" font="5">in eﬀective load balancing. Our implementation of HDA* uses the Zobrist</text>
<text top="870" left="189" width="538" height="16" font="5">function <a href="pdfxml.html#46">[41] </a>to map a SAS+ state representation <a href="pdfxml.html#47">[42] </a>to a hash key. The Zo-</text>
<text top="890" left="189" width="538" height="16" font="5">brist function is commonly used in the game tree search community to detect</text>
<text top="910" left="189" width="538" height="16" font="5">duplicate states. The Zobrist hash value is computed by XOR’ing predeﬁned</text>
<text top="931" left="189" width="538" height="16" font="5">random numbers associated with the components of a state. When a new</text>
<text top="951" left="189" width="538" height="16" font="5">state is generated, the hash value of the new state can be computed incre-</text>
<text top="971" left="189" width="538" height="16" font="5">mentally from the hash value of the parent state by incrementally XOR’ing</text>
<text top="991" left="189" width="538" height="16" font="5">the state components that diﬀer. The Zobrist function was previously used</text>
<text top="1036" left="449" width="16" height="16" font="5">13</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">in MacroFF, a sequential planner by Botea et al. <a href="pdfxml.html#47">[43]</a>. It is possible for</text>
<text top="219" left="189" width="538" height="16" font="5">two diﬀerent states to have the same hash key, although the probability</text>
<text top="240" left="189" width="538" height="16" font="5">of such a collision is extremely low with 64-bit keys. In MacroFF, as well</text>
<text top="260" left="189" width="538" height="16" font="5">as an earlier version of this work on HDA* <a href="pdfxml.html#44">[15]</a>, duplicate checking in the</text>
<text top="280" left="189" width="538" height="16" font="5">open/list was performed by checking if the hash key of a state was present</text>
<text top="300" left="189" width="538" height="16" font="5">in the open/closed list, so there was a non-zero (albeit tiny) probability of</text>
<text top="321" left="189" width="538" height="16" font="5">a false positive duplicate check result. In this paper, our HDA* implemen-</text>
<text top="341" left="189" width="538" height="16" font="5">tations perform duplicate checks by comparing the actual states. Although</text>
<text top="361" left="189" width="538" height="16" font="5">this is slightly slower than comparing only the hash key, duplicate checks</text>
<text top="382" left="189" width="207" height="16" font="5">are guaranteed to be correct.</text>
<text top="429" left="189" width="12" height="20" font="4">4</text>
<text top="429" left="225" width="212" height="20" font="4">Scalability of HDA*</text>
<text top="470" left="189" width="538" height="16" font="5">We experimentally evaluated HDA* for domain-independent planning. In</text>
<text top="490" left="189" width="543" height="16" font="5">addition, we also evaluated HDA* on an application-speciﬁc, 24-puzzle solver.</text>
<text top="510" left="189" width="538" height="16" font="5">The hardware environments vary from a single, multi-core machine to com-</text>
<text top="531" left="189" width="538" height="16" font="5">modity clusters and high-performance clusters (HPC clusters) with up to</text>
<text top="551" left="189" width="520" height="16" font="5">1024 processors. In this section, we empirically investigate the following:</text>
<text top="589" left="213" width="513" height="16" font="5">• We investigate the impact of synchronization by comparing HDA* and</text>
<text top="610" left="230" width="465" height="16" font="5">PRA* for planning on a single, multi-core machine (Section <a href="pdfxml.html#15">4.1)</a>.</text>
<text top="643" left="213" width="513" height="16" font="5">• We investigate the scalability of HDA* on a HPC cluster (using 1-1024</text>
<text top="664" left="230" width="497" height="16" font="5">CPU cores) on both planning (Section <a href="pdfxml.html#17">4.2) </a>and the 24-puzzle (Section</text>
<text top="684" left="230" width="32" height="16" font="5"><a href="pdfxml.html#25">4.3)</a>.</text>
<text top="718" left="213" width="513" height="16" font="5">• We investigate the impacts of aggregate amount of RAM available and</text>
<text top="738" left="230" width="497" height="16" font="5">communication delay of HDA* in planning on a HPC cluster (Sections</text>
<text top="758" left="230" width="115" height="16" font="5"><a href="pdfxml.html#22">4.2.1 </a>and <a href="pdfxml.html#23">4.2.2)</a>.</text>
<text top="792" left="213" width="513" height="16" font="5">• We investigate the scalability of HDA* on a commodity cluster (using</text>
<text top="813" left="230" width="264" height="16" font="5">1-64 cores) in planning (Section <a href="pdfxml.html#28">4.4)</a>.</text>
<text top="847" left="213" width="513" height="16" font="5">• We investigate the eﬀect of varying the number of states packed into</text>
<text top="867" left="230" width="208" height="16" font="5">each message (Section <a href="pdfxml.html#29">4.4.1)</a>.</text>
<text top="905" left="214" width="513" height="16" font="5">In all of our experiments, HDA* is implemented in C++, compiled with</text>
<text top="925" left="189" width="437" height="16" font="5">g++ and parallelized using the MPI message passing library.</text>
<text top="946" left="214" width="513" height="16" font="5">We ﬁrst describe experimental results for domain-independent planning.</text>
<text top="966" left="189" width="538" height="16" font="5">We parallelized the sequential optimal version of the Fast Downward plan-</text>
<text top="986" left="189" width="538" height="16" font="5">ner, enhanced with the so-called LFPA heuristic, which is based on explicit</text>
<text top="1036" left="449" width="16" height="16" font="5">14</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">(merge-and-shrink) state abstraction <a href="pdfxml.html#43">[3]</a>. All the reported results are ob-</text>
<text top="219" left="189" width="538" height="16" font="5">tained with the abstraction size set to 1,000. As reported in a previous</text>
<text top="240" left="189" width="538" height="16" font="5">conference version of this work <a href="pdfxml.html#44">[15]</a>, preliminary experiments with the ab-</text>
<text top="260" left="189" width="538" height="16" font="5">straction size set to 5,000 did not change the results qualitatively. As bench-</text>
<text top="280" left="189" width="538" height="16" font="5">mark problems, we use classical planning instances from the past planning</text>
<text top="300" left="189" width="538" height="16" font="5">competitions. Among the planning instances of these three competitions,</text>
<text top="321" left="189" width="538" height="16" font="5">we select instances that are hard or unsolvable for the sequential optimal</text>
<text top="341" left="189" width="190" height="16" font="5">version of Fast Downward.</text>
<text top="361" left="214" width="513" height="16" font="5">HDA*, like other asynchronous parallel search algorithms, behaves non-</text>
<text top="382" left="189" width="538" height="16" font="5">deterministically, resulting in some diﬀerences in search behavior between</text>
<text top="402" left="189" width="538" height="16" font="5">identical invocations of the algorithms. However, on the runs where we</text>
<text top="422" left="189" width="538" height="16" font="5">collected multiple data points, we did not observe signiﬁcant diﬀerences be-</text>
<text top="443" left="189" width="538" height="16" font="5">tween runs of HDA*. Therefore, due to the enormous resource requirements</text>
<text top="463" left="189" width="249" height="16" font="5">of a large-scale experimental stud<a href="pdfxml.html#15">y</a></text>
<text top="460" left="438" width="6" height="12" font="6"><a href="pdfxml.html#15">6</a></text>
<text top="463" left="445" width="274" height="16" font="5"><a href="pdfxml.html#15">, </a>the results shown are for single runs.</text>
<text top="506" left="189" width="26" height="17" font="2">4.1</text>
<text top="506" left="235" width="492" height="17" font="2">Asynchronous vs Synchronous Communications: Exper-</text>
<text top="527" left="235" width="354" height="17" font="2">iments on a Single, Multi-Core Machine</text>
<text top="559" left="189" width="538" height="16" font="5">First, we investigate the impact of asynchronous vs synchronous commu-</text>
<text top="579" left="189" width="538" height="16" font="5">nications in parallel A*. We compare HDA* with sequential A* and a</text>
<text top="599" left="189" width="538" height="16" font="5">shared-memory implementation of Parallel Retracting A* (PRA*) <a href="pdfxml.html#43">[5] </a>on</text>
<text top="620" left="189" width="538" height="16" font="5">a single, multi-core machine. As described in Section <a href="pdfxml.html#4">2, </a>PRA* uses the</text>
<text top="640" left="189" width="538" height="16" font="5">same hash-based work distribution strategy as HDA*, but uses synchronous</text>
<text top="660" left="189" width="330" height="16" font="5">communications due to the retraction scheme.</text>
<text top="681" left="214" width="513" height="16" font="5">Our HDA* implementation is the same MPI-based implementation used</text>
<text top="701" left="189" width="538" height="16" font="5">in our larger-scale, distributed memory experiments described below. MPI</text>
<text top="721" left="189" width="538" height="16" font="5">executes a separate OS process for each thread of execution, and we rely</text>
<text top="742" left="189" width="538" height="16" font="5">on the message passing functions in MPI for asynchronous communications.</text>
<text top="762" left="189" width="538" height="16" font="5">While it may be possible to develop a more eﬃcient implementation of HDA*</text>
<text top="782" left="189" width="538" height="16" font="5">speciﬁcally targeting shared memory machines (e.g., using kernel threads</text>
<text top="803" left="189" width="538" height="16" font="5">and shared memory constructs), we wanted to investigate the scalability of</text>
<text top="823" left="189" width="538" height="16" font="5">the same HDA* implementation on both shared memory and distributed</text>
<text top="843" left="189" width="133" height="16" font="5">memory machines.</text>
<text top="864" left="214" width="513" height="16" font="5">Because memory allocation and deallocation are often crucial for perfor-</text>
<text top="884" left="189" width="538" height="16" font="5">mance (especially for multithreaded programming), all implementations of</text>
<text top="904" left="189" width="370" height="16" font="5">the algorithms evaluated in this paper use TCMallo<a href="pdfxml.html#15">c</a></text>
<text top="901" left="559" width="6" height="12" font="6"><a href="pdfxml.html#15">7</a></text>
<text top="904" left="566" width="160" height="16" font="5">, a fast and thread-safe</text>
<text top="934" left="207" width="5" height="7" font="7">6</text>
<text top="936" left="214" width="513" height="13" font="8">We are using a shared cluster for our experiments, and large-scale experiments have</text>
<text top="952" left="189" width="538" height="13" font="8">issues of resource contention because we are competing for these resources with hundreds</text>
<text top="969" left="189" width="353" height="13" font="8">of other users. In addition, there is a cluster usage charge.</text>
<text top="983" left="207" width="5" height="7" font="7"><a href="http://code.google.com/p/google-perftools/">7</a></text>
<text top="986" left="214" width="296" height="12" font="8"><a href="http://code.google.com/p/google-perftools/">http://code.google.com/p/google-perftools/</a></text>
<text top="1036" left="449" width="16" height="16" font="5">15</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1188" width="918">
<text top="198" left="309" width="33" height="12" font="6">1 core</text>
<text top="198" left="423" width="38" height="12" font="6">4 cores</text>
<text top="198" left="602" width="38" height="12" font="6">8 cores</text>
<text top="213" left="327" width="16" height="12" font="6">A*</text>
<text top="215" left="384" width="30" height="7" font="7">HDA*</text>
<text top="215" left="472" width="29" height="7" font="7">PRA*</text>
<text top="215" left="563" width="30" height="7" font="7">HDA*</text>
<text top="215" left="651" width="29" height="7" font="7">PRA*</text>
<text top="213" left="723" width="27" height="12" font="6">Abst</text>
<text top="213" left="768" width="22" height="12" font="6">Opt</text>
<text top="227" left="318" width="25" height="12" font="6">time</text>
<text top="227" left="370" width="19" height="12" font="6">spd</text>
<text top="227" left="420" width="13" height="12" font="6">eﬀ</text>
<text top="227" left="458" width="19" height="12" font="6">spd</text>
<text top="227" left="508" width="13" height="12" font="6">eﬀ</text>
<text top="227" left="549" width="19" height="12" font="6">spd</text>
<text top="227" left="599" width="13" height="12" font="6">eﬀ</text>
<text top="227" left="637" width="19" height="12" font="6">spd</text>
<text top="227" left="687" width="13" height="12" font="6">eﬀ</text>
<text top="227" left="725" width="25" height="12" font="6">time</text>
<text top="227" left="774" width="16" height="12" font="6">len</text>
<text top="242" left="228" width="52" height="12" font="6">Average</text>
<text top="242" left="302" width="41" height="12" font="6">971.72</text>
<text top="242" left="363" width="26" height="12" font="6">2.71</text>
<text top="242" left="407" width="26" height="12" font="6">0.68</text>
<text top="242" left="451" width="26" height="12" font="6">2.56</text>
<text top="242" left="495" width="26" height="12" font="6">0.64</text>
<text top="242" left="542" width="26" height="12" font="6">4.98</text>
<text top="242" left="586" width="26" height="12" font="6">0.62</text>
<text top="242" left="630" width="26" height="12" font="6">4.45</text>
<text top="242" left="674" width="26" height="12" font="6">0.56</text>
<text top="242" left="724" width="26" height="12" font="6">2.76</text>
<text top="256" left="233" width="46" height="12" font="6">Depot10</text>
<text top="256" left="313" width="29" height="12" font="6">99.82</text>
<text top="256" left="367" width="23" height="12" font="6">2.51</text>
<text top="256" left="411" width="23" height="12" font="6">0.63</text>
<text top="256" left="455" width="23" height="12" font="6">2.45</text>
<text top="256" left="499" width="23" height="12" font="6">0.61</text>
<text top="256" left="546" width="23" height="12" font="6">4.61</text>
<text top="256" left="590" width="23" height="12" font="6">0.58</text>
<text top="256" left="634" width="23" height="12" font="6">4.11</text>
<text top="256" left="678" width="23" height="12" font="6">0.51</text>
<text top="256" left="727" width="23" height="12" font="6">1.96</text>
<text top="256" left="777" width="13" height="12" font="6">24</text>
<text top="271" left="233" width="46" height="12" font="6">Depot13</text>
<text top="271" left="301" width="41" height="12" font="6">1561.83</text>
<text top="271" left="367" width="23" height="12" font="6">2.66</text>
<text top="271" left="411" width="23" height="12" font="6">0.67</text>
<text top="271" left="455" width="23" height="12" font="6">2.57</text>
<text top="271" left="499" width="23" height="12" font="6">0.64</text>
<text top="271" left="546" width="23" height="12" font="6">4.78</text>
<text top="271" left="590" width="23" height="12" font="6">0.60</text>
<text top="271" left="634" width="23" height="12" font="6">4.44</text>
<text top="271" left="678" width="23" height="12" font="6">0.56</text>
<text top="271" left="727" width="23" height="12" font="6">4.16</text>
<text top="271" left="777" width="13" height="12" font="6">25</text>
<text top="286" left="222" width="58" height="12" font="6">Driverlog8</text>
<text top="286" left="307" width="35" height="12" font="6">102.55</text>
<text top="286" left="367" width="23" height="12" font="6">2.59</text>
<text top="286" left="411" width="23" height="12" font="6">0.65</text>
<text top="286" left="455" width="23" height="12" font="6">2.14</text>
<text top="286" left="499" width="23" height="12" font="6">0.54</text>
<text top="286" left="546" width="23" height="12" font="6">4.90</text>
<text top="286" left="590" width="23" height="12" font="6">0.61</text>
<text top="286" left="634" width="23" height="12" font="6">3.87</text>
<text top="286" left="678" width="23" height="12" font="6">0.48</text>
<text top="286" left="727" width="23" height="12" font="6">0.14</text>
<text top="286" left="777" width="13" height="12" font="6">22</text>
<text top="301" left="232" width="48" height="12" font="6">Freecell5</text>
<text top="301" left="307" width="35" height="12" font="6">137.01</text>
<text top="301" left="367" width="23" height="12" font="6">2.99</text>
<text top="301" left="411" width="23" height="12" font="6">0.75</text>
<text top="301" left="455" width="23" height="12" font="6">2.99</text>
<text top="301" left="499" width="23" height="12" font="6">0.75</text>
<text top="301" left="546" width="23" height="12" font="6">5.87</text>
<text top="301" left="590" width="23" height="12" font="6">0.73</text>
<text top="301" left="634" width="23" height="12" font="6">5.83</text>
<text top="301" left="678" width="23" height="12" font="6">0.73</text>
<text top="301" left="727" width="23" height="12" font="6">7.75</text>
<text top="301" left="777" width="13" height="12" font="6">30</text>
<text top="316" left="232" width="48" height="12" font="6">Freecell7</text>
<text top="316" left="301" width="41" height="12" font="6">2261.67</text>
<text top="316" left="367" width="23" height="12" font="6">3.12</text>
<text top="316" left="411" width="23" height="12" font="6">0.78</text>
<text top="316" left="455" width="23" height="12" font="6">3.06</text>
<text top="316" left="499" width="23" height="12" font="6">0.77</text>
<text top="316" left="546" width="23" height="12" font="6">5.88</text>
<text top="316" left="590" width="23" height="12" font="6">0.74</text>
<text top="316" left="634" width="23" height="12" font="6">5.85</text>
<text top="316" left="678" width="23" height="12" font="6">0.73</text>
<text top="316" left="727" width="23" height="12" font="6">9.60</text>
<text top="316" left="777" width="13" height="12" font="6">41</text>
<text top="330" left="235" width="45" height="12" font="6">Rover12</text>
<text top="330" left="307" width="35" height="12" font="6">923.23</text>
<text top="330" left="367" width="23" height="12" font="6">2.73</text>
<text top="330" left="411" width="23" height="12" font="6">0.68</text>
<text top="330" left="455" width="23" height="12" font="6">2.46</text>
<text top="330" left="499" width="23" height="12" font="6">0.61</text>
<text top="330" left="546" width="23" height="12" font="6">5.03</text>
<text top="330" left="590" width="23" height="12" font="6">0.63</text>
<text top="330" left="634" width="23" height="12" font="6">4.43</text>
<text top="330" left="678" width="23" height="12" font="6">0.55</text>
<text top="330" left="727" width="23" height="12" font="6">0.10</text>
<text top="330" left="777" width="13" height="12" font="6">19</text>
<text top="345" left="228" width="51" height="12" font="6">Satellite6</text>
<text top="345" left="307" width="35" height="12" font="6">104.83</text>
<text top="345" left="367" width="23" height="12" font="6">2.25</text>
<text top="345" left="411" width="23" height="12" font="6">0.56</text>
<text top="345" left="455" width="23" height="12" font="6">2.06</text>
<text top="345" left="499" width="23" height="12" font="6">0.51</text>
<text top="345" left="546" width="23" height="12" font="6">4.30</text>
<text top="345" left="590" width="23" height="12" font="6">0.54</text>
<text top="345" left="634" width="23" height="12" font="6">3.61</text>
<text top="345" left="678" width="23" height="12" font="6">0.45</text>
<text top="345" left="727" width="23" height="12" font="6">0.09</text>
<text top="345" left="777" width="13" height="12" font="6">20</text>
<text top="360" left="221" width="59" height="12" font="6">ZenoTrav9</text>
<text top="360" left="307" width="35" height="12" font="6">157.98</text>
<text top="360" left="367" width="23" height="12" font="6">2.57</text>
<text top="360" left="411" width="23" height="12" font="6">0.64</text>
<text top="360" left="455" width="23" height="12" font="6">2.29</text>
<text top="360" left="499" width="23" height="12" font="6">0.57</text>
<text top="360" left="546" width="23" height="12" font="6">4.61</text>
<text top="360" left="590" width="23" height="12" font="6">0.58</text>
<text top="360" left="634" width="23" height="12" font="6">3.66</text>
<text top="360" left="678" width="23" height="12" font="6">0.46</text>
<text top="360" left="727" width="23" height="12" font="6">0.19</text>
<text top="360" left="777" width="13" height="12" font="6">21</text>
<text top="375" left="215" width="65" height="12" font="6">ZenoTrav11</text>
<text top="375" left="307" width="35" height="12" font="6">424.68</text>
<text top="375" left="367" width="23" height="12" font="6">2.42</text>
<text top="375" left="411" width="23" height="12" font="6">0.60</text>
<text top="375" left="455" width="23" height="12" font="6">2.10</text>
<text top="375" left="499" width="23" height="12" font="6">0.52</text>
<text top="375" left="546" width="23" height="12" font="6">4.40</text>
<text top="375" left="590" width="23" height="12" font="6">0.55</text>
<text top="375" left="634" width="23" height="12" font="6">3.60</text>
<text top="375" left="678" width="23" height="12" font="6">0.45</text>
<text top="375" left="727" width="23" height="12" font="6">0.22</text>
<text top="375" left="777" width="13" height="12" font="6">14</text>
<text top="390" left="205" width="75" height="12" font="6">PipesNoTk14</text>
<text top="390" left="307" width="35" height="12" font="6">248.77</text>
<text top="390" left="367" width="23" height="12" font="6">3.91</text>
<text top="390" left="411" width="23" height="12" font="6">0.98</text>
<text top="390" left="455" width="23" height="12" font="6">3.65</text>
<text top="390" left="499" width="23" height="12" font="6">0.91</text>
<text top="390" left="546" width="23" height="12" font="6">5.50</text>
<text top="390" left="590" width="23" height="12" font="6">0.69</text>
<text top="390" left="634" width="23" height="12" font="6">4.74</text>
<text top="390" left="678" width="23" height="12" font="6">0.59</text>
<text top="390" left="727" width="23" height="12" font="6">1.68</text>
<text top="390" left="777" width="13" height="12" font="6">30</text>
<text top="404" left="205" width="75" height="12" font="6">PipesNoTk24</text>
<text top="404" left="301" width="41" height="12" font="6">1046.94</text>
<text top="404" left="367" width="23" height="12" font="6">2.97</text>
<text top="404" left="411" width="23" height="12" font="6">0.74</text>
<text top="404" left="455" width="23" height="12" font="6">2.72</text>
<text top="404" left="499" width="23" height="12" font="6">0.68</text>
<text top="404" left="546" width="23" height="12" font="6">5.37</text>
<text top="404" left="590" width="23" height="12" font="6">0.67</text>
<text top="404" left="634" width="23" height="12" font="6">4.82</text>
<text top="404" left="678" width="23" height="12" font="6">0.60</text>
<text top="404" left="727" width="23" height="12" font="6">5.99</text>
<text top="404" left="777" width="13" height="12" font="6">24</text>
<text top="419" left="232" width="48" height="12" font="6">Pegsol27</text>
<text top="419" left="307" width="35" height="12" font="6">178.71</text>
<text top="419" left="367" width="23" height="12" font="6">2.97</text>
<text top="419" left="411" width="23" height="12" font="6">0.74</text>
<text top="419" left="455" width="23" height="12" font="6">2.89</text>
<text top="419" left="499" width="23" height="12" font="6">0.72</text>
<text top="419" left="546" width="23" height="12" font="6">5.87</text>
<text top="419" left="590" width="23" height="12" font="6">0.73</text>
<text top="419" left="634" width="23" height="12" font="6">5.09</text>
<text top="419" left="678" width="23" height="12" font="6">0.64</text>
<text top="419" left="727" width="23" height="12" font="6">1.11</text>
<text top="419" left="777" width="13" height="12" font="6">28</text>
<text top="434" left="232" width="48" height="12" font="6">Pegsol28</text>
<text top="434" left="307" width="35" height="12" font="6">773.36</text>
<text top="434" left="367" width="23" height="12" font="6">2.98</text>
<text top="434" left="411" width="23" height="12" font="6">0.75</text>
<text top="434" left="455" width="23" height="12" font="6">2.94</text>
<text top="434" left="499" width="23" height="12" font="6">0.73</text>
<text top="434" left="546" width="23" height="12" font="6">5.87</text>
<text top="434" left="590" width="23" height="12" font="6">0.73</text>
<text top="434" left="634" width="23" height="12" font="6">4.92</text>
<text top="434" left="678" width="23" height="12" font="6">0.61</text>
<text top="434" left="727" width="23" height="12" font="6">0.65</text>
<text top="434" left="777" width="13" height="12" font="6">35</text>
<text top="449" left="226" width="54" height="12" font="6">Airport17</text>
<text top="449" left="307" width="35" height="12" font="6">322.21</text>
<text top="449" left="367" width="23" height="12" font="6">3.54</text>
<text top="449" left="411" width="23" height="12" font="6">0.89</text>
<text top="449" left="455" width="23" height="12" font="6">3.52</text>
<text top="449" left="499" width="23" height="12" font="6">0.88</text>
<text top="449" left="546" width="23" height="12" font="6">6.62</text>
<text top="449" left="590" width="23" height="12" font="6">0.83</text>
<text top="449" left="634" width="23" height="12" font="6">6.77</text>
<text top="449" left="678" width="23" height="12" font="6">0.85</text>
<text top="449" left="721" width="29" height="12" font="6">13.09</text>
<text top="449" left="777" width="13" height="12" font="6">88</text>
<text top="463" left="230" width="50" height="12" font="6">Gripper8</text>
<text top="463" left="307" width="35" height="12" font="6">304.82</text>
<text top="463" left="367" width="23" height="12" font="6">2.57</text>
<text top="463" left="411" width="23" height="12" font="6">0.64</text>
<text top="463" left="455" width="23" height="12" font="6">2.29</text>
<text top="463" left="499" width="23" height="12" font="6">0.57</text>
<text top="463" left="546" width="23" height="12" font="6">4.41</text>
<text top="463" left="590" width="23" height="12" font="6">0.55</text>
<text top="463" left="634" width="23" height="12" font="6">3.63</text>
<text top="463" left="678" width="23" height="12" font="6">0.45</text>
<text top="463" left="727" width="23" height="12" font="6">0.28</text>
<text top="463" left="777" width="13" height="12" font="6">53</text>
<text top="478" left="230" width="50" height="12" font="6">Gripper9</text>
<text top="478" left="301" width="41" height="12" font="6">1710.39</text>
<text top="478" left="367" width="23" height="12" font="6">2.63</text>
<text top="478" left="411" width="23" height="12" font="6">0.66</text>
<text top="478" left="455" width="23" height="12" font="6">2.31</text>
<text top="478" left="499" width="23" height="12" font="6">0.58</text>
<text top="478" left="546" width="23" height="12" font="6">4.51</text>
<text top="478" left="590" width="23" height="12" font="6">0.56</text>
<text top="478" left="634" width="23" height="12" font="6">4.05</text>
<text top="478" left="678" width="23" height="12" font="6">0.51</text>
<text top="478" left="727" width="23" height="12" font="6">0.36</text>
<text top="478" left="777" width="13" height="12" font="6">59</text>
<text top="493" left="228" width="52" height="12" font="6">Mystery6</text>
<text top="493" left="307" width="35" height="12" font="6">315.21</text>
<text top="493" left="367" width="23" height="12" font="6">3.08</text>
<text top="493" left="411" width="23" height="12" font="6">0.77</text>
<text top="493" left="455" width="23" height="12" font="6">3.01</text>
<text top="493" left="499" width="23" height="12" font="6">0.75</text>
<text top="493" left="546" width="23" height="12" font="6">5.64</text>
<text top="493" left="590" width="23" height="12" font="6">0.70</text>
<text top="493" left="634" width="23" height="12" font="6">5.39</text>
<text top="493" left="678" width="23" height="12" font="6">0.67</text>
<text top="493" left="721" width="29" height="12" font="6">17.51</text>
<text top="493" left="777" width="13" height="12" font="6">11</text>
<text top="508" left="241" width="38" height="12" font="6">Truck5</text>
<text top="508" left="307" width="35" height="12" font="6">365.38</text>
<text top="508" left="367" width="23" height="12" font="6">2.17</text>
<text top="508" left="411" width="23" height="12" font="6">0.54</text>
<text top="508" left="455" width="23" height="12" font="6">2.32</text>
<text top="508" left="499" width="23" height="12" font="6">0.58</text>
<text top="508" left="546" width="23" height="12" font="6">4.23</text>
<text top="508" left="590" width="23" height="12" font="6">0.53</text>
<text top="508" left="634" width="23" height="12" font="6">4.00</text>
<text top="508" left="678" width="23" height="12" font="6">0.50</text>
<text top="508" left="727" width="23" height="12" font="6">0.26</text>
<text top="508" left="777" width="13" height="12" font="6">25</text>
<text top="523" left="241" width="38" height="12" font="6">Truck6</text>
<text top="523" left="301" width="41" height="12" font="6">3597.24</text>
<text top="523" left="367" width="23" height="12" font="6">2.41</text>
<text top="523" left="411" width="23" height="12" font="6">0.60</text>
<text top="523" left="455" width="23" height="12" font="6">2.23</text>
<text top="523" left="499" width="23" height="12" font="6">0.56</text>
<text top="523" left="546" width="23" height="12" font="6">4.53</text>
<text top="523" left="590" width="23" height="12" font="6">0.57</text>
<text top="523" left="634" width="23" height="12" font="6">4.11</text>
<text top="523" left="678" width="23" height="12" font="6">0.51</text>
<text top="523" left="727" width="23" height="12" font="6">0.30</text>
<text top="523" left="777" width="13" height="12" font="6">30</text>
<text top="537" left="241" width="38" height="12" font="6">Truck8</text>
<text top="537" left="301" width="41" height="12" font="6">2194.38</text>
<text top="537" left="367" width="23" height="12" font="6">2.39</text>
<text top="537" left="411" width="23" height="12" font="6">0.60</text>
<text top="537" left="455" width="23" height="12" font="6">2.23</text>
<text top="537" left="499" width="23" height="12" font="6">0.56</text>
<text top="537" left="546" width="23" height="12" font="6">4.35</text>
<text top="537" left="590" width="23" height="12" font="6">0.54</text>
<text top="537" left="634" width="23" height="12" font="6">3.82</text>
<text top="537" left="678" width="23" height="12" font="6">0.48</text>
<text top="537" left="727" width="23" height="12" font="6">0.22</text>
<text top="537" left="777" width="13" height="12" font="6">25</text>
<text top="552" left="221" width="59" height="12" font="6">Sokoban19</text>
<text top="552" left="307" width="35" height="12" font="6">157.82</text>
<text top="552" left="367" width="23" height="12" font="6">2.90</text>
<text top="552" left="411" width="23" height="12" font="6">0.72</text>
<text top="552" left="455" width="23" height="12" font="6">2.57</text>
<text top="552" left="499" width="23" height="12" font="6">0.64</text>
<text top="552" left="546" width="23" height="12" font="6">5.61</text>
<text top="552" left="590" width="23" height="12" font="6">0.70</text>
<text top="552" left="634" width="23" height="12" font="6">4.76</text>
<text top="552" left="678" width="23" height="12" font="6">0.60</text>
<text top="552" left="727" width="23" height="12" font="6">1.59</text>
<text top="552" left="771" width="19" height="12" font="6">164</text>
<text top="567" left="221" width="59" height="12" font="6">Sokoban22</text>
<text top="567" left="307" width="35" height="12" font="6">428.91</text>
<text top="567" left="367" width="23" height="12" font="6">3.07</text>
<text top="567" left="411" width="23" height="12" font="6">0.77</text>
<text top="567" left="455" width="23" height="12" font="6">3.03</text>
<text top="567" left="499" width="23" height="12" font="6">0.76</text>
<text top="567" left="546" width="23" height="12" font="6">5.99</text>
<text top="567" left="590" width="23" height="12" font="6">0.75</text>
<text top="567" left="634" width="23" height="12" font="6">5.27</text>
<text top="567" left="678" width="23" height="12" font="6">0.66</text>
<text top="567" left="727" width="23" height="12" font="6">1.53</text>
<text top="567" left="771" width="19" height="12" font="6">172</text>
<text top="582" left="220" width="59" height="12" font="6">Blocks10-2</text>
<text top="582" left="307" width="35" height="12" font="6">327.03</text>
<text top="582" left="367" width="23" height="12" font="6">2.83</text>
<text top="582" left="411" width="23" height="12" font="6">0.71</text>
<text top="582" left="455" width="23" height="12" font="6">2.39</text>
<text top="582" left="499" width="23" height="12" font="6">0.60</text>
<text top="582" left="546" width="23" height="12" font="6">5.51</text>
<text top="582" left="590" width="23" height="12" font="6">0.69</text>
<text top="582" left="634" width="23" height="12" font="6">4.24</text>
<text top="582" left="678" width="23" height="12" font="6">0.53</text>
<text top="582" left="727" width="23" height="12" font="6">1.04</text>
<text top="582" left="777" width="13" height="12" font="6">34</text>
<text top="597" left="198" width="82" height="12" font="6">Logistics00-7-1</text>
<text top="597" left="301" width="41" height="12" font="6">1235.26</text>
<text top="597" left="367" width="23" height="12" font="6">2.40</text>
<text top="597" left="411" width="23" height="12" font="6">0.60</text>
<text top="597" left="455" width="23" height="12" font="6">2.16</text>
<text top="597" left="499" width="23" height="12" font="6">0.54</text>
<text top="597" left="546" width="23" height="12" font="6">4.43</text>
<text top="597" left="590" width="23" height="12" font="6">0.55</text>
<text top="597" left="634" width="23" height="12" font="6">3.75</text>
<text top="597" left="678" width="23" height="12" font="6">0.47</text>
<text top="597" left="727" width="23" height="12" font="6">0.07</text>
<text top="597" left="777" width="13" height="12" font="6">44</text>
<text top="611" left="198" width="82" height="12" font="6">Logistics00-9-1</text>
<text top="611" left="301" width="41" height="12" font="6">2082.76</text>
<text top="611" left="367" width="23" height="12" font="6">2.46</text>
<text top="611" left="411" width="23" height="12" font="6">0.61</text>
<text top="611" left="455" width="23" height="12" font="6">2.45</text>
<text top="611" left="499" width="23" height="12" font="6">0.61</text>
<text top="611" left="546" width="23" height="12" font="6">4.44</text>
<text top="611" left="590" width="23" height="12" font="6">0.55</text>
<text top="611" left="634" width="23" height="12" font="6">4.32</text>
<text top="611" left="678" width="23" height="12" font="6">0.54</text>
<text top="611" left="727" width="23" height="12" font="6">0.13</text>
<text top="611" left="777" width="13" height="12" font="6">30</text>
<text top="626" left="208" width="72" height="12" font="6">Micconic12-2</text>
<text top="626" left="301" width="41" height="12" font="6">2308.03</text>
<text top="626" left="367" width="23" height="12" font="6">2.11</text>
<text top="626" left="411" width="23" height="12" font="6">0.53</text>
<text top="626" left="455" width="23" height="12" font="6">2.19</text>
<text top="626" left="499" width="23" height="12" font="6">0.55</text>
<text top="626" left="546" width="23" height="12" font="6">3.76</text>
<text top="626" left="590" width="23" height="12" font="6">0.47</text>
<text top="626" left="634" width="23" height="12" font="6">3.46</text>
<text top="626" left="678" width="23" height="12" font="6">0.43</text>
<text top="626" left="727" width="23" height="12" font="6">0.08</text>
<text top="626" left="777" width="13" height="12" font="6">40</text>
<text top="641" left="208" width="72" height="12" font="6">Micconic12-4</text>
<text top="641" left="301" width="41" height="12" font="6">2463.13</text>
<text top="641" left="367" width="23" height="12" font="6">2.15</text>
<text top="641" left="411" width="23" height="12" font="6">0.54</text>
<text top="641" left="455" width="23" height="12" font="6">2.18</text>
<text top="641" left="499" width="23" height="12" font="6">0.54</text>
<text top="641" left="546" width="23" height="12" font="6">3.87</text>
<text top="641" left="590" width="23" height="12" font="6">0.48</text>
<text top="641" left="634" width="23" height="12" font="6">3.55</text>
<text top="641" left="678" width="23" height="12" font="6">0.44</text>
<text top="641" left="727" width="23" height="12" font="6">0.08</text>
<text top="641" left="777" width="13" height="12" font="6">41</text>
<text top="656" left="224" width="56" height="12" font="6">Mprime30</text>
<text top="656" left="301" width="41" height="12" font="6">1374.27</text>
<text top="656" left="367" width="23" height="12" font="6">2.52</text>
<text top="656" left="411" width="23" height="12" font="6">0.63</text>
<text top="656" left="455" width="23" height="12" font="6">2.49</text>
<text top="656" left="499" width="23" height="12" font="6">0.62</text>
<text top="656" left="546" width="23" height="12" font="6">4.58</text>
<text top="656" left="590" width="23" height="12" font="6">0.57</text>
<text top="656" left="634" width="23" height="12" font="6">4.64</text>
<text top="656" left="678" width="23" height="12" font="6">0.58</text>
<text top="656" left="727" width="23" height="12" font="6">7.18</text>
<text top="656" left="783" width="6" height="12" font="6">9</text>
<text top="685" left="189" width="59" height="16" font="5">Table 1:</text>
<text top="686" left="267" width="460" height="15" font="3">Comparison of sequential A*, HDA* and PRA* on 1, 4, and 8 cores</text>
<text top="706" left="189" width="538" height="15" font="3">on a 2.33GHZ dual quad-core Xeon L5410 machine with 6 × 2 MB L2 cache and</text>
<text top="727" left="189" width="538" height="15" font="3">32GB memory. Runtimes (in seconds), speedup (spd), eﬃciency (eﬀ), abstraction</text>
<text top="747" left="189" width="538" height="15" font="3">heuristic initialization times (not included in runtimes in previous columns), and</text>
<text top="767" left="189" width="203" height="15" font="3">optimal plan length are shown.</text>
<text top="834" left="189" width="212" height="16" font="5">memory management library<a href="pdfxml.html#16">.</a></text>
<text top="831" left="401" width="6" height="12" font="6"><a href="pdfxml.html#16">8</a></text>
<text top="834" left="418" width="308" height="16" font="5">In addition to locks available in the Boost</text>
<text top="854" left="189" width="466" height="16" font="5">C++ library, we also incorporated spin locks used in GPSshog<a href="pdfxml.html#16">i</a></text>
<text top="851" left="655" width="6" height="12" font="6"><a href="pdfxml.html#16">9</a></text>
<text top="854" left="669" width="58" height="16" font="5">in order</text>
<text top="874" left="189" width="538" height="16" font="5">to speed up PRA*. The spin lock implementation is based on the “xchgl”</text>
<text top="895" left="189" width="142" height="16" font="5">assembly operation.</text>
<text top="915" left="214" width="512" height="16" font="5">These experiments were run on a dual quad-core 2.33GHz Xeon L5410</text>
<text top="944" left="207" width="5" height="7" font="7">8</text>
<text top="947" left="214" width="513" height="13" font="8">Using TCMalloc also resulted in a slight speedup of our baseline sequential A* com-</text>
<text top="963" left="189" width="268" height="13" font="8">pared to the version obtained from Helmert.</text>
<text top="977" left="207" width="5" height="7" font="7"><a href="http://gps.tanaka.ecc.u-tokyo.ac.jp/gpsshogi/pukiwiki.php?GPSshogi">9</a></text>
<text top="980" left="214" width="466" height="12" font="8"><a href="http://gps.tanaka.ecc.u-tokyo.ac.jp/gpsshogi/pukiwiki.php?GPSshogi">http://gps.tanaka.ecc.u-tokyo.ac.jp/gpsshogi/pukiwiki.php?GPSshogi</a></text>
<text top="1036" left="449" width="16" height="16" font="5">16</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">with 6 MB L2 cache (total of 8 cores) and 32 gigabytes of RAM. Each</text>
<text top="219" left="189" width="538" height="16" font="5">algorithm used the full 32 gigabytes of RAM. That is, n-core HDA* spawns</text>
<text top="240" left="189" width="538" height="16" font="5">n processes, each using 32/n gigabytes of RAM, sequential A* used the full</text>
<text top="260" left="189" width="538" height="16" font="5">32GB available, and the multithreaded PRA* algorithm shared 32GB of</text>
<text top="280" left="189" width="224" height="16" font="5">RAM among all of the threads.</text>
<text top="300" left="214" width="512" height="16" font="5">Table <a href="pdfxml.html#16">1 </a>shows the speedup of HDA* and PRA* for 4 cores and 8 cores.</text>
<text top="321" left="189" width="538" height="16" font="5">Among all planning instances selected for our experiments as outlined ear-</text>
<text top="341" left="189" width="538" height="16" font="5">lier, in this table we show only instances that can be solved by the serial</text>
<text top="361" left="189" width="538" height="16" font="5">planner with 32GB RAM available. In addition to runtimes for the se-</text>
<text top="382" left="189" width="538" height="16" font="5">quential A* algorithm, the speedup and the parallel eﬃciency are shown</text>
<text top="402" left="189" width="538" height="16" font="5">for HDA* and PRA*, where eﬃciency is deﬁned as S/P , where S is the</text>
<text top="422" left="189" width="538" height="16" font="5">speedup over a serial run and P is the number of cores. As shown in Table</text>
<text top="443" left="189" width="538" height="16" font="5"><a href="pdfxml.html#16">1, </a>HDA* outperforms PRA*. With 4 cores, the speedup of HDA* ranges</text>
<text top="463" left="189" width="538" height="16" font="5">from 2.11 to 3.91, and the eﬃciency ranges from 0.53 to 0.98. With 8 cores,</text>
<text top="483" left="189" width="538" height="16" font="5">the speedup of HDA* ranges from 3.76 to 6.62, and the eﬃciency ranges</text>
<text top="504" left="189" width="127" height="16" font="5">from 0.47 to 0.83.</text>
<text top="546" left="189" width="26" height="17" font="2">4.2</text>
<text top="546" left="235" width="363" height="17" font="2">Planning Experiments on a HPC Cluster</text>
<text top="578" left="189" width="538" height="16" font="5">Next, we investigate the scaling behavior of HDA* on clusters of machines.</text>
<text top="599" left="189" width="538" height="16" font="5">These parallel experiments were performed on a Sun Fire X4600 cluster</text>
<text top="619" left="189" width="538" height="16" font="5">connected by a 20Gb Inﬁniband network, where each node has 8 AMD dual</text>
<text top="639" left="189" width="538" height="16" font="5">core Opteron processors (total 16 cores per node) and 32 GB RAM per node,</text>
<text top="660" left="189" width="538" height="16" font="5">with a clock speed of 2.4GHz. We used 1-64 nodes in our experiments (i.e.,</text>
<text top="680" left="189" width="106" height="16" font="5">16-1024 cores).</text>
<text top="700" left="214" width="513" height="16" font="5">Figure <a href="pdfxml.html#18">1 </a>shows the scaling behavior for domain-independent planning.</text>
<text top="721" left="189" width="538" height="16" font="5">We show the number of processors on the x-axis and relative runtime on the</text>
<text top="741" left="189" width="538" height="16" font="5">y-axis. The relative runtime of HDA* on an instance for n cores is deﬁned</text>
<text top="761" left="189" width="27" height="16" font="5">as t</text>
<text top="768" left="216" width="8" height="8" font="6">n</text>
<text top="761" left="224" width="14" height="16" font="5">/t</text>
<text top="768" left="238" width="23" height="8" font="6">min</text>
<text top="761" left="262" width="66" height="16" font="5">, where t</text>
<text top="768" left="328" width="8" height="8" font="6">n</text>
<text top="761" left="343" width="250" height="16" font="5">is the runtime with n cores, and t</text>
<text top="768" left="593" width="23" height="8" font="6">min</text>
<text top="761" left="624" width="103" height="16" font="5">is the runtime</text>
<text top="782" left="189" width="240" height="16" font="5">for the minimal number of cores c</text>
<text top="789" left="429" width="23" height="8" font="6">min</text>
<text top="782" left="458" width="269" height="16" font="5">∈ {1, 16, 64, 128, 256, 512, 1024} which</text>
<text top="802" left="189" width="467" height="16" font="5">was required to solve the problem. Thus, the relative runtime for c</text>
<text top="809" left="655" width="23" height="8" font="6">min</text>
<text top="802" left="684" width="43" height="16" font="5">= 1.0.</text>
<text top="822" left="189" width="162" height="16" font="5">For fewer cores than c</text>
<text top="829" left="350" width="23" height="8" font="6">min</text>
<text top="822" left="374" width="353" height="16" font="5">, the relative time is undeﬁned because, in those</text>
<text top="843" left="189" width="264" height="16" font="5">cases, HDA* terminates with failure.</text>
<text top="863" left="214" width="512" height="16" font="5">Table <a href="pdfxml.html#19">2 </a>shows the runtimes, speedup, and eﬃciency of HDA* on 16-1024</text>
<text top="883" left="189" width="538" height="16" font="5">cores, relative to sequential A*. The same runtime data as in Figure <a href="pdfxml.html#18">1 </a>is</text>
<text top="904" left="189" width="538" height="16" font="5">shown here. There was 2GB RAM per process, i.e., 32GB-2TB aggregate</text>
<text top="924" left="189" width="538" height="16" font="5">RAM for 16-1024 cores, respectively. Since there are 16 cores and 32GB</text>
<text top="944" left="189" width="538" height="16" font="5">memory per processing node in our cluster, this experiment uses all of the</text>
<text top="965" left="189" width="416" height="16" font="5">cores on each node, as well as all of the available memory.</text>
<text top="985" left="214" width="513" height="16" font="5">The sequential A* was run on a special machine with a very large amount</text>
<text top="1036" left="449" width="16" height="16" font="5">17</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1188" width="918">
<text top="708" left="189" width="538" height="16" font="5">Figure 1: HDA* planning scalability results: Relative runtime as number</text>
<text top="729" left="189" width="538" height="16" font="5">of processors increases. 1.0 is the relative runtime for the fewest number of</text>
<text top="749" left="189" width="48" height="16" font="5">cores c</text>
<text top="756" left="237" width="23" height="8" font="6">min</text>
<text top="749" left="266" width="460" height="16" font="5">∈ {1, 16, 64, 128, 256, 512, 1024} which solved the problem. Data</text>
<text top="769" left="189" width="538" height="16" font="5">with one core in use correspond to A*. Experiments were performed on a</text>
<text top="789" left="189" width="538" height="16" font="5">HPC cluster connected by a 20Gb Inﬁniband network, where each node has</text>
<text top="810" left="189" width="538" height="16" font="5">eight 2.4GHz AMD dual core Opteron processors (total 16 cores per node)</text>
<text top="830" left="189" width="127" height="16" font="5">and 32 GB RAM.</text>
<text top="894" left="189" width="538" height="16" font="5">of RAM (128GB). As the CPU for this machine is a 2.6GHz Opteron, we</text>
<text top="915" left="189" width="538" height="16" font="5">scaled the results for sequential A* by a factor of 2.6/2.4 in Table <a href="pdfxml.html#19">2 </a>and</text>
<text top="935" left="189" width="538" height="16" font="5">Figure <a href="pdfxml.html#18">1, </a>so that the sequential results could be compared with the parallel</text>
<text top="955" left="189" width="538" height="16" font="5">results which were run on 2.4GHz Opteron CPUs. We veriﬁed the cor-</text>
<text top="976" left="189" width="538" height="16" font="5">rectness of this scaling factor by using sequential search runtimes on easier</text>
<text top="1036" left="449" width="16" height="16" font="5">18</text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1188" width="918">
<text top="198" left="274" width="33" height="12" font="6">1 core</text>
<text top="198" left="339" width="44" height="12" font="6">16 cores</text>
<text top="198" left="417" width="44" height="12" font="6">64 cores</text>
<text top="198" left="491" width="51" height="12" font="6">128 cores</text>
<text top="198" left="571" width="51" height="12" font="6">512 cores</text>
<text top="198" left="652" width="57" height="12" font="6">1024 cores</text>
<text top="198" left="728" width="52" height="12" font="6">Abst Opt</text>
<text top="212" left="273" width="34" height="12" font="6">RAM:</text>
<text top="212" left="343" width="37" height="12" font="6">1 node</text>
<text top="212" left="418" width="42" height="12" font="6">4 nodes</text>
<text top="212" left="495" width="42" height="12" font="6">8 nodes</text>
<text top="212" left="572" width="48" height="12" font="6">32 nodes</text>
<text top="212" left="656" width="48" height="12" font="6">64 nodes</text>
<text top="212" left="730" width="50" height="12" font="6">time len</text>
<text top="226" left="271" width="38" height="12" font="6">128GB</text>
<text top="226" left="346" width="31" height="12" font="6">32GB</text>
<text top="226" left="420" width="38" height="12" font="6">128GB</text>
<text top="226" left="497" width="38" height="12" font="6">256GB</text>
<text top="226" left="584" width="24" height="12" font="6">1TB</text>
<text top="226" left="668" width="24" height="12" font="6">2TB</text>
<text top="241" left="189" width="60" height="12" font="6">Avg time</text>
<text top="241" left="266" width="48" height="12" font="6">1025.84</text>
<text top="241" left="345" width="34" height="12" font="6">98.34</text>
<text top="241" left="422" width="34" height="12" font="6">24.09</text>
<text top="241" left="500" width="34" height="12" font="6">13.48</text>
<text top="241" left="584" width="26" height="12" font="6">4.04</text>
<text top="241" left="667" width="26" height="12" font="6">6.76</text>
<text top="241" left="728" width="26" height="12" font="6">2.20</text>
<text top="256" left="189" width="64" height="12" font="6">Driverlog13</text>
<text top="256" left="280" width="20" height="12" font="6">n/a</text>
<text top="256" left="352" width="20" height="12" font="6">n/a</text>
<text top="256" left="429" width="20" height="12" font="6">n/a</text>
<text top="256" left="506" width="20" height="12" font="6">n/a</text>
<text top="256" left="582" width="29" height="12" font="6">41.01</text>
<text top="256" left="666" width="29" height="12" font="6">27.43</text>
<text top="256" left="732" width="23" height="12" font="6">0.63</text>
<text top="256" left="767" width="13" height="12" font="6">26</text>
<text top="270" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="270" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="270" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="270" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="270" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="285" left="189" width="48" height="12" font="6">Freecell6</text>
<text top="285" left="280" width="20" height="12" font="6">n/a</text>
<text top="285" left="352" width="20" height="12" font="6">n/a</text>
<text top="285" left="429" width="20" height="12" font="6">n/a</text>
<text top="285" left="499" width="35" height="12" font="6">137.08</text>
<text top="285" left="582" width="29" height="12" font="6">50.36</text>
<text top="285" left="666" width="29" height="12" font="6">23.39</text>
<text top="285" left="732" width="23" height="12" font="6">8.45</text>
<text top="285" left="767" width="13" height="12" font="6">34</text>
<text top="299" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="299" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="299" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="299" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="299" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="314" left="189" width="48" height="12" font="6">Freecell7</text>
<text top="314" left="269" width="41" height="12" font="6">2864.64</text>
<text top="314" left="352" width="20" height="12" font="6">n/a</text>
<text top="314" left="425" width="29" height="12" font="6">66.85</text>
<text top="314" left="502" width="29" height="12" font="6">34.00</text>
<text top="314" left="582" width="29" height="12" font="6">11.59</text>
<text top="314" left="666" width="29" height="12" font="6">18.92</text>
<text top="314" left="725" width="29" height="12" font="6">10.52</text>
<text top="314" left="767" width="13" height="12" font="6">41</text>
<text top="328" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="328" left="409" width="59" height="12" font="6">42.85, 0.67</text>
<text top="328" left="487" width="59" height="12" font="6">84.25, 0.66</text>
<text top="328" left="564" width="66" height="12" font="6">247.16, 0.48</text>
<text top="328" left="647" width="66" height="12" font="6">151.41, 0.15</text>
<text top="343" left="189" width="45" height="12" font="6">Rover12</text>
<text top="343" left="269" width="41" height="12" font="6">1149.74</text>
<text top="343" left="344" width="35" height="12" font="6">109.62</text>
<text top="343" left="425" width="29" height="12" font="6">17.68</text>
<text top="343" left="502" width="29" height="12" font="6">14.50</text>
<text top="343" left="585" width="23" height="12" font="6">4.06</text>
<text top="343" left="669" width="23" height="12" font="6">3.47</text>
<text top="343" left="732" width="23" height="12" font="6">0.17</text>
<text top="343" left="767" width="13" height="12" font="6">19</text>
<text top="357" left="332" width="59" height="12" font="6">10.49, 0.66</text>
<text top="357" left="409" width="59" height="12" font="6">65.03, 1.02</text>
<text top="357" left="487" width="59" height="12" font="6">79.29, 0.62</text>
<text top="357" left="564" width="66" height="12" font="6">283.19, 0.55</text>
<text top="357" left="647" width="66" height="12" font="6">331.34, 0.32</text>
<text top="372" left="189" width="51" height="12" font="6">Satellite7</text>
<text top="372" left="280" width="20" height="12" font="6">n/a</text>
<text top="372" left="352" width="20" height="12" font="6">n/a</text>
<text top="372" left="421" width="35" height="12" font="6">502.51</text>
<text top="372" left="499" width="35" height="12" font="6">209.73</text>
<text top="372" left="582" width="29" height="12" font="6">55.31</text>
<text top="372" left="666" width="29" height="12" font="6">37.64</text>
<text top="372" left="732" width="23" height="12" font="6">0.34</text>
<text top="372" left="767" width="13" height="12" font="6">21</text>
<text top="386" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="386" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="386" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="386" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="386" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="401" left="189" width="65" height="12" font="6">ZenoTrav11</text>
<text top="401" left="273" width="35" height="12" font="6">546.67</text>
<text top="401" left="347" width="29" height="12" font="6">61.26</text>
<text top="401" left="425" width="29" height="12" font="6">16.58</text>
<text top="401" left="505" width="23" height="12" font="6">8.55</text>
<text top="401" left="585" width="23" height="12" font="6">2.76</text>
<text top="401" left="669" width="23" height="12" font="6">9.05</text>
<text top="401" left="732" width="23" height="12" font="6">0.35</text>
<text top="401" left="767" width="13" height="12" font="6">14</text>
<text top="415" left="335" width="53" height="12" font="6">8.92, 0.56</text>
<text top="415" left="409" width="59" height="12" font="6">32.97, 0.52</text>
<text top="415" left="487" width="59" height="12" font="6">63.94, 0.50</text>
<text top="415" left="564" width="66" height="12" font="6">198.07, 0.39</text>
<text top="415" left="651" width="59" height="12" font="6">60.41, 0.06</text>
<text top="430" left="189" width="65" height="12" font="6">ZenoTrav12</text>
<text top="430" left="280" width="20" height="12" font="6">n/a</text>
<text top="430" left="352" width="20" height="12" font="6">n/a</text>
<text top="430" left="429" width="20" height="12" font="6">n/a</text>
<text top="430" left="506" width="20" height="12" font="6">n/a</text>
<text top="430" left="579" width="35" height="12" font="6">180.80</text>
<text top="430" left="666" width="29" height="12" font="6">90.14</text>
<text top="430" left="732" width="23" height="12" font="6">0.48</text>
<text top="430" left="767" width="13" height="12" font="6">21</text>
<text top="444" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="444" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="444" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="444" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="444" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="459" left="189" width="64" height="12" font="6">PipNoTk24</text>
<text top="459" left="269" width="41" height="12" font="6">1396.29</text>
<text top="459" left="344" width="35" height="12" font="6">139.25</text>
<text top="459" left="425" width="29" height="12" font="6">40.34</text>
<text top="459" left="502" width="29" height="12" font="6">20.47</text>
<text top="459" left="585" width="23" height="12" font="6">6.11</text>
<text top="459" left="666" width="29" height="12" font="6">11.60</text>
<text top="459" left="732" width="23" height="12" font="6">7.24</text>
<text top="459" left="767" width="13" height="12" font="6">24</text>
<text top="473" left="332" width="59" height="12" font="6">10.03, 0.63</text>
<text top="473" left="409" width="59" height="12" font="6">34.61, 0.54</text>
<text top="473" left="487" width="59" height="12" font="6">68.21, 0.53</text>
<text top="473" left="564" width="66" height="12" font="6">228.52, 0.45</text>
<text top="473" left="647" width="66" height="12" font="6">120.37, 0.12</text>
<text top="488" left="189" width="48" height="12" font="6">Pegsol28</text>
<text top="488" left="269" width="41" height="12" font="6">1010.65</text>
<text top="488" left="347" width="29" height="12" font="6">83.22</text>
<text top="488" left="425" width="29" height="12" font="6">21.77</text>
<text top="488" left="502" width="29" height="12" font="6">10.41</text>
<text top="488" left="585" width="23" height="12" font="6">3.23</text>
<text top="488" left="669" width="23" height="12" font="6">2.93</text>
<text top="488" left="732" width="23" height="12" font="6">1.04</text>
<text top="488" left="767" width="13" height="12" font="6">35</text>
<text top="502" left="332" width="59" height="12" font="6">12.14, 0.76</text>
<text top="502" left="409" width="59" height="12" font="6">46.42, 0.73</text>
<text top="502" left="487" width="59" height="12" font="6">97.08, 0.76</text>
<text top="502" left="564" width="66" height="12" font="6">312.90, 0.61</text>
<text top="502" left="647" width="66" height="12" font="6">344.93, 0.34</text>
<text top="517" left="189" width="48" height="12" font="6">Pegsol29</text>
<text top="517" left="269" width="41" height="12" font="6">5143.24</text>
<text top="517" left="352" width="20" height="12" font="6">n/a</text>
<text top="517" left="429" width="20" height="12" font="6">n/a</text>
<text top="517" left="502" width="29" height="12" font="6">52.28</text>
<text top="517" left="582" width="29" height="12" font="6">13.86</text>
<text top="517" left="669" width="23" height="12" font="6">7.89</text>
<text top="517" left="725" width="29" height="12" font="6">16.76</text>
<text top="517" left="767" width="13" height="12" font="6">37</text>
<text top="531" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="531" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="531" left="487" width="59" height="12" font="6">98.38, 0.77</text>
<text top="531" left="564" width="66" height="12" font="6">371.09, 0.72</text>
<text top="531" left="647" width="66" height="12" font="6">651.87, 0.64</text>
<text top="546" left="189" width="48" height="12" font="6">Pegsol30</text>
<text top="546" left="280" width="20" height="12" font="6">n/a</text>
<text top="546" left="352" width="20" height="12" font="6">n/a</text>
<text top="546" left="429" width="20" height="12" font="6">n/a</text>
<text top="546" left="506" width="20" height="12" font="6">n/a</text>
<text top="546" left="582" width="29" height="12" font="6">34.14</text>
<text top="546" left="666" width="29" height="12" font="6">18.19</text>
<text top="546" left="732" width="23" height="12" font="6">3.30</text>
<text top="546" left="767" width="13" height="12" font="6">48</text>
<text top="560" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="560" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="560" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="560" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="560" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="575" left="189" width="59" height="12" font="6">Sokoban24</text>
<text top="575" left="269" width="41" height="12" font="6">2635.37</text>
<text top="575" left="352" width="20" height="12" font="6">n/a</text>
<text top="575" left="425" width="29" height="12" font="6">57.29</text>
<text top="575" left="502" width="29" height="12" font="6">33.52</text>
<text top="575" left="582" width="29" height="12" font="6">15.97</text>
<text top="575" left="666" width="29" height="12" font="6">47.91</text>
<text top="575" left="732" width="48" height="12" font="6">1.55 205</text>
<text top="589" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="589" left="409" width="59" height="12" font="6">46.00, 0.72</text>
<text top="589" left="487" width="59" height="12" font="6">78.62, 0.61</text>
<text top="589" left="564" width="66" height="12" font="6">165.02, 0.32</text>
<text top="589" left="651" width="59" height="12" font="6">55.01, 0.05</text>
<text top="604" left="189" width="59" height="12" font="6">Sokoban26</text>
<text top="604" left="280" width="20" height="12" font="6">n/a</text>
<text top="604" left="352" width="20" height="12" font="6">n/a</text>
<text top="604" left="421" width="35" height="12" font="6">155.20</text>
<text top="604" left="502" width="29" height="12" font="6">77.60</text>
<text top="604" left="582" width="29" height="12" font="6">25.29</text>
<text top="604" left="666" width="29" height="12" font="6">26.50</text>
<text top="604" left="732" width="48" height="12" font="6">2.34 135</text>
<text top="618" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="618" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="618" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="618" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="618" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="633" left="189" width="59" height="12" font="6">Sokoban27</text>
<text top="633" left="280" width="20" height="12" font="6">n/a</text>
<text top="633" left="352" width="20" height="12" font="6">n/a</text>
<text top="633" left="429" width="20" height="12" font="6">n/a</text>
<text top="633" left="506" width="20" height="12" font="6">n/a</text>
<text top="633" left="582" width="29" height="12" font="6">36.53</text>
<text top="633" left="666" width="29" height="12" font="6">26.57</text>
<text top="633" left="732" width="23" height="12" font="6">3.68</text>
<text top="633" left="767" width="13" height="12" font="6">87</text>
<text top="647" left="338" width="47" height="12" font="6">n/a, n/a</text>
<text top="647" left="415" width="47" height="12" font="6">n/a, n/a</text>
<text top="647" left="493" width="47" height="12" font="6">n/a, n/a</text>
<text top="647" left="573" width="47" height="12" font="6">n/a, n/a</text>
<text top="647" left="656" width="47" height="12" font="6">n/a, n/a</text>
<text top="676" left="189" width="57" height="16" font="5">Table 2:</text>
<text top="677" left="253" width="474" height="15" font="3">Three-valued cells show the search time (excluding abstraction initializa-</text>
<text top="698" left="189" width="538" height="15" font="3">tion), speedup, and eﬃciency on a large-scale HPC cluster with using up to 1024</text>
<text top="718" left="189" width="538" height="15" font="3">2.4GHz Opteron cores (Abstraction size = 1000). The 1-core results, which indi-</text>
<text top="738" left="189" width="538" height="15" font="3">cate search time, use a Opteron-based machine. “n/a” = failure due to exhausted</text>
<text top="758" left="189" width="451" height="15" font="3">memory. Average is restricted to instances solved across all columns.</text>
<text top="825" left="189" width="538" height="16" font="5">problems with both this 2.6GHz machine and a single core on the 2.4GHz</text>
<text top="845" left="189" width="538" height="16" font="5">parallel machine. Although this 128GB machine has 16 cores, we use just</text>
<text top="865" left="189" width="514" height="16" font="5">one core, and use all of the 128GB of RAM for a sequential A* process<a href="pdfxml.html#19">.</a></text>
<text top="863" left="703" width="13" height="12" font="6"><a href="pdfxml.html#19">10</a></text>
<text top="886" left="214" width="512" height="16" font="5">As in Table <a href="pdfxml.html#16">1, </a>the times shown in Table <a href="pdfxml.html#19">2 </a>include the time for the search</text>
<text top="906" left="189" width="538" height="16" font="5">algorithm execution, and exclude the time required to compute the abstrac-</text>
<text top="926" left="189" width="538" height="16" font="5">tion table for the LFPA heuristic, since this phase of Fast Downward+LFPA</text>
<text top="956" left="202" width="11" height="7" font="7">10</text>
<text top="958" left="214" width="513" height="13" font="8">Due to the runtime scaling, as well as the architectural diﬀerences between Opteron</text>
<text top="975" left="189" width="538" height="13" font="8">and Xeon processors, the 1-core Opteron results in Table <a href="pdfxml.html#19">2 </a>are not directly comparable</text>
<text top="991" left="189" width="241" height="13" font="8">with the 1-core Xeon results in Table <a href="pdfxml.html#16">1.</a></text>
<text top="1036" left="449" width="16" height="16" font="5">19</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1188" width="918">
<text top="198" left="296" width="33" height="12" font="6">1 core</text>
<text top="198" left="368" width="44" height="12" font="6">16 cores</text>
<text top="198" left="430" width="44" height="12" font="6">64 cores</text>
<text top="198" left="492" width="51" height="12" font="6">128 cores</text>
<text top="198" left="561" width="51" height="12" font="6">512 cores</text>
<text top="198" left="630" width="57" height="12" font="6">1024 cores</text>
<text top="198" left="708" width="25" height="12" font="6">Opt.</text>
<text top="212" left="371" width="37" height="12" font="6">1 node</text>
<text top="212" left="431" width="42" height="12" font="6">4 nodes</text>
<text top="212" left="497" width="42" height="12" font="6">8 nodes</text>
<text top="212" left="563" width="48" height="12" font="6">32 nodes</text>
<text top="212" left="635" width="48" height="12" font="6">64 nodes</text>
<text top="212" left="709" width="24" height="12" font="6">plan</text>
<text top="226" left="294" width="38" height="12" font="6">128GB</text>
<text top="226" left="374" width="31" height="12" font="6">32GB</text>
<text top="226" left="433" width="38" height="12" font="6">128GB</text>
<text top="226" left="499" width="38" height="12" font="6">256GB</text>
<text top="226" left="575" width="24" height="12" font="6">1TB</text>
<text top="226" left="647" width="24" height="12" font="6">2TB</text>
<text top="226" left="713" width="16" height="12" font="6">len</text>
<text top="241" left="189" width="52" height="12" font="6">Average</text>
<text top="241" left="276" width="75" height="12" font="6">149,911,017</text>
<text top="241" left="379" width="23" height="12" font="6">n/a</text>
<text top="241" left="441" width="23" height="12" font="6">n/a</text>
<text top="241" left="499" width="38" height="12" font="6">8.49%</text>
<text top="241" left="564" width="46" height="12" font="6">28.07%</text>
<text top="241" left="632" width="53" height="12" font="6">203.32%</text>
<text top="256" left="189" width="65" height="12" font="6">ZenoTrav11</text>
<text top="256" left="284" width="58" height="12" font="6">14,619,024</text>
<text top="256" left="373" width="33" height="12" font="6">0.00%</text>
<text top="256" left="436" width="33" height="12" font="6">0.13%</text>
<text top="256" left="501" width="33" height="12" font="6">0.83%</text>
<text top="256" left="570" width="33" height="12" font="6">7.56%</text>
<text top="256" left="636" width="46" height="12" font="6">529.39%</text>
<text top="256" left="715" width="13" height="12" font="6">14</text>
<text top="271" left="189" width="45" height="12" font="6">Rover12</text>
<text top="271" left="284" width="58" height="12" font="6">37,243,958</text>
<text top="271" left="373" width="33" height="12" font="6">0.17%</text>
<text top="271" left="430" width="44" height="12" font="6">-37.63%</text>
<text top="271" left="501" width="33" height="12" font="6">0.54%</text>
<text top="271" left="570" width="33" height="12" font="6">0.85%</text>
<text top="271" left="640" width="37" height="12" font="6">-4.85%</text>
<text top="271" left="715" width="13" height="12" font="6">19</text>
<text top="285" left="189" width="75" height="12" font="6">PipesNoTk24</text>
<text top="285" left="284" width="58" height="12" font="6">72,782,203</text>
<text top="285" left="373" width="33" height="12" font="6">0.03%</text>
<text top="285" left="436" width="33" height="12" font="6">0.07%</text>
<text top="285" left="501" width="33" height="12" font="6">0.66%</text>
<text top="285" left="570" width="33" height="12" font="6">3.38%</text>
<text top="285" left="636" width="46" height="12" font="6">204.12%</text>
<text top="285" left="715" width="13" height="12" font="6">24</text>
<text top="300" left="189" width="48" height="12" font="6">Pegsol28</text>
<text top="300" left="281" width="64" height="12" font="6">111,419,815</text>
<text top="300" left="373" width="33" height="12" font="6">2.49%</text>
<text top="300" left="436" width="33" height="12" font="6">1.89%</text>
<text top="300" left="501" width="33" height="12" font="6">2.62%</text>
<text top="300" left="570" width="33" height="12" font="6">5.97%</text>
<text top="300" left="639" width="39" height="12" font="6">33.95%</text>
<text top="300" left="715" width="13" height="12" font="6">35</text>
<text top="315" left="189" width="48" height="12" font="6">Pegsol29</text>
<text top="315" left="281" width="64" height="12" font="6">478,930,258</text>
<text top="315" left="380" width="20" height="12" font="6">n/a</text>
<text top="315" left="442" width="20" height="12" font="6">n/a</text>
<text top="315" left="501" width="33" height="12" font="6">4.20%</text>
<text top="315" left="570" width="33" height="12" font="6">4.64%</text>
<text top="315" left="639" width="39" height="12" font="6">10.02%</text>
<text top="315" left="715" width="13" height="12" font="6">37</text>
<text top="330" left="189" width="48" height="12" font="6">Freecell7</text>
<text top="330" left="284" width="58" height="12" font="6">92,584,775</text>
<text top="330" left="380" width="20" height="12" font="6">n/a</text>
<text top="330" left="436" width="33" height="12" font="6">1.93%</text>
<text top="330" left="501" width="33" height="12" font="6">3.15%</text>
<text top="330" left="567" width="39" height="12" font="6">26.93%</text>
<text top="330" left="636" width="46" height="12" font="6">128.32%</text>
<text top="330" left="715" width="13" height="12" font="6">41</text>
<text top="345" left="189" width="59" height="12" font="6">Sokoban24</text>
<text top="345" left="281" width="64" height="12" font="6">241,797,086</text>
<text top="345" left="380" width="20" height="12" font="6">n/a</text>
<text top="345" left="433" width="39" height="12" font="6">15.12%</text>
<text top="345" left="498" width="39" height="12" font="6">47.44%</text>
<text top="345" left="564" width="46" height="12" font="6">147.17%</text>
<text top="345" left="636" width="46" height="12" font="6">522.28%</text>
<text top="345" left="712" width="19" height="12" font="6">205</text>
<text top="374" left="189" width="538" height="16" font="5">Table 3: Search overhead in planning as a percentage compared to sequential</text>
<text top="394" left="189" width="538" height="16" font="5">search. Compared to Table 2, instances not solved with sequential search, for</text>
<text top="415" left="189" width="538" height="16" font="5">which the search overhead is undeﬁned, have been excluded. Experiments</text>
<text top="435" left="189" width="538" height="16" font="5">were performed on a HPC cluster connected by a 20Gb Inﬁniband network,</text>
<text top="455" left="189" width="538" height="16" font="5">where each node has eight 2.4GHz AMD dual core Opteron processors (total</text>
<text top="476" left="189" width="265" height="16" font="5">16 cores per node) and 32 GB RAM.</text>
<text top="544" left="189" width="538" height="16" font="5">has not been parallelized yet and therefore requires the same amount of time</text>
<text top="564" left="189" width="538" height="16" font="5">to run regardless of the number of cores. The abstraction heuristic initial-</text>
<text top="584" left="189" width="538" height="16" font="5">ization times are shown separately in Table <a href="pdfxml.html#19">2. </a>For example, the IPC-6</text>
<text top="605" left="189" width="538" height="16" font="5">Pegsol-28 instance, which requires 1010.65 seconds with 1 core, was solved</text>
<text top="625" left="189" width="538" height="16" font="5">in 10.41 seconds with 128 cores, plus 1.04 seconds for the abstraction table</text>
<text top="645" left="189" width="538" height="16" font="5">generation. The “n/a” for the runtimes in Table <a href="pdfxml.html#19">2 </a>indicates a failure, i.e.,</text>
<text top="666" left="189" width="538" height="16" font="5">the planner terminated because one of the nodes ran out of memory. For</text>
<text top="686" left="189" width="460" height="16" font="5">example, the Pegsol-30 instance was ﬁrst solved using 512 cores.</text>
<text top="706" left="214" width="512" height="16" font="5">Compared to 1 core (128GB), HDA* achieved a search speedup of 9-12</text>
<text top="727" left="189" width="538" height="16" font="5">with 16 cores (32GB), 33-65 with 64 cores (128GB), 64-98 with 128 cores</text>
<text top="747" left="189" width="538" height="16" font="5">(256GB), 165-371 with 512 cores (1TB), and 55-651 with 1024 cores (2TB).</text>
<text top="767" left="189" width="538" height="16" font="5">The parallel eﬃciency of HDA* relative to 1 core (128GB) ranges between</text>
<text top="788" left="189" width="538" height="16" font="5">0.56-0.76 for 16 cores (32GB), 0.52-1.02 for 64 cores (128GB), 0.50-0.77 for</text>
<text top="808" left="189" width="538" height="16" font="5">128 cores (256GB), 0.32-0.72 with 512 cores (1TB), and 0.05-0.64 with 1024</text>
<text top="828" left="189" width="90" height="16" font="5">cores (2TB).</text>
<text top="849" left="214" width="513" height="16" font="5">Up to 512 cores, using more cores and RAM consistently reduces the</text>
<text top="869" left="189" width="538" height="16" font="5">total running time. With 1024 cores in use, two distinct tendencies are ob-</text>
<text top="889" left="189" width="538" height="16" font="5">served. In some but not all of the instances that are somewhat easier and</text>
<text top="910" left="189" width="538" height="16" font="5">can be solved with relatively fewer CPUs and less RAM, such as Freecell7,</text>
<text top="930" left="189" width="538" height="16" font="5">ZenoTrav11, PipNoTk24, Sokoban24, and Sokoban26, using 1024 cores re-</text>
<text top="950" left="189" width="538" height="16" font="5">sults in a slow down compared to using 512 cores. As shown later (Table <a href="pdfxml.html#20">3)</a>,</text>
<text top="971" left="189" width="538" height="16" font="5">the search overhead explains in part this behavior. We will see in Section</text>
<text top="991" left="189" width="538" height="16" font="5"><a href="pdfxml.html#25">4.3 </a>that a similar tendency is also apparent on the 24-puzzle. On the other</text>
<text top="1036" left="449" width="16" height="16" font="5">20</text>
</page>
<page number="21" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">hand, on the most diﬃcult problems that required the most state gener-</text>
<text top="219" left="189" width="538" height="16" font="5">ations to solve (Driverlog13, Freecell6, Satellite7, Pegsol29 and Pegsol30),</text>
<text top="240" left="189" width="538" height="16" font="5">HDA* with 1024 cores demonstrates close to linear (2x) speedup relative</text>
<text top="260" left="189" width="538" height="16" font="5">to 512 cores. Thus, HDA* demonstrates reasonably good scalability for a</text>
<text top="280" left="189" width="538" height="16" font="5">large number of processors. In other words, while the scalability of HDA*</text>
<text top="300" left="189" width="538" height="16" font="5">eventually degrades for easier problems, the algorithm scales well, relative</text>
<text top="321" left="189" width="538" height="16" font="5">to the minimal number of processors needed to solve the problem, in the</text>
<text top="341" left="189" width="418" height="16" font="5">hardest problems (requiring massive amounts of memory).</text>
<text top="359" left="214" width="512" height="16" font="5">Search overhead, which indicates the extra states explored by parallel</text>
<text top="377" left="189" width="146" height="16" font="5">search, is deﬁned as:</text>
<text top="418" left="238" width="88" height="15" font="3">SO = 100 × (</text>
<text top="408" left="336" width="295" height="15" font="3">number of states expanded by parallel search</text>
<text top="428" left="328" width="312" height="15" font="3">number of states expanded by sequential search</text>
<text top="418" left="645" width="32" height="15" font="3">− 1).</text>
<text top="458" left="189" width="538" height="16" font="5">Table <a href="pdfxml.html#20">3 </a>shows search overhead data for domain-independent planning. As</text>
<text top="478" left="189" width="538" height="16" font="5">remarked earlier, using 1024 cores can increase the search overhead signiﬁ-</text>
<text top="499" left="189" width="538" height="16" font="5">cantly. Note that there are some instances where search overhead is negative</text>
<text top="519" left="189" width="538" height="16" font="5">relative to 1 core, e.g., Rover12 (with 64 cores). This means that fewer nodes</text>
<text top="539" left="189" width="538" height="16" font="5">are expanded by HDA* compared to A*. Since the open list is distributed,</text>
<text top="560" left="189" width="538" height="16" font="5">a node can expand a state with an f -value higher than that which would be</text>
<text top="580" left="189" width="538" height="16" font="5">expanded with a global open list, and that state may lead to a goal state.</text>
<text top="600" left="189" width="481" height="16" font="5">In a sense, this is a form of accidental, speculative state expansion.</text>
<text top="621" left="214" width="513" height="16" font="5">A common metric for measuring how evenly the work is distributed</text>
<text top="641" left="189" width="538" height="16" font="5">among the cores is the load balance, deﬁned as the ratio of the maximal</text>
<text top="661" left="189" width="538" height="16" font="5">number of states expanded by a core and the average number of states</text>
<text top="682" left="189" width="538" height="16" font="5">expanded by each core. As shown in Table <a href="pdfxml.html#22">4, </a>HDA* achieves good load</text>
<text top="702" left="189" width="538" height="16" font="5">balance. For 128 cores, the worst load balance was 1.12 (Freecell7). For 512</text>
<text top="722" left="189" width="538" height="16" font="5">cores, the worst load balance was 1.22 (Freecell6). For 1024 cores, the worst</text>
<text top="743" left="189" width="238" height="16" font="5">balance was 1.47 (PipesNoTk24).</text>
<text top="763" left="214" width="513" height="16" font="5">One possible reason for the imbalance in some domains may be the</text>
<text top="783" left="189" width="538" height="16" font="5">“hotspots” – frequently generated duplicate nodes which are sent to a small</text>
<text top="803" left="189" width="538" height="16" font="5">number of cores by the hash function. This is caused by the fact that the</text>
<text top="824" left="189" width="538" height="16" font="5">search space contains transpositions, which are states that can be reached</text>
<text top="844" left="189" width="538" height="16" font="5">through diﬀerent paths. In HDA*, if a processor receives a state s which</text>
<text top="865" left="189" width="538" height="16" font="5">is already in the closed list but the g-value of s is smaller than that in</text>
<text top="885" left="189" width="538" height="16" font="5">the closed list, s must be enqueued in the open list. However, the heuris-</text>
<text top="905" left="189" width="538" height="16" font="5">tic value of s is not recomputed in saving s to the open list, because the</text>
<text top="926" left="189" width="538" height="16" font="5">value is already saved in the closed list. In Fast Downward, computing the</text>
<text top="946" left="189" width="538" height="16" font="5">heuristic value requires intensive computation, and reducing the frequency</text>
<text top="966" left="189" width="538" height="16" font="5">of calling the heuristic function results in increasing the node expansion rate.</text>
<text top="987" left="189" width="538" height="16" font="5">For example, in solving PipesNoTk24 with 1024 cores, more than 60% of</text>
<text top="1036" left="449" width="16" height="16" font="5">21</text>
</page>
<page number="22" position="absolute" top="0" left="0" height="1188" width="918">
<text top="197" left="327" width="48" height="13" font="8">16 cores</text>
<text top="197" left="399" width="48" height="13" font="8">64 cores</text>
<text top="197" left="470" width="55" height="13" font="8">128 cores</text>
<text top="197" left="548" width="55" height="13" font="8">512 cores</text>
<text top="197" left="626" width="62" height="13" font="8">1024 cores</text>
<text top="213" left="326" width="51" height="13" font="8">(1 node)</text>
<text top="213" left="395" width="56" height="13" font="8">(4 nodes)</text>
<text top="213" left="469" width="56" height="13" font="8">(8 nodes)</text>
<text top="213" left="544" width="64" height="13" font="8">(32 nodes)</text>
<text top="213" left="625" width="64" height="13" font="8">(64 nodes)</text>
<text top="230" left="233" width="70" height="13" font="8">Driverlog13</text>
<text top="230" left="341" width="21" height="13" font="8">n/a</text>
<text top="230" left="412" width="21" height="13" font="8">n/a</text>
<text top="230" left="487" width="21" height="13" font="8">n/a</text>
<text top="230" left="563" width="24" height="13" font="8">1.18</text>
<text top="230" left="645" width="24" height="13" font="8">1.24</text>
<text top="247" left="241" width="52" height="13" font="8">Freecell6</text>
<text top="247" left="341" width="21" height="13" font="8">n/a</text>
<text top="247" left="412" width="21" height="13" font="8">n/a</text>
<text top="247" left="485" width="24" height="13" font="8">1.07</text>
<text top="247" left="563" width="24" height="13" font="8">1.22</text>
<text top="247" left="645" width="24" height="13" font="8">1.20</text>
<text top="264" left="241" width="52" height="13" font="8">Freecell7</text>
<text top="264" left="341" width="21" height="13" font="8">n/a</text>
<text top="264" left="411" width="24" height="13" font="8">1.08</text>
<text top="264" left="485" width="24" height="13" font="8">1.12</text>
<text top="264" left="563" width="24" height="13" font="8">1.21</text>
<text top="264" left="645" width="24" height="13" font="8">1.30</text>
<text top="281" left="243" width="49" height="13" font="8">Rover12</text>
<text top="281" left="339" width="24" height="13" font="8">1.02</text>
<text top="281" left="411" width="24" height="13" font="8">1.04</text>
<text top="281" left="485" width="24" height="13" font="8">1.05</text>
<text top="281" left="563" width="24" height="13" font="8">1.08</text>
<text top="281" left="645" width="24" height="13" font="8">1.41</text>
<text top="298" left="239" width="56" height="13" font="8">Satellite7</text>
<text top="298" left="341" width="21" height="13" font="8">n/a</text>
<text top="298" left="411" width="24" height="13" font="8">1.07</text>
<text top="298" left="485" width="24" height="13" font="8">1.11</text>
<text top="298" left="563" width="24" height="13" font="8">1.06</text>
<text top="298" left="645" width="24" height="13" font="8">1.26</text>
<text top="315" left="232" width="71" height="13" font="8">ZenoTrav11</text>
<text top="315" left="336" width="31" height="13" font="8">1.002</text>
<text top="315" left="411" width="24" height="13" font="8">1.04</text>
<text top="315" left="485" width="24" height="13" font="8">1.06</text>
<text top="315" left="563" width="24" height="13" font="8">1.18</text>
<text top="315" left="645" width="24" height="13" font="8">1.37</text>
<text top="332" left="232" width="71" height="13" font="8">ZenoTrav12</text>
<text top="332" left="341" width="21" height="13" font="8">n/a</text>
<text top="332" left="412" width="21" height="13" font="8">n/a</text>
<text top="332" left="487" width="21" height="13" font="8">n/a</text>
<text top="332" left="563" width="24" height="13" font="8">1.09</text>
<text top="332" left="645" width="24" height="13" font="8">1.16</text>
<text top="349" left="227" width="81" height="13" font="8">PipesNoTk24</text>
<text top="349" left="339" width="24" height="13" font="8">1.01</text>
<text top="349" left="411" width="24" height="13" font="8">1.02</text>
<text top="349" left="485" width="24" height="13" font="8">1.04</text>
<text top="349" left="563" width="24" height="13" font="8">1.06</text>
<text top="349" left="645" width="24" height="13" font="8">1.47</text>
<text top="366" left="241" width="52" height="13" font="8">Pegsol28</text>
<text top="366" left="339" width="24" height="13" font="8">1.04</text>
<text top="366" left="411" width="24" height="13" font="8">1.03</text>
<text top="366" left="485" width="24" height="13" font="8">1.05</text>
<text top="366" left="563" width="24" height="13" font="8">1.08</text>
<text top="366" left="645" width="24" height="13" font="8">1.10</text>
<text top="384" left="241" width="52" height="13" font="8">Pegsol29</text>
<text top="384" left="341" width="21" height="13" font="8">n/a</text>
<text top="384" left="412" width="21" height="13" font="8">n/a</text>
<text top="384" left="485" width="24" height="13" font="8">1.07</text>
<text top="384" left="563" width="24" height="13" font="8">1.09</text>
<text top="384" left="645" width="24" height="13" font="8">1.07</text>
<text top="400" left="241" width="52" height="13" font="8">Pegsol30</text>
<text top="400" left="341" width="21" height="13" font="8">n/a</text>
<text top="400" left="412" width="21" height="13" font="8">n/a</text>
<text top="400" left="487" width="21" height="13" font="8">n/a</text>
<text top="400" left="563" width="24" height="13" font="8">1.06</text>
<text top="400" left="645" width="24" height="13" font="8">1.07</text>
<text top="418" left="235" width="64" height="13" font="8">Sokoban24</text>
<text top="418" left="341" width="21" height="13" font="8">n/a</text>
<text top="418" left="411" width="24" height="13" font="8">1.09</text>
<text top="418" left="485" width="24" height="13" font="8">1.10</text>
<text top="418" left="563" width="24" height="13" font="8">1.07</text>
<text top="418" left="645" width="24" height="13" font="8">1.04</text>
<text top="435" left="235" width="64" height="13" font="8">Sokoban26</text>
<text top="435" left="341" width="21" height="13" font="8">n/a</text>
<text top="435" left="411" width="24" height="13" font="8">1.09</text>
<text top="435" left="485" width="24" height="13" font="8">1.11</text>
<text top="435" left="563" width="24" height="13" font="8">1.09</text>
<text top="435" left="645" width="24" height="13" font="8">1.05</text>
<text top="452" left="235" width="64" height="13" font="8">Sokoban27</text>
<text top="452" left="341" width="21" height="13" font="8">n/a</text>
<text top="452" left="412" width="21" height="13" font="8">n/a</text>
<text top="452" left="487" width="21" height="13" font="8">n/a</text>
<text top="452" left="563" width="24" height="13" font="8">1.12</text>
<text top="452" left="645" width="24" height="13" font="8">1.15</text>
<text top="483" left="189" width="538" height="16" font="5">Table 4: Planning load balance data. Experiments were performed on a</text>
<text top="503" left="189" width="538" height="16" font="5">HPC cluster connected by a 20Gb Inﬁniband network, where each node has</text>
<text top="523" left="189" width="538" height="16" font="5">eight 2.4GHz AMD dual core Opteron processors (total 16 cores per node)</text>
<text top="544" left="189" width="127" height="16" font="5">and 32 GB RAM.</text>
<text top="608" left="189" width="538" height="16" font="5">generated states are duplicates. A processor that may be in the hotspot</text>
<text top="628" left="189" width="538" height="16" font="5">receives about 17% more duplicate states than the processor receiving du-</text>
<text top="649" left="189" width="538" height="16" font="5">plicate states least frequently, although we observe that they receive similar</text>
<text top="669" left="189" width="538" height="16" font="5">amounts of work. As a result, the numbers of calls for the heuristic function</text>
<text top="689" left="189" width="538" height="16" font="5">are diﬀerent (about 14%) between these processors. Thus, a processor which</text>
<text top="710" left="189" width="538" height="16" font="5">executes fewer heuristic evaluations (relative to other processors receiving</text>
<text top="730" left="189" width="538" height="16" font="5">a comparable number of states) has a higher state expansion rate than the</text>
<text top="750" left="189" width="323" height="16" font="5">other processors, resulting in load imbalance.</text>
<text top="794" left="189" width="39" height="16" font="5">4.2.1</text>
<text top="794" left="246" width="480" height="16" font="5">Impact of Aggregate, Distributed Memory on a HPC Clus-</text>
<text top="814" left="246" width="24" height="16" font="5">ter</text>
<text top="845" left="189" width="538" height="16" font="5">As the number of machines increases, we increase not only the number of</text>
<text top="865" left="189" width="538" height="16" font="5">CPU cores available, but also the aggregate amount of RAM available. This</text>
<text top="885" left="189" width="538" height="16" font="5">is very important for algorithms such as A*, where the amount of RAM</text>
<text top="906" left="189" width="538" height="16" font="5">is the limiting factor. We have observed that as we increase the aggregate</text>
<text top="926" left="189" width="538" height="16" font="5">RAM we are able to solve an increasing number of hard IPC instances.</text>
<text top="946" left="189" width="538" height="16" font="5">For example, with sequential Fast Downward on a machine with 32GB,</text>
<text top="967" left="189" width="538" height="16" font="5">we could only solve 22 out of the 30 IPC-6 Sokoban instances (with an</text>
<text top="987" left="189" width="538" height="16" font="5">abstraction size of 1000). Using 512 cores and aggregate 1024GB RAM, 28</text>
<text top="1036" left="449" width="16" height="16" font="5">22</text>
</page>
<page number="23" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">instances were solved. Furthermore, it was possible to solve all of the Pegsol</text>
<text top="219" left="189" width="538" height="16" font="5">problems (30 instances) with 512 cores. Fast Downward exhausts 128GB</text>
<text top="240" left="189" width="538" height="16" font="5">RAM within 3-6 hours, depending on the problem. As shown in Table <a href="pdfxml.html#19">2,</a></text>
<text top="260" left="189" width="538" height="16" font="5">the Driverlog13, Zenotrav12, Pegsol30, and Sokoban27 instances required</text>
<text top="280" left="189" width="485" height="16" font="5">more than 128 cores and 256GB aggregate cluster memory to solve.</text>
<text top="323" left="189" width="39" height="16" font="5">4.2.2</text>
<text top="323" left="246" width="480" height="16" font="5">Scaling Behavior and the Number of Nodes (Machines) on</text>
<text top="344" left="246" width="123" height="16" font="5">a HPC Cluster</text>
<text top="375" left="189" width="538" height="16" font="5">So far, we have considered the scaling of HDA* as the number of cores was</text>
<text top="395" left="189" width="538" height="16" font="5">increased. However, the scaling behavior of HDA* on a cluster is aﬀected by</text>
<text top="415" left="189" width="538" height="16" font="5">factors other than the number of cores. One factor is the cost of communi-</text>
<text top="436" left="189" width="538" height="16" font="5">cation between nodes. Communications between cores in the same node are</text>
<text top="456" left="189" width="538" height="16" font="5">done via a shared memory bus, while communications between cores residing</text>
<text top="476" left="189" width="515" height="16" font="5">on diﬀerent nodes are performed over a local area network (Inﬁniband).</text>
<text top="497" left="214" width="513" height="16" font="5">To evaluate the impact of the communication delay, we ran the planner</text>
<text top="517" left="189" width="538" height="16" font="5">using 64 cores, where the cores were distributed evenly on 4-64 nodes (i.e.,</text>
<text top="537" left="189" width="538" height="16" font="5">1-16 cores per node). The results are shown in the upper half of Table <a href="pdfxml.html#24">5.</a></text>
<text top="557" left="189" width="538" height="16" font="5">If the communication delay was a signiﬁcant factor, we would expect that,</text>
<text top="578" left="189" width="538" height="16" font="5">as the number of nodes increased, the speedup compared to 1 core would</text>
<text top="598" left="189" width="538" height="16" font="5">decrease. Interestingly, Table <a href="pdfxml.html#24">5 </a>(upper half) shows that speedups increased</text>
<text top="618" left="189" width="521" height="16" font="5">on almost all of the problem instances as the number of nodes increased.</text>
<text top="639" left="214" width="512" height="16" font="5">The explanation for this counterintuitive result is memory contention</text>
<text top="659" left="189" width="538" height="16" font="5">within each single node. The memory bus has limited bandwidth and gets</text>
<text top="679" left="189" width="538" height="16" font="5">crowded when many cores in the single node access memory at a time. To</text>
<text top="700" left="189" width="538" height="16" font="5">emphasize this conclusion, we performed the following analysis. First, cache</text>
<text top="720" left="189" width="538" height="16" font="5">contention was ruled out as a possible explanation because, in the speciﬁc</text>
<text top="740" left="189" width="538" height="16" font="5">architecture used here, which is AMD Opteron, each core has a private L1</text>
<text top="761" left="189" width="538" height="16" font="5">and L2 cache. Then, we performed an experiment where, again, we used 4-64</text>
<text top="781" left="189" width="538" height="16" font="5">nodes, but this time, on each node, on each core that was not used by HDA*,</text>
<text top="801" left="189" width="538" height="16" font="5">we executed a dummy process, which makes no direct contribution towards</text>
<text top="822" left="189" width="538" height="16" font="5">solving the instance at hand. Each dummy process is an instance of HDA*</text>
<text top="842" left="189" width="538" height="16" font="5">which is forced to run sequentially on the instance at hand, and therefore</text>
<text top="862" left="189" width="538" height="16" font="5">behaves similarly to the “real” HDA* process with respect to memory access</text>
<text top="883" left="189" width="538" height="16" font="5">patterns (and therefore contends for memory with the “real” HDA* process).</text>
<text top="903" left="214" width="513" height="16" font="5">The results shown in Table <a href="pdfxml.html#24">5 </a>indicate that the overhead of local memory</text>
<text top="923" left="189" width="538" height="16" font="5">access congestion within a node is much larger than the overhead due to com-</text>
<text top="944" left="189" width="538" height="16" font="5">munication between nodes. In the normal conﬁgurations without dummy</text>
<text top="964" left="189" width="538" height="16" font="5">processes (Table <a href="pdfxml.html#24">5, </a>upper half), using fewer cores per node results in less</text>
<text top="984" left="189" width="538" height="16" font="5">local memory contention and more inter-node communication. Overall, the</text>
<text top="1036" left="449" width="16" height="16" font="5">23</text>
</page>
<page number="24" position="absolute" top="0" left="0" height="1188" width="918">
<text top="198" left="381" width="165" height="13" font="8">Normal execution of HDA*</text>
<text top="215" left="302" width="36" height="13" font="8">1 core</text>
<text top="215" left="360" width="48" height="13" font="8">64 cores</text>
<text top="215" left="427" width="48" height="13" font="8">64 cores</text>
<text top="215" left="495" width="48" height="13" font="8">64 cores</text>
<text top="215" left="566" width="48" height="13" font="8">64 cores</text>
<text top="215" left="636" width="48" height="13" font="8">64 cores</text>
<text top="215" left="705" width="24" height="13" font="8">Opt</text>
<text top="232" left="299" width="41" height="13" font="8">128GB</text>
<text top="232" left="361" width="46" height="13" font="8">4 nodes</text>
<text top="232" left="428" width="46" height="13" font="8">8 nodes</text>
<text top="232" left="493" width="53" height="13" font="8">16 nodes</text>
<text top="232" left="564" width="53" height="13" font="8">32 nodes</text>
<text top="232" left="634" width="53" height="13" font="8">64 nodes</text>
<text top="232" left="705" width="22" height="13" font="8">Len</text>
<text top="249" left="206" width="65" height="13" font="8">Avg time</text>
<text top="249" left="307" width="24" height="13" font="8">n/a</text>
<text top="249" left="362" width="44" height="13" font="8">103.29</text>
<text top="249" left="433" width="36" height="13" font="8">97.49</text>
<text top="249" left="501" width="36" height="13" font="8">83.93</text>
<text top="249" left="572" width="36" height="13" font="8">83.09</text>
<text top="249" left="642" width="36" height="13" font="8">78.92</text>
<text top="266" left="212" width="52" height="13" font="8">Freecell7</text>
<text top="266" left="297" width="45" height="13" font="8">2864.64</text>
<text top="266" left="369" width="31" height="13" font="8">66.85</text>
<text top="266" left="435" width="31" height="13" font="8">68.61</text>
<text top="266" left="504" width="31" height="13" font="8">64.29</text>
<text top="266" left="574" width="31" height="13" font="8">59.24</text>
<text top="266" left="645" width="31" height="13" font="8">59.39</text>
<text top="266" left="710" width="14" height="13" font="8">41</text>
<text top="282" left="363" width="42" height="13" font="8">(42.85)</text>
<text top="282" left="430" width="42" height="13" font="8">(41.75)</text>
<text top="282" left="498" width="42" height="13" font="8">(44.56)</text>
<text top="282" left="569" width="42" height="13" font="8">(48.36)</text>
<text top="282" left="639" width="42" height="13" font="8">(48.23)</text>
<text top="299" left="214" width="49" height="13" font="8">Rover12</text>
<text top="299" left="297" width="45" height="13" font="8">1149.74</text>
<text top="299" left="369" width="31" height="13" font="8">17.68</text>
<text top="299" left="435" width="31" height="13" font="8">17.15</text>
<text top="299" left="504" width="31" height="13" font="8">27.71</text>
<text top="299" left="574" width="31" height="13" font="8">27.93</text>
<text top="299" left="645" width="31" height="13" font="8">26.27</text>
<text top="299" left="710" width="14" height="13" font="8">19</text>
<text top="316" left="363" width="42" height="13" font="8">(65.03)</text>
<text top="316" left="430" width="42" height="13" font="8">(67.04)</text>
<text top="316" left="498" width="42" height="13" font="8">(41.49)</text>
<text top="316" left="569" width="42" height="13" font="8">(41.16)</text>
<text top="316" left="639" width="42" height="13" font="8">(43.77)</text>
<text top="333" left="210" width="56" height="13" font="8">Satellite7</text>
<text top="333" left="309" width="21" height="13" font="8">n/a</text>
<text top="333" left="365" width="38" height="13" font="8">502.51</text>
<text top="333" left="432" width="38" height="13" font="8">468.07</text>
<text top="333" left="500" width="38" height="13" font="8">370.43</text>
<text top="333" left="571" width="38" height="13" font="8">375.86</text>
<text top="333" left="641" width="38" height="13" font="8">351.69</text>
<text top="333" left="710" width="14" height="13" font="8">21</text>
<text top="350" left="203" width="71" height="13" font="8">ZenoTrav11</text>
<text top="350" left="300" width="38" height="13" font="8">546.67</text>
<text top="350" left="369" width="31" height="13" font="8">16.58</text>
<text top="350" left="435" width="31" height="13" font="8">15.64</text>
<text top="350" left="504" width="31" height="13" font="8">15.29</text>
<text top="350" left="574" width="31" height="13" font="8">14.71</text>
<text top="350" left="645" width="31" height="13" font="8">14.41</text>
<text top="350" left="710" width="14" height="13" font="8">14</text>
<text top="366" left="363" width="42" height="13" font="8">(32.97)</text>
<text top="366" left="430" width="42" height="13" font="8">(34.95)</text>
<text top="366" left="498" width="42" height="13" font="8">(35.75)</text>
<text top="366" left="569" width="42" height="13" font="8">(37.16)</text>
<text top="366" left="639" width="42" height="13" font="8">(37.94)</text>
<text top="383" left="198" width="81" height="13" font="8">PipesNoTk24</text>
<text top="383" left="297" width="45" height="13" font="8">1396.29</text>
<text top="383" left="369" width="31" height="13" font="8">40.34</text>
<text top="383" left="435" width="31" height="13" font="8">39.85</text>
<text top="383" left="504" width="31" height="13" font="8">38.08</text>
<text top="383" left="574" width="31" height="13" font="8">35.34</text>
<text top="383" left="645" width="31" height="13" font="8">34.53</text>
<text top="383" left="710" width="14" height="13" font="8">24</text>
<text top="400" left="363" width="42" height="13" font="8">(34.61)</text>
<text top="400" left="430" width="42" height="13" font="8">(35.04)</text>
<text top="400" left="498" width="42" height="13" font="8">(36.67)</text>
<text top="400" left="569" width="42" height="13" font="8">(39.51)</text>
<text top="400" left="639" width="42" height="13" font="8">(40.44)</text>
<text top="417" left="212" width="52" height="13" font="8">Pegsol28</text>
<text top="417" left="297" width="45" height="13" font="8">1010.65</text>
<text top="417" left="369" width="31" height="13" font="8">21.77</text>
<text top="417" left="435" width="31" height="13" font="8">21.31</text>
<text top="417" left="504" width="31" height="13" font="8">20.75</text>
<text top="417" left="574" width="31" height="13" font="8">20.47</text>
<text top="417" left="645" width="31" height="13" font="8">19.64</text>
<text top="417" left="710" width="14" height="13" font="8">35</text>
<text top="433" left="363" width="42" height="13" font="8">(46.42)</text>
<text top="433" left="430" width="42" height="13" font="8">(47.43)</text>
<text top="433" left="498" width="42" height="13" font="8">(48.71)</text>
<text top="433" left="569" width="42" height="13" font="8">(49.37)</text>
<text top="433" left="639" width="42" height="13" font="8">(51.46)</text>
<text top="450" left="206" width="64" height="13" font="8">Sokoban24</text>
<text top="450" left="297" width="45" height="13" font="8">2635.37</text>
<text top="450" left="369" width="31" height="13" font="8">57.29</text>
<text top="450" left="435" width="31" height="13" font="8">51.82</text>
<text top="450" left="504" width="31" height="13" font="8">50.99</text>
<text top="450" left="574" width="31" height="13" font="8">48.08</text>
<text top="450" left="645" width="31" height="13" font="8">46.51</text>
<text top="450" left="706" width="21" height="13" font="8">205</text>
<text top="467" left="363" width="42" height="13" font="8">(46.00)</text>
<text top="467" left="430" width="42" height="13" font="8">(50.86)</text>
<text top="467" left="498" width="42" height="13" font="8">(51.68)</text>
<text top="467" left="569" width="42" height="13" font="8">(54.81)</text>
<text top="467" left="639" width="42" height="13" font="8">(56.66)</text>
<text top="484" left="286" width="355" height="13" font="8">HDA*, with dummy processes on cores not used by HDA*</text>
<text top="501" left="206" width="65" height="13" font="8">Avg time</text>
<text top="501" left="307" width="24" height="13" font="8">n/a</text>
<text top="501" left="362" width="44" height="13" font="8">103.29</text>
<text top="501" left="429" width="44" height="13" font="8">102.62</text>
<text top="501" left="507" width="24" height="13" font="8">n/a</text>
<text top="501" left="568" width="44" height="13" font="8">100.35</text>
<text top="501" left="638" width="44" height="13" font="8">102.61</text>
<text top="518" left="212" width="52" height="13" font="8">Freecell7</text>
<text top="518" left="297" width="45" height="13" font="8">2864.64</text>
<text top="518" left="369" width="31" height="13" font="8">66.85</text>
<text top="518" left="435" width="31" height="13" font="8">70.59</text>
<text top="518" left="504" width="31" height="13" font="8">72.13</text>
<text top="518" left="574" width="31" height="13" font="8">77.49</text>
<text top="518" left="645" width="31" height="13" font="8">76.15</text>
<text top="518" left="710" width="14" height="13" font="8">41</text>
<text top="535" left="363" width="42" height="13" font="8">(42.85)</text>
<text top="535" left="430" width="42" height="13" font="8">(40.58)</text>
<text top="535" left="498" width="42" height="13" font="8">(39.71)</text>
<text top="535" left="569" width="42" height="13" font="8">(36.97)</text>
<text top="535" left="639" width="42" height="13" font="8">(37.62)</text>
<text top="552" left="214" width="49" height="13" font="8">Rover12</text>
<text top="552" left="297" width="45" height="13" font="8">1149.74</text>
<text top="552" left="369" width="31" height="13" font="8">17.68</text>
<text top="552" left="435" width="31" height="13" font="8">35.07</text>
<text top="552" left="504" width="31" height="13" font="8">19.30</text>
<text top="552" left="574" width="31" height="13" font="8">34.47</text>
<text top="552" left="645" width="31" height="13" font="8">34.98</text>
<text top="552" left="710" width="14" height="13" font="8">19</text>
<text top="568" left="363" width="42" height="13" font="8">(65.03)</text>
<text top="568" left="430" width="42" height="13" font="8">(32.78)</text>
<text top="568" left="498" width="42" height="13" font="8">(59.57)</text>
<text top="568" left="569" width="42" height="13" font="8">(33.35)</text>
<text top="568" left="639" width="42" height="13" font="8">(32.87)</text>
<text top="585" left="210" width="56" height="13" font="8">Satellite7</text>
<text top="585" left="309" width="21" height="13" font="8">n/a</text>
<text top="585" left="365" width="38" height="13" font="8">502.51</text>
<text top="585" left="432" width="38" height="13" font="8">466.16</text>
<text top="585" left="500" width="38" height="13" font="8">535.86</text>
<text top="585" left="571" width="38" height="13" font="8">445.64</text>
<text top="585" left="641" width="38" height="13" font="8">462.22</text>
<text top="585" left="710" width="14" height="13" font="8">21</text>
<text top="602" left="203" width="71" height="13" font="8">ZenoTrav11</text>
<text top="602" left="300" width="38" height="13" font="8">546.67</text>
<text top="602" left="369" width="31" height="13" font="8">16.58</text>
<text top="602" left="435" width="31" height="13" font="8">21.17</text>
<text top="602" left="504" width="31" height="13" font="8">20.15</text>
<text top="602" left="574" width="31" height="13" font="8">19.89</text>
<text top="602" left="645" width="31" height="13" font="8">20.54</text>
<text top="602" left="710" width="14" height="13" font="8">14</text>
<text top="619" left="363" width="42" height="13" font="8">(32.97)</text>
<text top="619" left="430" width="42" height="13" font="8">(25.82)</text>
<text top="619" left="498" width="42" height="13" font="8">(27.13)</text>
<text top="619" left="569" width="42" height="13" font="8">(27.48)</text>
<text top="619" left="639" width="42" height="13" font="8">(26.61)</text>
<text top="636" left="198" width="81" height="13" font="8">PipesNoTk24</text>
<text top="636" left="297" width="45" height="13" font="8">1396.29</text>
<text top="636" left="369" width="31" height="13" font="8">40.34</text>
<text top="636" left="435" width="31" height="13" font="8">44.99</text>
<text top="636" left="504" width="31" height="13" font="8">45.26</text>
<text top="636" left="574" width="31" height="13" font="8">43.79</text>
<text top="636" left="645" width="31" height="13" font="8">43.80</text>
<text top="636" left="710" width="14" height="13" font="8">24</text>
<text top="652" left="363" width="42" height="13" font="8">(34.61)</text>
<text top="652" left="430" width="42" height="13" font="8">(31.04)</text>
<text top="652" left="498" width="42" height="13" font="8">(30.85)</text>
<text top="652" left="569" width="42" height="13" font="8">(31.89)</text>
<text top="652" left="639" width="42" height="13" font="8">(31.88)</text>
<text top="669" left="212" width="52" height="13" font="8">Pegsol28</text>
<text top="669" left="297" width="45" height="13" font="8">1010.65</text>
<text top="669" left="369" width="31" height="13" font="8">21.77</text>
<text top="669" left="435" width="31" height="13" font="8">22.88</text>
<text top="669" left="509" width="21" height="13" font="8">n/a</text>
<text top="669" left="574" width="31" height="13" font="8">23.23</text>
<text top="669" left="645" width="31" height="13" font="8">23.44</text>
<text top="669" left="710" width="14" height="13" font="8">35</text>
<text top="686" left="363" width="42" height="13" font="8">(46.42)</text>
<text top="686" left="430" width="42" height="13" font="8">(44.17)</text>
<text top="686" left="509" width="21" height="13" font="8">n/a</text>
<text top="686" left="569" width="42" height="13" font="8">(43.51)</text>
<text top="686" left="639" width="42" height="13" font="8">(43.12)</text>
<text top="703" left="206" width="64" height="13" font="8">Sokoban24</text>
<text top="703" left="297" width="45" height="13" font="8">2635.37</text>
<text top="703" left="369" width="31" height="13" font="8">57.29</text>
<text top="703" left="435" width="31" height="13" font="8">57.45</text>
<text top="703" left="504" width="31" height="13" font="8">56.07</text>
<text top="703" left="574" width="31" height="13" font="8">57.92</text>
<text top="703" left="645" width="31" height="13" font="8">57.16</text>
<text top="703" left="706" width="21" height="13" font="8">205</text>
<text top="719" left="363" width="42" height="13" font="8">(46.00)</text>
<text top="719" left="430" width="42" height="13" font="8">(45.87)</text>
<text top="719" left="498" width="42" height="13" font="8">(47.00)</text>
<text top="719" left="569" width="42" height="13" font="8">(45.50)</text>
<text top="719" left="639" width="42" height="13" font="8">(46.11)</text>
<text top="751" left="189" width="538" height="16" font="5">Table 5: 64-core scaling results with no dummy (upper half) and with</text>
<text top="771" left="189" width="538" height="16" font="5">dummy processes (bottom half). Time, speedup and plan length are shown.</text>
<text top="792" left="189" width="538" height="16" font="5">Notice the increase in the average time caused by adding dummy processes.</text>
<text top="812" left="189" width="538" height="16" font="5">Experiments were performed on a HPC cluster connected by a 20Gb Inﬁni-</text>
<text top="832" left="189" width="538" height="16" font="5">band network, where each node has eight 2.4GHz AMD dual core Opteron</text>
<text top="853" left="189" width="388" height="16" font="5">processors (total 16 cores per node) and 32 GB RAM.</text>
<text top="921" left="189" width="538" height="16" font="5">performance improves as the 64 cores are distributed among an increasing</text>
<text top="942" left="189" width="538" height="16" font="5">number of nodes. On the other hand, in the conﬁgurations with dummy</text>
<text top="962" left="189" width="538" height="16" font="5">processes (Table <a href="pdfxml.html#24">5, </a>bottom half), local memory access within a node be-</text>
<text top="982" left="189" width="538" height="16" font="5">comes equally congested regardless of the number of nodes, so there is no</text>
<text top="1036" left="449" width="16" height="16" font="5">24</text>
</page>
<page number="25" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">beneﬁt to distributing the cores. Once the local memory access overhead</text>
<text top="219" left="189" width="538" height="16" font="5">is equalized for all conﬁgurations (4-64 nodes), variations in performance</text>
<text top="240" left="189" width="538" height="16" font="5">(if any present) among conﬁgurations could be explained by the overhead</text>
<text top="260" left="189" width="538" height="16" font="5">of inter-node communication. We notice, however, that the diﬀerences are</text>
<text top="280" left="189" width="538" height="16" font="5">small in row “Avg time” in the bottom half of Table <a href="pdfxml.html#24">5. </a>Even on a per-</text>
<text top="300" left="189" width="538" height="16" font="5">instance basis, for most of the instances, the performance degradation as</text>
<text top="321" left="189" width="433" height="16" font="5">the number of nodes increases from 4 to 64 is within 20%<a href="pdfxml.html#25">.</a></text>
<text top="318" left="621" width="13" height="12" font="6"><a href="pdfxml.html#25">11</a></text>
<text top="321" left="646" width="80" height="16" font="5">This shows</text>
<text top="341" left="189" width="538" height="16" font="5">that communications among nodes is not a critical bottleneck for HDA* on</text>
<text top="361" left="189" width="197" height="16" font="5">the type of cluster we used.</text>
<text top="404" left="189" width="26" height="17" font="2">4.3</text>
<text top="404" left="235" width="386" height="17" font="2">Results on the 24-Puzzle on a HPC Cluster</text>
<text top="436" left="189" width="538" height="16" font="5">Next, we evaluated HDA* on the 24-puzzle, using an application-speciﬁc</text>
<text top="456" left="189" width="538" height="16" font="5">solver based on code provided by Korf, which uses a disjoint pattern database</text>
<text top="477" left="189" width="538" height="16" font="5">heuristic <a href="pdfxml.html#44">[12]</a>. We replaced the IDA* search strategy with A* and HDA*.</text>
<text top="497" left="189" width="538" height="16" font="5">In the original code, each state has two redundant halves, trading memory</text>
<text top="517" left="189" width="538" height="16" font="5">for a faster state processing. While this makes sense for IDA*, it is not</text>
<text top="538" left="189" width="538" height="16" font="5">the best trade-oﬀ for HDA*. Thus, we reduce the state size to one half</text>
<text top="558" left="189" width="538" height="16" font="5">and compute the missing half on demand with a loop of 25 iterations per</text>
<text top="578" left="189" width="538" height="16" font="5">state. Other parts of the program, including the disjoint pattern database</text>
<text top="599" left="189" width="538" height="16" font="5">heuristic, were used as is. As benchmark instances, we used the 50-instance</text>
<text top="619" left="189" width="538" height="16" font="5">set of 24-puzzles reported in <a href="pdfxml.html#44">[12]</a>, Table 2. We excluded the time required</text>
<text top="639" left="189" width="328" height="16" font="5">to read pattern databases from the hard-disk.</text>
<text top="660" left="214" width="512" height="16" font="5">First, we investigated the scalability of HDA* as by solving two instances,</text>
<text top="680" left="189" width="538" height="16" font="5">p1 and p29, on 1-1024 cores, using the maximal number of cores per node.</text>
<text top="700" left="189" width="538" height="16" font="5">These instances are two of the most diﬃcult ones solved by serial A* with</text>
<text top="721" left="189" width="538" height="16" font="5">128GB RAM. For a given number of cores, the speedups reported in Table <a href="pdfxml.html#26">6</a></text>
<text top="741" left="189" width="538" height="16" font="5">are lower than most speedups observed in planning (Table <a href="pdfxml.html#19">2)</a>. As previously</text>
<text top="761" left="189" width="538" height="16" font="5">mentioned in Section <a href="pdfxml.html#1">1, </a>a key diﬀerence between domain-independent plan-</text>
<text top="782" left="189" width="538" height="16" font="5">ning and the 24-puzzle is that individual states are processed much faster</text>
<text top="802" left="189" width="538" height="16" font="5">in the application speciﬁc 24-puzzle solver, and therefore parallel overheads</text>
<text top="822" left="189" width="538" height="16" font="5">have a greater weight in the total running time. Note the speedup degraded</text>
<text top="843" left="189" width="538" height="16" font="5">as the number of cores grows from 512 to 1024. Similarly to planning (Sec-</text>
<text top="863" left="189" width="538" height="16" font="5">tion <a href="pdfxml.html#17">4.2)</a>, we observe a signiﬁcant search overhead on 1024 cores (Table <a href="pdfxml.html#26">6,</a></text>
<text top="893" left="202" width="11" height="7" font="7">11</text>
<text top="896" left="214" width="513" height="13" font="8">A notable exception is the Rover12 instance. The reason is that Rover12 exhibits</text>
<text top="912" left="189" width="538" height="13" font="8">unusually large variation in the number of states expanded during the search by HDA*.</text>
<text top="929" left="189" width="538" height="13" font="8">For example, on the 64 core run on 4 nodes, 23,230,170 states were expanded, but for the 64</text>
<text top="945" left="189" width="538" height="13" font="8">core run on 16 nodes, 37,484,322 states were expanded. The diﬀerence in runtimes caused</text>
<text top="961" left="189" width="538" height="13" font="8">by this large variation in state expansion subsumes the local memory access contention</text>
<text top="978" left="189" width="186" height="13" font="8">eﬀect described in this section.</text>
<text top="1036" left="449" width="16" height="16" font="5">25</text>
</page>
<page number="26" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">Nodes expanded and Figure <a href="pdfxml.html#27">2)</a>. We observe that these generated nodes</text>
<text top="219" left="189" width="538" height="16" font="5">are not duplicates that are already saved in the closed list, which indicates</text>
<text top="240" left="189" width="538" height="16" font="5">that processors are performing (unsuccessful) speculative search, resulting</text>
<text top="260" left="189" width="538" height="16" font="5">in wasted work and degraded scaling of performance. A deeper understand-</text>
<text top="280" left="189" width="538" height="16" font="5">ing the behavior of HDA* with many cores remains an important direction</text>
<text top="300" left="189" width="108" height="16" font="5">as future work.</text>
<text top="333" left="264" width="42" height="13" font="8">1 core</text>
<text top="333" left="336" width="56" height="13" font="8">64 cores</text>
<text top="333" left="429" width="64" height="13" font="8">128 cores</text>
<text top="333" left="525" width="64" height="13" font="8">512 cores</text>
<text top="333" left="617" width="72" height="13" font="8">1024 cores</text>
<text top="349" left="338" width="53" height="13" font="8">4 nodes</text>
<text top="349" left="435" width="53" height="13" font="8">8 nodes</text>
<text top="349" left="527" width="61" height="13" font="8">32 nodes</text>
<text top="349" left="623" width="61" height="13" font="8">64 nodes</text>
<text top="369" left="372" width="172" height="13" font="8">Execution time and speedup</text>
<text top="386" left="226" width="15" height="13" font="8">p1</text>
<text top="386" left="266" width="38" height="13" font="8">828.07</text>
<text top="386" left="325" width="78" height="13" font="8">30.13 (27.48)</text>
<text top="386" left="422" width="78" height="13" font="8">16.93 (48.91)</text>
<text top="386" left="521" width="71" height="13" font="8">8.94 (92.63)</text>
<text top="386" left="614" width="78" height="13" font="8">15.95 (51.92)</text>
<text top="403" left="223" width="21" height="13" font="8">p29</text>
<text top="403" left="262" width="45" height="13" font="8">1144.36</text>
<text top="403" left="325" width="78" height="13" font="8">39.17 (29.22)</text>
<text top="403" left="422" width="78" height="13" font="8">20.55 (55.69)</text>
<text top="403" left="518" width="78" height="13" font="8">8.00 (143.05)</text>
<text top="403" left="614" width="78" height="13" font="8">13.92 (82.20)</text>
<text top="423" left="391" width="128" height="15" font="8">Nodes expanded ×10</text>
<text top="420" left="518" width="5" height="7" font="7">6</text>
<text top="439" left="281" width="7" height="13" font="8">1</text>
<text top="439" left="340" width="48" height="13" font="8">64 cores</text>
<text top="439" left="433" width="55" height="13" font="8">128 cores</text>
<text top="439" left="529" width="55" height="13" font="8">512 cores</text>
<text top="439" left="622" width="62" height="13" font="8">1024 cores</text>
<text top="456" left="342" width="46" height="13" font="8">4 nodes</text>
<text top="456" left="438" width="46" height="13" font="8">8 nodes</text>
<text top="456" left="531" width="53" height="13" font="8">32 nodes</text>
<text top="456" left="627" width="53" height="13" font="8">64 nodes</text>
<text top="472" left="226" width="15" height="13" font="8">p1</text>
<text top="472" left="275" width="21" height="13" font="8">120</text>
<text top="472" left="354" width="21" height="13" font="8">175</text>
<text top="472" left="451" width="21" height="13" font="8">188</text>
<text top="472" left="547" width="21" height="13" font="8">360</text>
<text top="472" left="638" width="31" height="13" font="8">1,151</text>
<text top="490" left="223" width="21" height="13" font="8">p29</text>
<text top="490" left="275" width="21" height="13" font="8">160</text>
<text top="490" left="354" width="21" height="13" font="8">218</text>
<text top="490" left="451" width="21" height="13" font="8">225</text>
<text top="490" left="547" width="21" height="13" font="8">307</text>
<text top="490" left="643" width="21" height="13" font="8">960</text>
<text top="510" left="390" width="129" height="15" font="8">Nodes generated ×10</text>
<text top="507" left="519" width="5" height="7" font="7">6</text>
<text top="526" left="226" width="15" height="13" font="8">p1</text>
<text top="526" left="275" width="21" height="13" font="8">382</text>
<text top="526" left="354" width="21" height="13" font="8">559</text>
<text top="526" left="451" width="21" height="13" font="8">603</text>
<text top="526" left="541" width="31" height="13" font="8">1,161</text>
<text top="526" left="638" width="31" height="13" font="8">3,704</text>
<text top="543" left="223" width="21" height="13" font="8">p29</text>
<text top="543" left="275" width="21" height="13" font="8">513</text>
<text top="543" left="354" width="21" height="13" font="8">706</text>
<text top="543" left="451" width="21" height="13" font="8">728</text>
<text top="543" left="547" width="21" height="13" font="8">999</text>
<text top="543" left="638" width="31" height="13" font="8">3,122</text>
<text top="563" left="356" width="203" height="13" font="8">Load balance wrt node expansion</text>
<text top="580" left="340" width="48" height="13" font="8">64 cores</text>
<text top="580" left="433" width="55" height="13" font="8">128 cores</text>
<text top="580" left="529" width="55" height="13" font="8">512 cores</text>
<text top="580" left="622" width="62" height="13" font="8">1024 cores</text>
<text top="596" left="342" width="46" height="13" font="8">4 nodes</text>
<text top="596" left="438" width="46" height="13" font="8">8 nodes</text>
<text top="596" left="531" width="53" height="13" font="8">32 nodes</text>
<text top="596" left="627" width="53" height="13" font="8">64 nodes</text>
<text top="613" left="226" width="15" height="13" font="8">p1</text>
<text top="613" left="352" width="24" height="13" font="8">1.19</text>
<text top="613" left="449" width="24" height="13" font="8">1.33</text>
<text top="613" left="545" width="24" height="13" font="8">1.32</text>
<text top="613" left="641" width="24" height="13" font="8">1.34</text>
<text top="630" left="223" width="21" height="13" font="8">p29</text>
<text top="630" left="352" width="24" height="13" font="8">1.21</text>
<text top="630" left="449" width="24" height="13" font="8">1.32</text>
<text top="630" left="545" width="24" height="13" font="8">1.33</text>
<text top="630" left="641" width="24" height="13" font="8">1.31</text>
<text top="650" left="349" width="218" height="13" font="8">Node expansion per second per core</text>
<text top="667" left="340" width="48" height="13" font="8">64 cores</text>
<text top="667" left="433" width="55" height="13" font="8">128 cores</text>
<text top="667" left="529" width="55" height="13" font="8">512 cores</text>
<text top="667" left="622" width="62" height="13" font="8">1024 cores</text>
<text top="683" left="342" width="46" height="13" font="8">4 nodes</text>
<text top="683" left="438" width="46" height="13" font="8">8 nodes</text>
<text top="683" left="531" width="53" height="13" font="8">32 nodes</text>
<text top="683" left="627" width="53" height="13" font="8">64 nodes</text>
<text top="700" left="226" width="15" height="13" font="8">p1</text>
<text top="700" left="339" width="52" height="13" font="8">90959.02</text>
<text top="700" left="435" width="52" height="13" font="8">87087.08</text>
<text top="700" left="531" width="52" height="13" font="8">78633.16</text>
<text top="700" left="627" width="52" height="13" font="8">70473.91</text>
<text top="717" left="223" width="21" height="13" font="8">p29</text>
<text top="717" left="339" width="52" height="13" font="8">87238.84</text>
<text top="717" left="435" width="52" height="13" font="8">85637.71</text>
<text top="717" left="531" width="52" height="13" font="8">75113.93</text>
<text top="717" left="627" width="52" height="13" font="8">67385.12</text>
<text top="748" left="189" width="538" height="16" font="5">Table 6: 24 puzzle scaling. Experiments were performed on a HPC cluster</text>
<text top="769" left="189" width="538" height="16" font="5">connected by a 20Gb Inﬁniband network, where each node has eight 2.4GHz</text>
<text top="789" left="189" width="538" height="16" font="5">AMD dual core Opteron processors (total 16 cores per node) and 32 GB</text>
<text top="809" left="189" width="44" height="16" font="5">RAM.</text>
<text top="865" left="214" width="513" height="16" font="5">Next, we investigate the eﬀect of scaling the number of processing nodes</text>
<text top="886" left="189" width="538" height="16" font="5">(machines) for the 24-puzzle. We ran the solver on a set of 64 nodes, which</text>
<text top="906" left="189" width="538" height="16" font="5">have 1024 cores in total, and varied the number of cores used per node</text>
<text top="926" left="189" width="538" height="16" font="5">between 1-16, so that 64-1024 cores were used. The runtimes are shown in</text>
<text top="947" left="189" width="538" height="16" font="5">Table <a href="pdfxml.html#49">7. </a>IDA* solves all 50 instances <a href="pdfxml.html#44">[12] </a>whereas with our sequential A*</text>
<text top="967" left="189" width="434" height="16" font="5">search only 5 instances can be solved with 32GB of memory.</text>
<text top="987" left="214" width="513" height="16" font="5">As shown in Table <a href="pdfxml.html#49">7, </a>using 512 cores (4GB/core), 31 out of the 50 prob-</text>
<text top="1036" left="449" width="16" height="16" font="5">26</text>
</page>
<page number="27" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="9" size="7" family="Times" color="#000000"/>
	<fontspec id="10" size="7" family="Times" color="#000000"/>
<text top="462" left="269" width="26" height="9" font="9"> 1e+08</text>
<text top="427" left="269" width="26" height="9" font="9"> 2e+08</text>
<text top="393" left="269" width="26" height="9" font="9"> 3e+08</text>
<text top="358" left="269" width="26" height="9" font="9"> 4e+08</text>
<text top="324" left="269" width="26" height="9" font="9"> 5e+08</text>
<text top="289" left="269" width="26" height="9" font="9"> 6e+08</text>
<text top="255" left="269" width="26" height="9" font="9"> 7e+08</text>
<text top="220" left="269" width="26" height="9" font="9"> 8e+08</text>
<text top="471" left="295" width="12" height="9" font="9"> 64</text>
<text top="471" left="645" width="22" height="9" font="9"> 1024</text>
<text top="386" left="253" width="0" height="9" font="10">Average expanded nodes</text>
<text top="486" left="436" width="84" height="9" font="9">Number of processors</text>
<text top="206" left="415" width="126" height="9" font="9">Expanded nodes in the 24 puzzle</text>
<text top="537" left="189" width="538" height="16" font="5">Figure 2: Illustrating the growth of the search overhead in the 24 puzzle</text>
<text top="557" left="189" width="538" height="16" font="5">as the number of cores increases. We plot the number of expanded nodes</text>
<text top="578" left="189" width="538" height="16" font="5">averaged over instances solved with all 5 conﬁgurations of cores (i.e., 64,</text>
<text top="598" left="189" width="538" height="16" font="5">128, 256, 512, 1024 cores). Experiments were performed on a HPC cluster</text>
<text top="618" left="189" width="538" height="16" font="5">connected by a 20Gb Inﬁniband network, where each node has eight 2.4GHz</text>
<text top="638" left="189" width="538" height="16" font="5">AMD dual core Opteron processors (total 16 cores per node) and 32 GB</text>
<text top="659" left="189" width="44" height="16" font="5">RAM.</text>
<text top="705" left="189" width="538" height="16" font="5">lems were solved. With 256 cores (8GB/core), 34 problems were solved.</text>
<text top="726" left="189" width="538" height="16" font="5">With 128 cores (16GB/core), 36 problems were solved, and with 64 cores</text>
<text top="746" left="189" width="538" height="16" font="5">(32GB/core), 39 problems were solved. That is, reducing the number of</text>
<text top="767" left="189" width="538" height="15" font="5">processes down to one process per node increases the number of solved in-</text>
<text top="787" left="189" width="50" height="15" font="5">stances</text>
<text top="786" left="239" width="5" height="16" font="5">.</text>
<text top="807" left="214" width="513" height="16" font="5">A closer look at the trade-oﬀs involved explains this behavior. First there</text>
<text top="827" left="189" width="538" height="16" font="5">is the reduction in execution time when performing a given amount of work</text>
<text top="847" left="189" width="538" height="16" font="5">with more cores. Indeed, Table <a href="pdfxml.html#49">7 </a>indicates that, if an instance is solved</text>
<text top="868" left="189" width="538" height="16" font="5">by a larger number of cores, the time decreases as more cores were used.</text>
<text top="888" left="189" width="538" height="16" font="5">The notable exception is the conﬁguration with 1024 cores where the large</text>
<text top="908" left="189" width="538" height="16" font="5">search overhead actually degrades the time performance. Other exceptions</text>
<text top="929" left="189" width="538" height="16" font="5">are instances that are easy for 64 cores, such as p25, p38, p40 and p44, which</text>
<text top="949" left="189" width="538" height="16" font="5">were solved in a few seconds and left little room for further improvement in</text>
<text top="969" left="189" width="61" height="16" font="5">runtime.</text>
<text top="990" left="214" width="513" height="16" font="5">On the other hand, using more cores per processing node can lead to</text>
<text top="1036" left="449" width="16" height="16" font="5">27</text>
</page>
<page number="28" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">solving fewer 24-puzzle instances. Suppose that k unique states need to</text>
<text top="219" left="189" width="538" height="16" font="5">be stored in open/closed in order to solve a problem. A sequential search</text>
<text top="240" left="189" width="538" height="16" font="5">with enough memory capacity to hold k states can solve this problem. If</text>
<text top="260" left="189" width="538" height="16" font="5">HDA* allocated work perfectly equally among the processors, and there was</text>
<text top="280" left="189" width="538" height="16" font="5">no search overhead, then the partitioning of memory among n cores would</text>
<text top="300" left="189" width="538" height="16" font="5">have no negative impact. In practice, load balancing is imperfect, and search</text>
<text top="321" left="189" width="538" height="16" font="5">overhead is non-zero, so increasing the number of cores (for a ﬁxed amount</text>
<text top="341" left="189" width="500" height="16" font="5">of aggregate RAM) increases the chance of failure on a hard problem.</text>
<text top="361" left="214" width="513" height="16" font="5">When analyzing the relative impact of search overhead vs. RAM par-</text>
<text top="382" left="189" width="538" height="16" font="5">titioning, we found that the former plays a signiﬁcantly greater role in the</text>
<text top="402" left="189" width="538" height="16" font="5">reduction of the number of solved instances. Figure <a href="pdfxml.html#27">2 </a>shows that the search</text>
<text top="422" left="189" width="538" height="16" font="5">overhead increases signiﬁcantly with the number of cores, meaning that more</text>
<text top="443" left="189" width="538" height="16" font="5">nodes must be stored in the open/closed lists. The increase rate gets steeper</text>
<text top="463" left="189" width="538" height="16" font="5">from 512 to 1024 cores. On the other hand, our use of static RAM partition-</text>
<text top="483" left="189" width="538" height="16" font="5">ing (as opposed to a more ﬂexible, dynamic partitioning) is not a signiﬁcant</text>
<text top="504" left="189" width="538" height="16" font="5">bottleneck. We collected statistics about the size of the open and closed</text>
<text top="524" left="189" width="538" height="16" font="5">lists for all processors, and observed that when the ﬁrst processor runs out</text>
<text top="544" left="189" width="538" height="16" font="5">of memory, most other processors have almost exhausted their memory as</text>
<text top="565" left="189" width="538" height="16" font="5">well. This means that there is little opportunity for improvements to be</text>
<text top="585" left="189" width="502" height="16" font="5">made by using a more ﬂexible, dynamic memory partitioning method.</text>
<text top="605" left="214" width="513" height="16" font="5">In Section <a href="pdfxml.html#23">4.2.2, </a>we observed slowdowns in domain-independent plan-</text>
<text top="626" left="189" width="538" height="16" font="5">ning as the number of cores increased, and ascribed the slowdown to local</text>
<text top="646" left="189" width="538" height="16" font="5">memory bus contention. Similarly, in the 24-puzzle, the node expansion</text>
<text top="666" left="189" width="538" height="16" font="5">rate decreases by 30% or more as the number of cores per processing node</text>
<text top="687" left="189" width="538" height="16" font="5">increased. Since each core sends generated successors to their home proces-</text>
<text top="707" left="189" width="538" height="16" font="5">sors in HDA*, the number of total messages exchanged among processors</text>
<text top="727" left="189" width="538" height="16" font="5">increases with a larger number of cores. Therefore, another factor of the</text>
<text top="748" left="189" width="538" height="16" font="5">slower node expansion rate may be related to the procedure of dealing with</text>
<text top="768" left="189" width="538" height="16" font="5">messages. Even with asynchronous communications, HDA* must deal with</text>
<text top="788" left="189" width="443" height="16" font="5">a larger number of messages as the number of cores increases.</text>
<text top="831" left="189" width="26" height="17" font="2">4.4</text>
<text top="831" left="235" width="487" height="17" font="2">Scaling Behavior on Planning on a Commodity Cluster</text>
<text top="863" left="189" width="538" height="16" font="5">While the previous set of large-scale experiments were performed on a cam-</text>
<text top="883" left="189" width="538" height="16" font="5">pus high-performance computing cluster, we also evaluated the scalability</text>
<text top="904" left="189" width="538" height="16" font="5">of HDA* on a commodity cluster. Each node in the cluster has 16GB RAM</text>
<text top="924" left="189" width="538" height="16" font="5">and two 2.33GHZ quad-core Xeon L5410 processors (total of 8 cores per</text>
<text top="944" left="189" width="538" height="16" font="5">node). The nodes are connected with standard 1Gb(x2, bonded) Ethernet.</text>
<text top="965" left="189" width="538" height="16" font="5">The main diﬀerence between the HPC cluster and this commodity cluster</text>
<text top="985" left="189" width="538" height="16" font="5">is the network bandwidth (20Gbps Inﬁniband vs. 1Gbps(x2) Ethernet). A</text>
<text top="1036" left="449" width="16" height="16" font="5">28</text>
</page>
<page number="29" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">machine with the same processors but with 32GB RAM was used to measure</text>
<text top="219" left="189" width="208" height="16" font="5">the performance of serial A*.</text>
<text top="240" left="214" width="513" height="16" font="5">The results for 1, 16, 32, and 64 cores are shown in Tables <a href="pdfxml.html#50">8-9. </a>The</text>
<text top="260" left="189" width="538" height="16" font="5">speedups were between 4.09-9.49 for 16 cores, 5.28-20.68 for 32 cores, 14.28-</text>
<text top="280" left="189" width="538" height="16" font="5">31.66 for 64 cores. These are signiﬁcantly lower speedups compared to the</text>
<text top="300" left="189" width="538" height="16" font="5">16-64 core results on the HPC cluster (Table <a href="pdfxml.html#19">2)</a>, so network performance</text>
<text top="321" left="189" width="538" height="16" font="5">clearly has a signiﬁcant eﬀect on the scalability of HDA*. Although the</text>
<text top="341" left="189" width="538" height="16" font="5">scaling behavior suﬀers compared to the HPC cluster, note that Freecell6,</text>
<text top="361" left="189" width="538" height="16" font="5">Satellite7, Sokoban26, Blocks11-1, and Logistics00-8-1 could only be solved</text>
<text top="382" left="189" width="538" height="16" font="5">using 64 cores, and Rover6 could only be solved with 32 or 64 cores, so the</text>
<text top="402" left="189" width="538" height="16" font="5">advantage of being able to exploit large amounts of aggregate distributed</text>
<text top="422" left="189" width="538" height="16" font="5">memory is clear on the commodity cluster as well. In addition, as shown</text>
<text top="443" left="189" width="538" height="16" font="5">below in Section <a href="pdfxml.html#31">6, </a>HDA* signiﬁcantly outperforms TDS, the previous state</text>
<text top="463" left="189" width="538" height="16" font="5">of the art algorithm, when the two are compared on this commodity cluster.</text>
<text top="506" left="189" width="39" height="16" font="5">4.4.1</text>
<text top="506" left="246" width="480" height="16" font="5">The Eﬀect of the Number of States Packed into Each Mes-</text>
<text top="527" left="246" width="35" height="16" font="5">sage</text>
<text top="557" left="189" width="538" height="16" font="5">In HDA*, each state generation necessitates sending the state from processor</text>
<text top="578" left="189" width="538" height="16" font="5">where a state is generated to the processor which “owns” the state. Sending</text>
<text top="598" left="189" width="538" height="16" font="5">a message from processor P to Q each time a state owned by Q is generated</text>
<text top="618" left="189" width="538" height="16" font="5">at P may result in excessive communication overhead, as well as overhead for</text>
<text top="639" left="189" width="538" height="16" font="5">creating/manipulating MPI message structures. In order to amortize these</text>
<text top="659" left="189" width="538" height="16" font="5">overheads, Romein et al. <a href="pdfxml.html#44">[13]</a>, in their work on TDS, proposed packing</text>
<text top="679" left="189" width="301" height="16" font="5">multiple states with the same destination.</text>
<text top="700" left="214" width="513" height="16" font="5">On the other hand, packing too many states into a message from pro-</text>
<text top="720" left="189" width="538" height="16" font="5">cessor P to Q might result in degraded performance for two reasons. First,</text>
<text top="740" left="189" width="538" height="16" font="5">the destination Q might be starved for work and be idle. Second, too much</text>
<text top="761" left="189" width="538" height="16" font="5">packing can result in search overhead, as follows. Consider a state S on an</text>
<text top="781" left="189" width="538" height="16" font="5">optimal path, which is “delayed” from being sent to its owner because the</text>
<text top="801" left="189" width="538" height="16" font="5">processor which generated S is waiting to pack more states into the message</text>
<text top="822" left="189" width="538" height="16" font="5">containing S. In the meantime, the owner of S is expanding states which</text>
<text top="842" left="189" width="538" height="16" font="5">are worse than S and possibly sending those successors to ﬁll up the open</text>
<text top="862" left="189" width="289" height="16" font="5">list of their owner processors, and so on.</text>
<text top="883" left="214" width="513" height="16" font="5">We compared packing 10, 100, and 1000 states per message on the com-</text>
<text top="903" left="189" width="538" height="16" font="5">modity cluster using 64 cores, using the same benchmark instances in Table</text>
<text top="923" left="189" width="538" height="16" font="5"><a href="pdfxml.html#50">8, </a>except that the Airport17 instance was excluded because it could not</text>
<text top="944" left="189" width="538" height="16" font="5">be solved using 10 states per message (therefore, the average speedup and</text>
<text top="964" left="189" width="538" height="16" font="5">search overhead for 100 states per message in Table <a href="pdfxml.html#51">10 </a>is slightly diﬀerent</text>
<text top="984" left="189" width="538" height="16" font="5">than the average speedup and search overhead shown in Table <a href="pdfxml.html#50">8)</a>. Table <a href="pdfxml.html#51">10</a></text>
<text top="1036" left="449" width="16" height="16" font="5">29</text>
</page>
<page number="30" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">shows that packing 100 states per message results in the best performance.</text>
<text top="219" left="189" width="538" height="16" font="5">The results for 1000 states show that the average search overhead (17.89%)</text>
<text top="240" left="189" width="538" height="16" font="5">is signiﬁcantly higher compared to packing 100 states per message (2.69%).</text>
<text top="287" left="189" width="12" height="20" font="4">5</text>
<text top="287" left="225" width="519" height="20" font="4">Hash-Based Work Distribution vs. Random Work</text>
<text top="314" left="225" width="329" height="20" font="4">Distribution on a HPC Cluster</text>
<text top="354" left="189" width="538" height="16" font="5">Kumar et al. <a href="pdfxml.html#45">[28] </a>and Karp and Zhang <a href="pdfxml.html#45">[29] </a>proposed a simple, random work</text>
<text top="375" left="189" width="538" height="16" font="5">distribution strategy for best-ﬁrst search where generated nodes are sent to</text>
<text top="395" left="189" width="538" height="16" font="5">a random processor. While this is similar to HDA* in that a randomiza-</text>
<text top="415" left="189" width="538" height="16" font="5">tion mechanism is used to distribute work, the diﬀerence is that duplicate</text>
<text top="436" left="189" width="538" height="16" font="5">states are not necessarily sent to the same processor, since a state has no</text>
<text top="456" left="189" width="538" height="16" font="5">“owner”. Although duplicates are pruned locally at each processor, there</text>
<text top="476" left="189" width="538" height="16" font="5">is no global duplicate detection, so in the worst case, a state can be in the</text>
<text top="497" left="189" width="341" height="16" font="5">local open/closed lists of every single processor.</text>
<text top="517" left="214" width="512" height="16" font="5">We evaluated this “Random” work distribution strategy on our Fast-</text>
<text top="537" left="189" width="538" height="16" font="5">Downward based domain-independent planner on a HPC cluster. First,</text>
<text top="558" left="189" width="538" height="16" font="5">we attempted to compare HDA* and Random using 16 cores, 2GB per</text>
<text top="578" left="189" width="538" height="16" font="5">core. However, the Random strategy failed to solve any of the test problems</text>
<text top="598" left="189" width="538" height="16" font="5">in this conﬁguration – all of the runs failed due to memory exhaustion.</text>
<text top="619" left="189" width="538" height="16" font="5">This indicated that, due to the lack of (global) duplicate detection, the</text>
<text top="639" left="189" width="538" height="16" font="5">random work distribution strategy requires much more RAM to solve our</text>
<text top="659" left="189" width="538" height="16" font="5">benchmarks. Hence we performed a comparison using 16 cores, 32GB per</text>
<text top="680" left="189" width="538" height="16" font="5">core (as with the experiments in Section <a href="pdfxml.html#23">4.2.2, </a>this conﬁguration left 15 of</text>
<text top="700" left="189" width="538" height="16" font="5">the 16 cores on each processing node idle, in order to maximize memory</text>
<text top="720" left="189" width="538" height="16" font="5">available per core). The results are shown in Table <a href="pdfxml.html#51">11. </a>The execution</text>
<text top="741" left="189" width="538" height="16" font="5">time and number of nodes expanded by HDA* is more than an order of</text>
<text top="761" left="189" width="538" height="16" font="5">magnitude less than those of the random work distribution strategy. In</text>
<text top="781" left="189" width="538" height="16" font="5">fact, the random work distribution strategy is slower than the sequential</text>
<text top="802" left="189" width="538" height="16" font="5">A* algorithm because of large search overhead. The load balance is similar</text>
<text top="822" left="189" width="538" height="16" font="5">for both HDA* and random work distribution, indicating that hash-based</text>
<text top="842" left="189" width="538" height="16" font="5">work distribution is successfully distributing the work as evenly as a pure,</text>
<text top="863" left="189" width="538" height="16" font="5">randomized strategy. These results clearly demonstrate the beneﬁt of using</text>
<text top="883" left="189" width="538" height="16" font="5">hash-based work distribution in order to perform global duplicate detection</text>
<text top="903" left="189" width="181" height="16" font="5">as well as load balancing.</text>
<text top="1036" left="449" width="16" height="16" font="5">30</text>
</page>
<page number="31" position="absolute" top="0" left="0" height="1188" width="918">
<text top="195" left="189" width="12" height="20" font="4">6</text>
<text top="195" left="225" width="502" height="20" font="4">Comparison of HDA* with TDS on a Commod-</text>
<text top="222" left="225" width="114" height="20" font="4">ity Cluster</text>
<text top="262" left="189" width="538" height="16" font="5">We compared the performance of HDA* with TDS <a href="pdfxml.html#44">[14] </a>on a commodity</text>
<text top="283" left="189" width="538" height="16" font="5">cluster using 1-64 cores. When 64 cores were used, the time limit of HDA*</text>
<text top="303" left="189" width="538" height="16" font="5">and TDS was set to 20 minutes per instance. As described in Section <a href="pdfxml.html#28">4.4,</a></text>
<text top="323" left="189" width="538" height="16" font="5">each node in the cluster has 16GB RAM and two 2.33GHZ quad-core Xeon</text>
<text top="344" left="189" width="538" height="16" font="5">L5410 processors (total of 8 cores per node). These nodes are connected</text>
<text top="364" left="189" width="170" height="16" font="5">with 1Gb(x2) Ethernet.</text>
<text top="384" left="214" width="512" height="16" font="5">Our implementation of TDS uses a transposition table implementation</text>
<text top="405" left="189" width="538" height="16" font="5">based on <a href="pdfxml.html#47">[44]</a>, where the table entry replacement policy is a batch replace-</text>
<text top="425" left="189" width="538" height="16" font="5">ment policy which sorts entries according to access frequency and periodi-</text>
<text top="445" left="189" width="538" height="16" font="5">cally frees 30% of the entries (preferring to keep most frequently accessed</text>
<text top="465" left="189" width="58" height="16" font="5">entries)<a href="pdfxml.html#31">.</a></text>
<text top="463" left="246" width="13" height="12" font="6"><a href="pdfxml.html#31">12</a></text>
<text top="465" left="275" width="451" height="16" font="5">We incorporated techniques to overcome higher latency in a</text>
<text top="486" left="189" width="538" height="16" font="5">lower-bandwidth network described in <a href="pdfxml.html#44">[14]</a>, such as their modiﬁcation to the</text>
<text top="506" left="189" width="538" height="16" font="5">termination detection algorithm. One important diﬀerence from Romein et</text>
<text top="526" left="189" width="538" height="16" font="5">al.’s implementation is that our TDS implementation delays state evalua-</text>
<text top="547" left="189" width="538" height="16" font="5">tion when a state is received by its home processor (called the late method</text>
<text top="567" left="189" width="538" height="16" font="5">in <a href="pdfxml.html#44">[14]</a>), because computing the heuristic value requires intensive computa-</text>
<text top="587" left="189" width="538" height="16" font="5">tion in planning. In contrast, due to a low overhead of evaluating states</text>
<text top="608" left="189" width="538" height="16" font="5">in Romein et al.’s applications, their implementation evaluates a state to</text>
<text top="628" left="189" width="538" height="16" font="5">check if that state can be discarded before it is migrated to its home pro-</text>
<text top="649" left="189" width="233" height="16" font="5">cessor (called the early method).</text>
<text top="669" left="214" width="513" height="16" font="5">Figure <a href="pdfxml.html#33">3 </a>provides a direct comparison between HDA* and TDS. It is re-</text>
<text top="689" left="189" width="538" height="16" font="5">stricted to those instances solved by both algorithms, for which it is possible</text>
<text top="709" left="189" width="538" height="16" font="5">to compute the ratios between performance measures such as time, expanded</text>
<text top="730" left="189" width="195" height="16" font="5">states and evaluated states<a href="pdfxml.html#31">.</a></text>
<text top="727" left="383" width="13" height="12" font="6"><a href="pdfxml.html#31">13</a></text>
<text top="730" left="404" width="323" height="16" font="5">HDA* is consistently faster, with a maximum</text>
<text top="750" left="189" width="538" height="16" font="5">speedup of about 65. Table <a href="pdfxml.html#52">12 </a>provides additional details, including actual</text>
<text top="770" left="189" width="538" height="16" font="5">times and numbers of expanded states. Furthermore, Table <a href="pdfxml.html#52">12 </a>details the</text>
<text top="791" left="189" width="538" height="16" font="5">results on a per-instance basis. It shows that, out of 35 instances, HDA*</text>
<text top="811" left="189" width="410" height="16" font="5">failed in one case (Blocks12-1) and TDS failed in 8 cases.</text>
<text top="831" left="214" width="513" height="16" font="5">There are several diﬀerences between HDA* and TDS that could cause</text>
<text top="858" left="202" width="11" height="7" font="7">12</text>
<text top="860" left="214" width="513" height="13" font="8">Although replacement based on subtree size performed best in sequential search <a href="pdfxml.html#47">[44]</a>,</text>
<text top="876" left="189" width="538" height="13" font="8">we did not implement this policy because subtree size computation would require extensive</text>
<text top="893" left="189" width="538" height="13" font="8">message passing in parallel search. Romein et al. describe that one important property of</text>
<text top="909" left="189" width="538" height="13" font="8">the TDS implementation of IDA* is that a child state does not report its search result to</text>
<text top="926" left="189" width="538" height="13" font="8">its parent and such a backpropagation is not necessary in their applications <a href="pdfxml.html#44">[14]</a>. However,</text>
<text top="942" left="189" width="529" height="13" font="8">with this replacement, a search result of a child must be propagated back to its parent.</text>
<text top="956" left="202" width="11" height="7" font="7">13</text>
<text top="959" left="214" width="513" height="13" font="8">Evaluated states are states which were not found in the OPEN/CLOSED set (in the</text>
<text top="975" left="189" width="463" height="13" font="8">case of HDA*), or not found in the transposition table (in the case of TDS).</text>
<text top="1036" left="449" width="16" height="16" font="5">31</text>
</page>
<page number="32" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">this signiﬁcant performance diﬀerence. Below, we ﬁrst enumerate these dif-</text>
<text top="219" left="189" width="538" height="16" font="5">ferences, and then consider how they apply to our data presented in Figure <a href="pdfxml.html#33">3</a></text>
<text top="240" left="189" width="98" height="16" font="5">and Table <a href="pdfxml.html#52">12.</a></text>
<text top="260" left="214" width="513" height="16" font="5">First, TDS is an iterative deepening strategy, so TDS will incur state</text>
<text top="280" left="189" width="538" height="16" font="5">reexpansion overhead, since many states will be reexpanded as the iteration</text>
<text top="300" left="189" width="133" height="16" font="5">f -bound increases.</text>
<text top="321" left="214" width="513" height="16" font="5">Second, there is a diﬀerence in state expansion policy, which results in</text>
<text top="341" left="189" width="538" height="16" font="5">diﬀerent search overhead (i.e., the number of unnecessary state generations</text>
<text top="361" left="189" width="538" height="16" font="5">compared to A*) for the two algorithms. HDA* opens states in a (processor-</text>
<text top="382" left="189" width="538" height="16" font="5">local) best-ﬁrst order. TDS opens states in a last-in-ﬁrst-out order in its local</text>
<text top="402" left="189" width="373" height="16" font="5">stack, subject to an iteration bound for the f -value.</text>
<text top="422" left="214" width="513" height="16" font="5">Third, each processor in TDS in planning needs memory not only for</text>
<text top="443" left="189" width="538" height="16" font="5">a transposition table and the merge-and-shrink abstraction, but also for a</text>
<text top="463" left="189" width="538" height="16" font="5">work stack. In our current implementation on the commodity cluster, each</text>
<text top="483" left="189" width="538" height="16" font="5">processor is allocated 2GB of memory. 1.2GB is allocated to the transposi-</text>
<text top="504" left="189" width="538" height="16" font="5">tion table and the abstraction. The remaining memory is reserved for the</text>
<text top="524" left="189" width="81" height="16" font="5">work stack<a href="pdfxml.html#32">.</a></text>
<text top="521" left="270" width="13" height="12" font="6"><a href="pdfxml.html#32">14</a></text>
<text top="524" left="293" width="434" height="16" font="5">Because of this, there may be cases where there is suﬃcient</text>
<text top="544" left="189" width="538" height="16" font="5">distributed memory in HDA* to solve an instance, but TDS (on the same</text>
<text top="565" left="189" width="538" height="16" font="5">machine) exhausts the space allocated for its distributed transposition table.</text>
<text top="585" left="189" width="538" height="16" font="5">In such a situation, TDS applies a replacement policy to replace some of its</text>
<text top="605" left="189" width="538" height="16" font="5">transposition table entries with newly expanded states. It is possible that</text>
<text top="626" left="189" width="538" height="16" font="5">valuable entries (states) in the table are replaced, resulting in wasted work</text>
<text top="646" left="189" width="262" height="16" font="5">later when these states are revisited.</text>
<text top="666" left="214" width="513" height="16" font="5">Fourth, TDS incurs synchronization overhead while all processors wait</text>
<text top="687" left="189" width="227" height="16" font="5">for the current iteration to end.</text>
<text top="707" left="214" width="512" height="16" font="5">In sequential heuristic search, standard IDA* has a potential advantage</text>
<text top="727" left="189" width="538" height="16" font="5">over A* in that state generation can be implemented extremely eﬃciently</text>
<text top="748" left="189" width="538" height="16" font="5">because a successor can be obtained by making an incremental change to</text>
<text top="768" left="189" width="538" height="16" font="5">the data structure representing the current state. Therefore, although IDA*</text>
<text top="788" left="189" width="538" height="16" font="5">searches less eﬃciently than A*, the faster state generation rate of IDA* can</text>
<text top="809" left="189" width="538" height="16" font="5">result in IDA* outperforming A* with respect to runtime. When a transpo-</text>
<text top="829" left="189" width="538" height="16" font="5">sition table is added to IDA*, state generation incurs a signiﬁcant overhead</text>
<text top="849" left="189" width="538" height="16" font="5">per state. The hash value of each generated state must be computed, and if</text>
<text top="879" left="202" width="11" height="7" font="7">14</text>
<text top="881" left="214" width="513" height="13" font="8">While Romein et al. state that the stack does not exceed 1MB in size in their appli-</text>
<text top="897" left="189" width="538" height="13" font="8">cations <a href="pdfxml.html#44">[14]</a>, we observed that the stack often used several hundred MB of memory. We</text>
<text top="914" left="189" width="538" height="13" font="8">hypothesize that our TDS implementation sends away more states when generating succes-</text>
<text top="930" left="189" width="538" height="13" font="8">sors, since our planning domains have much larger branching factors than their domains,</text>
<text top="947" left="189" width="538" height="13" font="8">such as 15-puzzle and Rubik’s cube. One idea to overcome this issue is to combine Dutt</text>
<text top="963" left="189" width="538" height="13" font="8">and Mahapatra’s technique in SEQ A* <a href="pdfxml.html#43">[6] </a>with TDS and restrict initiating parallelism.</text>
<text top="980" left="189" width="176" height="13" font="8">We leave this as future work.</text>
<text top="1036" left="449" width="16" height="16" font="5">32</text>
</page>
<page number="33" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="11" size="9" family="Times" color="#000000"/>
	<fontspec id="12" size="9" family="Times" color="#000000"/>
<text top="529" left="236" width="18" height="11" font="11"> 0.1</text>
<text top="428" left="245" width="9" height="11" font="11"> 1</text>
<text top="327" left="239" width="15" height="11" font="11"> 10</text>
<text top="226" left="233" width="21" height="11" font="11"> 100</text>
<text top="417" left="217" width="0" height="11" font="12">Ratio TDS/HDA*</text>
<text top="559" left="411" width="148" height="11" font="11">Instances ordered by time ratio</text>
<text top="209" left="450" width="71" height="11" font="11">HDA* vs TDS</text>
<text top="237" left="373" width="46" height="11" font="11">time ratio</text>
<text top="249" left="318" width="102" height="11" font="11">expanded nodes ratio</text>
<text top="261" left="318" width="102" height="11" font="11">evaluated nodes ratio</text>
<text top="612" left="189" width="538" height="16" font="5">Figure 3: Ratios TDS/HDA* on 64 cores. Experiments were performed on</text>
<text top="632" left="189" width="538" height="16" font="5">a commodity cluster connected by a 1Gb(x2) Ethernet network, where each</text>
<text top="653" left="189" width="538" height="16" font="5">node has two 2.33GHZ quad-core Xeon L5410 processors (total 8 cores per</text>
<text top="673" left="189" width="168" height="16" font="5">node) and 16GB RAM.</text>
<text top="724" left="189" width="538" height="16" font="5">there is a transposition table miss, some hashed representation of the state</text>
<text top="744" left="189" width="538" height="16" font="5">must be stored in the table. If state hashing can be implemented incremen-</text>
<text top="764" left="189" width="538" height="16" font="5">tally, and if the transposition table hit rate is high, the state generation rate</text>
<text top="785" left="189" width="538" height="16" font="5">for sequential IDA* may not be slowed down too much. However, in TDS,</text>
<text top="805" left="189" width="37" height="15" font="5">every</text>
<text top="805" left="231" width="496" height="16" font="5">distributed transposition table access requires a hashed representation</text>
<text top="825" left="189" width="538" height="16" font="5">of the state to be generated and sent to the owner process, which means that</text>
<text top="846" left="189" width="538" height="16" font="5">this parallel IDA* no longer has an inherently faster state generation rate</text>
<text top="866" left="189" width="121" height="16" font="5">than parallel A*.</text>
<text top="886" left="214" width="513" height="16" font="5">We now analyze how the diﬀerences between HDA* and TDS enumerated</text>
<text top="906" left="189" width="538" height="16" font="5">above explain the superior performance of HDA*. In Figure <a href="pdfxml.html#33">3, </a>the ratio of</text>
<text top="927" left="189" width="352" height="16" font="5">expanded states closely follows the runtime ratio<a href="pdfxml.html#33">.</a></text>
<text top="924" left="540" width="13" height="12" font="6"><a href="pdfxml.html#33">15</a></text>
<text top="927" left="561" width="165" height="16" font="5">On the other hand, the</text>
<text top="956" left="202" width="11" height="7" font="7">15</text>
<text top="959" left="218" width="509" height="13" font="8">The ratio of generated states (not shown to reduce clutter) is almost identical to the</text>
<text top="975" left="189" width="149" height="13" font="8">ratio of expanded states.</text>
<text top="1036" left="449" width="16" height="16" font="5">33</text>
</page>
<page number="34" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">ratio of evaluated states has a value close to 1 in most cases. The similarity in</text>
<text top="219" left="189" width="538" height="16" font="5">the number of evaluated states between HDA* and TDS suggests that both</text>
<text top="240" left="189" width="538" height="16" font="5">algorithms explore a similar number of unique states. In other words, the</text>
<text top="260" left="189" width="538" height="16" font="5">diﬀerence in the state expansion policy is not responsible for the performance</text>
<text top="280" left="189" width="538" height="16" font="5">gap between HDA* and TDS. Furthermore, the similarity in the number</text>
<text top="300" left="189" width="538" height="16" font="5">of evaluated states shows that the transposition table used by TDS is large</text>
<text top="321" left="189" width="538" height="16" font="5">enough to ﬁt most (unique) states generated during search, so the size of the</text>
<text top="341" left="189" width="538" height="16" font="5">transposition table did not limit the performance of TDS in this experiment.</text>
<text top="361" left="214" width="513" height="16" font="5">The diﬀerence in performance comes mostly from the fact that TDS</text>
<text top="382" left="189" width="538" height="16" font="5">re-expands many states as part of its iterative deepening, exploration strat-</text>
<text top="402" left="189" width="538" height="16" font="5">egy. This conclusion is supported by the close correspondence between the</text>
<text top="422" left="189" width="538" height="16" font="5">runtime ratio and the state expansion ratio. Also, it is consistent with the</text>
<text top="443" left="189" width="538" height="16" font="5">behavior of sequential A* and IDA* on our data. For example, in solving the</text>
<text top="463" left="189" width="538" height="16" font="5">Airport17 instance, both A* and IDA* evaluate 10,397,245 states. While A*</text>
<text top="483" left="189" width="538" height="16" font="5">expands only 7,126,967 states, IDA* expands 239,705,187 states, indicating</text>
<text top="504" left="189" width="282" height="16" font="5">that most of the states are reexpanded<a href="pdfxml.html#34">.</a></text>
<text top="501" left="471" width="13" height="12" font="6"><a href="pdfxml.html#34">16</a></text>
<text top="524" left="214" width="513" height="16" font="5">The synchronization overhead in TDS between iterations as all proces-</text>
<text top="544" left="189" width="538" height="16" font="5">sors wait for the iteration to end does not appear to be a signiﬁcant factor</text>
<text top="565" left="189" width="538" height="16" font="5">in most cases, which is consistent with Romein et al.’s results (if this was</text>
<text top="585" left="189" width="538" height="16" font="5">a signiﬁcant factor, then this would tend to consistently push the runtime</text>
<text top="605" left="189" width="358" height="16" font="5">ratio to be higher than the state expansion ratio).</text>
<text top="626" left="214" width="513" height="16" font="5">Next we consider the speedups obtained by HDA* and TDS over their se-</text>
<text top="646" left="189" width="538" height="16" font="5">quential counterparts, A* and IDA*. The speedup of TDS vs IDA* depends</text>
<text top="666" left="189" width="538" height="16" font="5">greatly on the amount of RAM memory available for the transposition table</text>
<text top="687" left="189" width="538" height="16" font="5">in IDA* and/or TDS. The larger the transposition table, the faster TDS</text>
<text top="707" left="189" width="538" height="16" font="5">and IDA* are. While it is possible to achieve drastically large (sometimes</text>
<text top="727" left="189" width="538" height="16" font="5">super linear) speedup over IDA* <a href="pdfxml.html#44">[13, 14]</a>, the speedup diminishes as IDA*</text>
<text top="748" left="189" width="538" height="16" font="5">has access to larger and larger transposition tables. We show in Figure <a href="pdfxml.html#35">4</a></text>
<text top="768" left="189" width="538" height="16" font="5">that, depending on the amount of RAM available to IDA*, the speedup of</text>
<text top="788" left="189" width="538" height="16" font="5">TDS vs IDA* can be either smaller or larger than speedup of HDA* vs A*.</text>
<text top="809" left="189" width="538" height="16" font="5">In this experiment, IDA* uses 1.5GB of RAM in one case and 26GB in the</text>
<text top="829" left="189" width="538" height="16" font="5">other. TDS uses 1.2GB × 64 cores, which adds up to 76.8GB. The time</text>
<text top="849" left="189" width="538" height="16" font="5">limit of serial IDA* was set to 1280 minutes (i.e., about 21.3 hours) per</text>
<text top="870" left="189" width="63" height="16" font="5">instance.</text>
<text top="896" left="202" width="11" height="7" font="7">16</text>
<text top="898" left="214" width="513" height="13" font="8">Our results suggest, as a future work topic, extending TDS to backpropagate search</text>
<text top="915" left="189" width="538" height="13" font="8">results. This could reduce the very high reexpansion overhead in planning, which did not</text>
<text top="931" left="189" width="225" height="13" font="8">occur in Romein et al.’s applications.</text>
<text top="1036" left="449" width="16" height="16" font="5">34</text>
</page>
<page number="35" position="absolute" top="0" left="0" height="1188" width="918">
<text top="529" left="253" width="9" height="11" font="11"> 1</text>
<text top="428" left="247" width="15" height="11" font="11"> 10</text>
<text top="327" left="241" width="21" height="11" font="11"> 100</text>
<text top="226" left="235" width="27" height="11" font="11"> 1000</text>
<text top="394" left="217" width="0" height="11" font="12">Speedup</text>
<text top="559" left="401" width="176" height="11" font="11">Instances ordered by HDA* speedup</text>
<text top="209" left="413" width="150" height="11" font="11">Speedup over sequential search</text>
<text top="237" left="335" width="63" height="11" font="11">HDA* vs A*</text>
<text top="249" left="297" width="101" height="11" font="11">TDS vs 1.5GB IDA*</text>
<text top="261" left="300" width="98" height="11" font="11">TDS vs 26GB IDA*</text>
<text top="612" left="189" width="538" height="16" font="5">Figure 4: Speedup over sequential search. A missing data point indicates</text>
<text top="632" left="189" width="538" height="16" font="5">that the sequential algorithm or both the sequential and the parallel algo-</text>
<text top="653" left="189" width="538" height="16" font="5">rithm failed to ﬁnd a solution. Experiments were performed on a commodity</text>
<text top="673" left="189" width="538" height="16" font="5">cluster connected by a 1Gb(x2) Ethernet network, where each node has two</text>
<text top="694" left="189" width="538" height="16" font="5">2.33GHZ quad-core Xeon L5410 processors (total 8 cores per node) and</text>
<text top="714" left="189" width="538" height="16" font="5">16GB RAM. A machine with the same processors but with 32GB RAM was</text>
<text top="734" left="189" width="376" height="16" font="5">used to measure the performance of serial A*/IDA*.</text>
<text top="783" left="189" width="26" height="17" font="2">6.1</text>
<text top="783" left="235" width="490" height="17" font="2">A Simple, Hybrid Strategy Combining HDA* and TDS</text>
<text top="815" left="189" width="538" height="16" font="5">The results above indicate that, for planning, HDA* signiﬁcantly outper-</text>
<text top="836" left="189" width="538" height="16" font="5">forms TDS on instances that can be solved within the memory available</text>
<text top="856" left="189" width="538" height="16" font="5">to HDA*. However, an advantage of TDS compared HDA* is that TDS</text>
<text top="876" left="189" width="538" height="16" font="5">will not terminate if the local transposition table at any processor becomes</text>
<text top="897" left="189" width="538" height="16" font="5">full. Although exhausting space in the table can result in degraded search</text>
<text top="917" left="189" width="538" height="16" font="5">eﬃciency (compared to the case when space is not exhausted), the replace-</text>
<text top="937" left="189" width="538" height="16" font="5">ment policy for the transposition table can try to maintain the most useful</text>
<text top="958" left="189" width="240" height="16" font="5">working set of states in the table.</text>
<text top="978" left="214" width="513" height="16" font="5">In contrast, HDA* will terminate and fail when memory is exhausted at</text>
<text top="1036" left="449" width="16" height="16" font="5">35</text>
</page>
<page number="36" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">any processor. Mechanisms which allow A*-based search to continue after</text>
<text top="219" left="189" width="538" height="16" font="5">memory is exhausted have been previously proposed, and in fact, PRA* <a href="pdfxml.html#43">[5]</a>,</text>
<text top="240" left="189" width="538" height="16" font="5">which HDA* is based upon, has a state retraction mechanism which frees</text>
<text top="260" left="189" width="538" height="16" font="5">memory by retracting some states at the search frontier. Determining an ef-</text>
<text top="280" left="189" width="538" height="16" font="5">fective state retraction policy involves tradeoﬀs similar to those encountered</text>
<text top="300" left="189" width="538" height="16" font="5">when designing transposition table replacement policies <a href="pdfxml.html#47">[44]</a>, and will be an</text>
<text top="321" left="189" width="538" height="16" font="5">interesting avenue of future work involving nontrivial extensions to HDA*,</text>
<text top="341" left="189" width="271" height="16" font="5">but is beyond the scope of this paper.</text>
<text top="361" left="214" width="512" height="16" font="5">We now consider instances which are solvable by TDS but not by HDA*.</text>
<text top="382" left="189" width="538" height="16" font="5">First, note that such problems are not very common. Given that HDA*</text>
<text top="402" left="189" width="538" height="16" font="5">and TDS explore a very similar set of unique states (as shown above), if a</text>
<text top="422" left="189" width="538" height="16" font="5">problem can not be solved by HDA*, it indicates that the instance is quite</text>
<text top="443" left="189" width="538" height="16" font="5">diﬃcult, and it is likely that TDS can not solve the problem either within a</text>
<text top="463" left="189" width="156" height="16" font="5">reasonable time limit.</text>
<text top="483" left="214" width="513" height="16" font="5">In our benchmark set, we identiﬁed the instances that HDA* failed to</text>
<text top="504" left="189" width="538" height="16" font="5">solve given 16, 32, and 64 cores, respectively (all with 2GB per core). Below,</text>
<text top="524" left="189" width="538" height="16" font="5">we indicate the names of the instances, as well as the amount of time HDA*</text>
<text top="544" left="189" width="452" height="16" font="5">executed before terminating with a memory exhaustion failure:</text>
<text top="583" left="213" width="513" height="16" font="5">• Failed with 16 cores: Freecell6 (269 sec), Rover6 (453 sec), Satellite7</text>
<text top="603" left="230" width="497" height="16" font="5">(573 sec), Sokoban26 (176 sec), Blocks11-1 (165 sec), Blocks12-1 (148</text>
<text top="623" left="230" width="217" height="16" font="5">sec), Logistics00-8-1 (416 sec);</text>
<text top="657" left="213" width="518" height="16" font="5">• Failed with 32 cores: Freecell6 (303 sec), Satellite7 (722 sec), Sokoban26</text>
<text top="677" left="230" width="496" height="16" font="5">(190 sec), Blocks11-1 (190 sec), Blocks12-1 (156 sec), Logistics00-8-1</text>
<text top="698" left="230" width="68" height="16" font="5">(399 sec);</text>
<text top="731" left="213" width="322" height="16" font="5">• Failed with 64 cores: Blocks12-1 (189 sec).</text>
<text top="770" left="214" width="513" height="16" font="5">Next, we attempted to solve these instances using TDS with 16, 32, and</text>
<text top="790" left="189" width="538" height="16" font="5">64 cores (all with 2GB/core), with an extended time limit of 1.5 hours for</text>
<text top="810" left="189" width="538" height="16" font="5">32 and 64 cores and 3 hours for 16 cores per instance. Below, we show the</text>
<text top="831" left="189" width="538" height="16" font="5">runtimes on the instances which were solved by TDS, but not by HDA*</text>
<text top="851" left="189" width="538" height="16" font="5">(TDS failed to ﬁnd a solution within the time limit on the other instances).</text>
<text top="889" left="213" width="408" height="16" font="5">• 16 cores: Blocks11-1 (2928 sec), Blocks12-1 (4139 sec);</text>
<text top="923" left="213" width="513" height="16" font="5">• 32 cores: Freecell6 (4350 sec), Blocks11-1 (974 sec), Blocks12-1 (1874</text>
<text top="943" left="230" width="32" height="16" font="5">sec);</text>
<text top="977" left="213" width="236" height="16" font="5">• 64 cores: Blocks12-1 (838 sec).</text>
<text top="1036" left="449" width="16" height="16" font="5">36</text>
</page>
<page number="37" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="214" width="513" height="16" font="5">This data shows that even with a 1.5 or 3 hour limit per instance, many</text>
<text top="219" left="189" width="538" height="16" font="5">instances that can not be solved by HDA* can not be solved by TDS. In</text>
<text top="240" left="189" width="538" height="16" font="5">addition, on the instances where HDA* fails and TDS succeeds, HDA* fails</text>
<text top="260" left="189" width="538" height="16" font="5">relatively quickly compared to the time required by TDS to solve the prob-</text>
<text top="280" left="189" width="538" height="16" font="5">lem. For example, with 32 cores HDA* runs out of memory in 156 seconds</text>
<text top="300" left="189" width="538" height="16" font="5">in solving Blocks12-1, and although TDS can solve this problem with 32</text>
<text top="321" left="189" width="223" height="16" font="5">cores, it required 1874 seconds.</text>
<text top="341" left="214" width="512" height="16" font="5">This suggests a very simple, hybrid approach which successfully combines</text>
<text top="361" left="189" width="538" height="16" font="5">the speed of HDA* and the ability of of TDS to eventually solve diﬃcult</text>
<text top="382" left="189" width="302" height="16" font="5">problems without running out of memory:</text>
<text top="402" left="214" width="513" height="16" font="5">Given an instance, ﬁrst, try to solve it with a slightly modiﬁed version of</text>
<text top="422" left="189" width="538" height="16" font="5">HDA* as follows: At every processor, we record the processor-local frontier</text>
<text top="443" left="189" width="538" height="16" font="5">value (the lowest f -cost in the OPEN list). If HDA* ﬁnds a solution, then</text>
<text top="463" left="189" width="538" height="16" font="5">it is returned. However, if HDA* exhausts memory at any processor, then it</text>
<text top="483" left="189" width="538" height="16" font="5">terminates with failure, and also returns the minimum frontier value among</text>
<text top="504" left="189" width="162" height="16" font="5">all of the processors, f</text>
<text top="511" left="350" width="23" height="8" font="6">min</text>
<text top="504" left="374" width="352" height="16" font="5">. Then (since HDA* failed), we next try to solve</text>
<text top="524" left="189" width="538" height="16" font="5">it using TDS, except that instead of starting with a iteration bound of</text>
<text top="544" left="189" width="538" height="16" font="5">h(initial), where h(initial) is the heuristic value at the initial state, we</text>
<text top="565" left="189" width="85" height="16" font="5">start with f</text>
<text top="572" left="273" width="23" height="8" font="6">min</text>
<text top="565" left="303" width="141" height="16" font="5">as the lower bound.</text>
<text top="585" left="214" width="512" height="16" font="5">This hybrid strategy ﬁrst applies HDA*. According to the data above,</text>
<text top="605" left="189" width="538" height="16" font="5">if HDA* succeeds, it will succeed signiﬁcantly faster than TDS would, and</text>
<text top="626" left="189" width="538" height="16" font="5">if it fails, it will fail relatively quickly. Upon failure, the hybrid starts TDS</text>
<text top="646" left="189" width="178" height="16" font="5">with a iteration bound f</text>
<text top="653" left="367" width="23" height="8" font="6">min</text>
<text top="646" left="397" width="330" height="16" font="5">in order to allow TDS to skip some iterations</text>
<text top="666" left="189" width="339" height="16" font="5">and avoid some of the wasted state expansions.</text>
<text top="687" left="214" width="513" height="16" font="5">On instances that can be solved by HDA*, the runtime for this hybrid</text>
<text top="707" left="189" width="538" height="16" font="5">will clearly be the same as for HDA*. On instances where HDA* fails but</text>
<text top="727" left="189" width="538" height="16" font="5">TDS would eventually succeed, the runtime for the hybrid would be similar</text>
<text top="748" left="189" width="538" height="16" font="5">to the runtime of TDS. We expect that the time spent in the failed run of</text>
<text top="768" left="189" width="538" height="16" font="5">HDA* will only be a small fraction of the time required to eventually solve</text>
<text top="788" left="189" width="269" height="16" font="5">the instance; furthermore, using the f</text>
<text top="795" left="458" width="23" height="8" font="6">min</text>
<text top="788" left="487" width="239" height="16" font="5">initial bound for TDS is expected</text>
<text top="809" left="189" width="538" height="16" font="5">to oﬀset some of the time spent in the failed HDA* run by eliminating some</text>
<text top="829" left="189" width="212" height="16" font="5">of wasted expansions in TDS.</text>
<text top="849" left="214" width="513" height="16" font="5">We applied this hybrid to the instances which we identiﬁed above as</text>
<text top="870" left="189" width="538" height="16" font="5">instances which caused HDA* to fail. The results are presented in Table <a href="pdfxml.html#53">13.</a></text>
<text top="890" left="189" width="538" height="16" font="5">They show that, in most cases where HDA* fails, the runtimes for the hy-</text>
<text top="910" left="189" width="538" height="16" font="5">brid are comparable to the runtimes for TDS, i.e., there is no signiﬁcant</text>
<text top="931" left="189" width="538" height="16" font="5">penalty for trying HDA* ﬁrst and failing before running TDS. This shows</text>
<text top="951" left="189" width="538" height="16" font="5">that the hybrid successfully combines the strengths of both HDA* and TDS</text>
<text top="971" left="189" width="538" height="16" font="5">while avoiding their disadvantages, and does so while avoiding excessive</text>
<text top="991" left="189" width="168" height="16" font="5">hybridization overhead.</text>
<text top="1036" left="449" width="16" height="16" font="5">37</text>
</page>
<page number="38" position="absolute" top="0" left="0" height="1188" width="918">
<text top="195" left="189" width="12" height="20" font="4">7</text>
<text top="195" left="225" width="147" height="20" font="4">Related Work</text>
<text top="235" left="189" width="538" height="16" font="5">We have discussed the related work on parallelizing search by partitioning</text>
<text top="256" left="189" width="538" height="16" font="5">the search space in Section <a href="pdfxml.html#4">2. </a>Here, we review other approaches to paral-</text>
<text top="276" left="189" width="185" height="16" font="5">lelizing search algorithms.</text>
<text top="296" left="214" width="513" height="16" font="5">One approach is to parallelize the computation done during the process-</text>
<text top="317" left="189" width="538" height="16" font="5">ing of a single search node. A well-known example of this is the specialized</text>
<text top="337" left="189" width="538" height="16" font="5">hardware used for move generation in the Deep Blue chess computer <a href="pdfxml.html#47">[45]</a>.</text>
<text top="357" left="189" width="538" height="16" font="5">Another example is parallel evaluation of nodes (parallel playout) in Monte</text>
<text top="378" left="189" width="215" height="16" font="5">Carlo Tree Search for Go <a href="pdfxml.html#47">[46]</a>.</text>
<text top="398" left="214" width="512" height="16" font="5">A parallel planning algorithm which parallelizes the computation at each</text>
<text top="418" left="189" width="538" height="16" font="5">node is the Operator Distribution Method for parallel Planning (ODMP)</text>
<text top="439" left="189" width="538" height="16" font="5">by Vrakas, Refanidis, and Vlahavas <a href="pdfxml.html#47">[47]</a>. ODMP is a method for paralleliz-</text>
<text top="459" left="189" width="538" height="16" font="5">ing heuristic, state-space planning, which is a type of domain-independent</text>
<text top="479" left="189" width="538" height="16" font="5">planning where the goal is to ﬁnd some (possibly suboptimal) solution. In</text>
<text top="500" left="189" width="538" height="16" font="5">ODMP, there is a single, controlling thread, and several planning threads.</text>
<text top="520" left="189" width="538" height="16" font="5">The controlling thread is responsible for initializing and maintaining the</text>
<text top="540" left="189" width="538" height="16" font="5">current search state. At each step of the controlling thread main loop, the</text>
<text top="560" left="189" width="538" height="16" font="5">controlling thread generates the applicable operators, inserts them in an</text>
<text top="581" left="189" width="91" height="15" font="5">operator pool</text>
<text top="581" left="280" width="447" height="16" font="5">, and activates the planning threads. Each planning thread in-</text>
<text top="601" left="189" width="538" height="16" font="5">dependently takes an operator from this shared operator pool, computes the</text>
<text top="622" left="189" width="538" height="16" font="5">grounded actions, generates the resulting states, evaluates the states with</text>
<text top="642" left="189" width="538" height="16" font="5">the heuristic function, and stores the new state and its heuristic value in a</text>
<text top="663" left="189" width="95" height="15" font="5">global agenda</text>
<text top="662" left="289" width="438" height="16" font="5">data structure which is accessible from the controller thread.</text>
<text top="683" left="189" width="538" height="16" font="5">After the operator pool is empty and all planning threads have completed</text>
<text top="703" left="189" width="538" height="16" font="5">their work, the controlling thread extracts the best new state from the global</text>
<text top="723" left="189" width="538" height="16" font="5">agenda, assigning it to the new, current state. This continues until a plan</text>
<text top="744" left="189" width="62" height="16" font="5">is found.</text>
<text top="764" left="214" width="512" height="16" font="5">Another approach is to run a diﬀerent search algorithm on each parallel</text>
<text top="784" left="189" width="538" height="16" font="5">process. Each process executes mostly independently, with periodic com-</text>
<text top="804" left="189" width="538" height="16" font="5">munication of information between processors. This approach, which is a</text>
<text top="825" left="189" width="538" height="16" font="5">parallel version of an algorithm portfolio <a href="pdfxml.html#47">[48, 49]</a>, seeks to exploit the long-</text>
<text top="845" left="189" width="538" height="16" font="5">tailed runtime distribution behavior encountered in search algorithms <a href="pdfxml.html#47">[50]</a></text>
<text top="865" left="189" width="538" height="16" font="5">by using diﬀerent versions of search algorithms to search diﬀerent (poten-</text>
<text top="886" left="189" width="538" height="16" font="5">tially overlapping) portions of the search space. Each processor starts at the</text>
<text top="906" left="189" width="538" height="16" font="5">same root and searches the search space using its own strategy. An exam-</text>
<text top="926" left="189" width="538" height="16" font="5">ple of this is the ManySAT solver <a href="pdfxml.html#47">[51]</a>, a SAT solver in which each process</text>
<text top="947" left="189" width="538" height="16" font="5">executes a diﬀerent version of a DPLL-based backtracking solver. Lemmas</text>
<text top="967" left="189" width="538" height="16" font="5">(implied clauses learned during search) are exchanged among the processes.</text>
<text top="987" left="189" width="497" height="16" font="5">The system terminates when one of the processes solves the problem.</text>
<text top="1036" left="449" width="16" height="16" font="5">38</text>
</page>
<page number="39" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="214" width="512" height="16" font="5">A third approach is parallel-window search for IDA* <a href="pdfxml.html#47">[52]</a>. In parallel</text>
<text top="219" left="189" width="538" height="16" font="5">window IDA*, each processor is assigned the same root node for the search</text>
<text top="240" left="189" width="538" height="16" font="5">tree, but is assigned a diﬀerent bound – that is, each processor is assigned a</text>
<text top="260" left="189" width="538" height="16" font="5">diﬀerent, independent iteration of IDA*. When a node ﬁnishes an iteration,</text>
<text top="280" left="189" width="538" height="16" font="5">it is assigned the next highest bound which has not yet been assigned to a</text>
<text top="300" left="189" width="538" height="16" font="5">processor. The ﬁrst solution found by parallel window IDA* is not necessar-</text>
<text top="321" left="189" width="538" height="16" font="5">ily optimal. However, if, after ﬁnding a solution in the processor assigned</text>
<text top="341" left="189" width="538" height="16" font="5">bound b, we wait until all processes with bound less than b complete, then</text>
<text top="361" left="189" width="371" height="16" font="5">the optimality of the best solution found is assured.</text>
<text top="382" left="214" width="513" height="16" font="5">Vidal et al. <a href="pdfxml.html#48">[53] </a>introduce a parallel version of the KBFS algorithm <a href="pdfxml.html#44">[17]</a>.</text>
<text top="402" left="189" width="538" height="16" font="5">In this approach, each thread expands one node from the Open list at a</text>
<text top="422" left="189" width="538" height="16" font="5">time. As each expansion step requires operations on the Open and Closed</text>
<text top="443" left="189" width="538" height="16" font="5">list, synchronization is needed to ensure that only one thread at a time can</text>
<text top="463" left="189" width="538" height="16" font="5">perform such operations. Experiments are reported for satisﬁcing planning,</text>
<text top="483" left="189" width="448" height="16" font="5">as opposed to our work, which is focused on optimal planning.</text>
<text top="504" left="214" width="513" height="16" font="5">The best parallelization strategy for a search algorithm depends on prop-</text>
<text top="524" left="189" width="538" height="16" font="5">erties of the search space, as well as the parallel architecture on which the</text>
<text top="544" left="189" width="538" height="16" font="5">search algorithm is executed. The EUREKA system <a href="pdfxml.html#48">[54] </a>used machine learn-</text>
<text top="565" left="189" width="538" height="16" font="5">ing to automatically conﬁgure parallel IDA* for various problems (including</text>
<text top="585" left="189" width="337" height="16" font="5">nonlinear planning) and machine architectures.</text>
<text top="633" left="189" width="12" height="20" font="4">8</text>
<text top="633" left="225" width="281" height="20" font="4">Discussion and Conclusion</text>
<text top="673" left="189" width="538" height="16" font="5">This paper investigated the use of hash-based work distribution to par-</text>
<text top="693" left="189" width="538" height="16" font="5">allelize A* for hard graph search problems such as domain-independent</text>
<text top="714" left="189" width="538" height="16" font="5">planning. We implemented Hash-Distributed A*, a simple, scalable par-</text>
<text top="734" left="189" width="538" height="16" font="5">allelization of A*. The key idea, which was ﬁrst used in Parallel Retract-</text>
<text top="754" left="189" width="538" height="16" font="5">ing A* <a href="pdfxml.html#43">[5] </a>is to distribute work according to the hash value for generated</text>
<text top="775" left="189" width="538" height="16" font="5">states. HDA* is a simple implementation of this idea, which, to our knowl-</text>
<text top="795" left="189" width="538" height="16" font="5">edge, has not been previously evaluated in depth. Unlike PRA*, which</text>
<text top="815" left="189" width="538" height="16" font="5">was a synchronous algorithm due to its retraction mechanism, HDA* oper-</text>
<text top="836" left="189" width="538" height="16" font="5">ates completely asynchronously. Also, unlike previous work such as PRA*</text>
<text top="856" left="189" width="538" height="16" font="5">and GOHA <a href="pdfxml.html#43">[6]</a>, which implemented hash-based work distribution on vari-</text>
<text top="876" left="189" width="538" height="16" font="5">ants of A*, HDA* is a straightforward implementation of hash-based work</text>
<text top="897" left="189" width="538" height="16" font="5">distribution for standard A*. We evaluated HDA* as a replacement for</text>
<text top="917" left="189" width="538" height="16" font="5">the sequential A* search engine for the state-of-the-art, optimal sequential</text>
<text top="937" left="189" width="538" height="16" font="5">planner, Fast Downward+LFPA (Explicit State Abstraction Heuristic) <a href="pdfxml.html#43">[3]</a>.</text>
<text top="958" left="189" width="538" height="16" font="5">We also evaluated HDA* on the 24-puzzle by implementing a parallel solver</text>
<text top="978" left="189" width="538" height="16" font="5">with a disjoint pattern database heuristic <a href="pdfxml.html#44">[12]</a>, based on code provided by</text>
<text top="1036" left="449" width="16" height="16" font="5">39</text>
</page>
<page number="40" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="37" height="16" font="5">Korf.</text>
<text top="219" left="214" width="512" height="16" font="5">Our experimental evaluation shows that HDA* scales well in several</text>
<text top="240" left="189" width="538" height="16" font="5">parallel hardware conﬁgurations, including a single shared memory machine,</text>
<text top="260" left="189" width="538" height="16" font="5">a high-performance computing cluster using Inﬁniband interconnects, and a</text>
<text top="280" left="189" width="324" height="16" font="5">local cluster with 1Gb(x2) Ethernet network.</text>
<text top="300" left="214" width="512" height="16" font="5">While HDA* is naturally suited for distributed memory parallel search</text>
<text top="321" left="189" width="538" height="16" font="5">on a distributed memory cluster of machines, we have shown that HDA*</text>
<text top="341" left="189" width="538" height="16" font="5">also achieves reasonable speedup on a single, shared memory machine with</text>
<text top="361" left="189" width="538" height="16" font="5">up to 8 cores, with results that are superior to PRA*. HDA* yields speedups</text>
<text top="382" left="189" width="538" height="16" font="5">of 3.8-6.6 on 8 cores. Burns et al. have recently proposed PBNF, a shared</text>
<text top="402" left="189" width="538" height="16" font="5">memory, parallel best-ﬁrst search algorithm, and showed that PBNF outper-</text>
<text top="422" left="189" width="538" height="16" font="5">forms HDA* on planning in shared memory environments <a href="pdfxml.html#48">[55]</a>. On the other</text>
<text top="443" left="189" width="538" height="16" font="5">hand, while HDA* is not necessarily the fastest algorithm on a shared mem-</text>
<text top="463" left="189" width="538" height="16" font="5">ory environment, HDA* is simpler than PBNF (which is based on structured</text>
<text top="483" left="189" width="538" height="16" font="5">duplicate detection techniques). Furthermore, HDA* is suited for larger,</text>
<text top="504" left="189" width="538" height="16" font="5">distributed memory clusters, while PBNF is designed for shared memory</text>
<text top="524" left="189" width="70" height="16" font="5">machines.</text>
<text top="544" left="214" width="512" height="16" font="5">Evaluation of HDA* on a large high-performance cluster using 1-1024</text>
<text top="565" left="189" width="538" height="16" font="5">cores showed that parallel eﬃciency between 30-70% could be obtained for</text>
<text top="585" left="189" width="538" height="16" font="5">domain-independent planning. HDA* exploits the large amount of dis-</text>
<text top="605" left="189" width="538" height="16" font="5">tributed memory available on a modern cluster. Using up to 2 terabytes</text>
<text top="626" left="189" width="538" height="16" font="5">of aggregate RAM, HDA* was able to compute optimal solutions to larger</text>
<text top="646" left="189" width="538" height="16" font="5">planning benchmark problems than was previously possible on a single ma-</text>
<text top="666" left="189" width="538" height="16" font="5">chine. Comparison with a randomized work distribution strategy which per-</text>
<text top="687" left="189" width="538" height="16" font="5">forms load balancing but no duplicate detection <a href="pdfxml.html#45">[28, 29] </a>showed the simple</text>
<text top="707" left="189" width="538" height="16" font="5">hash-based duplicate detection mechanism is essential to the performance of</text>
<text top="727" left="189" width="538" height="16" font="5">HDA*. The scaling behavior of HDA* on a small commodity cluster with</text>
<text top="748" left="189" width="538" height="16" font="5">1Gb(x2) Ethernet show similar trends as on the HPC cluster, but the slower</text>
<text top="768" left="189" width="327" height="16" font="5">communications resulted in smaller speedups.</text>
<text top="788" left="214" width="513" height="16" font="5">On the 24-puzzle, HDA* scales up fairly well (speed-wise) to around 512</text>
<text top="809" left="189" width="538" height="16" font="5">cores, but speedups degrade beyond that due to large amounts of search</text>
<text top="829" left="189" width="538" height="16" font="5">overhead (nodes expanded by HDA* but not by sequential A*, due to the</text>
<text top="849" left="189" width="538" height="16" font="5">distributed, local nature of the open lists). We showed that since memory</text>
<text top="870" left="189" width="538" height="16" font="5">capacity is the primary concern in A* for the 24-puzzle, using fewer cores</text>
<text top="890" left="189" width="538" height="16" font="5">per processing node (maximizing the memory available per core) results in</text>
<text top="910" left="189" width="165" height="16" font="5">solving more instances.</text>
<text top="931" left="214" width="513" height="16" font="5">Much of the previous literature on parallel search has focused on maxi-</text>
<text top="951" left="189" width="538" height="16" font="5">mizing usage of all available CPU cores. Our results indicate that this ap-</text>
<text top="971" left="189" width="538" height="16" font="5">proach can be suboptimal. In fact, the best performance can be obtained by</text>
<text top="991" left="189" width="538" height="16" font="5">keeping many of the available processors idle. This is a result of the preva-</text>
<text top="1036" left="449" width="16" height="16" font="5">40</text>
</page>
<page number="41" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">lent architecture in current clusters, which are composed of commodity,</text>
<text top="219" left="189" width="538" height="16" font="5">multicore shared-memory processors connected via a high-speed network.</text>
<text top="240" left="189" width="538" height="16" font="5">There are two distinct factors which can lead to suboptimal performance</text>
<text top="260" left="189" width="538" height="16" font="5">when CPU core usage is maximized. First, as we showed in Section <a href="pdfxml.html#23">4.2.2,</a></text>
<text top="280" left="189" width="538" height="16" font="5">contention for local memory on each machine becomes a signiﬁcant bottle-</text>
<text top="300" left="189" width="538" height="16" font="5">neck, so using all of the available cores on a machine results in performance</text>
<text top="321" left="189" width="538" height="16" font="5">degradation. Automatically determining the optimal number of cores to use</text>
<text top="341" left="189" width="538" height="16" font="5">per processing node in order to obtain the best tradeoﬀ between computa-</text>
<text top="361" left="189" width="538" height="16" font="5">tion and memory bandwidth is an area for future work. Second, in parallel</text>
<text top="382" left="189" width="538" height="16" font="5">best-ﬁrst search, there is a tradeoﬀ between the number of cores used per</text>
<text top="402" left="189" width="538" height="16" font="5">machine, and the fragmentation of the local open list. Fragmentation of</text>
<text top="422" left="189" width="538" height="16" font="5">the open list results in search overhead, because the local open lists are not</text>
<text top="443" left="189" width="538" height="16" font="5">aware of the current global best f -values. Developing mechanisms which</text>
<text top="463" left="189" width="445" height="16" font="5">seek to reduce this search overhead is an area for future work.</text>
<text top="483" left="214" width="513" height="16" font="5">Our comparison of HDA* with TDS showed that when HDA* had suf-</text>
<text top="504" left="189" width="538" height="16" font="5">ﬁcient memory to solve a problem, it signiﬁcantly outperformed TDS on</text>
<text top="524" left="189" width="538" height="16" font="5">our benchmark planning instances. We showed that this performance gap</text>
<text top="544" left="189" width="538" height="16" font="5">was due to reexpansion of states by TDS. We observed that on problem</text>
<text top="565" left="189" width="538" height="16" font="5">instances where HDA* fails due to memory exhaustion, TDS either fails</text>
<text top="585" left="189" width="538" height="16" font="5">due to exceeding the time limit, or TDS eventually solves the instance but</text>
<text top="605" left="189" width="538" height="16" font="5">requires a long time. Thus, we investigated a simple, hybrid strategy which</text>
<text top="626" left="189" width="538" height="16" font="5">ﬁrst executes HDA* until either the problem is solved or until memory is</text>
<text top="646" left="189" width="538" height="16" font="5">exhausted, and then executes TDS in case HDA* failed. We showed that</text>
<text top="666" left="189" width="538" height="16" font="5">this hybrid strategy eﬀectively combines the advantage of both HDA* and</text>
<text top="687" left="189" width="38" height="16" font="5">TDS.</text>
<text top="707" left="214" width="513" height="16" font="5">One particularly attractive feature of HDA* is its simplicity. Work dis-</text>
<text top="727" left="189" width="538" height="16" font="5">tribution and duplicate detection is done by a simple hash function, and</text>
<text top="748" left="189" width="538" height="16" font="5">there is no complex load balancing mechanism. All communications are</text>
<text top="768" left="189" width="538" height="16" font="5">asynchronous. As far as we know, HDA* is the simplest parallelization for</text>
<text top="788" left="189" width="538" height="16" font="5">A* which achieves both load balancing and duplicate detection. Despite</text>
<text top="809" left="189" width="538" height="16" font="5">its simplicity, HDA* achieves signiﬁcant speedup over the state-of-the-art</text>
<text top="829" left="189" width="538" height="16" font="5">solvers used in our experiments. Simplicity is very important for parallel</text>
<text top="849" left="189" width="538" height="16" font="5">algorithms, particularly for an algorithm that runs on multiple machines,</text>
<text top="870" left="189" width="538" height="16" font="5">as debugging a multi-machine, multi-core algorithm is extremely challeng-</text>
<text top="890" left="189" width="538" height="16" font="5">ing. In some preliminary eﬀorts to implement a distributed memory, work-</text>
<text top="910" left="189" width="538" height="16" font="5">stealing algorithm, we have found that it is signiﬁcantly more diﬃcult to</text>
<text top="931" left="189" width="538" height="16" font="5">implement correctly and eﬃciently compared to HDA*. Furthermore, us-</text>
<text top="951" left="189" width="538" height="16" font="5">ing the standard MPI message passing library, the same HDA* code can</text>
<text top="971" left="189" width="538" height="16" font="5">be recompiled and executed on a wide range of shared memory and dis-</text>
<text top="991" left="189" width="538" height="16" font="5">tributed clusters, making it simple to port HDA*. This is in contrast to</text>
<text top="1036" left="449" width="16" height="16" font="5">41</text>
</page>
<page number="42" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">more complex algorithms which depend on speciﬁc architectural features</text>
<text top="219" left="189" width="170" height="16" font="5">such as shared memory.</text>
<text top="240" left="214" width="512" height="16" font="5">This paper focused on the search phase of problem solving. Paralleliza-</text>
<text top="260" left="189" width="538" height="16" font="5">tion of the heuristic construction phase (e.g., computation of the abstrac-</text>
<text top="280" left="189" width="538" height="16" font="5">tion heuristic table <a href="pdfxml.html#43">[3] </a>and pattern database generation <a href="pdfxml.html#44">[12]</a>) is another area</text>
<text top="300" left="189" width="538" height="16" font="5">for future work. A related avenue for future work is more eﬀective use of</text>
<text top="321" left="189" width="538" height="16" font="5">memory for heuristic tables. Our current implementation of HDA* uses a</text>
<text top="341" left="189" width="538" height="16" font="5">single process per core. When executed on a (shared memory) multicore</text>
<text top="361" left="189" width="538" height="16" font="5">machine, our implementation of HDA* executes as a set of independent</text>
<text top="382" left="189" width="538" height="16" font="5">processes without sharing any memory resources among cores that are on</text>
<text top="402" left="189" width="538" height="16" font="5">the same machine. This means that the memory used for an abstraction</text>
<text top="422" left="189" width="538" height="16" font="5">heuristic in planning or for a pattern database in 24-puzzle is unnecessarily</text>
<text top="443" left="189" width="538" height="16" font="5">replicated n times on an n-core machine, which can be a signiﬁcant source</text>
<text top="463" left="189" width="538" height="16" font="5">of ineﬃciency in memory usage. We are currently investigating a hybrid,</text>
<text top="483" left="189" width="538" height="16" font="5">distributed/shared memory implementation of HDA* which eliminates this</text>
<text top="504" left="189" width="538" height="16" font="5">ineﬃciency. One possible approach is to distribute work among machines</text>
<text top="524" left="189" width="538" height="16" font="5">using hash-based distribution, but within a single machine incorporate tech-</text>
<text top="544" left="189" width="538" height="16" font="5">niques such as speculative expansion that have been shown to scale well on</text>
<text top="565" left="189" width="245" height="16" font="5">a shared memory environment <a href="pdfxml.html#44">[9]</a>.</text>
<text top="585" left="214" width="513" height="16" font="5">Finally, combining HDA* with the landmark cut heuristic in planning</text>
<text top="605" left="189" width="538" height="16" font="5"><a href="pdfxml.html#48">[56] </a>could further elucidate the behavior of HDA* when the heuristic func-</text>
<text top="626" left="189" width="538" height="16" font="5">tion computation is substantially more expensive than the abstraction based</text>
<text top="646" left="189" width="194" height="16" font="5">heuristic used in this work.</text>
<text top="694" left="189" width="190" height="20" font="4">Acknowledgments</text>
<text top="734" left="189" width="538" height="16" font="5">This research is supported by the JSPS Compview GCOE, the JST PRESTO</text>
<text top="754" left="189" width="538" height="16" font="5">program, and JSPS grants-in-aid for research. Most of this work was per-</text>
<text top="775" left="189" width="538" height="16" font="5">formed when the third author was aﬃliated with NICTA and the Australian</text>
<text top="795" left="189" width="538" height="16" font="5">National University. Thanks to Malte Helmert for providing the Fast Down-</text>
<text top="815" left="189" width="538" height="16" font="5">ward code, and to Rich Korf for providing his IDA* 24-puzzle solver, pattern</text>
<text top="836" left="189" width="538" height="16" font="5">database code, and puzzle instances. We thank the anonymous reviewers</text>
<text top="856" left="189" width="130" height="16" font="5">for their feedback.</text>
<text top="904" left="189" width="538" height="20" font="4">Appendix: Diﬀerences in Planning Results Com-</text>
<text top="931" left="189" width="402" height="20" font="4">pared to Previously Reported Results</text>
<text top="971" left="189" width="538" height="16" font="5">The planning experiments described in this paper are a superset of the</text>
<text top="991" left="189" width="538" height="16" font="5">experiments reported in a previous conference version of this work <a href="pdfxml.html#44">[15]</a>. For</text>
<text top="1036" left="449" width="16" height="16" font="5">42</text>
</page>
<page number="43" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">the common part (e.g., domain-independent planning with up to 128 cores in</text>
<text top="219" left="189" width="538" height="16" font="5">use), the new numerical results are slightly diﬀerent from the corresponding</text>
<text top="240" left="189" width="538" height="16" font="5">results in the conference paper. This is because of a diﬀerence in HDA*</text>
<text top="260" left="189" width="538" height="16" font="5">implementations as well as the nondeterministic behavior of parallel search.</text>
<text top="280" left="189" width="538" height="16" font="5">Normally, checking for a duplicate state in A* is done by checking if the</text>
<text top="300" left="189" width="538" height="16" font="5">state is in the open/closed lists. In the implementation of HDA* in <a href="pdfxml.html#44">[15]</a>,</text>
<text top="321" left="189" width="538" height="16" font="5">duplicate checking was performed by checking if the hash key of a state</text>
<text top="341" left="189" width="538" height="16" font="5">was present in a local open/closed list. While the probability of a false</text>
<text top="361" left="189" width="538" height="16" font="5">positive duplicate detection occurring with a 64-bit hash value is quite small,</text>
<text top="382" left="189" width="538" height="16" font="5">the guarantee of correctness is compromised, so in this paper, our HDA*</text>
<text top="402" left="189" width="538" height="16" font="5">implementation checks for duplicates by comparing the actual state. This is</text>
<text top="422" left="189" width="538" height="16" font="5">slightly slower than checking only the hash value, but guarantees correctness.</text>
<text top="443" left="189" width="538" height="16" font="5">Additionally, the Sokoban instances used in our previous work <a href="pdfxml.html#44">[15] </a>were from</text>
<text top="463" left="189" width="538" height="16" font="5">the satisﬁcing track of IPC-6, while the Sokoban instances used in this paper</text>
<text top="483" left="189" width="195" height="16" font="5">are from the optimal track.</text>
<text top="530" left="189" width="113" height="20" font="4">References</text>
<text top="570" left="197" width="530" height="16" font="5">[1] P. Haslum, H. Geﬀner, Admissible Heuristics for Optimal Planning, in:</text>
<text top="591" left="222" width="504" height="16" font="5">Proceedings of the Fifth International Conference on AI Planning and</text>
<text top="611" left="222" width="285" height="16" font="5">Scheduling AIPS-00, 2000, pp. 140–149.</text>
<text top="642" left="197" width="530" height="16" font="5">[2] S. Edelkamp, Planning with Pattern Databases, in: Proceedings of the</text>
<text top="663" left="222" width="505" height="16" font="5">European Conference on Planning ECP-01, Toledo, Spain, 2001, pp.</text>
<text top="683" left="222" width="45" height="16" font="5">13–34.</text>
<text top="714" left="197" width="530" height="16" font="5">[3] M. Helmert, P. Haslum, J. Hoﬀmann, Flexible Abstraction Heuristics</text>
<text top="735" left="222" width="504" height="16" font="5">for Optimal Sequential Planning, in: Proceedings of the Seventeenth In-</text>
<text top="755" left="222" width="505" height="16" font="5">ternational Conference on Automated Planning and Scheduling ICAPS-</text>
<text top="775" left="222" width="159" height="16" font="5">07, 2007, pp. 176–183.</text>
<text top="807" left="197" width="530" height="16" font="5">[4] P. Hart, N. Nilsson, B. Raphael, A formal basis for the heuristic de-</text>
<text top="827" left="222" width="504" height="16" font="5">termination of minimum cost paths, IEEE Transactions on Systems</text>
<text top="847" left="222" width="331" height="16" font="5">Science and Cybernetics 4 (2) (1968) 100–107.</text>
<text top="879" left="197" width="380" height="16" font="5">[5] M. Evett, J. Hendler, A. Mahanti, D. Nau, PRA</text>
<text top="878" left="577" width="6" height="11" font="6">∗</text>
<text top="879" left="584" width="143" height="16" font="5">: Massively Parallel</text>
<text top="899" left="222" width="504" height="16" font="5">Heuristic Search, Journal of Parallel and Distributed Computing 25 (2)</text>
<text top="919" left="222" width="112" height="16" font="5">(1995) 133–143.</text>
<text top="951" left="197" width="529" height="16" font="5">[6] N. Mahapatra, S. Dutt, Scalable Global and Local Hashing Strategies</text>
<text top="971" left="222" width="504" height="16" font="5">for Duplicate Pruning in Parallel A* Graph Search, IEEE Transactions</text>
<text top="991" left="222" width="417" height="16" font="5">on Parallel and Distributed Systems 8 (7) (1997) 738–756.</text>
<text top="1036" left="449" width="16" height="16" font="5">43</text>
</page>
<page number="44" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="197" width="530" height="16" font="5">[7] R. Korf, P. Schultze, Large-Scale Parallel Breadth-First Search, in: Pro-</text>
<text top="219" left="222" width="504" height="16" font="5">ceedings of the National Conference on Artiﬁcial Intelligence AAAI,</text>
<text top="240" left="222" width="148" height="16" font="5">2005, pp. 1380–1386.</text>
<text top="271" left="197" width="530" height="16" font="5">[8] R. Zhou, E. Hansen, Parallel Structured Duplicate Detection, in: Pro-</text>
<text top="291" left="222" width="504" height="16" font="5">ceedings of the National Conference on Artiﬁcial Intelligence AAAI,</text>
<text top="312" left="222" width="431" height="16" font="5">Vancouver, British Columbia, Canada, 2007, pp. 1217–1223.</text>
<text top="343" left="197" width="530" height="16" font="5">[9] E. Burns, S. Lemons, R. Zhou, W. Ruml, Best-First Heuristic Search for</text>
<text top="363" left="222" width="504" height="16" font="5">Multi-Core Machines, in: Proceedings of the Twenty-First International</text>
<text top="384" left="222" width="504" height="16" font="5">Joint Conference on Artiﬁcial Intelligence IJCAI-09, 2009, pp. 449–455.</text>
<text top="415" left="189" width="538" height="16" font="5">[10] C. Lin, L. Snyder, Principles of parallel programming, Addison–Wesley,</text>
<text top="435" left="222" width="37" height="16" font="5">2009.</text>
<text top="467" left="189" width="516" height="16" font="5">[11] M. Snir, W. Gropp, MPI: the complete reference, MIT Press, 1998.</text>
<text top="498" left="189" width="538" height="16" font="5">[12] R. E. Korf, A. Felner, Disjoint Pattern Database Heuristics, Artiﬁcial</text>
<text top="519" left="222" width="244" height="16" font="5">Intelligence 134 (1-2) (2002) 9–22.</text>
<text top="550" left="189" width="538" height="16" font="5">[13] J. W. Romein, A. Plaat, H. E. Bal, J. Schaeﬀer, Transposition Table</text>
<text top="570" left="222" width="504" height="16" font="5">Driven Work Scheduling in Distributed Search, in: Proceedings of the</text>
<text top="591" left="222" width="504" height="16" font="5">National Conference on Artiﬁcial Intelligence AAAI-99, 1999, pp. 725–</text>
<text top="611" left="222" width="29" height="16" font="5">731.</text>
<text top="642" left="189" width="538" height="16" font="5">[14] J. W. Romein, H. E. Bal, J. Schaeﬀer, A. Plaat, A Performance Analysis</text>
<text top="663" left="222" width="504" height="16" font="5">of Transposition-Table-Driven Work Scheduling in Distributed Search,</text>
<text top="683" left="222" width="504" height="16" font="5">IEEE Transactions on Parallel and Distributed Systems 13 (5) (2002)</text>
<text top="703" left="222" width="61" height="16" font="5">447–459.</text>
<text top="735" left="189" width="538" height="16" font="5">[15] A. Kishimoto, A. Fukunaga, A. Botea, Scalable, Parallel Best-First</text>
<text top="755" left="222" width="504" height="16" font="5">Search for Optimal Sequential Planning, in: Proceedings of the Inter-</text>
<text top="775" left="222" width="504" height="16" font="5">national Conference on Automated Planning and Scheduling ICAPS-09,</text>
<text top="796" left="222" width="132" height="16" font="5">2009, pp. 201–208.</text>
<text top="827" left="189" width="538" height="16" font="5">[16] A. Kishimoto, A. Fukunaga, A. Botea, On the Scaling Behavior of</text>
<text top="847" left="222" width="504" height="16" font="5">HDA*, in: Proceedings of the Symposium on Combinatorial Search</text>
<text top="868" left="222" width="186" height="16" font="5">SoCS-10, 2010, pp. 61–62.</text>
<text top="899" left="189" width="538" height="16" font="5">[17] A. Felner, S. Kraus, R. E. Korf, Kbfs: K-best-ﬁrst search, Annals of</text>
<text top="919" left="222" width="403" height="16" font="5">Mathematics and Artiﬁcial Intelligence 39 (2003) 19–39.</text>
<text top="951" left="189" width="538" height="16" font="5">[18] V. N. Rao, V. Kumar, Parallel Depth-First Search on Multiprocessors</text>
<text top="971" left="222" width="504" height="16" font="5">Part I: Implementation, International Journal of Parallel Programming</text>
<text top="991" left="222" width="160" height="16" font="5">16 (6) (1987) 479–499.</text>
<text top="1036" left="449" width="16" height="16" font="5">44</text>
</page>
<page number="45" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">[19] R. Feldmann, Spielbaumsuche auf Massiv Parallelen Systemen, Ph.D.</text>
<text top="219" left="222" width="504" height="16" font="5">thesis, University of Paderborn, English translation titled Game tree</text>
<text top="240" left="222" width="257" height="15" font="5">search on massively parallel systems</text>
<text top="240" left="485" width="138" height="16" font="5">is available. (1993).</text>
<text top="273" left="189" width="538" height="16" font="5">[20] M. Frigo, C. E. Leiserson, K. H. Randall, The Implementation of the</text>
<text top="294" left="222" width="504" height="16" font="5">Cilk-5 Multithreaded Language, in: ACM SIGPLAN Conferences on</text>
<text top="314" left="222" width="504" height="16" font="5">Programming Language Design and Implementation (PLDI’98), 1998,</text>
<text top="334" left="222" width="89" height="16" font="5">pp. 212–223.</text>
<text top="368" left="189" width="538" height="16" font="5">[21] C. Powley, C. Ferguson, R. Korf, Depth-ﬁrst heuristic search on a SIMD</text>
<text top="388" left="222" width="358" height="16" font="5">machine, Artiﬁcial Intelligence 60 (1993) 199–242.</text>
<text top="422" left="189" width="538" height="16" font="5">[22] A. Mahanti, C. Daniels, A SIMD Approach to Parallel Heuristic Search,</text>
<text top="442" left="222" width="289" height="16" font="5">Artiﬁcial Intelligence 60 (1993) 243–282.</text>
<text top="476" left="189" width="538" height="16" font="5">[23] R. Korf, Best-ﬁrst frontier search with delayed duplicate detection, in:</text>
<text top="497" left="222" width="504" height="16" font="5">Proceedings of the National Conference on Artiﬁcial Intelligence AAAI,</text>
<text top="517" left="222" width="132" height="16" font="5">2004, pp. 650–657.</text>
<text top="551" left="189" width="538" height="16" font="5">[24] R. Korf, Linear-time disk-based implicit graph search, Journal of the</text>
<text top="571" left="222" width="91" height="16" font="5">ACM 55 (6).</text>
<text top="605" left="189" width="538" height="16" font="5">[25] R. Zhou, E. Hansen, Structured Duplicate Detection in External-</text>
<text top="625" left="222" width="504" height="16" font="5">Memory Graph Search, in: Proceedings of the Nineteenth National</text>
<text top="645" left="222" width="469" height="16" font="5">Conference on Artiﬁcial Intelligence AAAI-04, 2004, pp. 683–689.</text>
<text top="679" left="189" width="538" height="16" font="5">[26] S. Edelkamp, S. Jabbar, Cost-Optimal External Planning, in: Pro-</text>
<text top="699" left="222" width="504" height="16" font="5">ceedings of the National Conference on Artiﬁcial Intelligence AAAI-06,</text>
<text top="720" left="222" width="132" height="16" font="5">2006, pp. 821–826.</text>
<text top="754" left="189" width="538" height="16" font="5">[27] R. Niewiadomski, J. N. Amaral, R. C. Holte, Sequential and Parallel</text>
<text top="774" left="222" width="504" height="16" font="5">Algorithms for Frontier A* with Delayed Duplicate Detection, in: Pro-</text>
<text top="794" left="222" width="504" height="16" font="5">ceedings of the National Conference on AI AAAI-06, 2006, pp. 1039–</text>
<text top="814" left="222" width="37" height="16" font="5">1044.</text>
<text top="848" left="189" width="538" height="16" font="5">[28] V. Kumar, K. Ramesh, V. N. Rao, Parallel Best-First Search of State-</text>
<text top="869" left="222" width="504" height="16" font="5">Space Graphs: A Summary of Results, in: Proceedings of the 7th Na-</text>
<text top="889" left="222" width="504" height="16" font="5">tional Conference on Artiﬁcial Intelligence AAAI-88, 1988, pp. 122–127.</text>
<text top="923" left="189" width="538" height="16" font="5">[29] R. Karp, Y. Zhang, A Randomized Parallel Branch-and-Bound Pro-</text>
<text top="943" left="222" width="504" height="16" font="5">cedure, in: Proceedings of the 20th ACM Symposium on Theory of</text>
<text top="963" left="222" width="286" height="16" font="5">Computing (STOC), 1988, pp. 290–300.</text>
<text top="1036" left="449" width="16" height="16" font="5">45</text>
</page>
<page number="46" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="537" height="16" font="5">[30] R. Karp, Y. Zhang, Randomized Parallel Algorithms for Backtrack</text>
<text top="219" left="222" width="504" height="16" font="5">Search and Branch-and-Bound Computation, Journal of the Associ-</text>
<text top="240" left="222" width="393" height="16" font="5">ation for Computing Machinery 40 (3) (1993) 765–789.</text>
<text top="273" left="189" width="538" height="16" font="5">[31] S. Dutt, N. Mahapatra, Scalable Load Balancing Strategies for Parallel</text>
<text top="293" left="222" width="504" height="16" font="5">A* Algorithms, Journal of parallel and distributed computing 22 (1994)</text>
<text top="313" left="222" width="61" height="16" font="5">488–505.</text>
<text top="347" left="189" width="538" height="16" font="5">[32] R. E. Korf, W. Zhang, Divide-and-Conquer Frontier Search Applied</text>
<text top="367" left="222" width="504" height="16" font="5">to Optimal Sequence Alignment, in: Proceedings of the 17th National</text>
<text top="387" left="222" width="469" height="16" font="5">Conference on Artiﬁcial Intelligence AAAI-00, 2000, pp. 910–916.</text>
<text top="421" left="189" width="538" height="16" font="5">[33] R. Zhou, E. Hansen, Domain-Independent Structured Duplicate De-</text>
<text top="441" left="222" width="504" height="16" font="5">tection, in: Proceedings of the 21st National Conference on Artiﬁcial</text>
<text top="461" left="222" width="293" height="16" font="5">Intelligence AAAI-06, 2006, pp. 683–688.</text>
<text top="494" left="189" width="538" height="16" font="5">[34] P. Chakrabarti, S. Ghose, A. Acharya, S. de Sarkar, Heuristic Search</text>
<text top="515" left="222" width="482" height="16" font="5">in Restricted Memory, Artiﬁcial Intelligence 41 (2) (1989) 197–221.</text>
<text top="548" left="189" width="538" height="16" font="5">[35] S. Russell, Eﬃcient Memory-Bounded Search Methods, in: Proceedings</text>
<text top="568" left="222" width="374" height="16" font="5">of the European Conference on AI (ECAI-92), 1992.</text>
<text top="602" left="189" width="538" height="16" font="5">[36] Y. Kobayashi, A. Kishimoto, O. Watanabe, Evaluations of Hash Dis-</text>
<text top="622" left="222" width="504" height="16" font="5">tributed A* in Optimal Sequence Alignment, in: Proceedings of the</text>
<text top="642" left="222" width="504" height="16" font="5">Twenty-Second International Joint Conference on Artiﬁcial Intelligence</text>
<text top="663" left="222" width="208" height="16" font="5">IJCAI-11, 2011, pp. 584–590.</text>
<text top="696" left="189" width="538" height="16" font="5">[37] A. Kishimoto, J. Schaeﬀer, Distributed Game-Tree Search Using Trans-</text>
<text top="716" left="222" width="504" height="16" font="5">position Table Driven Work Scheduling, in: Proceedings of the 31st In-</text>
<text top="737" left="222" width="504" height="16" font="5">ternational Conference on Parallel Processing ICPP-02, 2002, pp. 323–</text>
<text top="757" left="222" width="29" height="16" font="5">330.</text>
<text top="790" left="189" width="538" height="16" font="5">[38] J. W. Romein, H. E. Bal, Solving Awari with Parallel Retrograde Anal-</text>
<text top="810" left="222" width="311" height="16" font="5">ysis, IEEE Computer 36 (10) (2003) 26–33.</text>
<text top="844" left="189" width="538" height="16" font="5">[39] K. Yoshizoe, A. Kishimoto, T. Kaneko, H. Yoshimoto, Y. Ishikawa.,</text>
<text top="864" left="222" width="504" height="16" font="5">Scalable Distributed Monte-Carlo Tree Search, in: Proceedings of the</text>
<text top="884" left="222" width="478" height="16" font="5">Symposium on Combinatorial Search SOCS-11, 2011, pp. 180–187.</text>
<text top="918" left="189" width="538" height="16" font="5">[40] F. Mattern, Algorithms for Distributed Termination Detection, Dis-</text>
<text top="938" left="222" width="301" height="16" font="5">tributed Computing 2 (3) (1987) 161–175.</text>
<text top="971" left="189" width="538" height="16" font="5">[41] A. L. Zobrist, A New Hashing Method with Applications for Game</text>
<text top="991" left="222" width="504" height="16" font="5">Playing, Tech. rep., Dept of CS, Univ. of Wisconsin, Madison, reprinted</text>
<text top="1036" left="449" width="16" height="16" font="5">46</text>
</page>
<page number="47" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="222" width="503" height="16" font="5">in International Computer Chess Association Journal, 13(2):169-173,</text>
<text top="219" left="222" width="88" height="16" font="5">1990 (1970).</text>
<text top="253" left="189" width="117" height="16" font="5">[42] C. B¨ackstr¨</text>
<text top="253" left="298" width="301" height="16" font="5">om, B. Nebel, Complexity Results for SAS</text>
<text top="250" left="599" width="10" height="12" font="6">+</text>
<text top="253" left="614" width="112" height="16" font="5">Planning, Com-</text>
<text top="273" left="222" width="326" height="16" font="5">putational Intelligence 11 (4) (1995) 625–655.</text>
<text top="307" left="189" width="277" height="16" font="5">[43] A. Botea, M. Enzenberger, M. M¨</text>
<text top="307" left="456" width="270" height="16" font="5">uller, J. Schaeﬀer, Macro-FF: Improv-</text>
<text top="327" left="222" width="505" height="16" font="5">ing AI Planning with Automatically Learned Macro-Operators, Journal</text>
<text top="348" left="222" width="377" height="16" font="5">of Artiﬁcial Intelligence Research 24 (2005) 581–621.</text>
<text top="381" left="189" width="538" height="16" font="5">[44] Y. Akagi, A. Kishimoto, A. Fukunaga, On transposition tables for</text>
<text top="402" left="222" width="504" height="16" font="5">single-agent search and planning: Summary of results, in: Proceedings</text>
<text top="422" left="222" width="483" height="16" font="5">of the Symposium on Combinatorial Search (SOCS), 2010, pp. 1–8.</text>
<text top="456" left="189" width="538" height="16" font="5">[45] M. Campbell, J. Hoane, F. Hsu, Deep Blue, Artiﬁcial Intelligence</text>
<text top="476" left="222" width="166" height="16" font="5">134 (1-2) (2002) 57–83.</text>
<text top="510" left="189" width="538" height="16" font="5">[46] T. Cazenave, N. Jouandeau, On the parallelization of UCT, in: H. van</text>
<text top="530" left="222" width="504" height="16" font="5">den Herik et al. (Ed.), Proceedings of Computers and Games CG-08,</text>
<text top="551" left="222" width="330" height="16" font="5">Vol. 5131 of LNCS, Springer, 2008, pp. 72–80.</text>
<text top="584" left="189" width="538" height="16" font="5">[47] D. Vrakas, I. Refanidis, I. Vlahavas, Parallel Planning via the Distribu-</text>
<text top="605" left="222" width="504" height="16" font="5">tion of Operators, Journal of Experimental and Theoretical Artiﬁcial</text>
<text top="625" left="222" width="247" height="16" font="5">Intelligence 13 (3) (2001) 211–226.</text>
<text top="659" left="189" width="538" height="16" font="5">[48] B. Huberman, R. Lukose, T. Hogg, An Economics Approach to Hard</text>
<text top="679" left="222" width="424" height="16" font="5">Computational Problems, Science 275 (5296) (1997) 51–54.</text>
<text top="713" left="189" width="538" height="16" font="5">[49] C. Gomes, B. Selman, Algorithm Portfolios, Artiﬁcial Intelligence 126</text>
<text top="733" left="222" width="96" height="16" font="5">(2001) 43–62.</text>
<text top="767" left="189" width="538" height="16" font="5">[50] C. Gomes, B. Selman, N. Crato, H. Kautz, Heavy-tailed Phenomena</text>
<text top="787" left="222" width="504" height="16" font="5">in Satisﬁability and Constraint Satisfaction Problems, Journal of Au-</text>
<text top="808" left="222" width="309" height="16" font="5">tomated Reasoning 24 (1-2) (2000) 67–100.</text>
<text top="841" left="189" width="538" height="16" font="5">[51] Y. Hamadi, S. Jabbour, L. Sais, ManySAT: a Parallel SAT Solver,</text>
<text top="862" left="222" width="504" height="16" font="5">Journal on Satisﬁability, Boolean Modeling and Computation 6 (2009)</text>
<text top="882" left="222" width="61" height="16" font="5">245–262.</text>
<text top="916" left="189" width="538" height="16" font="5">[52] C. Powley, R. Korf, Single-agent Parallel Window Search, IEEE Trans-</text>
<text top="936" left="222" width="504" height="16" font="5">actions on Pattern Analysis and Machine Intelligence 13 (5) (1991)</text>
<text top="956" left="222" width="61" height="16" font="5">466–477.</text>
<text top="1036" left="449" width="16" height="16" font="5">47</text>
</page>
<page number="48" position="absolute" top="0" left="0" height="1188" width="918">
<text top="199" left="189" width="538" height="16" font="5">[53] V. Vidal, L. Bordeaux, Y. Hamadi, Adaptive K-Parallel Best-First</text>
<text top="219" left="222" width="504" height="16" font="5">Search: A Simple but Eﬃcient Algorithm for Multi-Core Domain-</text>
<text top="240" left="222" width="504" height="16" font="5">Independent Planning, in: Proceedings of the 3rd Symposium on Com-</text>
<text top="260" left="222" width="504" height="16" font="5">binatorial Search (SOCS’10), AAAI Press, Stone Mountain, GA, USA,</text>
<text top="280" left="222" width="37" height="16" font="5">2010.</text>
<text top="314" left="189" width="538" height="16" font="5">[54] D. Cook, R. Varnell, Adaptive Parallel Iterative Deepening Search,</text>
<text top="334" left="222" width="428" height="16" font="5">Journal of Artiﬁcial Intelligence Research 9 (1998) 139–166.</text>
<text top="368" left="189" width="538" height="16" font="5">[55] E. Burns, S. Lemons, W. Ruml, R. Zhou, Best-ﬁrst heuristic search for</text>
<text top="388" left="222" width="504" height="16" font="5">multicore machines, Journal of Artiﬁcial Intelligence Research (JAIR)</text>
<text top="409" left="222" width="134" height="16" font="5">39 (2010) 689–743.</text>
<text top="442" left="189" width="538" height="16" font="5">[56] M. Helmert, C. Domshlak, Landmarks, Critical Paths and Abstrac-</text>
<text top="463" left="222" width="504" height="16" font="5">tions: What’s the Diﬀerence Anyway?, in: Proceedings of the Nine-</text>
<text top="483" left="222" width="504" height="16" font="5">teenth International Conference on Automated Planning and Schedul-</text>
<text top="503" left="222" width="271" height="16" font="5">ing (ICAPS 2009), 2009, pp. 162–169.</text>
<text top="1036" left="449" width="16" height="16" font="5">48</text>
</page>
<page number="49" position="absolute" top="0" left="0" height="1188" width="918">
<text top="224" left="334" width="44" height="12" font="6">64 cores</text>
<text top="224" left="397" width="51" height="12" font="6">128 cores</text>
<text top="224" left="466" width="51" height="12" font="6">256 cores</text>
<text top="224" left="535" width="51" height="12" font="6">512 cores</text>
<text top="224" left="603" width="57" height="12" font="6">1024 cores</text>
<text top="239" left="260" width="52" height="12" font="6">Average</text>
<text top="239" left="340" width="34" height="12" font="6">52.73</text>
<text top="239" left="406" width="34" height="12" font="6">28.71</text>
<text top="239" left="474" width="34" height="12" font="6">17.66</text>
<text top="239" left="543" width="34" height="12" font="6">12.92</text>
<text top="239" left="615" width="34" height="12" font="6">18.84</text>
<text top="254" left="255" width="62" height="12" font="6">Nr solved</text>
<text top="254" left="349" width="15" height="12" font="6">39</text>
<text top="254" left="415" width="15" height="12" font="6">36</text>
<text top="254" left="484" width="15" height="12" font="6">34</text>
<text top="254" left="553" width="15" height="12" font="6">31</text>
<text top="254" left="625" width="15" height="12" font="6">19</text>
<text top="269" left="279" width="13" height="12" font="6">p1</text>
<text top="269" left="342" width="29" height="12" font="6">21.17</text>
<text top="269" left="408" width="29" height="12" font="6">10.95</text>
<text top="269" left="480" width="23" height="12" font="6">7.97</text>
<text top="269" left="549" width="23" height="12" font="6">5.68</text>
<text top="269" left="618" width="29" height="12" font="6">15.95</text>
<text top="283" left="279" width="13" height="12" font="6">p2</text>
<text top="283" left="336" width="41" height="12" font="6">1086.90</text>
<text top="283" left="405" width="35" height="12" font="6">626.49</text>
<text top="283" left="481" width="20" height="12" font="6">n/a</text>
<text top="283" left="550" width="20" height="12" font="6">n/a</text>
<text top="283" left="622" width="20" height="12" font="6">n/a</text>
<text top="298" left="279" width="13" height="12" font="6">p3</text>
<text top="298" left="339" width="35" height="12" font="6">102.31</text>
<text top="298" left="408" width="29" height="12" font="6">53.83</text>
<text top="298" left="477" width="29" height="12" font="6">30.06</text>
<text top="298" left="546" width="29" height="12" font="6">22.62</text>
<text top="298" left="618" width="29" height="12" font="6">18.89</text>
<text top="313" left="279" width="13" height="12" font="6">p4</text>
<text top="313" left="339" width="35" height="12" font="6">109.95</text>
<text top="313" left="408" width="29" height="12" font="6">55.01</text>
<text top="313" left="477" width="29" height="12" font="6">37.20</text>
<text top="313" left="546" width="29" height="12" font="6">20.39</text>
<text top="313" left="618" width="29" height="12" font="6">18.97</text>
<text top="328" left="279" width="13" height="12" font="6">p5</text>
<text top="328" left="342" width="29" height="12" font="6">37.50</text>
<text top="328" left="408" width="29" height="12" font="6">19.32</text>
<text top="328" left="477" width="29" height="12" font="6">16.87</text>
<text top="328" left="546" width="29" height="12" font="6">12.38</text>
<text top="328" left="618" width="29" height="12" font="6">23.13</text>
<text top="343" left="279" width="13" height="12" font="6">p6</text>
<text top="343" left="339" width="35" height="12" font="6">244.79</text>
<text top="343" left="405" width="35" height="12" font="6">144.25</text>
<text top="343" left="477" width="29" height="12" font="6">79.35</text>
<text top="343" left="546" width="29" height="12" font="6">45.67</text>
<text top="343" left="618" width="29" height="12" font="6">34.13</text>
<text top="357" left="279" width="13" height="12" font="6">p7</text>
<text top="357" left="339" width="35" height="12" font="6">703.91</text>
<text top="357" left="405" width="35" height="12" font="6">356.17</text>
<text top="357" left="474" width="35" height="12" font="6">207.60</text>
<text top="357" left="550" width="20" height="12" font="6">n/a</text>
<text top="357" left="622" width="20" height="12" font="6">n/a</text>
<text top="372" left="279" width="13" height="12" font="6">p8</text>
<text top="372" left="339" width="35" height="12" font="6">683.25</text>
<text top="372" left="405" width="35" height="12" font="6">341.40</text>
<text top="372" left="474" width="35" height="12" font="6">202.55</text>
<text top="372" left="542" width="35" height="12" font="6">108.59</text>
<text top="372" left="622" width="20" height="12" font="6">n/a</text>
<text top="387" left="276" width="20" height="12" font="6">p13</text>
<text top="387" left="342" width="29" height="12" font="6">43.60</text>
<text top="387" left="408" width="29" height="12" font="6">23.71</text>
<text top="387" left="477" width="29" height="12" font="6">12.87</text>
<text top="387" left="549" width="23" height="12" font="6">9.79</text>
<text top="387" left="618" width="29" height="12" font="6">25.13</text>
<text top="402" left="276" width="20" height="12" font="6">p15</text>
<text top="402" left="336" width="41" height="12" font="6">1505.50</text>
<text top="402" left="412" width="20" height="12" font="6">n/a</text>
<text top="402" left="481" width="20" height="12" font="6">n/a</text>
<text top="402" left="550" width="20" height="12" font="6">n/a</text>
<text top="402" left="622" width="20" height="12" font="6">n/a</text>
<text top="417" left="276" width="20" height="12" font="6">p16</text>
<text top="417" left="342" width="29" height="12" font="6">38.26</text>
<text top="417" left="408" width="29" height="12" font="6">18.89</text>
<text top="417" left="477" width="29" height="12" font="6">11.20</text>
<text top="417" left="549" width="23" height="12" font="6">7.84</text>
<text top="417" left="618" width="29" height="12" font="6">29.32</text>
<text top="431" left="276" width="20" height="12" font="6">p19</text>
<text top="431" left="339" width="35" height="12" font="6">508.59</text>
<text top="431" left="405" width="35" height="12" font="6">305.44</text>
<text top="431" left="474" width="35" height="12" font="6">169.00</text>
<text top="431" left="546" width="29" height="12" font="6">96.18</text>
<text top="431" left="622" width="20" height="12" font="6">n/a</text>
<text top="446" left="276" width="20" height="12" font="6">p20</text>
<text top="446" left="339" width="35" height="12" font="6">686.12</text>
<text top="446" left="405" width="35" height="12" font="6">329.08</text>
<text top="446" left="474" width="35" height="12" font="6">202.85</text>
<text top="446" left="546" width="29" height="12" font="6">99.05</text>
<text top="446" left="622" width="20" height="12" font="6">n/a</text>
<text top="461" left="276" width="20" height="12" font="6">p22</text>
<text top="461" left="342" width="29" height="12" font="6">12.36</text>
<text top="461" left="411" width="23" height="12" font="6">6.36</text>
<text top="461" left="480" width="23" height="12" font="6">4.64</text>
<text top="461" left="549" width="23" height="12" font="6">5.47</text>
<text top="461" left="618" width="29" height="12" font="6">14.46</text>
<text top="476" left="276" width="20" height="12" font="6">p23</text>
<text top="476" left="336" width="41" height="12" font="6">1462.71</text>
<text top="476" left="412" width="20" height="12" font="6">n/a</text>
<text top="476" left="481" width="20" height="12" font="6">n/a</text>
<text top="476" left="550" width="20" height="12" font="6">n/a</text>
<text top="476" left="622" width="20" height="12" font="6">n/a</text>
<text top="491" left="276" width="20" height="12" font="6">p24</text>
<text top="491" left="339" width="35" height="12" font="6">902.68</text>
<text top="491" left="405" width="35" height="12" font="6">462.02</text>
<text top="491" left="474" width="35" height="12" font="6">336.07</text>
<text top="491" left="550" width="20" height="12" font="6">n/a</text>
<text top="491" left="622" width="20" height="12" font="6">n/a</text>
<text top="505" left="276" width="20" height="12" font="6">p25</text>
<text top="505" left="345" width="23" height="12" font="6">2.82</text>
<text top="505" left="411" width="23" height="12" font="6">1.61</text>
<text top="505" left="480" width="23" height="12" font="6">2.21</text>
<text top="505" left="549" width="23" height="12" font="6">3.67</text>
<text top="505" left="618" width="29" height="12" font="6">10.08</text>
<text top="520" left="276" width="20" height="12" font="6">p26</text>
<text top="520" left="339" width="35" height="12" font="6">112.13</text>
<text top="520" left="408" width="29" height="12" font="6">60.26</text>
<text top="520" left="477" width="29" height="12" font="6">37.01</text>
<text top="520" left="546" width="29" height="12" font="6">23.13</text>
<text top="520" left="618" width="29" height="12" font="6">28.72</text>
<text top="535" left="276" width="20" height="12" font="6">p27</text>
<text top="535" left="339" width="35" height="12" font="6">207.75</text>
<text top="535" left="405" width="35" height="12" font="6">108.62</text>
<text top="535" left="477" width="29" height="12" font="6">74.03</text>
<text top="535" left="546" width="29" height="12" font="6">38.91</text>
<text top="535" left="622" width="20" height="12" font="6">n/a</text>
<text top="550" left="276" width="20" height="12" font="6">p28</text>
<text top="550" left="345" width="23" height="12" font="6">8.34</text>
<text top="550" left="411" width="23" height="12" font="6">4.58</text>
<text top="550" left="480" width="23" height="12" font="6">4.33</text>
<text top="550" left="549" width="23" height="12" font="6">7.26</text>
<text top="550" left="618" width="29" height="12" font="6">13.61</text>
<text top="565" left="276" width="20" height="12" font="6">p29</text>
<text top="565" left="342" width="29" height="12" font="6">25.02</text>
<text top="565" left="408" width="29" height="12" font="6">15.50</text>
<text top="565" left="480" width="23" height="12" font="6">8.60</text>
<text top="565" left="549" width="23" height="12" font="6">6.53</text>
<text top="565" left="618" width="29" height="12" font="6">13.92</text>
<text top="579" left="276" width="20" height="12" font="6">p30</text>
<text top="579" left="342" width="29" height="12" font="6">15.24</text>
<text top="579" left="411" width="23" height="12" font="6">7.82</text>
<text top="579" left="480" width="23" height="12" font="6">4.97</text>
<text top="579" left="549" width="23" height="12" font="6">5.13</text>
<text top="579" left="618" width="29" height="12" font="6">13.29</text>
<text top="594" left="276" width="20" height="12" font="6">p31</text>
<text top="594" left="339" width="35" height="12" font="6">179.49</text>
<text top="594" left="408" width="29" height="12" font="6">96.60</text>
<text top="594" left="477" width="29" height="12" font="6">55.28</text>
<text top="594" left="546" width="29" height="12" font="6">36.77</text>
<text top="594" left="618" width="29" height="12" font="6">27.63</text>
<text top="609" left="276" width="20" height="12" font="6">p32</text>
<text top="609" left="345" width="23" height="12" font="6">7.40</text>
<text top="609" left="411" width="23" height="12" font="6">4.07</text>
<text top="609" left="480" width="23" height="12" font="6">3.11</text>
<text top="609" left="549" width="23" height="12" font="6">4.99</text>
<text top="609" left="618" width="29" height="12" font="6">13.05</text>
<text top="624" left="276" width="20" height="12" font="6">p34</text>
<text top="624" left="336" width="41" height="12" font="6">1415.30</text>
<text top="624" left="412" width="20" height="12" font="6">n/a</text>
<text top="624" left="481" width="20" height="12" font="6">n/a</text>
<text top="624" left="550" width="20" height="12" font="6">n/a</text>
<text top="624" left="622" width="20" height="12" font="6">n/a</text>
<text top="638" left="276" width="20" height="12" font="6">p35</text>
<text top="638" left="339" width="35" height="12" font="6">698.15</text>
<text top="638" left="405" width="35" height="12" font="6">327.57</text>
<text top="638" left="474" width="35" height="12" font="6">184.17</text>
<text top="638" left="542" width="35" height="12" font="6">102.49</text>
<text top="638" left="622" width="20" height="12" font="6">n/a</text>
<text top="653" left="276" width="20" height="12" font="6">p36</text>
<text top="653" left="342" width="29" height="12" font="6">15.65</text>
<text top="653" left="411" width="23" height="12" font="6">7.86</text>
<text top="653" left="480" width="23" height="12" font="6">5.48</text>
<text top="653" left="549" width="23" height="12" font="6">9.17</text>
<text top="653" left="622" width="20" height="12" font="6">n/a</text>
<text top="668" left="276" width="20" height="12" font="6">p37</text>
<text top="668" left="342" width="29" height="12" font="6">35.63</text>
<text top="668" left="408" width="29" height="12" font="6">17.72</text>
<text top="668" left="477" width="29" height="12" font="6">11.52</text>
<text top="668" left="546" width="29" height="12" font="6">11.61</text>
<text top="668" left="618" width="29" height="12" font="6">23.77</text>
<text top="683" left="276" width="20" height="12" font="6">p38</text>
<text top="683" left="345" width="23" height="12" font="6">1.79</text>
<text top="683" left="411" width="23" height="12" font="6">2.26</text>
<text top="683" left="480" width="23" height="12" font="6">4.64</text>
<text top="683" left="549" width="23" height="12" font="6">9.28</text>
<text top="683" left="618" width="29" height="12" font="6">14.70</text>
<text top="698" left="276" width="20" height="12" font="6">p39</text>
<text top="698" left="339" width="35" height="12" font="6">920.94</text>
<text top="698" left="405" width="35" height="12" font="6">453.45</text>
<text top="698" left="481" width="20" height="12" font="6">n/a</text>
<text top="698" left="550" width="20" height="12" font="6">n/a</text>
<text top="698" left="622" width="20" height="12" font="6">n/a</text>
<text top="712" left="276" width="20" height="12" font="6">p40</text>
<text top="712" left="345" width="23" height="12" font="6">0.60</text>
<text top="712" left="411" width="23" height="12" font="6">0.82</text>
<text top="712" left="480" width="23" height="12" font="6">1.57</text>
<text top="712" left="549" width="23" height="12" font="6">3.53</text>
<text top="712" left="621" width="23" height="12" font="6">9.30</text>
<text top="727" left="276" width="20" height="12" font="6">p41</text>
<text top="727" left="339" width="35" height="12" font="6">154.15</text>
<text top="727" left="408" width="29" height="12" font="6">79.98</text>
<text top="727" left="477" width="29" height="12" font="6">47.88</text>
<text top="727" left="546" width="29" height="12" font="6">29.99</text>
<text top="727" left="622" width="20" height="12" font="6">n/a</text>
<text top="742" left="276" width="20" height="12" font="6">p42</text>
<text top="742" left="339" width="35" height="12" font="6">865.88</text>
<text top="742" left="405" width="35" height="12" font="6">608.46</text>
<text top="742" left="474" width="35" height="12" font="6">319.26</text>
<text top="742" left="550" width="20" height="12" font="6">n/a</text>
<text top="742" left="622" width="20" height="12" font="6">n/a</text>
<text top="757" left="276" width="20" height="12" font="6">p43</text>
<text top="757" left="339" width="35" height="12" font="6">188.09</text>
<text top="757" left="408" width="29" height="12" font="6">98.90</text>
<text top="757" left="477" width="29" height="12" font="6">58.75</text>
<text top="757" left="546" width="29" height="12" font="6">41.18</text>
<text top="757" left="622" width="20" height="12" font="6">n/a</text>
<text top="772" left="276" width="20" height="12" font="6">p44</text>
<text top="772" left="345" width="23" height="12" font="6">3.54</text>
<text top="772" left="411" width="23" height="12" font="6">2.01</text>
<text top="772" left="480" width="23" height="12" font="6">2.12</text>
<text top="772" left="549" width="23" height="12" font="6">3.68</text>
<text top="772" left="621" width="23" height="12" font="6">9.91</text>
<text top="786" left="276" width="20" height="12" font="6">p45</text>
<text top="786" left="339" width="35" height="12" font="6">409.99</text>
<text top="786" left="405" width="35" height="12" font="6">211.52</text>
<text top="786" left="474" width="35" height="12" font="6">153.10</text>
<text top="786" left="546" width="29" height="12" font="6">76.32</text>
<text top="786" left="622" width="20" height="12" font="6">n/a</text>
<text top="801" left="276" width="20" height="12" font="6">p46</text>
<text top="801" left="339" width="35" height="12" font="6">586.72</text>
<text top="801" left="405" width="35" height="12" font="6">289.25</text>
<text top="801" left="474" width="35" height="12" font="6">171.51</text>
<text top="801" left="546" width="29" height="12" font="6">90.53</text>
<text top="801" left="622" width="20" height="12" font="6">n/a</text>
<text top="816" left="276" width="20" height="12" font="6">p47</text>
<text top="816" left="339" width="35" height="12" font="6">108.44</text>
<text top="816" left="408" width="29" height="12" font="6">52.79</text>
<text top="816" left="477" width="29" height="12" font="6">36.16</text>
<text top="816" left="546" width="29" height="12" font="6">20.97</text>
<text top="816" left="622" width="20" height="12" font="6">n/a</text>
<text top="831" left="276" width="20" height="12" font="6">p49</text>
<text top="831" left="339" width="35" height="12" font="6">302.13</text>
<text top="831" left="405" width="35" height="12" font="6">164.40</text>
<text top="831" left="477" width="29" height="12" font="6">86.04</text>
<text top="831" left="546" width="29" height="12" font="6">45.94</text>
<text top="831" left="622" width="20" height="12" font="6">n/a</text>
<text top="860" left="189" width="538" height="16" font="5">Table 7: Runtimes in the 24 puzzle on 64 processing nodes. Average is re-</text>
<text top="881" left="189" width="538" height="16" font="5">stricted to instances solved across all table columns. Instances failed across</text>
<text top="901" left="189" width="538" height="16" font="5">all columns are skipped. The hardware is a HPC cluster with a 20Gb In-</text>
<text top="921" left="189" width="538" height="16" font="5">ﬁniband network. Each node has eight 2.4GHz AMD dual core Opteron</text>
<text top="941" left="189" width="388" height="16" font="5">processors (total 16 cores per node) and 32 GB RAM.</text>
<text top="1036" left="449" width="16" height="16" font="5">49</text>
</page>
<page number="50" position="absolute" top="0" left="0" height="1188" width="918">
<text top="203" left="223" width="46" height="12" font="6">Instance</text>
<text top="203" left="355" width="16" height="12" font="6">A*</text>
<text top="203" left="389" width="83" height="12" font="6">HDA* 16 cores</text>
<text top="203" left="495" width="83" height="12" font="6">HDA* 32 cores</text>
<text top="203" left="609" width="83" height="12" font="6">HDA* 64 cores</text>
<text top="220" left="223" width="148" height="12" font="6">min, avg, max speedup</text>
<text top="220" left="398" width="74" height="12" font="6">4.1, 6.4, 9.5</text>
<text top="220" left="490" width="89" height="12" font="6">5.3, 13.5, 20.7</text>
<text top="220" left="597" width="96" height="12" font="6">14.3, 21.8, 31.7</text>
<text top="235" left="223" width="46" height="12" font="6">Depot10</text>
<text top="235" left="342" width="29" height="12" font="6">99.82</text>
<text top="235" left="402" width="70" height="12" font="6">16.97 ( 5.88)</text>
<text top="235" left="513" width="65" height="12" font="6">8.09 (12.33)</text>
<text top="235" left="627" width="65" height="12" font="6">5.60 (17.84)</text>
<text top="250" left="223" width="46" height="12" font="6">Depot13</text>
<text top="250" left="329" width="41" height="12" font="6">1561.83</text>
<text top="250" left="396" width="76" height="12" font="6">254.41 ( 6.14)</text>
<text top="250" left="500" width="78" height="12" font="6">115.85 (13.48)</text>
<text top="250" left="621" width="72" height="12" font="6">75.09 (20.80)</text>
<text top="265" left="223" width="58" height="12" font="6">Driverlog8</text>
<text top="265" left="336" width="35" height="12" font="6">102.55</text>
<text top="265" left="402" width="70" height="12" font="6">18.22 ( 5.63)</text>
<text top="265" left="513" width="65" height="12" font="6">7.29 (14.07)</text>
<text top="265" left="627" width="65" height="12" font="6">4.41 (23.23)</text>
<text top="280" left="223" width="48" height="12" font="6">Freecell5</text>
<text top="280" left="336" width="35" height="12" font="6">137.01</text>
<text top="280" left="402" width="70" height="12" font="6">16.27 ( 8.42)</text>
<text top="280" left="513" width="65" height="12" font="6">8.41 (16.30)</text>
<text top="280" left="627" width="65" height="12" font="6">5.99 (22.87)</text>
<text top="294" left="223" width="48" height="12" font="6">Freecell7</text>
<text top="294" left="329" width="41" height="12" font="6">2261.67</text>
<text top="294" left="396" width="76" height="12" font="6">265.00 ( 8.53)</text>
<text top="294" left="500" width="78" height="12" font="6">128.74 (17.57)</text>
<text top="294" left="621" width="72" height="12" font="6">75.27 (30.05)</text>
<text top="309" left="223" width="39" height="12" font="6">Rover6</text>
<text top="309" left="351" width="20" height="12" font="6">n/a</text>
<text top="309" left="414" width="58" height="12" font="6">n/a ( n/a)</text>
<text top="309" left="505" width="73" height="12" font="6">268.59 ( n/a)</text>
<text top="309" left="619" width="73" height="12" font="6">162.82 ( n/a)</text>
<text top="324" left="223" width="45" height="12" font="6">Rover12</text>
<text top="324" left="336" width="35" height="12" font="6">923.23</text>
<text top="324" left="396" width="76" height="12" font="6">126.11 ( 7.32)</text>
<text top="324" left="507" width="72" height="12" font="6">57.66 (16.01)</text>
<text top="324" left="621" width="72" height="12" font="6">40.27 (22.93)</text>
<text top="339" left="223" width="51" height="12" font="6">Satellite6</text>
<text top="339" left="336" width="35" height="12" font="6">104.83</text>
<text top="339" left="402" width="70" height="12" font="6">24.64 ( 4.26)</text>
<text top="339" left="509" width="70" height="12" font="6">19.86 ( 5.28)</text>
<text top="339" left="627" width="65" height="12" font="6">7.34 (14.28)</text>
<text top="354" left="223" width="59" height="12" font="6">ZenoTrav9</text>
<text top="354" left="336" width="35" height="12" font="6">157.98</text>
<text top="354" left="402" width="70" height="12" font="6">29.87 ( 5.29)</text>
<text top="354" left="507" width="72" height="12" font="6">11.65 (13.56)</text>
<text top="354" left="627" width="65" height="12" font="6">7.26 (21.75)</text>
<text top="368" left="223" width="65" height="12" font="6">ZenoTrav11</text>
<text top="368" left="336" width="35" height="12" font="6">424.68</text>
<text top="368" left="402" width="70" height="12" font="6">81.43 ( 5.22)</text>
<text top="368" left="507" width="72" height="12" font="6">32.36 (13.12)</text>
<text top="368" left="621" width="72" height="12" font="6">19.33 (21.97)</text>
<text top="383" left="223" width="75" height="12" font="6">PipesNoTk14</text>
<text top="383" left="336" width="35" height="12" font="6">248.77</text>
<text top="383" left="402" width="70" height="12" font="6">34.26 ( 7.26)</text>
<text top="383" left="507" width="72" height="12" font="6">12.03 (20.68)</text>
<text top="383" left="627" width="65" height="12" font="6">7.86 (31.66)</text>
<text top="398" left="223" width="75" height="12" font="6">PipesNoTk24</text>
<text top="398" left="329" width="41" height="12" font="6">1046.94</text>
<text top="398" left="396" width="76" height="12" font="6">145.49 ( 7.20)</text>
<text top="398" left="507" width="72" height="12" font="6">63.31 (16.54)</text>
<text top="398" left="621" width="72" height="12" font="6">38.67 (27.08)</text>
<text top="413" left="223" width="48" height="12" font="6">Pegsol27</text>
<text top="413" left="336" width="35" height="12" font="6">178.71</text>
<text top="413" left="402" width="70" height="12" font="6">22.06 ( 8.10)</text>
<text top="413" left="507" width="72" height="12" font="6">11.08 (16.12)</text>
<text top="413" left="627" width="65" height="12" font="6">7.43 (24.07)</text>
<text top="428" left="223" width="48" height="12" font="6">Pegsol28</text>
<text top="428" left="336" width="35" height="12" font="6">773.36</text>
<text top="428" left="402" width="70" height="12" font="6">93.55 ( 8.27)</text>
<text top="428" left="507" width="72" height="12" font="6">45.40 (17.03)</text>
<text top="428" left="621" width="72" height="12" font="6">29.45 (26.26)</text>
<text top="442" left="223" width="54" height="12" font="6">Airport17</text>
<text top="442" left="336" width="35" height="12" font="6">322.21</text>
<text top="442" left="402" width="70" height="12" font="6">33.96 ( 9.49)</text>
<text top="442" left="507" width="72" height="12" font="6">23.78 (13.55)</text>
<text top="442" left="621" width="72" height="12" font="6">15.99 (20.15)</text>
<text top="457" left="223" width="50" height="12" font="6">Gripper8</text>
<text top="457" left="336" width="35" height="12" font="6">304.82</text>
<text top="457" left="402" width="70" height="12" font="6">53.95 ( 5.65)</text>
<text top="457" left="507" width="72" height="12" font="6">22.51 (13.54)</text>
<text top="457" left="621" width="72" height="12" font="6">14.97 (20.36)</text>
<text top="472" left="223" width="50" height="12" font="6">Gripper9</text>
<text top="472" left="329" width="41" height="12" font="6">1710.39</text>
<text top="472" left="396" width="76" height="12" font="6">273.47 ( 6.25)</text>
<text top="472" left="500" width="78" height="12" font="6">118.38 (14.45)</text>
<text top="472" left="621" width="72" height="12" font="6">76.39 (22.39)</text>
<text top="487" left="223" width="52" height="12" font="6">Mystery6</text>
<text top="487" left="336" width="35" height="12" font="6">315.21</text>
<text top="487" left="402" width="70" height="12" font="6">39.17 ( 8.05)</text>
<text top="487" left="507" width="72" height="12" font="6">20.13 (15.66)</text>
<text top="487" left="621" width="72" height="12" font="6">11.91 (26.46)</text>
<text top="502" left="223" width="38" height="12" font="6">Truck5</text>
<text top="502" left="336" width="35" height="12" font="6">365.38</text>
<text top="502" left="402" width="70" height="12" font="6">73.72 ( 4.96)</text>
<text top="502" left="509" width="70" height="12" font="6">68.71 ( 5.32)</text>
<text top="502" left="621" width="72" height="12" font="6">22.46 (16.27)</text>
<text top="516" left="223" width="38" height="12" font="6">Truck6</text>
<text top="516" left="329" width="41" height="12" font="6">3597.24</text>
<text top="516" left="396" width="76" height="12" font="6">675.71 ( 5.32)</text>
<text top="516" left="500" width="78" height="12" font="6">337.01 (10.67)</text>
<text top="516" left="614" width="78" height="12" font="6">168.39 (21.36)</text>
<text top="531" left="223" width="38" height="12" font="6">Truck8</text>
<text top="531" left="329" width="41" height="12" font="6">2194.38</text>
<text top="531" left="396" width="76" height="12" font="6">489.57 ( 4.48)</text>
<text top="531" left="503" width="76" height="12" font="6">284.01 ( 7.73)</text>
<text top="531" left="614" width="78" height="12" font="6">116.22 (18.88)</text>
<text top="546" left="223" width="59" height="12" font="6">Sokoban19</text>
<text top="546" left="336" width="35" height="12" font="6">157.82</text>
<text top="546" left="402" width="70" height="12" font="6">21.10 ( 7.48)</text>
<text top="546" left="507" width="72" height="12" font="6">11.30 (13.97)</text>
<text top="546" left="627" width="65" height="12" font="6">9.72 (16.24)</text>
<text top="561" left="223" width="59" height="12" font="6">Sokoban22</text>
<text top="561" left="336" width="35" height="12" font="6">428.91</text>
<text top="561" left="402" width="70" height="12" font="6">49.18 ( 8.72)</text>
<text top="561" left="507" width="72" height="12" font="6">25.20 (17.02)</text>
<text top="561" left="621" width="72" height="12" font="6">19.57 (21.92)</text>
<text top="575" left="223" width="59" height="12" font="6">Blocks10-2</text>
<text top="575" left="336" width="35" height="12" font="6">327.03</text>
<text top="575" left="402" width="70" height="12" font="6">47.35 ( 6.91)</text>
<text top="575" left="507" width="72" height="12" font="6">20.69 (15.80)</text>
<text top="575" left="621" width="72" height="12" font="6">12.64 (25.88)</text>
<text top="590" left="223" width="82" height="12" font="6">Logistics00-7-1</text>
<text top="590" left="329" width="41" height="12" font="6">1235.26</text>
<text top="590" left="396" width="76" height="12" font="6">230.97 ( 5.35)</text>
<text top="590" left="507" width="72" height="12" font="6">91.09 (13.56)</text>
<text top="590" left="621" width="72" height="12" font="6">53.37 (23.15)</text>
<text top="605" left="223" width="82" height="12" font="6">Logistics00-9-1</text>
<text top="605" left="329" width="41" height="12" font="6">2082.76</text>
<text top="605" left="396" width="76" height="12" font="6">361.88 ( 5.76)</text>
<text top="605" left="500" width="78" height="12" font="6">154.09 (13.52)</text>
<text top="605" left="621" width="72" height="12" font="6">86.91 (23.97)</text>
<text top="620" left="223" width="72" height="12" font="6">Micconic12-2</text>
<text top="620" left="329" width="41" height="12" font="6">2308.03</text>
<text top="620" left="396" width="76" height="12" font="6">564.09 ( 4.09)</text>
<text top="620" left="503" width="76" height="12" font="6">259.01 ( 8.91)</text>
<text top="620" left="614" width="78" height="12" font="6">159.48 (14.47)</text>
<text top="635" left="223" width="72" height="12" font="6">Micconic12-4</text>
<text top="635" left="329" width="41" height="12" font="6">2463.13</text>
<text top="635" left="396" width="76" height="12" font="6">600.22 ( 4.10)</text>
<text top="635" left="503" width="76" height="12" font="6">266.08 ( 9.26)</text>
<text top="635" left="614" width="78" height="12" font="6">169.49 (14.53)</text>
<text top="649" left="223" width="56" height="12" font="6">Mprime30</text>
<text top="649" left="329" width="41" height="12" font="6">1374.27</text>
<text top="649" left="396" width="76" height="12" font="6">247.19 ( 5.56)</text>
<text top="649" left="500" width="78" height="12" font="6">100.27 (13.71)</text>
<text top="649" left="621" width="72" height="12" font="6">68.28 (20.13)</text>
<text top="667" left="262" width="391" height="12" font="6">Solved only on 64 cores: Freecell6 (302.50 seconds), Satellite7 (633.26)</text>
<text top="681" left="263" width="389" height="12" font="6">Sokoban26 (205.80), Blocks11-1 (194.57) and Logistics00-8-1 (491.02).</text>
<text top="712" left="189" width="538" height="16" font="5">Table 8: HDA* time and speed-up (between brackets) on a commodity</text>
<text top="732" left="189" width="538" height="16" font="5">cluster connected by a 1Gb(x2) Ethernet network, where each node has two</text>
<text top="752" left="189" width="538" height="16" font="5">2.33GHZ quad-core Xeon L5410 processors (total 8 cores per node) and</text>
<text top="773" left="189" width="538" height="16" font="5">16GB RAM. A machine with the same processors but with 32GB RAM was</text>
<text top="793" left="189" width="329" height="16" font="5">used to measure the performance of serial A*.</text>
<text top="853" left="367" width="48" height="13" font="8">16 cores</text>
<text top="853" left="433" width="48" height="13" font="8">32 cores</text>
<text top="853" left="500" width="48" height="13" font="8">64 cores</text>
<text top="870" left="379" width="36" height="13" font="8">0.36%</text>
<text top="870" left="446" width="36" height="13" font="8">0.71%</text>
<text top="870" left="512" width="36" height="13" font="8">3.03%</text>
<text top="902" left="189" width="538" height="16" font="5">Table 9: Average search overhead of HDA* for instances solved by serial A*</text>
<text top="922" left="189" width="538" height="16" font="5">on a commodity cluster connected by a 1Gb(x2) Ethernet network, where</text>
<text top="943" left="189" width="538" height="16" font="5">each node has two 2.33GHZ quad-core Xeon L5410 processors (total 8 cores</text>
<text top="963" left="189" width="196" height="16" font="5">per node) and 16GB RAM.</text>
<text top="1036" left="449" width="16" height="16" font="5">50</text>
</page>
<page number="51" position="absolute" top="0" left="0" height="1188" width="918">
<text top="249" left="331" width="53" height="13" font="8">10 states</text>
<text top="249" left="424" width="60" height="13" font="8">100 states</text>
<text top="249" left="521" width="67" height="13" font="8">1000 states</text>
<text top="265" left="320" width="21" height="13" font="8">spd</text>
<text top="265" left="373" width="12" height="13" font="8">so</text>
<text top="265" left="417" width="21" height="13" font="8">spd</text>
<text top="265" left="469" width="12" height="13" font="8">so</text>
<text top="265" left="513" width="21" height="13" font="8">spd</text>
<text top="265" left="569" width="12" height="13" font="8">so</text>
<text top="282" left="318" width="24" height="13" font="8">15.7</text>
<text top="282" left="361" width="36" height="13" font="8">0.53%</text>
<text top="282" left="415" width="24" height="13" font="8">21.9</text>
<text top="282" left="457" width="36" height="13" font="8">2.69%</text>
<text top="282" left="511" width="24" height="13" font="8">14.1</text>
<text top="282" left="554" width="43" height="13" font="8">17.89%</text>
<text top="314" left="189" width="538" height="16" font="5">Table 10: Average speedup (spd) and search overhead (so) of HDA* using</text>
<text top="335" left="189" width="538" height="16" font="5">64 cores for instances solved by serial and all the HDA* versions using 64</text>
<text top="355" left="189" width="538" height="16" font="5">cores on a commodity cluster connected by a 1Gb(x2) Ethernet network,</text>
<text top="375" left="189" width="538" height="16" font="5">where each node has two 2.33GHZ quad-core Xeon L5410 processors (total</text>
<text top="396" left="189" width="251" height="16" font="5">8 cores per node) and 16GB RAM.</text>
<text top="548" left="324" width="92" height="13" font="8">Execution time</text>
<text top="548" left="445" width="125" height="15" font="8">nodes expanded ×10</text>
<text top="546" left="570" width="5" height="7" font="7">6</text>
<text top="548" left="610" width="75" height="13" font="8">load balance</text>
<text top="565" left="313" width="51" height="13" font="8">Random</text>
<text top="565" left="390" width="38" height="13" font="8">HDA*</text>
<text top="565" left="445" width="51" height="13" font="8">Random</text>
<text top="565" left="539" width="38" height="13" font="8">HDA*</text>
<text top="565" left="595" width="51" height="13" font="8">Random</text>
<text top="565" left="663" width="38" height="13" font="8">HDA*</text>
<text top="582" left="214" width="70" height="13" font="8">Driverlog13</text>
<text top="582" left="343" width="21" height="13" font="8">n/a</text>
<text top="582" left="382" width="45" height="13" font="8">1056.24</text>
<text top="582" left="475" width="21" height="13" font="8">n/a</text>
<text top="582" left="556" width="21" height="13" font="8">618</text>
<text top="582" left="624" width="21" height="13" font="8">n/a</text>
<text top="582" left="677" width="24" height="13" font="8">1.05</text>
<text top="599" left="214" width="52" height="13" font="8">Freecell6</text>
<text top="599" left="343" width="21" height="13" font="8">n/a</text>
<text top="599" left="389" width="38" height="13" font="8">990.19</text>
<text top="599" left="475" width="21" height="13" font="8">n/a</text>
<text top="599" left="556" width="21" height="13" font="8">341</text>
<text top="599" left="624" width="21" height="13" font="8">n/a</text>
<text top="599" left="677" width="24" height="13" font="8">1.04</text>
<text top="616" left="214" width="52" height="13" font="8">Freecell7</text>
<text top="616" left="319" width="45" height="13" font="8">3170.81</text>
<text top="616" left="389" width="38" height="13" font="8">234.37</text>
<text top="616" left="465" width="31" height="13" font="8">1,202</text>
<text top="616" left="563" width="14" height="13" font="8">97</text>
<text top="616" left="621" width="24" height="13" font="8">1.01</text>
<text top="616" left="677" width="24" height="13" font="8">1.02</text>
<text top="634" left="214" width="49" height="13" font="8">Rover12</text>
<text top="634" left="319" width="45" height="13" font="8">1150.77</text>
<text top="634" left="396" width="31" height="13" font="8">56.70</text>
<text top="634" left="475" width="21" height="13" font="8">366</text>
<text top="634" left="563" width="14" height="13" font="8">23</text>
<text top="634" left="614" width="31" height="13" font="8">1.003</text>
<text top="634" left="677" width="24" height="13" font="8">1.01</text>
<text top="651" left="214" width="56" height="13" font="8">Satellite7</text>
<text top="651" left="343" width="21" height="13" font="8">n/a</text>
<text top="651" left="382" width="45" height="13" font="8">1493.33</text>
<text top="651" left="475" width="21" height="13" font="8">n/a</text>
<text top="651" left="556" width="21" height="13" font="8">219</text>
<text top="651" left="624" width="21" height="13" font="8">n/a</text>
<text top="651" left="670" width="31" height="13" font="8">1.005</text>
<text top="668" left="214" width="71" height="13" font="8">ZenoTrav11</text>
<text top="668" left="319" width="45" height="13" font="8">1022.57</text>
<text top="668" left="396" width="31" height="13" font="8">54.93</text>
<text top="668" left="475" width="21" height="13" font="8">221</text>
<text top="668" left="563" width="14" height="13" font="8">14</text>
<text top="668" left="607" width="38" height="13" font="8">1.0002</text>
<text top="668" left="677" width="24" height="13" font="8">1.13</text>
<text top="685" left="214" width="71" height="13" font="8">ZenoTrav12</text>
<text top="685" left="343" width="21" height="13" font="8">n/a</text>
<text top="685" left="382" width="45" height="13" font="8">4393.80</text>
<text top="685" left="475" width="21" height="13" font="8">n/a</text>
<text top="685" left="545" width="31" height="13" font="8">1,152</text>
<text top="685" left="624" width="21" height="13" font="8">n/a</text>
<text top="685" left="677" width="24" height="13" font="8">1.03</text>
<text top="702" left="214" width="81" height="13" font="8">PipesNoTk24</text>
<text top="702" left="319" width="45" height="13" font="8">2094.81</text>
<text top="702" left="389" width="38" height="13" font="8">130.13</text>
<text top="702" left="465" width="31" height="13" font="8">1,065</text>
<text top="702" left="563" width="14" height="13" font="8">72</text>
<text top="702" left="607" width="38" height="13" font="8">1.0001</text>
<text top="702" left="670" width="31" height="13" font="8">1.005</text>
<text top="719" left="214" width="52" height="13" font="8">Pegsol28</text>
<text top="719" left="319" width="45" height="13" font="8">1040.28</text>
<text top="719" left="396" width="31" height="13" font="8">74.04</text>
<text top="719" left="465" width="31" height="13" font="8">1,364</text>
<text top="719" left="556" width="21" height="13" font="8">112</text>
<text top="719" left="621" width="24" height="13" font="8">1.01</text>
<text top="719" left="670" width="31" height="13" font="8">1.005</text>
<text top="736" left="214" width="52" height="13" font="8">Pegsol29</text>
<text top="736" left="343" width="21" height="13" font="8">n/a</text>
<text top="736" left="389" width="38" height="13" font="8">364.39</text>
<text top="736" left="475" width="21" height="13" font="8">n/a</text>
<text top="736" left="556" width="21" height="13" font="8">481</text>
<text top="736" left="624" width="21" height="13" font="8">n/a</text>
<text top="736" left="677" width="24" height="13" font="8">1.01</text>
<text top="753" left="214" width="52" height="13" font="8">Pegsol30</text>
<text top="753" left="343" width="21" height="13" font="8">n/a</text>
<text top="753" left="389" width="38" height="13" font="8">978.11</text>
<text top="753" left="475" width="21" height="13" font="8">n/a</text>
<text top="753" left="545" width="31" height="13" font="8">1,379</text>
<text top="753" left="624" width="21" height="13" font="8">n/a</text>
<text top="753" left="677" width="24" height="13" font="8">1.01</text>
<text top="770" left="214" width="64" height="13" font="8">Sokoban24</text>
<text top="770" left="319" width="45" height="13" font="8">2748.71</text>
<text top="770" left="389" width="38" height="13" font="8">171.28</text>
<text top="770" left="465" width="31" height="13" font="8">3,254</text>
<text top="770" left="556" width="21" height="13" font="8">244</text>
<text top="770" left="621" width="24" height="13" font="8">1.01</text>
<text top="770" left="677" width="24" height="13" font="8">1.01</text>
<text top="787" left="214" width="64" height="13" font="8">Sokoban26</text>
<text top="787" left="343" width="21" height="13" font="8">n/a</text>
<text top="787" left="389" width="38" height="13" font="8">488.15</text>
<text top="787" left="475" width="21" height="13" font="8">n/a</text>
<text top="787" left="556" width="21" height="13" font="8">659</text>
<text top="787" left="624" width="21" height="13" font="8">n/a</text>
<text top="787" left="677" width="24" height="13" font="8">1.01</text>
<text top="804" left="214" width="64" height="13" font="8">Sokoban27</text>
<text top="804" left="343" width="21" height="13" font="8">n/a</text>
<text top="804" left="389" width="38" height="13" font="8">942.57</text>
<text top="804" left="475" width="21" height="13" font="8">n/a</text>
<text top="804" left="545" width="31" height="13" font="8">1,162</text>
<text top="804" left="624" width="21" height="13" font="8">n/a</text>
<text top="804" left="677" width="24" height="13" font="8">1.03</text>
<text top="836" left="189" width="538" height="16" font="5">Table 11: HDA* vs random work distribution (“Random”). Execution time,</text>
<text top="856" left="189" width="538" height="16" font="5">nodes expanded, and load balance on 16 cores (on 16 processing nodes), us-</text>
<text top="877" left="189" width="538" height="16" font="5">ing 32GB per core. Experiments were performed on a HPC cluster connected</text>
<text top="897" left="189" width="538" height="16" font="5">by a 20Gb Inﬁniband network, where each node has eight 2.4GHz AMD dual</text>
<text top="917" left="189" width="487" height="16" font="5">core Opteron processors (total 16 cores per node) and 32 GB RAM.</text>
<text top="1036" left="449" width="16" height="16" font="5">51</text>
</page>
<page number="52" position="absolute" top="0" left="0" height="1188" width="918">
<text top="261" left="374" width="98" height="13" font="8">Time in seconds</text>
<text top="261" left="532" width="128" height="15" font="8">States expanded ×10</text>
<text top="259" left="660" width="5" height="7" font="7">6</text>
<text top="278" left="237" width="50" height="13" font="8">Instance</text>
<text top="278" left="348" width="38" height="13" font="8">HDA*</text>
<text top="278" left="419" width="28" height="13" font="8">TDS</text>
<text top="278" left="466" width="33" height="13" font="8">Ratio</text>
<text top="278" left="520" width="38" height="13" font="8">HDA*</text>
<text top="278" left="593" width="28" height="13" font="8">TDS</text>
<text top="278" left="645" width="33" height="13" font="8">Ratio</text>
<text top="298" left="237" width="57" height="13" font="8">Average</text>
<text top="298" left="349" width="36" height="13" font="8">48.46</text>
<text top="298" left="403" width="44" height="13" font="8">267.83</text>
<text top="298" left="471" width="28" height="13" font="8">5.53</text>
<text top="298" left="522" width="36" height="13" font="8">69.53</text>
<text top="298" left="577" width="44" height="13" font="8">439.52</text>
<text top="298" left="650" width="28" height="13" font="8">6.32</text>
<text top="315" left="237" width="51" height="13" font="8">Depot10</text>
<text top="315" left="361" width="24" height="13" font="8">5.60</text>
<text top="315" left="416" width="31" height="13" font="8">18.23</text>
<text top="315" left="474" width="24" height="13" font="8">3.26</text>
<text top="315" left="534" width="24" height="13" font="8">5.27</text>
<text top="315" left="590" width="31" height="13" font="8">14.72</text>
<text top="315" left="654" width="24" height="13" font="8">2.79</text>
<text top="332" left="237" width="51" height="13" font="8">Depot13</text>
<text top="332" left="354" width="31" height="13" font="8">75.09</text>
<text top="332" left="409" width="38" height="13" font="8">177.28</text>
<text top="332" left="474" width="24" height="13" font="8">2.36</text>
<text top="332" left="527" width="31" height="13" font="8">63.93</text>
<text top="332" left="583" width="38" height="13" font="8">143.74</text>
<text top="332" left="654" width="24" height="13" font="8">2.25</text>
<text top="349" left="237" width="63" height="13" font="8">Driverlog8</text>
<text top="349" left="361" width="24" height="13" font="8">4.41</text>
<text top="349" left="423" width="24" height="13" font="8">9.25</text>
<text top="349" left="474" width="24" height="13" font="8">2.10</text>
<text top="349" left="534" width="24" height="13" font="8">5.75</text>
<text top="349" left="597" width="24" height="13" font="8">8.83</text>
<text top="349" left="654" width="24" height="13" font="8">1.54</text>
<text top="366" left="237" width="52" height="13" font="8">Freecell5</text>
<text top="366" left="361" width="24" height="13" font="8">5.99</text>
<text top="366" left="416" width="31" height="13" font="8">27.75</text>
<text top="366" left="474" width="24" height="13" font="8">4.63</text>
<text top="366" left="534" width="24" height="13" font="8">7.21</text>
<text top="366" left="590" width="31" height="13" font="8">34.15</text>
<text top="366" left="654" width="24" height="13" font="8">4.74</text>
<text top="383" left="237" width="52" height="13" font="8">Freecell7</text>
<text top="383" left="354" width="31" height="13" font="8">75.27</text>
<text top="383" left="409" width="38" height="13" font="8">354.63</text>
<text top="383" left="474" width="24" height="13" font="8">4.71</text>
<text top="383" left="527" width="31" height="13" font="8">92.88</text>
<text top="383" left="583" width="38" height="13" font="8">457.95</text>
<text top="383" left="654" width="24" height="13" font="8">4.93</text>
<text top="400" left="237" width="49" height="13" font="8">Rover12</text>
<text top="400" left="354" width="31" height="13" font="8">40.27</text>
<text top="400" left="416" width="31" height="13" font="8">82.65</text>
<text top="400" left="474" width="24" height="13" font="8">2.05</text>
<text top="400" left="527" width="31" height="13" font="8">38.48</text>
<text top="400" left="590" width="31" height="13" font="8">66.90</text>
<text top="400" left="654" width="24" height="13" font="8">1.74</text>
<text top="417" left="237" width="56" height="13" font="8">Satellite6</text>
<text top="417" left="361" width="24" height="13" font="8">7.34</text>
<text top="417" left="416" width="31" height="13" font="8">16.06</text>
<text top="417" left="474" width="24" height="13" font="8">2.19</text>
<text top="417" left="534" width="24" height="13" font="8">3.91</text>
<text top="417" left="597" width="24" height="13" font="8">7.98</text>
<text top="417" left="654" width="24" height="13" font="8">2.04</text>
<text top="434" left="237" width="64" height="13" font="8">ZenoTrav9</text>
<text top="434" left="361" width="24" height="13" font="8">7.26</text>
<text top="434" left="416" width="31" height="13" font="8">13.69</text>
<text top="434" left="474" width="24" height="13" font="8">1.89</text>
<text top="434" left="534" width="24" height="13" font="8">7.79</text>
<text top="434" left="590" width="31" height="13" font="8">10.45</text>
<text top="434" left="654" width="24" height="13" font="8">1.34</text>
<text top="451" left="237" width="71" height="13" font="8">ZenoTrav11</text>
<text top="451" left="354" width="31" height="13" font="8">19.33</text>
<text top="451" left="416" width="31" height="13" font="8">39.61</text>
<text top="451" left="474" width="24" height="13" font="8">2.05</text>
<text top="451" left="527" width="31" height="13" font="8">14.63</text>
<text top="451" left="590" width="31" height="13" font="8">24.94</text>
<text top="451" left="654" width="24" height="13" font="8">1.71</text>
<text top="468" left="237" width="81" height="13" font="8">PipesNoTk14</text>
<text top="468" left="361" width="24" height="13" font="8">7.86</text>
<text top="468" left="416" width="31" height="13" font="8">26.47</text>
<text top="468" left="474" width="24" height="13" font="8">3.37</text>
<text top="468" left="527" width="31" height="13" font="8">21.30</text>
<text top="468" left="590" width="31" height="13" font="8">67.81</text>
<text top="468" left="654" width="24" height="13" font="8">3.18</text>
<text top="485" left="237" width="81" height="13" font="8">PipesNoTk24</text>
<text top="485" left="354" width="31" height="13" font="8">38.67</text>
<text top="485" left="409" width="38" height="13" font="8">104.33</text>
<text top="485" left="474" width="24" height="13" font="8">2.70</text>
<text top="485" left="527" width="31" height="13" font="8">72.83</text>
<text top="485" left="583" width="38" height="13" font="8">184.84</text>
<text top="485" left="654" width="24" height="13" font="8">2.54</text>
<text top="502" left="237" width="52" height="13" font="8">Pegsol27</text>
<text top="502" left="361" width="24" height="13" font="8">7.43</text>
<text top="502" left="416" width="31" height="13" font="8">30.26</text>
<text top="502" left="474" width="24" height="13" font="8">4.07</text>
<text top="502" left="527" width="31" height="13" font="8">26.29</text>
<text top="502" left="583" width="38" height="13" font="8">115.75</text>
<text top="502" left="654" width="24" height="13" font="8">4.40</text>
<text top="519" left="237" width="52" height="13" font="8">Pegsol28</text>
<text top="519" left="354" width="31" height="13" font="8">29.45</text>
<text top="519" left="409" width="38" height="13" font="8">224.51</text>
<text top="519" left="474" width="24" height="13" font="8">7.62</text>
<text top="519" left="520" width="38" height="13" font="8">111.60</text>
<text top="519" left="576" width="45" height="13" font="8">1029.17</text>
<text top="519" left="654" width="24" height="13" font="8">9.22</text>
<text top="536" left="237" width="59" height="13" font="8">Airport17</text>
<text top="536" left="354" width="31" height="13" font="8">15.99</text>
<text top="536" left="409" width="38" height="13" font="8">454.44</text>
<text top="536" left="467" width="31" height="13" font="8">28.42</text>
<text top="536" left="534" width="24" height="13" font="8">8.02</text>
<text top="536" left="583" width="38" height="13" font="8">244.30</text>
<text top="536" left="647" width="31" height="13" font="8">30.48</text>
<text top="553" left="237" width="54" height="13" font="8">Gripper8</text>
<text top="553" left="354" width="31" height="13" font="8">14.97</text>
<text top="553" left="409" width="38" height="13" font="8">466.78</text>
<text top="553" left="467" width="31" height="13" font="8">31.18</text>
<text top="553" left="527" width="31" height="13" font="8">50.81</text>
<text top="553" left="576" width="45" height="13" font="8">1687.10</text>
<text top="553" left="647" width="31" height="13" font="8">33.20</text>
<text top="570" left="237" width="57" height="13" font="8">Mystery6</text>
<text top="570" left="354" width="31" height="13" font="8">11.91</text>
<text top="570" left="409" width="38" height="13" font="8">168.96</text>
<text top="570" left="467" width="31" height="13" font="8">14.19</text>
<text top="570" left="534" width="24" height="13" font="8">5.81</text>
<text top="570" left="590" width="31" height="13" font="8">60.14</text>
<text top="570" left="647" width="31" height="13" font="8">10.36</text>
<text top="588" left="237" width="42" height="13" font="8">Truck5</text>
<text top="588" left="354" width="31" height="13" font="8">22.46</text>
<text top="588" left="409" width="38" height="13" font="8">136.39</text>
<text top="588" left="474" width="24" height="13" font="8">6.07</text>
<text top="588" left="527" width="31" height="13" font="8">20.67</text>
<text top="588" left="583" width="38" height="13" font="8">105.53</text>
<text top="588" left="654" width="24" height="13" font="8">5.11</text>
<text top="605" left="237" width="42" height="13" font="8">Truck8</text>
<text top="605" left="347" width="38" height="13" font="8">116.22</text>
<text top="605" left="409" width="38" height="13" font="8">731.43</text>
<text top="605" left="474" width="24" height="13" font="8">6.29</text>
<text top="605" left="520" width="38" height="13" font="8">107.18</text>
<text top="605" left="583" width="38" height="13" font="8">523.18</text>
<text top="605" left="654" width="24" height="13" font="8">4.88</text>
<text top="622" left="237" width="64" height="13" font="8">Sokoban19</text>
<text top="622" left="361" width="24" height="13" font="8">9.72</text>
<text top="622" left="409" width="38" height="13" font="8">631.43</text>
<text top="622" left="467" width="31" height="13" font="8">64.96</text>
<text top="622" left="527" width="31" height="13" font="8">32.45</text>
<text top="622" left="576" width="45" height="13" font="8">2525.67</text>
<text top="622" left="647" width="31" height="13" font="8">77.84</text>
<text top="639" left="237" width="64" height="13" font="8">Blocks10-2</text>
<text top="639" left="354" width="31" height="13" font="8">12.64</text>
<text top="639" left="416" width="31" height="13" font="8">54.12</text>
<text top="639" left="474" width="24" height="13" font="8">4.28</text>
<text top="639" left="527" width="31" height="13" font="8">40.61</text>
<text top="639" left="583" width="38" height="13" font="8">161.63</text>
<text top="639" left="654" width="24" height="13" font="8">3.98</text>
<text top="656" left="237" width="64" height="13" font="8">Blocks11-1</text>
<text top="656" left="347" width="38" height="13" font="8">194.57</text>
<text top="656" left="409" width="38" height="13" font="8">624.34</text>
<text top="656" left="474" width="24" height="13" font="8">3.21</text>
<text top="656" left="520" width="38" height="13" font="8">546.31</text>
<text top="656" left="576" width="45" height="13" font="8">1750.10</text>
<text top="656" left="654" width="24" height="13" font="8">3.20</text>
<text top="673" left="237" width="64" height="13" font="8">Blocks12-1</text>
<text top="673" left="364" width="21" height="13" font="8">n/a</text>
<text top="673" left="409" width="38" height="13" font="8">837.77</text>
<text top="673" left="477" width="21" height="13" font="8">n/a</text>
<text top="673" left="537" width="21" height="13" font="8">n/a</text>
<text top="673" left="576" width="45" height="13" font="8">1723.94</text>
<text top="673" left="657" width="21" height="13" font="8">n/a</text>
<text top="690" left="237" width="89" height="13" font="8">Logistics00-7-1</text>
<text top="690" left="354" width="31" height="13" font="8">53.37</text>
<text top="690" left="409" width="38" height="13" font="8">370.47</text>
<text top="690" left="474" width="24" height="13" font="8">6.94</text>
<text top="690" left="520" width="38" height="13" font="8">107.54</text>
<text top="690" left="583" width="38" height="13" font="8">671.17</text>
<text top="690" left="654" width="24" height="13" font="8">6.24</text>
<text top="707" left="237" width="89" height="13" font="8">Logistics00-9-1</text>
<text top="707" left="354" width="31" height="13" font="8">86.91</text>
<text top="707" left="409" width="38" height="13" font="8">315.03</text>
<text top="707" left="474" width="24" height="13" font="8">3.62</text>
<text top="707" left="520" width="38" height="13" font="8">149.80</text>
<text top="707" left="583" width="38" height="13" font="8">523.57</text>
<text top="707" left="654" width="24" height="13" font="8">3.50</text>
<text top="724" left="237" width="78" height="13" font="8">Micconic12-2</text>
<text top="724" left="347" width="38" height="13" font="8">159.48</text>
<text top="724" left="409" width="38" height="13" font="8">612.86</text>
<text top="724" left="474" width="24" height="13" font="8">3.84</text>
<text top="724" left="520" width="38" height="13" font="8">126.19</text>
<text top="724" left="583" width="38" height="13" font="8">472.39</text>
<text top="724" left="654" width="24" height="13" font="8">3.74</text>
<text top="741" left="237" width="78" height="13" font="8">Micconic12-4</text>
<text top="741" left="347" width="38" height="13" font="8">169.49</text>
<text top="741" left="409" width="38" height="13" font="8">605.57</text>
<text top="741" left="474" width="24" height="13" font="8">3.57</text>
<text top="741" left="520" width="38" height="13" font="8">132.55</text>
<text top="741" left="583" width="38" height="13" font="8">466.97</text>
<text top="741" left="654" width="24" height="13" font="8">3.52</text>
<text top="758" left="237" width="61" height="13" font="8">Mprime30</text>
<text top="758" left="354" width="31" height="13" font="8">68.28</text>
<text top="758" left="409" width="38" height="13" font="8">667.08</text>
<text top="758" left="474" width="24" height="13" font="8">9.77</text>
<text top="758" left="534" width="24" height="13" font="8">8.03</text>
<text top="758" left="590" width="31" height="13" font="8">68.53</text>
<text top="758" left="654" width="24" height="13" font="8">8.53</text>
<text top="775" left="237" width="431" height="13" font="8">Solved only by HDA*: Logistics00-8-1, Sokoban22, Sokoban26, Truck6,</text>
<text top="791" left="237" width="442" height="13" font="8">Gripper9, Freecell6, Rover6, Satellite7. Timing data available in Table <a href="pdfxml.html#50">8.</a></text>
<text top="823" left="189" width="538" height="16" font="5">Table 12: HDA* vs TDS on 64 cores. Ratio is TDS value divided by HDA*</text>
<text top="844" left="189" width="538" height="16" font="5">value. Average is computed over instances solved by both programs. Ex-</text>
<text top="864" left="189" width="538" height="16" font="5">periments were performed on a commodity cluster connected by a 1Gb(x2)</text>
<text top="884" left="189" width="538" height="16" font="5">Ethernet network, where each node has two 2.33GHZ quad-core Xeon L5410</text>
<text top="905" left="189" width="375" height="16" font="5">processors (total 8 cores per node) and 16GB RAM.</text>
<text top="1036" left="449" width="16" height="16" font="5">52</text>
</page>
<page number="53" position="absolute" top="0" left="0" height="1188" width="918">
<text top="417" left="454" width="50" height="16" font="5">Hybrid</text>
<text top="437" left="306" width="60" height="16" font="5">Instance</text>
<text top="437" left="403" width="45" height="16" font="5">HDA*</text>
<text top="437" left="466" width="33" height="16" font="5">TDS</text>
<text top="437" left="518" width="37" height="16" font="5">Total</text>
<text top="437" left="576" width="33" height="16" font="5">TDS</text>
<text top="461" left="306" width="66" height="16" font="5">16 cores</text>
<text top="482" left="306" width="76" height="16" font="5">Blocks11-1</text>
<text top="482" left="424" width="24" height="16" font="5">165</text>
<text top="482" left="467" width="32" height="16" font="5">2517</text>
<text top="482" left="523" width="32" height="16" font="5">2682</text>
<text top="482" left="577" width="32" height="16" font="5">2928</text>
<text top="503" left="306" width="76" height="16" font="5">Blocks12-1</text>
<text top="503" left="424" width="24" height="16" font="5">148</text>
<text top="503" left="467" width="32" height="16" font="5">4192</text>
<text top="503" left="523" width="32" height="16" font="5">4340</text>
<text top="503" left="577" width="32" height="16" font="5">4139</text>
<text top="526" left="306" width="66" height="16" font="5">32 cores</text>
<text top="547" left="306" width="62" height="16" font="5">Freecell6</text>
<text top="547" left="424" width="24" height="16" font="5">303</text>
<text top="547" left="467" width="32" height="16" font="5">3781</text>
<text top="547" left="523" width="32" height="16" font="5">4084</text>
<text top="547" left="577" width="32" height="16" font="5">4350</text>
<text top="568" left="306" width="76" height="16" font="5">Blocks11-1</text>
<text top="568" left="424" width="24" height="16" font="5">190</text>
<text top="568" left="475" width="24" height="16" font="5">865</text>
<text top="568" left="523" width="32" height="16" font="5">1055</text>
<text top="568" left="585" width="24" height="16" font="5">974</text>
<text top="589" left="306" width="76" height="16" font="5">Blocks12-1</text>
<text top="589" left="424" width="24" height="16" font="5">156</text>
<text top="589" left="467" width="32" height="16" font="5">1876</text>
<text top="589" left="523" width="32" height="16" font="5">2032</text>
<text top="589" left="577" width="32" height="16" font="5">1874</text>
<text top="613" left="306" width="66" height="16" font="5">64 cores</text>
<text top="633" left="306" width="76" height="16" font="5">Blocks12-1</text>
<text top="633" left="424" width="24" height="16" font="5">189</text>
<text top="633" left="475" width="24" height="16" font="5">566</text>
<text top="633" left="531" width="24" height="16" font="5">755</text>
<text top="633" left="585" width="24" height="16" font="5">838</text>
<text top="668" left="189" width="538" height="16" font="5">Table 13: Time in seconds for TDS and Hybrid HDA* + TDS (these are</text>
<text top="689" left="189" width="538" height="16" font="5">instances which could not be solved by HDA* by itself). Experiments were</text>
<text top="709" left="189" width="538" height="16" font="5">performed on a commodity cluster connected by a 1Gb(x2) Ethernet net-</text>
<text top="729" left="189" width="538" height="16" font="5">work, where each node has two 2.33GHZ quad-core Xeon L5410 processors</text>
<text top="750" left="189" width="297" height="16" font="5">(total 8 cores per node) and 16GB RAM.</text>
<text top="1036" left="449" width="16" height="16" font="5">53</text>
</page>
</pdf2xml>
