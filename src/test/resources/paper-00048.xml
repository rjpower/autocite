<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="0" size="11" family="Times" color="#000000"/>
	<fontspec id="1" size="16" family="Times" color="#000000"/>
	<fontspec id="2" size="25" family="Times" color="#000000"/>
	<fontspec id="3" size="25" family="Times" color="#000000"/>
	<fontspec id="4" size="16" family="Times" color="#000000"/>
	<fontspec id="5" size="19" family="Times" color="#000000"/>
<text top="83" left="481" width="7" height="13" font="0"> </text>
<text top="1101" left="481" width="7" height="14" font="0"> </text>
<text top="193" left="162" width="5" height="16" font="1"> </text>
<text top="254" left="169" width="613" height="24" font="2"><b>Investigation of Parallel Computation—MPI, CUDA </b></text>
<text top="300" left="323" width="305" height="24" font="2"><b>and Parallel Visualization </b></text>
<text top="371" left="473" width="5" height="16" font="1"> </text>
<text top="429" left="162" width="5" height="16" font="1"> </text>
<text top="460" left="423" width="109" height="16" font="1">A Manuscript  </text>
<text top="481" left="473" width="5" height="16" font="1"> </text>
<text top="502" left="426" width="102" height="16" font="1">Submitted to  </text>
<text top="522" left="473" width="5" height="16" font="1"> </text>
<text top="543" left="336" width="278" height="16" font="1">The Department of Computer Science </text>
<text top="564" left="473" width="5" height="16" font="1"> </text>
<text top="584" left="392" width="167" height="16" font="1">And the Faculty of the </text>
<text top="605" left="473" width="5" height="16" font="1"> </text>
<text top="626" left="345" width="259" height="16" font="1">University of Wisconsin-La Crosse </text>
<text top="647" left="473" width="5" height="16" font="1"> </text>
<text top="667" left="394" width="162" height="16" font="1">La Crosse, Wisconsin </text>
<text top="688" left="473" width="5" height="16" font="1"> </text>
<text top="709" left="473" width="5" height="16" font="1"> </text>
<text top="729" left="473" width="5" height="16" font="1"> </text>
<text top="750" left="473" width="5" height="16" font="1"> </text>
<text top="771" left="473" width="5" height="16" font="1"> </text>
<text top="792" left="473" width="5" height="16" font="1"> </text>
<text top="812" left="162" width="5" height="16" font="1"> </text>
<text top="833" left="462" width="26" height="16" font="1">By </text>
<text top="854" left="473" width="5" height="16" font="1"> </text>
<text top="875" left="443" width="64" height="16" font="4"><b>Lei Fan </b></text>
<text top="895" left="473" width="5" height="16" font="1"> </text>
<text top="916" left="374" width="202" height="16" font="1">In Partial Fulfillment of the </text>
<text top="936" left="473" width="5" height="16" font="1"> </text>
<text top="957" left="359" width="232" height="16" font="1">Requirements for the Degree of </text>
<text top="978" left="473" width="5" height="16" font="1"> </text>
<text top="1000" left="329" width="293" height="19" font="5"><b>Master of Software Engineering </b></text>
<text top="1024" left="473" width="5" height="19" font="5"><b> </b></text>
<text top="1047" left="413" width="124" height="16" font="1">December, 2011 </text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="6" size="19" family="Times" color="#000000"/>
	<fontspec id="7" size="16" family="Times" color="#000000"/>
<text top="83" left="481" width="7" height="13" font="0"> </text>
<text top="1101" left="180" width="7" height="14" font="0"> </text>
<text top="1128" left="478" width="7" height="14" font="0"> </text>
<text top="166" left="473" width="5" height="16" font="4"><b> </b></text>
<text top="187" left="473" width="5" height="16" font="4"><b> </b></text>
<text top="208" left="473" width="5" height="16" font="4"><b> </b></text>
<text top="250" left="179" width="592" height="19" font="5"><b>Investigation of Parallel Computation—MPI, CUDA and Parallel </b></text>
<text top="298" left="414" width="123" height="19" font="5"><b>Visualization </b></text>
<text top="345" left="162" width="5" height="16" font="1"> </text>
<text top="366" left="162" width="5" height="16" font="1"> </text>
<text top="387" left="162" width="5" height="16" font="1"> </text>
<text top="408" left="432" width="86" height="16" font="1">By Lei Fan </text>
<text top="428" left="162" width="5" height="16" font="1"> </text>
<text top="449" left="162" width="5" height="16" font="1"> </text>
<text top="470" left="162" width="5" height="16" font="1"> </text>
<text top="490" left="162" width="624" height="16" font="1">We recommend acceptance of this manuscript in partial fulfillment of this candidate’s </text>
<text top="511" left="162" width="618" height="16" font="1">requirements for the degree of Master of Software Engineering in Computer Science. </text>
<text top="532" left="162" width="571" height="16" font="1">The candidate has completed the oral examination requirement of the capstone </text>
<text top="552" left="162" width="163" height="16" font="1">project for the degree. </text>
<text top="573" left="162" width="5" height="16" font="1"> </text>
<text top="594" left="162" width="5" height="16" font="1"> </text>
<text top="614" left="162" width="5" height="16" font="1"> </text>
<text top="635" left="162" width="329" height="16" font="1">____________________________________ </text>
<text top="635" left="540" width="212" height="16" font="1">_______________________ </text>
<text top="656" left="162" width="167" height="16" font="1">Dr. Thomas Gendreau  </text>
<text top="656" left="378" width="5" height="16" font="1"> </text>
<text top="656" left="432" width="5" height="16" font="1"> </text>
<text top="656" left="486" width="5" height="16" font="1"> </text>
<text top="656" left="540" width="39" height="16" font="1">Date </text>
<text top="676" left="162" width="273" height="16" font="1">Examination Committee Chairperson </text>
<text top="697" left="162" width="5" height="16" font="1"> </text>
<text top="718" left="162" width="5" height="16" font="1"> </text>
<text top="739" left="162" width="329" height="16" font="1">____________________________________ </text>
<text top="739" left="540" width="212" height="16" font="1">_______________________ </text>
<text top="759" left="162" width="121" height="16" font="1">Dr. Kenny Hunt </text>
<text top="759" left="324" width="5" height="16" font="1"> </text>
<text top="759" left="378" width="5" height="16" font="1"> </text>
<text top="759" left="432" width="5" height="16" font="1"> </text>
<text top="759" left="486" width="5" height="16" font="1"> </text>
<text top="759" left="540" width="39" height="16" font="1">Date </text>
<text top="780" left="162" width="246" height="16" font="1">Examination Committee Member </text>
<text top="801" left="162" width="5" height="16" font="1"> </text>
<text top="821" left="162" width="5" height="16" font="1"> </text>
<text top="842" left="162" width="329" height="16" font="1">____________________________________ </text>
<text top="842" left="540" width="212" height="16" font="1">_______________________ </text>
<text top="863" left="162" width="167" height="16" font="1">Dr. Kasi Periyasamy   </text>
<text top="863" left="378" width="5" height="16" font="1"> </text>
<text top="863" left="432" width="5" height="16" font="1"> </text>
<text top="863" left="486" width="5" height="16" font="1"> </text>
<text top="863" left="540" width="39" height="16" font="1">Date </text>
<text top="884" left="162" width="246" height="16" font="1">Examination Committee Member </text>
<text top="904" left="162" width="5" height="16" font="1"> </text>
<text top="924" left="162" width="9" height="18" font="7"> </text>
<text top="987" left="162" width="5" height="16" font="1"> </text>
<text top="1045" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="8" size="21" family="Times" color="#000000"/>
<text top="83" left="481" width="7" height="13" font="0"> </text>
<text top="1101" left="180" width="7" height="14" font="0"> </text>
<text top="1128" left="471" width="27" height="14" font="0">iii </text>
<text top="220" left="481" width="5" height="16" font="4"><b> </b></text>
<text top="251" left="162" width="5" height="16" font="1"> </text>
<text top="273" left="407" width="137" height="22" font="8"><b>ABSTRACT </b></text>
<text top="313" left="162" width="5" height="16" font="1"> </text>
<text top="341" left="162" width="548" height="20" font="7">Fan Lei, ―Investigation of Parallel Computation—MPI, CUDA and Parallel </text>
<text top="372" left="162" width="564" height="20" font="7">Visualization‖, Master of Software Engineering, December 2011 (Dr Thomas </text>
<text top="406" left="162" width="85" height="16" font="1">Gendreau). </text>
<text top="437" left="162" width="5" height="16" font="1"> </text>
<text top="469" left="162" width="575" height="16" font="1">In this manuscript, the parallel computation is investigated including reviewing </text>
<text top="500" left="162" width="611" height="16" font="1">different programming APIs and architectures. Two specific parallel API—MPI and </text>
<text top="531" left="162" width="576" height="16" font="1">CUDA C are deeply analyzed. Two sorting algorithms and a visual mathematic </text>
<text top="562" left="162" width="607" height="16" font="1">problem are implemented with MPI alone with performance analysis. A stable fluid </text>
<text top="593" left="162" width="615" height="16" font="1">dynamics simulation has been experimented with CUDA.  We also present a parallel </text>
<text top="624" left="162" width="608" height="16" font="1">way to implement a visualization application in the cluster with integration of multi-</text>
<text top="655" left="162" width="541" height="16" font="1">thread, CUDA and OpenGL. The performance analysis is given and future </text>
<text top="686" left="162" width="258" height="16" font="1">improvements are also pointed out. </text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="481" width="7" height="13" font="0"> </text>
<text top="1101" left="475" width="20" height="14" font="0">iv </text>
<text top="249" left="162" width="6" height="22" font="8"><b> </b></text>
<text top="290" left="331" width="289" height="22" font="8"><b>ACKNOWLEDGEMENTS </b></text>
<text top="357" left="162" width="5" height="16" font="1"> </text>
<text top="405" left="162" width="569" height="16" font="1">    I would like to acknowledge for many people who being instrumental in the </text>
<text top="436" left="162" width="618" height="16" font="1">completion and success of my capstone project. First, I appreciate my project advisor </text>
<text top="467" left="162" width="621" height="16" font="1">Dr. Thomas Gendreau giving great guidance and useful advices throughout the whole </text>
<text top="498" left="162" width="595" height="16" font="1">research process of my capstone. He showed tremendous patience, understanding, </text>
<text top="529" left="162" width="585" height="16" font="1">and kindness during my research study. He also gave invaluable suggestions and </text>
<text top="556" left="162" width="576" height="20" font="7">contributions in my thesis’s writing. Special thanks go to Dr. Steven Senger for </text>
<text top="591" left="162" width="590" height="16" font="1">helping me solve cluster running and library installation problems and Dr. Kenny </text>
<text top="622" left="162" width="618" height="16" font="1">Hunt for providing me a knots simulation problem which gave me some first ideas of </text>
<text top="653" left="162" width="612" height="16" font="1">investigating on visualization area with parallel programming methods. I would also </text>
<text top="684" left="162" width="546" height="16" font="1">greatly thanks Dr. Kasi Periyasamy and Dr. Mao Zheng for all the valuable </text>
<text top="711" left="162" width="604" height="20" font="7">knowledge that they taught me during my master’s study and Becky Yoshizumi for </text>
<text top="746" left="162" width="338" height="16" font="1">her continuous help in my daily academic life. </text>
<text top="777" left="162" width="614" height="16" font="1">    I express my deepest thanks to my families and friends for being supportive of me </text>
<text top="808" left="162" width="619" height="16" font="1">during this time and giving me encouragement when I need it. Thank you all for your </text>
<text top="839" left="162" width="200" height="16" font="1">understanding and support. </text>
<text top="897" left="162" width="5" height="16" font="1"> </text>
<text top="956" left="162" width="5" height="16" font="1"> </text>
<text top="1013" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="9" size="14" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">v </text>
<text top="220" left="486" width="5" height="16" font="1"> </text>
<text top="270" left="366" width="265" height="22" font="8"><b>TABLE OF CONTENTS </b></text>
<text top="309" left="775" width="39" height="16" font="1">Page </text>
<text top="340" left="162" width="653" height="16" font="1"><a href="pdfxml.html#13">1. Introduction of Parallel Computation ..............................................................................1 </a></text>
<text top="371" left="199" width="180" height="16" font="1"><a href="pdfxml.html#13">1.1 Parallel Computation</a></text>
<text top="372" left="379" width="435" height="15" font="9"><a href="pdfxml.html#13"> ..................................................................................................... 1 </a></text>
<text top="402" left="199" width="269" height="16" font="1"><a href="pdfxml.html#14">1.2 Parallel Computing Architectures</a></text>
<text top="403" left="468" width="346" height="15" font="9"><a href="pdfxml.html#14">................................................................................ 2 </a></text>
<text top="433" left="216" width="157" height="16" font="1"><a href="pdfxml.html#14">1.2.1 Shared Memory</a></text>
<text top="434" left="373" width="441" height="15" font="9"><a href="pdfxml.html#14"> ...................................................................................................... 2 </a></text>
<text top="464" left="216" width="188" height="16" font="1"><a href="pdfxml.html#14">1.2.2 Distributed Memory</a></text>
<text top="465" left="404" width="410" height="15" font="9"><a href="pdfxml.html#14"> ............................................................................................... 2 </a></text>
<text top="496" left="199" width="199" height="16" font="1"><a href="pdfxml.html#15">1.3 Multi-cored Computing</a></text>
<text top="497" left="397" width="417" height="15" font="9"><a href="pdfxml.html#15"> ................................................................................................. 3 </a></text>
<text top="527" left="199" width="149" height="16" font="1"><a href="pdfxml.html#15">1.4 GPU Computing</a></text>
<text top="528" left="347" width="467" height="15" font="9"><a href="pdfxml.html#15"> ............................................................................................................. 3 </a></text>
<text top="558" left="162" width="653" height="16" font="1"><a href="pdfxml.html#17">2. CPU Parallel Programming—MPI ..................................................................................5 </a></text>
<text top="589" left="199" width="151" height="16" font="1"><a href="pdfxml.html#17">2.1 MPI introduction</a></text>
<text top="590" left="350" width="464" height="15" font="9"><a href="pdfxml.html#17"> ............................................................................................................ 5 </a></text>
<text top="620" left="199" width="110" height="16" font="1"><a href="pdfxml.html#17">2.2 MPI Basics</a></text>
<text top="621" left="309" width="505" height="15" font="9"><a href="pdfxml.html#17"> ...................................................................................................................... 5 </a></text>
<text top="651" left="199" width="195" height="16" font="1"><a href="pdfxml.html#18">2.3 MPI program Structure</a></text>
<text top="652" left="394" width="420" height="15" font="9"><a href="pdfxml.html#18"> ................................................................................................. 6 </a></text>
<text top="682" left="199" width="369" height="16" font="1"><a href="pdfxml.html#21">2.4 Building and Run MPI programs on the Cluster</a></text>
<text top="683" left="568" width="246" height="15" font="9"><a href="pdfxml.html#21"> ....................................................... 9 </a></text>
<text top="713" left="199" width="176" height="16" font="1"><a href="pdfxml.html#23">2.5 Basic MPI programs</a></text>
<text top="714" left="375" width="439" height="15" font="9"><a href="pdfxml.html#23"> .................................................................................................... 11 </a></text>
<text top="744" left="216" width="147" height="16" font="1"><a href="pdfxml.html#23">2.5.1 Time Function</a></text>
<text top="745" left="363" width="451" height="15" font="9"><a href="pdfxml.html#23"> ....................................................................................................... 11 </a></text>
<text top="775" left="216" width="250" height="16" font="1"><a href="pdfxml.html#25">2.5.2 Initialize and Abort Function</a></text>
<text top="776" left="466" width="348" height="15" font="9"><a href="pdfxml.html#25"> .............................................................................. 13 </a></text>
<text top="806" left="199" width="283" height="16" font="1"><a href="pdfxml.html#27">2.6 MPI Implementation of Algorithms</a></text>
<text top="807" left="482" width="332" height="15" font="9"><a href="pdfxml.html#27"> .......................................................................... 15 </a></text>
<text top="837" left="216" width="113" height="16" font="1"><a href="pdfxml.html#27">2.6.1 Rank Sort</a></text>
<text top="838" left="329" width="485" height="15" font="9"><a href="pdfxml.html#27"> ............................................................................................................... 15 </a></text>
<text top="868" left="216" width="277" height="16" font="1"><a href="pdfxml.html#30">2.6.2 Rank Sort Performance Analysis</a></text>
<text top="869" left="493" width="321" height="15" font="9"><a href="pdfxml.html#30"> ....................................................................... 18 </a></text>
<text top="899" left="216" width="119" height="16" font="1"><a href="pdfxml.html#32">2.6.3 Quick Sort</a></text>
<text top="900" left="335" width="479" height="15" font="9"><a href="pdfxml.html#32"> .............................................................................................................. 20 </a></text>
<text top="930" left="216" width="283" height="16" font="1"><a href="pdfxml.html#36">2.6.4 Quick Sort Performance Analysis</a></text>
<text top="931" left="499" width="315" height="15" font="9"><a href="pdfxml.html#36"> ...................................................................... 24 </a></text>
<text top="961" left="216" width="397" height="16" font="1"><a href="pdfxml.html#40">2.6.5 Combine MPI with OpenGL--Julia Set Generator</a></text>
<text top="962" left="613" width="201" height="15" font="9"><a href="pdfxml.html#40"> .......................................... 28 </a></text>
<text top="992" left="162" width="653" height="16" font="1">3. GPU Parallel Programming—CUDA ............................................................................33 </text>
<text top="1023" left="199" width="171" height="16" font="1"><a href="pdfxml.html#45">3.1 CUDA Introduction</a></text>
<text top="1024" left="370" width="444" height="15" font="9"><a href="pdfxml.html#45"> ..................................................................................................... 33 </a></text>
<text top="1055" left="199" width="233" height="16" font="1"><a href="pdfxml.html#46">3.2 CUDA Programming Model</a></text>
<text top="1056" left="432" width="383" height="15" font="9"><a href="pdfxml.html#46"> ...................................................................................... 34 </a></text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">v </text>
<text top="166" left="216" width="96" height="16" font="1"><a href="pdfxml.html#46">3.2.1 Kernels</a></text>
<text top="167" left="313" width="502" height="15" font="9"><a href="pdfxml.html#46"> ................................................................................................................... 34 </a></text>
<text top="197" left="216" width="179" height="16" font="1"><a href="pdfxml.html#46">3.2.2 Thread Hierarchies</a></text>
<text top="198" left="395" width="419" height="15" font="9"><a href="pdfxml.html#46"> ............................................................................................... 34 </a></text>
<text top="228" left="216" width="190" height="16" font="1"><a href="pdfxml.html#49">3.2.3 Memory Hierarchies</a></text>
<text top="229" left="406" width="408" height="15" font="9"><a href="pdfxml.html#49"> ............................................................................................ 37 </a></text>
<text top="259" left="199" width="332" height="16" font="1"><a href="pdfxml.html#50">3.3 CUDA Basic Program—GPU Vector Add</a></text>
<text top="260" left="531" width="284" height="15" font="9"><a href="pdfxml.html#50"> .............................................................. 38 </a></text>
<text top="290" left="199" width="342" height="16" font="1"><a href="pdfxml.html#53">3.4 CUDA Implementation of Fluid Simulation</a></text>
<text top="291" left="541" width="273" height="15" font="9"><a href="pdfxml.html#53"> ............................................................ 41 </a></text>
<text top="321" left="216" width="162" height="16" font="1"><a href="pdfxml.html#53">3.4.1 Fluid Simulation</a></text>
<text top="322" left="378" width="436" height="15" font="9"><a href="pdfxml.html#53"> ................................................................................................... 41 </a></text>
<text top="352" left="216" width="173" height="16" font="1"><a href="pdfxml.html#53">3.4.2 Mathematics Core</a></text>
<text top="353" left="389" width="425" height="15" font="9"><a href="pdfxml.html#53"> ................................................................................................. 41 </a></text>
<text top="383" left="216" width="198" height="16" font="1"><a href="pdfxml.html#54">3.4.3 Fluids Representation</a></text>
<text top="384" left="414" width="400" height="15" font="9"><a href="pdfxml.html#54">........................................................................................... 42 </a></text>
<text top="415" left="216" width="420" height="16" font="1"><a href="pdfxml.html#55">3.4.4 Algorithm Cores based on Navier-Strokes Equations</a></text>
<text top="416" left="636" width="178" height="15" font="9"><a href="pdfxml.html#55"> ..................................... 43 </a></text>
<text top="446" left="199" width="75" height="16" font="1"><a href="pdfxml.html#57">Advection</a></text>
<text top="447" left="274" width="540" height="15" font="9"><a href="pdfxml.html#57"> ............................................................................................................................ 45 </a></text>
<text top="477" left="199" width="69" height="16" font="1"><a href="pdfxml.html#58">Diffusion</a></text>
<text top="478" left="268" width="547" height="15" font="9"><a href="pdfxml.html#58"> .............................................................................................................................. 46 </a></text>
<text top="508" left="199" width="74" height="16" font="1"><a href="pdfxml.html#59">Projection</a></text>
<text top="509" left="273" width="542" height="15" font="9"><a href="pdfxml.html#59"> ............................................................................................................................. 47 </a></text>
<text top="539" left="216" width="349" height="16" font="1"><a href="pdfxml.html#59">3.4.5 Implementation and Performance Analysis</a></text>
<text top="540" left="565" width="249" height="15" font="9"><a href="pdfxml.html#59"> ...................................................... 47 </a></text>
<text top="570" left="162" width="633" height="16" font="1"><a href="pdfxml.html#63">4. Parallel Visualization—Tiled Display Visualization System Integrated with Multiple </a></text>
<text top="601" left="162" width="653" height="16" font="1"><a href="pdfxml.html#63">GPUs ..................................................................................................................................51 </a></text>
<text top="632" left="199" width="116" height="16" font="1"><a href="pdfxml.html#63">4.1 Introduction</a></text>
<text top="633" left="315" width="500" height="15" font="9"><a href="pdfxml.html#63">................................................................................................................... 51 </a></text>
<text top="663" left="199" width="90" height="16" font="1"><a href="pdfxml.html#63">4.2 OpenGL</a></text>
<text top="664" left="289" width="526" height="15" font="9"><a href="pdfxml.html#63"> ......................................................................................................................... 51 </a></text>
<text top="694" left="199" width="211" height="16" font="1"><a href="pdfxml.html#64">4.3 GLSL Shading Language</a></text>
<text top="695" left="410" width="405" height="15" font="9"><a href="pdfxml.html#64"> ............................................................................................ 52 </a></text>
<text top="725" left="199" width="96" height="16" font="1"><a href="pdfxml.html#64">4.4 Equalizer</a></text>
<text top="726" left="295" width="520" height="15" font="9"><a href="pdfxml.html#64"> ....................................................................................................................... 52 </a></text>
<text top="756" left="199" width="263" height="16" font="1"><a href="pdfxml.html#65">4.5 Principles for Parallel Rendering</a></text>
<text top="757" left="462" width="352" height="15" font="9"><a href="pdfxml.html#65"> ............................................................................... 53 </a></text>
<text top="787" left="199" width="190" height="16" font="1"><a href="pdfxml.html#66">4.6 Equalizer Architecture</a></text>
<text top="788" left="389" width="425" height="15" font="9"><a href="pdfxml.html#66">................................................................................................. 54 </a></text>
<text top="818" left="199" width="162" height="16" font="1"><a href="pdfxml.html#67">4.6 Galaxy Simulation</a></text>
<text top="819" left="361" width="453" height="15" font="9"><a href="pdfxml.html#67"> ....................................................................................................... 55 </a></text>
<text top="849" left="216" width="267" height="16" font="1"><a href="pdfxml.html#68">4.6.1 Parallel Programming Interface</a></text>
<text top="850" left="483" width="331" height="15" font="9"><a href="pdfxml.html#68"> .......................................................................... 56 </a></text>
<text top="880" left="216" width="191" height="16" font="1"><a href="pdfxml.html#68">4.6.2 Programming Model</a></text>
<text top="881" left="407" width="407" height="15" font="9"><a href="pdfxml.html#68"> ............................................................................................ 56 </a></text>
<text top="911" left="216" width="196" height="16" font="1"><a href="pdfxml.html#69">4.6.3 Integrate with CUDA</a></text>
<text top="912" left="412" width="402" height="15" font="9"><a href="pdfxml.html#69"> ........................................................................................... 57 </a></text>
<text top="942" left="216" width="160" height="16" font="1"><a href="pdfxml.html#71">4.6.4 Astronomy Data</a></text>
<text top="943" left="376" width="438" height="15" font="9"><a href="pdfxml.html#71"> .................................................................................................... 59 </a></text>
<text top="974" left="216" width="161" height="16" font="1"><a href="pdfxml.html#71">4.6.5 N-body Problem</a></text>
<text top="975" left="377" width="437" height="15" font="9"><a href="pdfxml.html#71"> ................................................................................................... 59 </a></text>
<text top="1004" left="216" width="269" height="16" font="1"><a href="pdfxml.html#74">4.6.6 N-body CUDA Implementation</a></text>
<text top="1005" left="486" width="329" height="15" font="9"><a href="pdfxml.html#74"> ......................................................................... 62 </a></text>
<text top="1036" left="199" width="217" height="16" font="1"><a href="pdfxml.html#75">Body-Body Force Calculation</a></text>
<text top="1037" left="416" width="399" height="15" font="9"><a href="pdfxml.html#75"> .......................................................................................... 63 </a></text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">vi </text>
<text top="166" left="199" width="162" height="16" font="1"><a href="pdfxml.html#75">Tile Force Calculation</a></text>
<text top="167" left="361" width="453" height="15" font="9"><a href="pdfxml.html#75"> ....................................................................................................... 63 </a></text>
<text top="197" left="216" width="211" height="16" font="1"><a href="pdfxml.html#76">4.6.7 Galaxy Implementation</a></text>
<text top="198" left="427" width="387" height="15" font="9"><a href="pdfxml.html#76"> ....................................................................................... 64 </a></text>
<text top="228" left="216" width="94" height="16" font="1"><a href="pdfxml.html#78">4.6.8 Results</a></text>
<text top="229" left="310" width="505" height="15" font="9"><a href="pdfxml.html#78"> .................................................................................................................... 66 </a></text>
<text top="259" left="199" width="186" height="16" font="1"><a href="pdfxml.html#79">4.7 Performance Analysis</a></text>
<text top="260" left="385" width="429" height="15" font="9"><a href="pdfxml.html#79"> ................................................................................................. 67 </a></text>
<text top="290" left="216" width="151" height="16" font="1"><a href="pdfxml.html#79">4.7.1 Approximation</a></text>
<text top="291" left="367" width="448" height="15" font="9"><a href="pdfxml.html#79"> ...................................................................................................... 67 </a></text>
<text top="321" left="216" width="157" height="16" font="1"><a href="pdfxml.html#80">4.7.2 Shared Memory</a></text>
<text top="322" left="373" width="441" height="15" font="9"><a href="pdfxml.html#80"> .................................................................................................... 68 </a></text>
<text top="352" left="216" width="130" height="16" font="1"><a href="pdfxml.html#80">4.7.3 Loop Unroll</a></text>
<text top="353" left="346" width="468" height="15" font="9"><a href="pdfxml.html#80"> ........................................................................................................... 68 </a></text>
<text top="383" left="216" width="351" height="16" font="1"><a href="pdfxml.html#81">4.7.4 Performance Increase as Block Size Varies</a></text>
<text top="384" left="567" width="247" height="15" font="9"><a href="pdfxml.html#81"> ...................................................... 69 </a></text>
<text top="415" left="216" width="302" height="16" font="1"><a href="pdfxml.html#82">4.7.5 Improving Performance for Small N</a></text>
<text top="416" left="519" width="296" height="15" font="9"><a href="pdfxml.html#82"> ................................................................. 70 </a></text>
<text top="446" left="162" width="653" height="16" font="1"><a href="pdfxml.html#83">5. Future Work and Conclusion .........................................................................................71 </a></text>
<text top="477" left="199" width="119" height="16" font="1"><a href="pdfxml.html#83">5.1 Future Work</a></text>
<text top="478" left="318" width="496" height="15" font="9"><a href="pdfxml.html#83"> .................................................................................................................. 71 </a></text>
<text top="508" left="199" width="109" height="16" font="1"><a href="pdfxml.html#84">5.2 Conclusion</a></text>
<text top="509" left="308" width="506" height="15" font="9"><a href="pdfxml.html#84"> .................................................................................................................... 72 </a></text>
<text top="539" left="162" width="653" height="16" font="1"><a href="pdfxml.html#85">Bibliography ......................................................................................................................73 </a></text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">v </text>
<text top="247" left="486" width="5" height="16" font="1"> </text>
<text top="280" left="389" width="201" height="22" font="8"><b>LIST OF TABLES </b></text>
<text top="320" left="486" width="5" height="16" font="4"><b> </b></text>
<text top="351" left="248" width="566" height="16" font="1">                                                                                                                     Page </text>
<text top="382" left="162" width="657" height="16" font="1">1. 16 nodes for MPI Program…………………………………………………...………..19  </text>
<text top="413" left="162" width="652" height="16" font="1">2. Each node has only one process ………………………………………………………20 </text>
<text top="444" left="162" width="652" height="16" font="1">3. 16 nodes for MPI Quicksort……...…………………………………………………....24 </text>
<text top="475" left="162" width="652" height="16" font="1">4. Each node has only one process…..…………………………………………………...25 </text>
<text top="506" left="162" width="649" height="16" font="1">5. Different number of processes in fixed nodes...………………………………………26 </text>
<text top="537" left="162" width="649" height="16" font="1">6. Different number of processes running on the head node...…………………………..27 </text>
<text top="568" left="162" width="650" height="16" font="1">7. Performance for sequential and MPI implementation…..………………..…………...32 </text>
<text top="626" left="162" width="5" height="16" font="1"> </text>
<text top="684" left="162" width="5" height="16" font="1"> </text>
<text top="742" left="162" width="5" height="16" font="1"> </text>
<text top="800" left="162" width="5" height="16" font="1"> </text>
<text top="858" left="162" width="5" height="16" font="1"> </text>
<text top="916" left="162" width="5" height="16" font="1"> </text>
<text top="974" left="162" width="5" height="16" font="1"> </text>
<text top="1032" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">vi </text>
<text top="220" left="162" width="5" height="16" font="1"> </text>
<text top="253" left="383" width="213" height="22" font="8"><b>LIST OF FIGURES </b></text>
<text top="293" left="486" width="5" height="16" font="4"><b> </b></text>
<text top="324" left="248" width="566" height="16" font="1">                                                                                                                     Page </text>
<text top="355" left="162" width="657" height="16" font="1">1. MPI and C data  type….………………………………………………………………..7  </text>
<text top="386" left="162" width="653" height="16" font="1">2. Rank Sort Performance Result.……………………..…………………………………19 </text>
<text top="417" left="162" width="653" height="16" font="1">3. Quick Sort diagrammatic representation………...…………………………………....21 </text>
<text top="448" left="162" width="653" height="16" font="1">4. MPI parallel sort with 6 processes..…………………………………………………...23 </text>
<text top="479" left="162" width="653" height="16" font="1">5. Quick Sort Performance Result.………………………………………………………25 </text>
<text top="510" left="162" width="653" height="16" font="1">6. Performance for different number of nodes…………………………………………..26 </text>
<text top="541" left="162" width="653" height="16" font="1">7. Performance for Multiple Processes………………………...………………………...27 </text>
<text top="572" left="162" width="653" height="16" font="1">8.  Julia  Sets  results………………………………………….…………………………...31 </text>
<text top="603" left="162" width="653" height="16" font="1">9. Iteration=3000 times…..………………………………….…………………………...32 </text>
<text top="634" left="162" width="653" height="16" font="1">10. CUDA Thread Hierarchies…..…………………………………….………………...36 </text>
<text top="665" left="162" width="653" height="16" font="1">11. CUDA Memory Hierarchies…………………………….…………………………...38 </text>
<text top="696" left="162" width="653" height="16" font="1">12. Velocity and density are defined in the center of each cell…..……………………...43 </text>
<text top="727" left="162" width="653" height="16" font="1">13.  Advection…....………………………………………….…………………….……..45 </text>
<text top="758" left="162" width="653" height="16" font="1">14. Difussion ……………………………………………….…………………….……...46 </text>
<text top="789" left="162" width="653" height="16" font="1">15. Mass conserving field……….………………………….…………………….……...47 </text>
<text top="820" left="162" width="653" height="16" font="1">16. Fluid simulation with waves and rain….……………….…………………….……...49 </text>
<text top="851" left="162" width="653" height="16" font="1">17. Performance for each function………………………….…………………….……...50 </text>
<text top="883" left="162" width="653" height="16" font="1">18. Parallel Rendering……………………………………………………………………54 </text>
<text top="914" left="162" width="653" height="16" font="1">19. Equalizer Libraries...…………………………………………………………………55 </text>
<text top="945" left="162" width="653" height="16" font="1">20. Programming Model…………………………………………………………………57 </text>
<text top="976" left="162" width="653" height="16" font="1">21. CUDA Integration……………………………………………………………………58 </text>
<text top="1007" left="162" width="653" height="16" font="1">22.  Data  Transmission……...……………………………………………………………58 </text>
<text top="1038" left="162" width="653" height="16" font="1">23. CUDA Galaxy Simulation…...………………………………………………………66 </text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="485" width="27" height="14" font="0">vii </text>
<text top="220" left="162" width="5" height="16" font="1"> </text>
<text top="253" left="420" width="132" height="22" font="8"><b>GLOSSARY</b></text>
<text top="257" left="552" width="5" height="16" font="1"> </text>
<text top="292" left="162" width="5" height="16" font="1"> </text>
<text top="324" left="162" width="156" height="16" font="4"><b>Parallel Computing </b></text>
<text top="355" left="180" width="634" height="16" font="1">Parallel computing is a form of computation in which many calculations are carried out </text>
<text top="386" left="162" width="635" height="16" font="1">simultaneously, operating on the principle that large problems can often be divided into </text>
<text top="417" left="162" width="362" height="16" font="1">smaller ones, which are then solved concurrently. </text>
<text top="448" left="162" width="5" height="16" font="4"><b> </b></text>
<text top="479" left="162" width="232" height="16" font="4"><b>Shared Memory Architecture </b></text>
<text top="510" left="180" width="633" height="16" font="1">In computer architecture, Shared Memory Architecture (SMA) refers to a design where </text>
<text top="541" left="162" width="644" height="16" font="1">each machine/chip does not have its own dedicated memory, and instead shares the main </text>
<text top="572" left="162" width="371" height="16" font="1">system RAM with the CPU and other components. </text>
<text top="603" left="162" width="5" height="16" font="1"> </text>
<text top="635" left="162" width="266" height="16" font="4"><b>Distributed Memory Architecture </b></text>
<text top="665" left="180" width="608" height="16" font="1">Distributed Shared Memory (DSM), in Computer Architecture is a form of memory </text>
<text top="696" left="162" width="643" height="16" font="1">architecture where the (physically separate) memories can be addressed as one (logically </text>
<text top="727" left="162" width="165" height="16" font="1">shared) address space. </text>
<text top="758" left="162" width="5" height="16" font="1"> </text>
<text top="790" left="162" width="183" height="16" font="4"><b>Multi-Core Computing </b></text>
<text top="820" left="180" width="615" height="16" font="1">Multi-core computing is, at its most basic, the issue of how to fit multiple processing </text>
<text top="851" left="162" width="498" height="16" font="1">cores onto a single chip to produce a functional and efficient whole.  </text>
<text top="883" left="162" width="5" height="16" font="1"> </text>
<text top="914" left="162" width="134" height="16" font="4"><b>GPU Computing </b></text>
<text top="945" left="180" width="569" height="16" font="1">By using the power of a GPU (graphics processing unit) to do general purpose </text>
<text top="976" left="162" width="600" height="16" font="1">scientific and engineering computing, also called General-Purpose computation on </text>
<text top="1007" left="162" width="280" height="16" font="1">Graphics Processing Units (GPGPU).  </text>
<text top="1038" left="180" width="5" height="16" font="1"> </text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">v </text>
<text top="166" left="162" width="39" height="16" font="4"><b>MPI </b></text>
<text top="197" left="180" width="588" height="16" font="1">Message Passing Interface (MPI) is a standardized and portable message-passing </text>
<text top="228" left="162" width="631" height="16" font="1">library designed by a group of researchers from academia and industry to function on a </text>
<text top="259" left="162" width="261" height="16" font="1">wide variety of parallel computers.  </text>
<text top="290" left="162" width="5" height="16" font="1"> </text>
<text top="322" left="162" width="86" height="16" font="4"><b>Open MPI </b></text>
<text top="352" left="180" width="623" height="16" font="1">The Open MPI Project is an open source MPI-2 implementation that is developed and </text>
<text top="383" left="162" width="536" height="16" font="1">maintained by a consortium of academic, research, and industry partners.  </text>
<text top="415" left="162" width="5" height="16" font="1"> </text>
<text top="446" left="162" width="62" height="16" font="4"><b>Cluster </b></text>
<text top="477" left="180" width="607" height="16" font="1">A computer cluster is a group of linked computers, working together closely thus in </text>
<text top="508" left="162" width="627" height="16" font="1">many respects forming a single computer. The components of a cluster are commonly, </text>
<text top="539" left="162" width="529" height="16" font="1">but not always, connected to each other through fast local area networks. </text>
<text top="570" left="162" width="5" height="16" font="1"> </text>
<text top="601" left="162" width="230" height="16" font="1"> <b>Divide and Conquer Method </b></text>
<text top="632" left="180" width="611" height="16" font="1">A divide and conquer algorithm works by recursively breaking down a problem into </text>
<text top="663" left="162" width="599" height="16" font="1">two or more sub-problems of the same (or related) type, until these become simple </text>
<text top="694" left="162" width="618" height="16" font="1">enough to be solved directly. The solutions to the sub-problems are then combined to </text>
<text top="725" left="162" width="285" height="16" font="1">give a solution to the original problem. </text>
<text top="756" left="162" width="5" height="16" font="1"> </text>
<text top="788" left="162" width="73" height="16" font="4"><b>OpenGL </b></text>
<text top="818" left="180" width="583" height="16" font="1">OpenGL (Open Graphics Library)[3] is a standard specification defining a cross-</text>
<text top="849" left="162" width="640" height="16" font="1">language, cross-platform API for writing applications that produce 2D and 3D computer </text>
<text top="880" left="162" width="75" height="16" font="1">graphics.  </text>
<text top="911" left="162" width="5" height="16" font="1"> </text>
<text top="942" left="162" width="5" height="16" font="1"> </text>
<text top="974" left="162" width="5" height="16" font="1"> </text>
<text top="1005" left="162" width="57" height="16" font="4"><b>CUDA </b></text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">vi </text>
<text top="162" left="180" width="579" height="20" font="7">Compute United Device Architecture (CUDA) is NVIDIA’s parallel computing </text>
<text top="197" left="162" width="631" height="16" font="1">architecture. It enables dramatic increases in computing performance by harnessing the </text>
<text top="228" left="162" width="152" height="16" font="1">power of the GPUs.  </text>
<text top="259" left="162" width="5" height="16" font="1"> </text>
<text top="291" left="162" width="64" height="16" font="4"><b>Kernels </b></text>
<text top="321" left="180" width="613" height="16" font="1">CUDA C extends C by allowing the programmer to define C functions which can be </text>
<text top="352" left="162" width="165" height="16" font="1">run on a GPU device.  </text>
<text top="383" left="162" width="5" height="16" font="1"> </text>
<text top="415" left="162" width="203" height="16" font="4"><b>Navier-Strokes Equations </b></text>
<text top="446" left="180" width="631" height="16" font="1">In physics, the Navier–Stokes equations, named after Claude-Louis Navier and George </text>
<text top="477" left="162" width="410" height="16" font="1">Gabriel Stokes, describe the motion of fluid substances.  </text>
<text top="508" left="162" width="5" height="16" font="1"> </text>
<text top="539" left="162" width="255" height="16" font="4"><b>Helmholtz Hodge decomposition </b></text>
<text top="570" left="180" width="617" height="16" font="1">In physics and mathematics, in the area of vector calculus, Helmholtz's theorem, also </text>
<text top="601" left="162" width="649" height="16" font="1">known as the fundamental theorem of vector calculus, states that any sufficiently smooth, </text>
<text top="632" left="162" width="608" height="16" font="1">rapidly decaying vector field in three dimensions can be resolved into the sum of an </text>
<text top="663" left="162" width="597" height="16" font="1">irrotational (curl-free) vector field and a solenoidal (divergence-free) vector field;  </text>
<text top="694" left="162" width="5" height="16" font="1"> </text>
<text top="725" left="162" width="150" height="16" font="4"><b>Parallel Rendering </b></text>
<text top="756" left="180" width="631" height="16" font="1">Parallel rendering (or Distributed rendering) is the application of parallel programming </text>
<text top="787" left="162" width="603" height="16" font="1">to the computational domain of computer graphics. Rendering graphics can require </text>
<text top="818" left="162" width="646" height="16" font="1">massive computational resources for complex scenes that arise in scientific visualization, </text>
<text top="849" left="162" width="438" height="16" font="1">medical visualization, CAD applications, and virtual reality. </text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">1 </text>
<text top="249" left="291" width="415" height="22" font="8"><b>1. Introduction of Parallel Computation </b></text>
<text top="316" left="162" width="5" height="16" font="4"><b> </b></text>
<text top="346" left="162" width="5" height="16" font="1"> </text>
<text top="367" left="162" width="5" height="16" font="1"> </text>
<text top="416" left="162" width="236" height="19" font="5"><b>1.1 Parallel Computation  </b></text>
<text top="478" left="162" width="638" height="16" font="1">    The complexity and data requirements of computational science problems in research </text>
<text top="509" left="162" width="617" height="16" font="1">areas such as astronomy simulation, weather prediction, and global climate modeling </text>
<text top="540" left="162" width="610" height="16" font="1">continue to increase in recent year. However, the computational ability has been left </text>
<text top="571" left="162" width="643" height="16" font="1">behind. For this reason, parallel computing methods were developed. Parallel computing </text>
<text top="602" left="162" width="619" height="16" font="1">is an evolution of serial computing that attempts to emulate what has always been the </text>
<text top="633" left="162" width="634" height="16" font="1">state of affairs in the natural world: many complex, interrelated events happening at the </text>
<text top="665" left="162" width="652" height="16" font="1">same time, yet within a sequence [3]. In parallel computing, a large number of computers, </text>
<text top="696" left="162" width="646" height="16" font="1">each with multiple processors, are connected to each other and make every processor can </text>
<text top="727" left="162" width="652" height="16" font="1">work simultaneously to solve a smaller part of a complex problem which is too large for a </text>
<text top="758" left="162" width="638" height="16" font="1">single computer. To take advantage of parallel computing, a program must be written in </text>
<text top="789" left="162" width="615" height="16" font="1">parallel. Execution of the program occurs on more than one process, where a process </text>
<text top="820" left="162" width="636" height="16" font="1">represents a single instance of a program (or subprogram) executing autonomously on a </text>
<text top="851" left="162" width="646" height="16" font="1">physical processor. The obvious performance increased in the parallel computation is the </text>
<text top="882" left="162" width="132" height="16" font="1">primary objective.</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">2 </text>
<text top="194" left="162" width="341" height="19" font="5"><b>1.2 Parallel Computing Architectures </b></text>
<text top="256" left="162" width="648" height="16" font="1">    We can categorize parallel machine based on its memory architecture. Each one has its </text>
<text top="287" left="162" width="598" height="16" font="1">own advantage and disadvantage. Both of them are widely used in today’s parallel </text>
<text top="318" left="162" width="77" height="16" font="1">machines. </text>
<text top="349" left="162" width="5" height="16" font="1"> </text>
<text top="398" left="162" width="171" height="16" font="4"><b>1.2.1 Shared Memory </b></text>
<text top="455" left="162" width="637" height="16" font="1">   Shared memory refers to a large block of random access memory that can be accessed </text>
<text top="486" left="162" width="620" height="16" font="1">by several different central processing units (CPUs) in a multiple-processor computer </text>
<text top="517" left="162" width="644" height="16" font="1">system [2]. Multiple processors can operate independently while share the same memory </text>
<text top="548" left="162" width="652" height="16" font="1">resources. Changes in a memory location effected by one processor are visible to all other </text>
<text top="579" left="162" width="639" height="16" font="1">processors. The advantages of this architecture are providing a user friend programming </text>
<text top="611" left="162" width="650" height="16" font="1">perspective to memory and it also has data sharing between tasks is both fast and uniform </text>
<text top="642" left="162" width="613" height="16" font="1">due to the proximity of memory to CPUs. On the other side, primary disadvantage is </text>
<text top="673" left="162" width="645" height="16" font="1">lacking of scalability between memory and CPUs. Adding more CPUs can geometrically </text>
<text top="704" left="162" width="647" height="16" font="1">increase on the shared memory-CPU path, and for cache coherent systems, geometrically </text>
<text top="735" left="162" width="603" height="16" font="1">increase traffic associated with cache/memory management. In addition, it requires </text>
<text top="766" left="162" width="617" height="16" font="1">programmer’s responsibility to do the synchronization and ensure &#34;correct&#34; access of </text>
<text top="797" left="162" width="584" height="16" font="1">global memory. The expense of this behavior becomes increasingly difficult and </text>
<text top="828" left="162" width="644" height="16" font="1">expensive to design and produce shared memory machines with ever increasing numbers </text>
<text top="859" left="162" width="109" height="16" font="1">of processors.  </text>
<text top="890" left="162" width="5" height="16" font="1"> </text>
<text top="948" left="162" width="203" height="16" font="4"><b>1.2.2 Distributed Memory </b></text>
<text top="1006" left="180" width="599" height="16" font="1">Like shared memory systems, distributed memory systems vary widely but share a </text>
<text top="1037" left="162" width="650" height="16" font="1">common characteristic. Distributed memory systems require a communication network to </text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="10" size="12" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">3 </text>
<text top="166" left="162" width="596" height="16" font="1">connect inter-processor memory. The advantages include memory is scalable with </text>
<text top="197" left="162" width="594" height="16" font="1">number of processors. Each processor can rapidly access its own memory without </text>
<text top="228" left="162" width="640" height="16" font="1">interference and without the overhead incurred with trying to maintain cache coherency. </text>
<text top="259" left="162" width="609" height="16" font="1">It can also use commodity, off-the-shelf processors and networking to save the cost. </text>
<text top="290" left="162" width="615" height="16" font="1">However, the programmer is responsible for many of the details associated with data </text>
<text top="321" left="162" width="630" height="16" font="1">communication between processors. It may be difficult to map existing data structures, </text>
<text top="352" left="162" width="404" height="16" font="1">based on global memory, to this memory organization.  </text>
<text top="383" left="162" width="5" height="16" font="1"> </text>
<text top="443" left="162" width="251" height="19" font="5"><b>1.3 Multi-cored Computing </b></text>
<text top="505" left="180" width="614" height="16" font="1">A multi-core system is a single-processor CPU that contains two or more cores, with </text>
<text top="536" left="162" width="636" height="16" font="1">each core housing independent microprocessors. A multi-core microprocessor performs </text>
<text top="567" left="162" width="597" height="16" font="1">multiprocessing in a single physical package. Multi-core systems share computing </text>
<text top="598" left="162" width="631" height="16" font="1">resources that are often duplicated in multiprocessor systems, such as the L2 cache and </text>
<text top="629" left="162" width="568" height="16" font="1">front-side bus [7]. The performance brought by multi-core system is similar to </text>
<text top="660" left="162" width="652" height="16" font="1">multiprocessor systems but often at a significantly lower cost because a motherboard with </text>
<text top="691" left="162" width="603" height="16" font="1">support for multiple processors, such as multiple processor sockets, is not required. </text>
<text top="722" left="162" width="5" height="16" font="1"> </text>
<text top="781" left="162" width="188" height="19" font="5"><b>1.4 GPU Computing </b></text>
<text top="843" left="180" width="627" height="16" font="1">General-purpose computing on graphics processing units (GPGPU) is the technique of </text>
<text top="875" left="162" width="594" height="16" font="1">using a GPU, which typically handles computation only for computer graphics, to </text>
<text top="905" left="162" width="589" height="16" font="1">perform computation in applications traditionally handled by the CPU. It is made </text>
<text top="937" left="162" width="628" height="16" font="1">possible by the addition of programmable stages and higher precision arithmetic to the </text>
<text top="968" left="162" width="633" height="16" font="1">rendering pipelines, which allows software developers to use stream processing on non-</text>
<text top="999" left="162" width="125" height="16" font="1">graphics data [1].</text>
<text top="995" left="287" width="4" height="19" font="10"> </text>
<text top="999" left="292" width="487" height="16" font="1">In comparison to the central processor’s traditional data processing </text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">4 </text>
<text top="166" left="162" width="641" height="16" font="1">pipeline, performing general-purpose computations on a graphics processing unit (GPU) </text>
<text top="197" left="162" width="632" height="16" font="1">is a new concept. There are a variety of computational resources available on the GPU: </text>
<text top="228" left="162" width="649" height="16" font="4"><b>Programmable processors</b> – Vertex, primitive, and fragment shaders allow programmer </text>
<text top="259" left="162" width="271" height="16" font="1">to perform kernel on streams of data. </text>
<text top="290" left="162" width="609" height="16" font="4"><b>Rasterizer</b> – creates fragments and interpolates per-vertex constants such as texture </text>
<text top="321" left="162" width="164" height="16" font="1">coordinates and color. </text>
<text top="352" left="162" width="326" height="16" font="4"><b>Texture Unit</b> – read only memory interface. </text>
<text top="383" left="162" width="331" height="16" font="4"><b>Framebuffer</b> – write only memory interface. </text>
<text top="415" left="162" width="601" height="16" font="1">In fact, the programmer can substitute a write only texture for output instead of the </text>
<text top="446" left="162" width="632" height="16" font="1">framebuffer. This is accomplished either through Render to Texture (RTT), Render-To-</text>
<text top="477" left="162" width="530" height="16" font="1">Backbuffer-Copy-To-Texture (RTBCTT), or the more recent stream-out. </text>
<text top="543" left="162" width="5" height="16" font="1"> </text>
<text top="609" left="162" width="5" height="16" font="1"> </text>
<text top="675" left="162" width="5" height="16" font="1"> </text>
<text top="741" left="162" width="5" height="16" font="1"> </text>
<text top="807" left="162" width="5" height="16" font="1"> </text>
<text top="873" left="162" width="5" height="16" font="1"> </text>
<text top="940" left="162" width="5" height="16" font="1"> </text>
<text top="1006" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="11" size="21" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">5 </text>
<text top="222" left="305" width="392" height="22" font="8"><b>2. CPU Parallel Programming—MPI  </b></text>
<text top="289" left="162" width="5" height="16" font="1"> </text>
<text top="319" left="162" width="5" height="16" font="1"> </text>
<text top="340" left="162" width="5" height="16" font="1"> </text>
<text top="389" left="162" width="195" height="19" font="5"><b>2.1 MPI introduction </b></text>
<text top="451" left="180" width="613" height="16" font="1">MPI was designed to be a standard implementation of the message-passing model of </text>
<text top="482" left="162" width="623" height="16" font="1">parallel computing and consists of a set of C functions or FORTRAN subroutines that </text>
<text top="513" left="162" width="645" height="16" font="1">you insert into source code to perform data communication between processes. Although </text>
<text top="544" left="162" width="615" height="16" font="1">MPI programs include one or more calls to a library of message-passing functions or </text>
<text top="575" left="162" width="637" height="16" font="1">subroutines, MPI itself is not a library. Rather, MPI is an interface specification of what </text>
<text top="606" left="162" width="647" height="16" font="1">such a message-passing library should be in order to provide a standard for the writing of </text>
<text top="638" left="162" width="260" height="16" font="1">message passing parallel programs. </text>
<text top="669" left="162" width="5" height="16" font="1"> </text>
<text top="728" left="162" width="139" height="19" font="5"><b>2.2 MPI Basics </b></text>
<text top="728" left="324" width="5" height="19" font="5"><b> </b></text>
<text top="790" left="180" width="609" height="16" font="1">For the beginning, we should understand the standard of MPI. The latest version for </text>
<text top="821" left="162" width="638" height="16" font="1">MPI standard is MPI-2 [4]. It usually specifies the names, calling sequences, and results </text>
<text top="852" left="162" width="612" height="16" font="1">of subroutines and functions to be called from Fortran 77 and C, respectively. It also </text>
<text top="883" left="162" width="610" height="16" font="1">provides for additional features, including tools for parallel I/O, C++ and Fortran 90 </text>
<text top="914" left="162" width="76" height="16" font="1">bindings.  </text>
<text top="945" left="180" width="622" height="16" font="1">MPI includes the following kind of routines: point to point communication, collective </text>
<text top="976" left="162" width="633" height="16" font="1">communication, process groups, process topologies, and environment management and </text>
<text top="1007" left="162" width="66" height="16" font="1">inquiry.  </text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="12" size="16" family="Symbol" color="#000000"/>
	<fontspec id="13" size="16" family="Helvetica" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">6 </text>
<text top="166" left="180" width="619" height="16" font="1">We focus mainly on point to point communication and collective communication. It's </text>
<text top="197" left="162" width="544" height="16" font="1">the elementary communication operation in MPI which indicates the direct </text>
<text top="228" left="162" width="426" height="16" font="1">communication between tow processors or two processes.  </text>
<text top="259" left="180" width="621" height="16" font="1">To understand collective communication, first we need to know the communicator. A </text>
<text top="290" left="162" width="621" height="16" font="1">communicator is an MPI object that defines a group of processes that are permitted to </text>
<text top="321" left="162" width="637" height="16" font="1">communicate with one another. Every MPI message must specify a communicator via a </text>
<text top="349" left="162" width="643" height="20" font="7">―name‖ that is included as an explicit parameter within the argument list of the MPI call. </text>
<text top="383" left="162" width="554" height="16" font="1">By default, all processes are defined as being members of the communicator </text>
<text top="415" left="162" width="599" height="16" font="1">MPI_COMM_WORLD. Collective communication routines, also called collective </text>
<text top="446" left="162" width="614" height="16" font="1">operations, transmit data among all processes in a group. These routines allow larger </text>
<text top="477" left="162" width="627" height="16" font="1">groups of processors to communicate in various ways like one-to-several or several-to-</text>
<text top="508" left="162" width="39" height="16" font="1">one.  </text>
<text top="539" left="162" width="5" height="16" font="1"> </text>
<text top="598" left="162" width="254" height="19" font="5"><b>2.3 MPI program Structure </b></text>
<text top="660" left="180" width="586" height="16" font="1">Like other programs, MPI programs have some general structures. They include: </text>
<text top="687" left="189" width="8" height="22" font="12"></text>
<text top="692" left="197" width="5" height="17" font="13"> </text>
<text top="692" left="216" width="118" height="16" font="1">MPI header file </text>
<text top="719" left="189" width="8" height="22" font="12"></text>
<text top="724" left="197" width="5" height="17" font="13"> </text>
<text top="725" left="216" width="177" height="16" font="1">To declare the variables </text>
<text top="751" left="189" width="8" height="22" font="12"></text>
<text top="756" left="197" width="5" height="17" font="13"> </text>
<text top="757" left="216" width="374" height="16" font="1">Initialize the MPI environment and communication </text>
<text top="784" left="189" width="8" height="22" font="12"></text>
<text top="789" left="197" width="5" height="17" font="13"> </text>
<text top="789" left="216" width="354" height="16" font="1">MPI calls and functions for parallel computation </text>
<text top="816" left="189" width="8" height="22" font="12"></text>
<text top="821" left="197" width="5" height="17" font="13"> </text>
<text top="822" left="216" width="225" height="16" font="1">Close the MPI communication </text>
<text top="853" left="189" width="5" height="16" font="1"> </text>
<text top="884" left="180" width="626" height="16" font="1">MPI header files like the other libraries in C, contains the prototypes of MPI functions </text>
<text top="915" left="162" width="621" height="16" font="1">and definitions of macros, special constants and data types. In C we use the following </text>
<text top="946" left="162" width="290" height="16" font="1">way to add MPI library to our program: </text>
<text top="977" left="180" width="5" height="16" font="1"> </text>
<text top="1008" left="162" width="133" height="16" font="1">#include &lt;mpi.h&gt; </text>
<text top="1039" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">7 </text>
<text top="166" left="180" width="617" height="16" font="1">The MPI functions can be called in C in the following way MPI_xxx(); For example, </text>
<text top="197" left="162" width="555" height="16" font="1">every MPI program should have at least these two functions: MPI_Init() and </text>
<text top="228" left="162" width="646" height="16" font="1">MPI_Finalize(). In C, specially defined types correspond to many MPI entities. Rules for </text>
<text top="259" left="162" width="638" height="16" font="1">type names follow the C function naming convention above. MPI defines and maintains </text>
<text top="290" left="162" width="619" height="16" font="1">its own internal data structures. These data structures are referenced through handlers </text>
<text top="321" left="162" width="657" height="16" font="1">which are returned by various MPI calls and may be used as arguments in other MPI calls. </text>
<text top="352" left="162" width="649" height="16" font="1">In C, handles are pointers to specially defined datatypes that are created via the C typedef </text>
<text top="383" left="162" width="95" height="16" font="1">mechanism.  </text>
<text top="415" left="180" width="614" height="16" font="1">As a general rule, the MPI datatype given in a receiver must match the MPI datatype </text>
<text top="446" left="162" width="620" height="16" font="1">specified in the sender. MPI hides the details of the floating-point representation. The </text>
<text top="477" left="162" width="621" height="16" font="1">following picture shows the MPI datatype corresponding to C type. Besides this, MPI </text>
<text top="508" left="162" width="648" height="16" font="1">also has its own types like MPI_COMM and MPI_STATUS which can’t be equivalent to </text>
<text top="539" left="162" width="91" height="16" font="1">standard C.  </text>
<text top="1008" left="634" width="5" height="16" font="1"> </text>
<text top="1035" left="373" width="230" height="16" font="1">Figure 1. MPI and C data types </text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">8 </text>
<text top="166" left="180" width="525" height="16" font="1">It’s necessary to know the first step for MPI programming—initializing, </text>
<text top="197" left="162" width="635" height="16" font="1">communicating and terminating.  MPI uses MPI_INIT routine to do the initialization of </text>
<text top="228" left="162" width="358" height="16" font="1">MPI program. In C it should be written like this:  </text>
<text top="259" left="180" width="5" height="16" font="1"> </text>
<text top="290" left="162" width="187" height="16" font="1">MPI_Init(&amp;argc, &amp;argv). </text>
<text top="321" left="162" width="5" height="16" font="1"> </text>
<text top="352" left="180" width="568" height="16" font="1">This function will help us set up MPI environment. It initializes MPI. All MPI </text>
<text top="383" left="162" width="601" height="16" font="1">programs must call MPI_INIT before any other MPI routine. More than one call to </text>
<text top="415" left="162" width="623" height="16" font="1">MPI_INIT by any task is erroneous. Then we need to specify our communicator. This </text>
<text top="446" left="162" width="593" height="16" font="1">will allow us to define a group of processors to communicate with each other. It’s </text>
<text top="477" left="162" width="551" height="16" font="1">essential for every MPI message to specify a communicator in the MPI call. </text>
<text top="509" left="162" width="575" height="15" font="9">MPI_COMM_WORLD is the default communicator and it contains all the processors. </text>
<text top="508" left="737" width="40" height="16" font="1"> In C </text>
<text top="539" left="162" width="575" height="16" font="1">program, usually we need to do the following thing to specify a communicator: </text>
<text top="597" left="162" width="407" height="16" font="1">    int MPI_Comm_rank(MPI_Comm comm, int *rank); </text>
<text top="663" left="162" width="399" height="16" font="1">    int MPI_Comm_size(MPI_Comm comm, int *size); </text>
<text top="729" left="180" width="552" height="16" font="1">The first line returns the rank of the local task in the group associated with a </text>
<text top="760" left="162" width="630" height="16" font="1">communicator. The rank is a unique identification in the communicator group which is </text>
<text top="791" left="162" width="642" height="16" font="1">usually started from 0. The second line defines the number of processors in the program. </text>
<text top="822" left="162" width="585" height="16" font="1">Finally, the exit routine for MPI program is described as followed in C like this:  </text>
<text top="874" left="162" width="138" height="16" font="1">    MPI_Finalize(); </text>
<text top="926" left="180" width="629" height="16" font="1">This function terminates the program by cleaning up all MPI data structures, canceling </text>
<text top="958" left="162" width="612" height="16" font="1">operations that never completed. All MPI processes should call this functions before </text>
<text top="988" left="162" width="67" height="16" font="1">finished. </text>
<text top="1019" left="162" width="5" height="16" font="1"> </text>
<text top="1051" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="21" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="492" width="14" height="14" font="0">9 </text>
<text top="167" left="162" width="468" height="19" font="5"><b>2.4 Building and Run MPI programs on the Cluster </b></text>
<text top="229" left="180" width="628" height="16" font="1">The following part is a Hello World MPI program written in C. All basic MPI routines </text>
<text top="260" left="162" width="429" height="16" font="1">are used and it will let each process print out its process id. </text>
<text top="641" left="784" width="5" height="16" font="1"> </text>
<text top="667" left="359" width="259" height="16" font="1">Code 1. MPI Hello World Program </text>
<text top="699" left="180" width="606" height="16" font="1">There is only one main.c file in the program. We use openMPI [5] library and write </text>
<text top="730" left="162" width="658" height="16" font="1">program in C, the compiler for it is mpicc. The mpicc command can be found as followed: </text>
<text top="972" left="810" width="5" height="16" font="1"> </text>
<text top="1020" left="162" width="504" height="16" font="1">Here we simply using mpicc to do the compling and linking like this: </text>
<text top="1051" left="162" width="5" height="16" font="1"> </text>
<text top="298" left="174" width="128" height="15" font="9">#include &lt;stdio.h&gt; </text>
<text top="326" left="174" width="122" height="15" font="9">#include &lt;mpi.h&gt; </text>
<text top="354" left="174" width="229" height="15" font="9">void main (int argc, char *argv[])  </text>
<text top="383" left="174" width="12" height="15" font="9">{ </text>
<text top="411" left="228" width="115" height="15" font="9">int myrank, size; </text>
<text top="440" left="228" width="393" height="15" font="9">MPI_Init(&amp;argc, &amp;argv);                 /* Initialize MPI       */ </text>
<text top="468" left="228" width="499" height="15" font="9">MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); /* Get my rank   */ </text>
<text top="497" left="228" width="529" height="15" font="9">MPI_Comm_size(MPI_COMM_WORLD, &amp;size);   /* Get the total  number of </text>
<text top="525" left="228" width="91" height="15" font="9">processors */ </text>
<text top="554" left="228" width="407" height="15" font="9">printf(&#34;Processor %d of %d: Hello World!\n&#34;, myrank, size); </text>
<text top="582" left="228" width="323" height="15" font="9">MPI_Finalize();                         /* Close MPI  */ </text>
<text top="611" left="174" width="12" height="15" font="9">} </text>
<text top="639" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="22" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">10 </text>
<text top="166" left="180" width="221" height="16" font="1"> mpicc –o helloworld main.c;  </text>
<text top="197" left="180" width="92" height="16" font="1">./helloworld </text>
<text top="228" left="162" width="5" height="16" font="1"> </text>
<text top="280" left="180" width="626" height="16" font="1">The running command for MPI command is mpirun. It is a shell script that attempts to </text>
<text top="311" left="162" width="596" height="16" font="1">hide the differences in starting jobs for various devices from the user. Mpirun will </text>
<text top="342" left="162" width="644" height="16" font="1">determine what kind of machine it is running on and start the required number of jobs on </text>
<text top="374" left="162" width="106" height="16" font="1">that machine.  </text>
<text top="404" left="180" width="588" height="16" font="1">The machine file can decide which node is involved in the program. Here we can </text>
<text top="436" left="162" width="641" height="16" font="1">simply use node machine name or IP address and write them in a file as the machine file </text>
<text top="467" left="162" width="429" height="16" font="1">(namachine). Then run this program in the cluster like this: </text>
<text top="533" left="162" width="374" height="16" font="1">mpirun –machinefile  namachine –np 4 helloworld; </text>
<text top="599" left="162" width="559" height="16" font="1">If everything goes well, the following result will be printed out in the screen: </text>
<text top="651" left="162" width="227" height="16" font="1">Processor 2 of 4: Hello World! </text>
<text top="682" left="162" width="227" height="16" font="1">Processor 1 of 4: Hello World! </text>
<text top="713" left="162" width="227" height="16" font="1">Processor 3 of 4: Hello World! </text>
<text top="744" left="162" width="227" height="16" font="1">Processor 0 of 4: Hello World! </text>
<text top="775" left="180" width="621" height="16" font="1">Each processor executes the same code simultaneously, including probing for its rank </text>
<text top="806" left="162" width="607" height="16" font="1">and size and printing the string. The order of the printed lines is essentially random. </text>
<text top="837" left="162" width="647" height="16" font="1">There is no intrinsic synchronization of operations on different processors. Therefore, for </text>
<text top="868" left="162" width="535" height="16" font="1">each time the program running, the order of the output lines may change.  </text>
<text top="899" left="162" width="5" height="16" font="1"> </text>
<text top="920" left="162" width="5" height="16" font="1"> </text>
<text top="941" left="162" width="5" height="16" font="1"> </text>
<text top="961" left="162" width="5" height="16" font="1"> </text>
<text top="982" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="23" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">11 </text>
<text top="167" left="162" width="223" height="19" font="5"><b>2.5 Basic MPI programs </b></text>
<text top="229" left="180" width="587" height="16" font="1">We will review some basic MPI programs and functions in this section. They are </text>
<text top="260" left="162" width="282" height="16" font="1">widely used in most of MPI programs. </text>
<text top="291" left="162" width="5" height="16" font="1"> </text>
<text top="350" left="162" width="159" height="16" font="4"><b>2.5.1 Time Function </b></text>
<text top="408" left="180" width="613" height="16" font="1">Time function is a widely used function is MPI programs. This function is important </text>
<text top="439" left="162" width="590" height="16" font="1">for analyzing the performance. Therefore, it’s necessary to know how to use time </text>
<text top="470" left="162" width="316" height="16" font="1">function first. In C, it declared as followed: </text>
<text top="501" left="180" width="5" height="16" font="1"> </text>
<text top="532" left="180" width="196" height="16" font="1">double MPI_Wtime(void)  </text>
<text top="563" left="162" width="5" height="16" font="1"> </text>
<text top="594" left="180" width="611" height="16" font="1">This subroutine returns the current value of time as a double precision floating point </text>
<text top="625" left="162" width="643" height="16" font="1">number of seconds. The value represents elapsed time since some point in the past. With </text>
<text top="656" left="162" width="585" height="16" font="1">this, it’s easy to calculate the time in the program for some performance analysis </text>
<text top="687" left="162" width="429" height="16" font="1">purposes.  Here is part of program for testing this function: </text>
<text top="718" left="180" width="5" height="16" font="1"> </text>
<text top="749" left="162" width="4" height="15" font="9"> </text>
<text top="777" left="162" width="4" height="15" font="9"> </text>
<text top="806" left="162" width="4" height="15" font="9"> </text>
<text top="834" left="162" width="4" height="15" font="9"> </text>
<text top="863" left="162" width="4" height="15" font="9"> </text>
<text top="891" left="162" width="4" height="15" font="9"> </text>
<text top="919" left="162" width="4" height="15" font="9"> </text>
<text top="948" left="162" width="4" height="15" font="9"> </text>
<text top="976" left="162" width="4" height="15" font="9"> </text>
</page>
<page number="24" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="14" size="14" family="Times" color="#000000"/>
	<fontspec id="15" size="18" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">12 </text>
<text top="1029" left="784" width="4" height="15" font="9"> </text>
<text top="1054" left="355" width="267" height="16" font="1">Code 2. MPI Time Testing Function </text>
<text top="174" left="228" width="282" height="15" font="9">t1 = MPI_Wtime();/*current time t1*/ </text>
<text top="206" left="228" width="278" height="15" font="9">t2 = MPI_Wtime();/*current time t2*/ </text>
<text top="236" left="228" width="203" height="15" font="9">if (t2 - t1 &gt; 0.1 || t2 - t1 &lt; 0.0)  </text>
<text top="265" left="228" width="12" height="15" font="9">{ </text>
<text top="293" left="282" width="50" height="15" font="9"> err++; </text>
<text top="322" left="282" width="493" height="15" font="9">fprintf ( stderr, &#34;Two successive calls to MPI_Wtime gave strange results: </text>
<text top="350" left="282" width="145" height="15" font="9">(%f) (%f)\n&#34;, t1, t2 ); </text>
<text top="379" left="228" width="12" height="15" font="9">} </text>
<text top="407" left="228" width="148" height="15" font="9">for (i = 0; i&lt;10; i++)   </text>
<text top="436" left="228" width="12" height="15" font="9">{ </text>
<text top="466" left="282" width="348" height="15" font="9">t1 = MPI_Wtime();/*start to calculate time*/ </text>
<text top="496" left="174" width="21" height="15" font="9">     </text>
<text top="496" left="228" width="4" height="15" font="9"> </text>
<text top="496" left="282" width="62" height="15" font="9">sleep(1); </text>
<text top="525" left="174" width="21" height="15" font="9">     </text>
<text top="525" left="228" width="4" height="15" font="9"> </text>
<text top="525" left="282" width="133" height="15" font="9">t2 = MPI_Wtime(); </text>
<text top="553" left="174" width="21" height="15" font="9">     </text>
<text top="553" left="228" width="4" height="15" font="9"> </text>
<text top="553" left="282" width="336" height="15" font="9">if (t2 - t1 &gt;= (1.0 - 0.01) &amp;&amp; t2 - t1 &lt;= 5.0) break; </text>
<text top="582" left="282" width="111" height="15" font="9">if (t2 - t1 &gt; 5.0)  </text>
<text top="610" left="282" width="39" height="15" font="9">i = 9; </text>
<text top="639" left="228" width="12" height="15" font="9">} </text>
<text top="667" left="228" width="81" height="15" font="9">if (i == 10)  </text>
<text top="695" left="228" width="12" height="15" font="9">{ </text>
<text top="724" left="282" width="406" height="15" font="9">fprintf( stderr, &#34;Timer around sleep(1) did not give 1 second; </text>
<text top="753" left="282" width="136" height="15" font="9">gave %f\n&#34;,t2 - t1 ); </text>
<text top="781" left="282" width="42" height="15" font="9">err++;</text>
<text top="780" left="324" width="5" height="16" font="1"> </text>
<text top="809" left="228" width="12" height="15" font="9">} </text>
<text top="838" left="228" width="236" height="15" font="9">tick = MPI_Wtick();                      //</text>
<text top="835" left="464" width="5" height="18" font="15"> </text>
<text top="838" left="469" width="254" height="15" font="9">Returns the resolution of MPI_Wtime </text>
<text top="866" left="228" width="182" height="15" font="9">if (tick &gt; 1.0 || tick &lt; 0.0) { </text>
<text top="895" left="282" width="46" height="15" font="9">err++; </text>
<text top="923" left="282" width="431" height="15" font="9">fprintf( stderr, &#34;MPI_Wtick gave a strange result: (%f)\n&#34;, tick ); </text>
<text top="952" left="228" width="12" height="15" font="9">} </text>
<text top="980" left="228" width="115" height="15" font="9">MPI_Finalize( ); </text>
<text top="1009" left="174" width="8" height="15" font="9">}</text>
<text top="1008" left="182" width="5" height="16" font="1"> </text>
<text top="1037" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="25" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">13 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="224" left="162" width="271" height="16" font="4"><b>2.5.2 Initialize and Abort Function </b></text>
<text top="290" left="180" width="599" height="16" font="1">The initialized function is the only function that can be called before MPI_Init() to </text>
<text top="321" left="162" width="625" height="16" font="1">indicate whether MPI_Init() has been called.  The Abort function provides a chance to </text>
<text top="352" left="162" width="599" height="16" font="1">exit the program when some fatal errors occurred. In C, they declared as followed: </text>
<text top="418" left="180" width="201" height="15" font="9">int MPI_Initialized(int *flag); </text>
<text top="482" left="180" width="338" height="15" font="9">int MPI_Abort(MPI_Comm comm, int errorcode); </text>
<text top="532" left="162" width="613" height="16" font="1">Then we have the following example to use the function. In this program, the master </text>
<text top="563" left="162" width="148" height="16" font="1">node will be killed.  </text>
</page>
<page number="26" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">14 </text>
<text top="638" left="784" width="4" height="15" font="9"> </text>
<text top="662" left="162" width="4" height="15" font="9"> </text>
<text top="974" left="784" width="4" height="15" font="9"> </text>
<text top="999" left="280" width="417" height="16" font="1">Code 3. Example of MPI initialization and abort function </text>
<text top="1030" left="162" width="5" height="16" font="1"> </text>
<text top="172" left="174" width="117" height="15" font="9">#include &#34;mpi.h&#34; </text>
<text top="201" left="174" width="128" height="15" font="9">#include &lt;stdio.h&gt; </text>
<text top="229" left="174" width="214" height="15" font="9">int main( int argc, char **argv ) </text>
<text top="258" left="174" width="12" height="15" font="9">{ </text>
<text top="286" left="228" width="109" height="15" font="9">int node, size, i; </text>
<text top="315" left="228" width="132" height="15" font="9">int masternode = 0; </text>
<text top="343" left="228" width="172" height="15" font="9">MPI_Init(&amp;argc, &amp;argv); </text>
<text top="371" left="228" width="352" height="15" font="9">MPI_Comm_rank(MPI_COMM_WORLD, &amp;node); </text>
<text top="400" left="228" width="342" height="15" font="9">MPI_Comm_size(MPI_COMM_WORLD, &amp;size); </text>
<text top="429" left="228" width="156" height="15" font="9">for (i=1; i&lt;argc; i++) { </text>
<text top="457" left="282" width="486" height="15" font="9">fprintf(stderr,&#34;myid=%d,procs=%d,argv[%d]=%s\n&#34;,node,size,i,argv[i]); </text>
<text top="485" left="282" width="353" height="15" font="9">if (argv[i] &amp;&amp; strcmp( &#34;lastmaster&#34;, argv[i] ) == 0) { </text>
<text top="514" left="336" width="338" height="15" font="9">masternode = size-1; /* the last one is the master*/ </text>
<text top="542" left="282" width="12" height="15" font="9">} </text>
<text top="571" left="228" width="12" height="15" font="9">} </text>
<text top="599" left="228" width="172" height="15" font="9">if(node == masternode) { </text>
<text top="628" left="174" width="5" height="16" font="1"> </text>
<text top="697" left="282" width="262" height="15" font="9">// the master will do the abort function; </text>
<text top="726" left="282" width="375" height="15" font="9">fprintf(stderr,&#34;myid=%d is masternode Abort!\n&#34;,node); </text>
<text top="754" left="282" width="279" height="15" font="9">MPI_Abort(MPI_COMM_WORLD, 99); </text>
<text top="783" left="228" width="12" height="15" font="9">} </text>
<text top="811" left="228" width="42" height="15" font="9">else { </text>
<text top="840" left="282" width="408" height="15" font="9">fprintf(stderr,&#34;myid=%d is not masternode Barrier!\n&#34;,node); </text>
<text top="868" left="282" width="263" height="15" font="9">MPI_Barrier(MPI_COMM_WORLD); </text>
<text top="897" left="282" width="12" height="15" font="9">} </text>
<text top="925" left="228" width="111" height="15" font="9">MPI_Finalize(); </text>
<text top="954" left="174" width="9" height="16" font="1">}</text>
<text top="955" left="183" width="4" height="15" font="9"> </text>
<text top="985" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="27" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="16" size="16" family="Times" color="#008000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">15 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="225" left="162" width="361" height="19" font="5"><b>2.6 MPI Implementation of Algorithms  </b></text>
<text top="287" left="180" width="514" height="16" font="1">This section looks for some algorithms and tries to provide the parallel </text>
<text top="318" left="162" width="650" height="16" font="1">implementations using MPI. Rank Sort, Quick Sort and Fast Fourier Transform (FFT) are </text>
<text top="350" left="162" width="414" height="16" font="1">investigated and relevant performance data are provided. </text>
<text top="381" left="162" width="5" height="16" font="1"> </text>
<text top="439" left="162" width="125" height="16" font="4"><b>2.6.1 Rank Sort </b></text>
<text top="497" left="180" width="604" height="16" font="1">This is a simple sorting algorithm and is easy to apply it in a parallel programming. </text>
<text top="528" left="162" width="640" height="16" font="1">The detail of this algorithm is to give each element a rank. The ranks mean find out how </text>
<text top="559" left="162" width="631" height="16" font="1">many elements in the whole are less than the current element. As we get every rank for </text>
<text top="590" left="162" width="297" height="16" font="1">every element, we will finally sort them. </text>
<text top="621" left="180" width="597" height="16" font="1">The sequential version of rank sort can be described as followed: We assume a[1], </text>
<text top="648" left="162" width="580" height="20" font="7">a[2]….a[n] are input numbers, and b[1]….b[n] are output numbers, we have the </text>
<text top="683" left="162" width="154" height="16" font="1">following algorithm: </text>
<text top="714" left="180" width="5" height="16" font="1"> </text>
<text top="747" left="162" width="136" height="16" font="1">Input：a[1]…a[n] </text>
<text top="782" left="162" width="151" height="16" font="1">Output：b[1]…b[n] </text>
<text top="815" left="162" width="48" height="16" font="1">Begin </text>
<text top="846" left="162" width="118" height="16" font="1">for i=1 to n do   </text>
<text top="846" left="280" width="181" height="16" font="16">// do a for loop (n times) </text>
<text top="877" left="162" width="26" height="16" font="1">(1) </text>
<text top="877" left="216" width="33" height="16" font="1">k=1 </text>
<text top="877" left="249" width="521" height="16" font="16">// k is served as an index and first is set to the first element of the inputs </text>
<text top="908" left="162" width="26" height="16" font="1">(2) </text>
<text top="908" left="216" width="118" height="16" font="1">for j=1 to n do   </text>
<text top="908" left="334" width="192" height="16" font="16">//do a inner loop (n times) </text>
<text top="939" left="162" width="5" height="16" font="1"> </text>
<text top="939" left="216" width="5" height="16" font="1"> </text>
<text top="939" left="270" width="5" height="16" font="1"> </text>
<text top="939" left="324" width="5" height="16" font="1"> </text>
<text top="939" left="378" width="116" height="16" font="1">if a[i]&gt;a[j] then </text>
<text top="970" left="162" width="5" height="16" font="1"> </text>
<text top="970" left="216" width="5" height="16" font="1"> </text>
<text top="970" left="270" width="5" height="16" font="1"> </text>
<text top="970" left="324" width="5" height="16" font="1"> </text>
<text top="970" left="378" width="5" height="16" font="1"> </text>
<text top="970" left="432" width="61" height="16" font="1">k=k+1   </text>
<text top="970" left="493" width="319" height="16" font="16">//find out how many inputs are smaller than </text>
<text top="1001" left="162" width="204" height="16" font="16">a[i] (count the rank for a[i]) </text>
<text top="1032" left="162" width="5" height="16" font="1"> </text>
<text top="1032" left="216" width="5" height="16" font="1"> </text>
<text top="1032" left="270" width="5" height="16" font="1"> </text>
<text top="1032" left="324" width="5" height="16" font="1"> </text>
<text top="1032" left="378" width="46" height="16" font="1">end if </text>
</page>
<page number="28" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">16 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="166" left="216" width="5" height="16" font="1"> </text>
<text top="166" left="270" width="5" height="16" font="1"> </text>
<text top="166" left="324" width="60" height="16" font="1">end for  </text>
<text top="166" left="384" width="123" height="16" font="16">// inner loop end </text>
<text top="197" left="162" width="5" height="16" font="1"> </text>
<text top="197" left="216" width="5" height="16" font="1"> </text>
<text top="197" left="270" width="26" height="16" font="1">(3) </text>
<text top="197" left="324" width="74" height="16" font="1">b[k]= a[i] </text>
<text top="197" left="398" width="176" height="16" font="16">//exchange the position  </text>
<text top="228" left="162" width="5" height="16" font="1"> </text>
<text top="228" left="216" width="5" height="16" font="1"> </text>
<text top="228" left="270" width="56" height="16" font="1">end for </text>
<text top="228" left="326" width="144" height="16" font="16">// external loop end </text>
<text top="259" left="162" width="33" height="16" font="1">End </text>
<text top="290" left="162" width="5" height="16" font="1"> </text>
<text top="321" left="180" width="578" height="16" font="1">The parallel way for this algorithm is not difficult. A divide and conquer way is </text>
<text top="352" left="162" width="602" height="16" font="1">adopted to do the parallelism. The whole sequence is divided into N parts and each </text>
<text top="383" left="162" width="649" height="16" font="1">processor (slave node) is responsible for calculating its own part and finally return results </text>
<text top="415" left="162" width="456" height="16" font="1">back to the head node. The algorithm is described as followed: </text>
<text top="447" left="162" width="141" height="16" font="1">Input： a[1]…a[n] </text>
<text top="482" left="162" width="147" height="16" font="1">Output:  b[1]…b[n] </text>
<text top="516" left="162" width="48" height="16" font="1">Begin </text>
<text top="548" left="162" width="26" height="16" font="1">(1) </text>
<text top="548" left="216" width="327" height="16" font="1">P0 broadcast a [1]…a[n] to all the processes  </text>
<text top="548" left="543" width="262" height="16" font="16">// the process 0 broadcasts the input </text>
<text top="582" left="162" width="425" height="16" font="16">streams to all the processes (assume we have N processes) </text>
<text top="614" left="162" width="26" height="16" font="1">(2) </text>
<text top="614" left="216" width="243" height="16" font="1">for all Pi where 1≤i≤N para-do </text>
<text top="614" left="459" width="326" height="16" font="16">//each of process do its own calculations and </text>
<text top="648" left="162" width="618" height="16" font="16">then return the results back to process 0. Notice that each process only calculates n/N </text>
<text top="679" left="162" width="372" height="16" font="16">numbers of inputs and the offset is based on the Pi. </text>
<text top="710" left="162" width="87" height="16" font="1">(2.1)  k=1 </text>
<text top="741" left="162" width="172" height="16" font="1">(2.2)  for j = 1 to n do </text>
<text top="772" left="162" width="5" height="16" font="1"> </text>
<text top="772" left="216" width="5" height="16" font="1"> </text>
<text top="772" left="270" width="5" height="16" font="1"> </text>
<text top="772" left="324" width="297" height="16" font="1">if (a[i] &gt; a[j]) or (a[i] = a[j] and i&gt;j) then </text>
<text top="803" left="162" width="5" height="16" font="1"> </text>
<text top="803" left="216" width="5" height="16" font="1"> </text>
<text top="803" left="270" width="5" height="16" font="1"> </text>
<text top="803" left="324" width="5" height="16" font="1"> </text>
<text top="803" left="378" width="5" height="16" font="1"> </text>
<text top="803" left="432" width="61" height="16" font="1">k = k+1 </text>
<text top="834" left="162" width="5" height="16" font="1"> </text>
<text top="834" left="216" width="5" height="16" font="1"> </text>
<text top="834" left="270" width="5" height="16" font="1"> </text>
<text top="834" left="324" width="46" height="16" font="1">end if </text>
<text top="865" left="162" width="5" height="16" font="1"> </text>
<text top="865" left="216" width="5" height="16" font="1"> </text>
<text top="865" left="270" width="5" height="16" font="1"> </text>
<text top="865" left="324" width="56" height="16" font="1">end for </text>
<text top="896" left="162" width="5" height="16" font="1"> </text>
<text top="896" left="216" width="26" height="16" font="1">(3) </text>
<text top="896" left="270" width="398" height="16" font="1">P0 receive all feed back and resort the whole sequence </text>
<text top="927" left="162" width="33" height="16" font="1">End </text>
<text top="958" left="162" width="5" height="16" font="1"> </text>
<text top="989" left="162" width="635" height="16" font="1">Then we give the code for the major function of this algorithm.  The first thing we need </text>
<text top="1020" left="162" width="294" height="16" font="1">to do is to count the rank for each value. </text>
</page>
<page number="29" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">17 </text>
<text top="623" left="784" width="5" height="16" font="1"> </text>
<text top="650" left="379" width="219" height="15" font="9">Code 4. Rank Counting function </text>
<text top="679" left="162" width="5" height="16" font="1"> </text>
<text top="710" left="162" width="361" height="16" font="1">We do the sorting in the main function with MPI: </text>
<text top="741" left="162" width="5" height="16" font="1"> </text>
<text top="772" left="162" width="5" height="16" font="1"> </text>
<text top="172" left="174" width="553" height="15" font="9">int CountRank(int *data,int DataSize,int MyLength,int *rank,int SumID,int MyID) </text>
<text top="201" left="174" width="12" height="15" font="9">{ </text>
<text top="229" left="228" width="48" height="15" font="9">int i, j; </text>
<text top="258" left="174" width="4" height="15" font="9"> </text>
<text top="258" left="228" width="91" height="15" font="9">int start, end; </text>
<text top="286" left="174" width="4" height="15" font="9"> </text>
<text top="286" left="228" width="507" height="15" font="9">start=DataSize/SumID*MyID;      /*get the start position of the target data*/ </text>
<text top="315" left="174" width="4" height="15" font="9"> </text>
<text top="315" left="228" width="474" height="15" font="9">end=start+MyLength;             /*get the end position of the target data*/ </text>
<text top="343" left="228" width="4" height="15" font="9"> </text>
<text top="343" left="282" width="147" height="15" font="9">for(j=start;j&lt;end;j++) </text>
<text top="343" left="444" width="146" height="15" font="9">/*calculate the rank*/ </text>
<text top="371" left="228" width="49" height="15" font="9">{          </text>
<text top="400" left="174" width="4" height="15" font="9"> </text>
<text top="400" left="228" width="4" height="15" font="9"> </text>
<text top="400" left="282" width="105" height="15" font="9">rank[j-start]=0; </text>
<text top="429" left="174" width="4" height="15" font="9"> </text>
<text top="429" left="228" width="4" height="15" font="9"> </text>
<text top="429" left="282" width="170" height="15" font="9">for(i=0;i&lt;DataSize;i++){ </text>
<text top="457" left="174" width="4" height="15" font="9"> </text>
<text top="457" left="228" width="4" height="15" font="9"> </text>
<text top="457" left="282" width="4" height="15" font="9"> </text>
<text top="457" left="336" width="337" height="15" font="9">if((data[j]&gt;data[i]) || ((data[j]==data[i]) &amp;&amp; (j&gt;i))) </text>
<text top="485" left="174" width="4" height="15" font="9"> </text>
<text top="485" left="228" width="4" height="15" font="9"> </text>
<text top="485" left="282" width="4" height="15" font="9"> </text>
<text top="485" left="336" width="4" height="15" font="9"> </text>
<text top="485" left="390" width="106" height="15" font="9">rank[j-start]++; </text>
<text top="514" left="174" width="4" height="15" font="9"> </text>
<text top="514" left="228" width="4" height="15" font="9"> </text>
<text top="514" left="282" width="12" height="15" font="9">} </text>
<text top="542" left="174" width="4" height="15" font="9"> </text>
<text top="542" left="228" width="12" height="15" font="9">} </text>
<text top="571" left="228" width="60" height="15" font="9">return 1; </text>
<text top="599" left="174" width="12" height="15" font="9">} </text>
<text top="628" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="30" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">18 </text>
<text top="785" left="784" width="5" height="16" font="1"> </text>
<text top="812" left="365" width="247" height="15" font="9">Code 5. MPI calculation for ranksort </text>
<text top="841" left="162" width="5" height="16" font="1"> </text>
<text top="899" left="162" width="298" height="16" font="4"><b>2.6.2 Rank Sort Performance Analysis </b></text>
<text top="957" left="180" width="608" height="16" font="1">Ranksort implementation was benchmarked with a MPI version and with sequential </text>
<text top="988" left="162" width="647" height="16" font="1">Ranksort implementation letting them to sort same set of data in varying sizes. These test </text>
<text top="1019" left="162" width="641" height="16" font="1">results were gathered by running a batch of sorting tasks on each test case and averaging </text>
<text top="1050" left="162" width="172" height="16" font="1">all the obtained results. </text>
<text top="169" left="228" width="171" height="18" font="14">…..   //doing other things </text>
<text top="201" left="228" width="264" height="15" font="9">/*broadcast the data to all the process*/ </text>
<text top="229" left="228" width="467" height="15" font="9">MPI_Bcast(data_in, DataSize, MPI_INT, 0, MPI_COMM_WORLD); </text>
<text top="258" left="174" width="4" height="15" font="9"> </text>
<text top="258" left="228" width="321" height="15" font="9">/*each of the processor calculate their own part/ </text>
<text top="286" left="174" width="4" height="15" font="9"> </text>
<text top="286" left="228" width="411" height="15" font="9">CountRank(data_in,DataSize,MyLength,rank,SumID,MyID); </text>
<text top="315" left="174" width="4" height="15" font="9"> </text>
<text top="315" left="228" width="263" height="15" font="9">/*then return back to the master node*/ </text>
<text top="343" left="228" width="81" height="15" font="9">getOffset(); </text>
<text top="371" left="228" width="499" height="15" font="9">MPI_Gatherv(rank, MyLength, MPI_INT, offset, MyLength, MPI_INT, 0, </text>
<text top="400" left="228" width="177" height="15" font="9">MPI_COMM_WORLD);  </text>
<text top="429" left="174" width="4" height="15" font="9"> </text>
<text top="429" left="228" width="314" height="15" font="9">/*resorting the whole data in the master node*/ </text>
<text top="457" left="174" width="4" height="15" font="9"> </text>
<text top="457" left="228" width="92" height="15" font="9">if(MyID==0) </text>
<text top="485" left="228" width="12" height="15" font="9">{ </text>
<text top="514" left="174" width="4" height="15" font="9"> </text>
<text top="514" left="228" width="4" height="15" font="9"> </text>
<text top="514" left="282" width="162" height="15" font="9">for(i=0;i&lt;DataSize;i++) </text>
<text top="542" left="174" width="4" height="15" font="9"> </text>
<text top="542" left="228" width="4" height="15" font="9"> </text>
<text top="542" left="282" width="4" height="15" font="9"> </text>
<text top="542" left="336" width="195" height="15" font="9">data_out[rank[i]]=data_in[i]; </text>
<text top="571" left="174" width="4" height="15" font="9"> </text>
<text top="571" left="228" width="4" height="15" font="9"> </text>
<text top="571" left="282" width="170" height="15" font="9">for(i=0;i&lt;DataSize;i++){ </text>
<text top="599" left="174" width="4" height="15" font="9"> </text>
<text top="599" left="228" width="4" height="15" font="9"> </text>
<text top="599" left="282" width="4" height="15" font="9"> </text>
<text top="599" left="336" width="189" height="15" font="9">printf(&#34;%10d &#34;,data_out[i]); </text>
<text top="628" left="174" width="4" height="15" font="9"> </text>
<text top="628" left="228" width="4" height="15" font="9"> </text>
<text top="628" left="282" width="12" height="15" font="9">} </text>
<text top="656" left="174" width="4" height="15" font="9"> </text>
<text top="656" left="228" width="4" height="15" font="9"> </text>
<text top="656" left="282" width="83" height="15" font="9">printf(&#34;\n&#34;); </text>
<text top="685" left="174" width="4" height="15" font="9"> </text>
<text top="685" left="228" width="12" height="15" font="9">} </text>
<text top="713" left="174" width="4" height="15" font="9"> </text>
<text top="713" left="228" width="123" height="15" font="9">MPI_Finalize();    </text>
<text top="742" left="228" width="60" height="15" font="9">return 1; </text>
<text top="770" left="174" width="12" height="15" font="9">} </text>
</page>
<page number="31" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="17" size="12" family="Helvetica" color="#000000"/>
	<fontspec id="18" size="16" family="Helvetica" color="#000000"/>
	<fontspec id="19" size="12" family="Helvetica" color="#000000"/>
	<fontspec id="20" size="12" family="Helvetica" color="#000000"/>
	<fontspec id="21" size="12" family="Helvetica" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">19 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="222" left="243" width="118" height="14" font="17">Numbers of Data </text>
<text top="196" left="430" width="75" height="14" font="17">Sequential </text>
<text top="222" left="404" width="128" height="14" font="17">Implementation (s) </text>
<text top="222" left="574" width="159" height="14" font="17">MPI Implementation (s) </text>
<text top="248" left="287" width="29" height="14" font="17">500 </text>
<text top="248" left="447" width="42" height="14" font="17">0.002 </text>
<text top="248" left="633" width="42" height="14" font="17">0.005 </text>
<text top="274" left="283" width="37" height="14" font="17">1000 </text>
<text top="274" left="447" width="42" height="14" font="17">0.011 </text>
<text top="274" left="633" width="42" height="14" font="17">0.009 </text>
<text top="300" left="283" width="37" height="14" font="17">5000 </text>
<text top="300" left="447" width="42" height="14" font="17">0.118 </text>
<text top="300" left="633" width="42" height="14" font="17">0.110 </text>
<text top="326" left="279" width="46" height="14" font="17">10000 </text>
<text top="326" left="447" width="42" height="14" font="17">0.451 </text>
<text top="326" left="633" width="42" height="14" font="17">0.248 </text>
<text top="351" left="279" width="46" height="14" font="17">20000 </text>
<text top="351" left="447" width="42" height="14" font="17">1.784 </text>
<text top="351" left="633" width="42" height="14" font="17">0.532 </text>
<text top="377" left="279" width="46" height="14" font="17">50000 </text>
<text top="377" left="443" width="50" height="14" font="17">11.096 </text>
<text top="377" left="633" width="42" height="14" font="17">4.152 </text>
<text top="403" left="275" width="54" height="14" font="17">100000 </text>
<text top="403" left="443" width="50" height="14" font="17">44.347 </text>
<text top="403" left="629" width="50" height="14" font="17">11.012 </text>
<text top="430" left="369" width="238" height="15" font="9">Table 1. 16 nodes for MPI program </text>
<text top="458" left="180" width="5" height="16" font="1"> </text>
<text top="490" left="180" width="604" height="16" font="1">The Table 1 shows the calculation time for two programs based on different size of </text>
<text top="521" left="162" width="607" height="16" font="1">data. Both sequential and MPI programs are using random function to generate data </text>
<text top="552" left="162" width="641" height="16" font="1">arrays. Random seed is 896. The compiler and environment are same and time functions </text>
<text top="583" left="162" width="633" height="16" font="1">are only responsible for calculating sorting procedures (ignoring print and initialization </text>
<text top="614" left="162" width="495" height="16" font="1">functions). MPI program is using 16 nodes (processors) in this case. </text>
<text top="645" left="180" width="5" height="16" font="1"> </text>
<text top="693" left="386" width="205" height="17" font="18"><b>Rank Sort Performance </b></text>
<text top="865" left="245" width="8" height="14" font="17">0</text>
<text top="840" left="237" width="16" height="14" font="17">10</text>
<text top="815" left="237" width="16" height="14" font="17">20</text>
<text top="790" left="237" width="16" height="14" font="17">30</text>
<text top="765" left="237" width="16" height="14" font="17">40</text>
<text top="740" left="237" width="16" height="14" font="17">50</text>
<text top="900" left="266" width="11" height="14" font="19">50</text>
<text top="888" left="277" width="6" height="14" font="19">0</text>
<text top="905" left="306" width="11" height="14" font="19">10</text>
<text top="894" left="318" width="11" height="14" font="19">00</text>
<text top="905" left="353" width="11" height="14" font="19">50</text>
<text top="894" left="365" width="11" height="14" font="19">00</text>
<text top="911" left="395" width="11" height="14" font="19">10</text>
<text top="899" left="407" width="11" height="14" font="19">00</text>
<text top="888" left="418" width="6" height="14" font="19">0</text>
<text top="911" left="441" width="11" height="14" font="19">20</text>
<text top="899" left="453" width="11" height="14" font="19">00</text>
<text top="888" left="464" width="6" height="14" font="19">0</text>
<text top="911" left="488" width="11" height="14" font="19">50</text>
<text top="899" left="500" width="11" height="14" font="19">00</text>
<text top="888" left="511" width="6" height="14" font="19">0</text>
<text top="917" left="529" width="11" height="14" font="19">10</text>
<text top="905" left="541" width="11" height="14" font="19">00</text>
<text top="894" left="552" width="11" height="14" font="19">00</text>
<text top="940" left="394" width="68" height="14" font="20"><b>Data Size</b></text>
<text top="857" left="227" width="0" height="14" font="21"><b>C</b></text>
<text top="847" left="227" width="0" height="14" font="21"><b>a</b></text>
<text top="839" left="227" width="0" height="14" font="21"><b>lc</b></text>
<text top="827" left="227" width="0" height="14" font="21"><b>ul</b></text>
<text top="813" left="227" width="0" height="14" font="21"><b>a</b></text>
<text top="806" left="227" width="0" height="14" font="21"><b>ti</b></text>
<text top="797" left="227" width="0" height="14" font="21"><b>on</b></text>
<text top="779" left="227" width="0" height="14" font="21"><b> Ti</b></text>
<text top="761" left="227" width="0" height="14" font="21"><b>m</b></text>
<text top="747" left="227" width="0" height="14" font="21"><b>e</b></text>
<text top="791" left="644" width="123" height="14" font="17">Sequential Version</text>
<text top="814" left="644" width="80" height="14" font="17">MPI Version</text>
<text top="965" left="781" width="5" height="16" font="1"> </text>
<text top="991" left="354" width="269" height="15" font="9">Figure 2. Rank Sort Performance Result </text>
<text top="1020" left="180" width="626" height="16" font="1">The Figure 2 and Table 1 show the result of calculating time with data sets range from </text>
<text top="1051" left="162" width="652" height="16" font="1">500 to 100000. Each data set is averaged with multiple runs and the MPI program uses 16 </text>
</page>
<page number="32" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="22" size="8" family="Times" color="#000000"/>
	<fontspec id="23" size="15" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">20 </text>
<text top="166" left="162" width="611" height="16" font="1">processes in 16 nodes in a Rocks Cluster [9]. The graph indicates a prominent lower </text>
<text top="197" left="162" width="550" height="16" font="1">running time for MPI implementation as the data size is greater than 10000. </text>
<text top="228" left="162" width="5" height="16" font="1"> </text>
<text top="258" left="290" width="74" height="14" font="17">Number of </text>
<text top="284" left="309" width="36" height="14" font="17">Data </text>
<text top="284" left="401" width="53" height="14" font="17">1 Node </text>
<text top="284" left="475" width="60" height="14" font="17">2 Nodes </text>
<text top="284" left="556" width="64" height="14" font="17">4 Nodes  </text>
<text top="258" left="659" width="21" height="14" font="17">16 </text>
<text top="284" left="646" width="48" height="14" font="17">Nodes </text>
<text top="310" left="312" width="29" height="14" font="17">500 </text>
<text top="310" left="406" width="42" height="14" font="17">0.007 </text>
<text top="310" left="484" width="42" height="14" font="17">0.001 </text>
<text top="310" left="565" width="42" height="14" font="17">0.002 </text>
<text top="310" left="649" width="42" height="14" font="17">0.009 </text>
<text top="336" left="308" width="37" height="14" font="17">1000 </text>
<text top="336" left="406" width="42" height="14" font="17">0.029 </text>
<text top="336" left="484" width="42" height="14" font="17">0.005 </text>
<text top="336" left="565" width="42" height="14" font="17">0.008 </text>
<text top="336" left="649" width="42" height="14" font="17">0.003 </text>
<text top="362" left="308" width="37" height="14" font="17">5000 </text>
<text top="362" left="406" width="42" height="14" font="17">0.291 </text>
<text top="362" left="484" width="42" height="14" font="17">0.252 </text>
<text top="362" left="565" width="42" height="14" font="17">0.258 </text>
<text top="362" left="649" width="42" height="14" font="17">0.110 </text>
<text top="388" left="304" width="46" height="14" font="17">10000 </text>
<text top="388" left="406" width="42" height="14" font="17">1.076 </text>
<text top="388" left="484" width="42" height="14" font="17">0.860 </text>
<text top="388" left="565" width="42" height="14" font="17">0.705 </text>
<text top="388" left="649" width="42" height="14" font="17">0.248 </text>
<text top="414" left="304" width="46" height="14" font="17">20000 </text>
<text top="414" left="406" width="42" height="14" font="17">4.236 </text>
<text top="414" left="484" width="42" height="14" font="17">3.634 </text>
<text top="414" left="565" width="42" height="14" font="17">2.441 </text>
<text top="414" left="649" width="42" height="14" font="17">0.532 </text>
<text top="440" left="304" width="46" height="14" font="17">50000 </text>
<text top="440" left="402" width="50" height="14" font="17">26.255 </text>
<text top="440" left="479" width="50" height="14" font="17">22.336 </text>
<text top="440" left="561" width="50" height="14" font="17">12.930 </text>
<text top="440" left="649" width="42" height="14" font="17">4.152 </text>
<text top="465" left="300" width="54" height="14" font="17">100000 </text>
<text top="465" left="398" width="58" height="14" font="17">104.941 </text>
<text top="465" left="479" width="50" height="14" font="17">91.665 </text>
<text top="465" left="561" width="50" height="14" font="17">46.596 </text>
<text top="465" left="645" width="50" height="14" font="17">11.012 </text>
<text top="492" left="352" width="269" height="15" font="9">Table 2. Each node has only one process</text>
<text top="552" left="180" width="541" height="16" font="1">The Table 2 shows MPI sorting performance based on different number of </text>
<text top="583" left="162" width="617" height="16" font="1">processors on the cluster. By adding more processors to the program, more improved </text>
<text top="614" left="162" width="346" height="16" font="1">performance gained from MPI implementation. </text>
<text top="645" left="180" width="559" height="16" font="1">These results show that overall parallel MPI implementations outperform the </text>
<text top="676" left="162" width="621" height="16" font="1">sequential ranksort especially when the data size is becoming larger. Since and whole </text>
<text top="707" left="162" width="593" height="16" font="1">data are averagely divided into all the nodes/processors and each of them are only </text>
<text top="734" left="162" width="605" height="20" font="7">responsible for its own part. There isn’t too much network communication between </text>
<text top="769" left="162" width="624" height="16" font="1">each slave node in the cluster. By adding more nodes to the program we can get better </text>
<text top="800" left="162" width="104" height="16" font="1">performance.  </text>
<text top="831" left="162" width="5" height="16" font="1"> </text>
<text top="890" left="162" width="134" height="16" font="4"><b>2.6.3 Quick Sort  </b></text>
<text top="947" left="180" width="579" height="16" font="1">Quick sort is a sorting algorithm developed by Tony Hoare [6] that, on average, </text>
<text top="978" left="162" width="602" height="16" font="1">makes O (nlog n) (big O notation) comparisons to sort n items. In the worst case, it </text>
<text top="1012" left="162" width="74" height="16" font="1">makes O (</text>
<text top="1009" left="249" width="5" height="9" font="22">2</text>
<text top="1012" left="239" width="9" height="16" font="23"><i>n</i></text>
<text top="1012" left="257" width="517" height="16" font="1">) comparisons, though this behavior is rare. Quick sort is often faster in </text>
<text top="1044" left="162" width="304" height="16" font="1">practice than other O(nlog n) algorithms.  </text>
</page>
<page number="33" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">21 </text>
<text top="370" left="709" width="5" height="16" font="1"> </text>
<text top="396" left="333" width="329" height="15" font="9">Figure 3. Quick sort diagrammatic representation </text>
<text top="425" left="495" width="4" height="15" font="9"> </text>
<text top="454" left="180" width="624" height="16" font="1">The idea of quick sort is to find a pivot in R [0, n] in the current sequence. It’s usually </text>
<text top="485" left="162" width="608" height="16" font="1">the first, last or middle element of the sequence. Using this pivot divides the current </text>
<text top="516" left="162" width="644" height="16" font="1">sequence in two parts, and then reorders the list so that all elements with values less than </text>
<text top="547" left="162" width="615" height="16" font="1">the pivot come before the pivot; while all elements with values greater than the pivot </text>
<text top="578" left="162" width="628" height="16" font="1">come after it (equal values can go either way). After this partitioning, the pivot is in its </text>
<text top="609" left="162" width="641" height="16" font="1">final position. This is called the partition operation. Then Recursively sort the sub-list of </text>
<text top="640" left="162" width="612" height="16" font="1">lesser elements and the sub-list of greater elements. The pseudocode is given below: </text>
<text top="671" left="162" width="5" height="16" font="1"> </text>
<text top="702" left="162" width="5" height="16" font="1"> </text>
<text top="733" left="162" width="5" height="16" font="1"> </text>
<text top="765" left="162" width="5" height="16" font="1"> </text>
<text top="795" left="162" width="5" height="16" font="1"> </text>
<text top="827" left="162" width="5" height="16" font="1"> </text>
<text top="858" left="162" width="5" height="16" font="1"> </text>
<text top="889" left="162" width="5" height="16" font="1"> </text>
<text top="920" left="162" width="5" height="16" font="1"> </text>
<text top="951" left="162" width="5" height="16" font="1"> </text>
<text top="982" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="34" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">22 </text>
<text top="474" left="783" width="5" height="16" font="1"> </text>
<text top="500" left="389" width="199" height="15" font="9">Code 6. Sequential quick sort </text>
<text top="529" left="180" width="5" height="16" font="1"> </text>
<text top="560" left="180" width="618" height="16" font="1">The parallel way for this sort can be done by letting each process sort a section of the </text>
<text top="591" left="162" width="657" height="16" font="1">sequence of data. This is done by performing a scatter operation by the head node/process. </text>
<text top="622" left="162" width="637" height="16" font="1">Each node/process works on its subsequence individually using the sequential quicksort </text>
<text top="653" left="162" width="591" height="16" font="1">algorithm explained in previous part and sends its sorted sub sequence for merge. </text>
<text top="684" left="180" width="601" height="16" font="1">A simple method of merging of all sorted subsequences would have been, a simple </text>
<text top="715" left="162" width="615" height="16" font="1">gather implementation where the master gathers the sorted subsequences and merges </text>
<text top="746" left="162" width="603" height="16" font="1">them. But this would degrade the performance. If there are n elements to sort and p </text>
<text top="777" left="162" width="600" height="16" font="1">processes, then each slave node sorts (n/p) values and head node gathers the sorted </text>
<text top="808" left="162" width="631" height="16" font="1">subsequences. Head node now has p sorted subsequences and it will have to call merge </text>
<text top="839" left="162" width="638" height="16" font="1">operation (p-1) times. Hence a time complexity is O ((p-1) (n1+n2)). However, with the </text>
<text top="871" left="162" width="638" height="16" font="1">tree based merge, each process sends its sorted subsequence to its neighbor and a merge </text>
<text top="902" left="162" width="529" height="16" font="1">operation is performed at each step. This reduces the time complexity to  </text>
<text top="933" left="162" width="521" height="16" font="1">O ((log p )(n1+n2))is shown in the diagram below alone with MPI code </text>
<text top="172" left="173" width="252" height="15" font="9">quicksort( void *a, int low, int high )  </text>
<text top="200" left="173" width="16" height="15" font="9">{  </text>
<text top="229" left="192" width="68" height="15" font="9">int pivot;  </text>
<text top="257" left="192" width="179" height="15" font="9">Termination condition! */  </text>
<text top="286" left="192" width="118" height="15" font="9"> if ( high &gt; low )  </text>
<text top="314" left="192" width="16" height="15" font="9">{  </text>
<text top="342" left="227" width="217" height="15" font="9">pivot = partition( a, low, high );  </text>
<text top="371" left="192" width="21" height="15" font="9">     </text>
<text top="371" left="227" width="190" height="15" font="9">quicksort( a, low, pivot-1 );  </text>
<text top="399" left="192" width="21" height="15" font="9">     </text>
<text top="399" left="227" width="198" height="15" font="9">quicksort( a, pivot+1, high );  </text>
<text top="428" left="192" width="24" height="15" font="9">  }  </text>
<text top="457" left="173" width="12" height="15" font="9">} </text>
</page>
<page number="35" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">23 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="509" left="756" width="5" height="16" font="1"> </text>
<text top="536" left="329" width="324" height="16" font="1">Figure 4. MPI parallel sort with 6 processes  </text>
<text top="567" left="162" width="5" height="16" font="1"> </text>
<text top="598" left="162" width="5" height="16" font="1"> </text>
<text top="629" left="162" width="5" height="16" font="1"> </text>
<text top="660" left="162" width="5" height="16" font="1"> </text>
<text top="691" left="162" width="5" height="16" font="1"> </text>
<text top="722" left="162" width="5" height="16" font="1"> </text>
<text top="753" left="162" width="5" height="16" font="1"> </text>
<text top="784" left="162" width="5" height="16" font="1"> </text>
<text top="815" left="162" width="5" height="16" font="1"> </text>
<text top="847" left="162" width="5" height="16" font="1"> </text>
<text top="878" left="162" width="5" height="16" font="1"> </text>
<text top="909" left="162" width="5" height="16" font="1"> </text>
<text top="940" left="162" width="5" height="16" font="1"> </text>
<text top="971" left="162" width="5" height="16" font="1"> </text>
<text top="1002" left="162" width="5" height="16" font="1"> </text>
<text top="1033" left="162" width="5" height="16" font="1"> </text>
<text top="591" left="173" width="145" height="18" font="14">….doing other things </text>
<text top="623" left="173" width="187" height="15" font="9">// up to log_2 p merge steps </text>
<text top="651" left="173" width="252" height="15" font="9">for (step = 1; step &lt; p; step = 2*step)  </text>
<text top="680" left="173" width="12" height="15" font="9">{ </text>
<text top="708" left="227" width="162" height="15" font="9">if (id % (2*step) != 0) { </text>
<text top="737" left="227" width="430" height="15" font="9">// id is no multiple of 2*step: send chunk to id-step and exit loop </text>
<text top="765" left="173" width="29" height="15" font="9">       </text>
<text top="765" left="227" width="455" height="15" font="9">MPI_Send(chunk, s, MPI_INT, id-step, 0, MPI_COMM_WORLD); </text>
<text top="794" left="173" width="29" height="15" font="9">       </text>
<text top="794" left="227" width="45" height="15" font="9">break; </text>
<text top="822" left="173" width="16" height="15" font="9"> } </text>
<text top="850" left="173" width="454" height="15" font="9"> // id is multiple of 2*step: merge in chunk from id+step (if it exists) </text>
<text top="879" left="173" width="112" height="15" font="9"> if (id+step &lt; p)  </text>
<text top="907" left="173" width="12" height="15" font="9">{ </text>
<text top="936" left="173" width="8" height="15" font="9">  </text>
<text top="936" left="227" width="263" height="15" font="9">// compute size of chunk to be received </text>
<text top="964" left="173" width="29" height="15" font="9">       </text>
<text top="964" left="227" width="365" height="15" font="9">o = (n &gt;= c * (id+2*step)) ? c * step : n - c * (id+step); </text>
<text top="993" left="173" width="29" height="15" font="9">       </text>
<text top="993" left="227" width="148" height="15" font="9">// receive other chunk </text>
<text top="1021" left="173" width="29" height="15" font="9">       </text>
<text top="1021" left="227" width="250" height="15" font="9">other = (int *)malloc(o * sizeof(int)); </text>
<text top="1050" left="173" width="29" height="15" font="9">       </text>
<text top="1050" left="227" width="514" height="15" font="9">MPI_Recv(other, o, MPI_INT, id+step, 0, MPI_COMM_WORLD, &amp;status); </text>
<text top="1078" left="173" width="29" height="15" font="9">       </text>
<text top="1078" left="227" width="4" height="15" font="9"> </text>
</page>
<page number="36" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">24 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="197" left="162" width="5" height="16" font="1"> </text>
<text top="228" left="162" width="5" height="16" font="1"> </text>
<text top="259" left="162" width="5" height="16" font="1"> </text>
<text top="290" left="162" width="5" height="16" font="1"> </text>
<text top="321" left="162" width="5" height="16" font="1"> </text>
<text top="352" left="162" width="5" height="16" font="1"> </text>
<text top="383" left="162" width="5" height="16" font="1"> </text>
<text top="414" left="162" width="4" height="15" font="9"> </text>
<text top="443" left="366" width="244" height="15" font="9">Code 7. Tree based Merge functions </text>
<text top="499" left="162" width="5" height="16" font="4"><b> </b></text>
<text top="557" left="162" width="304" height="16" font="4"><b>2.6.4 Quick Sort Performance Analysis </b></text>
<text top="615" left="180" width="585" height="16" font="1">Similar with Rank Sort algorithm, we need to compare the performance between </text>
<text top="646" left="162" width="646" height="16" font="1">sequential version and parallel version. Other factors like number of nodes and processes </text>
<text top="677" left="162" width="398" height="16" font="1">are also considered in the following performance tests. </text>
<text top="708" left="162" width="5" height="16" font="1"> </text>
<text top="764" left="243" width="118" height="14" font="17">Numbers of Data </text>
<text top="738" left="430" width="75" height="14" font="17">Sequential </text>
<text top="764" left="404" width="128" height="14" font="17">Implementation (s) </text>
<text top="764" left="574" width="159" height="14" font="17">MPI Implementation (s) </text>
<text top="789" left="279" width="46" height="14" font="17">10000 </text>
<text top="789" left="447" width="42" height="14" font="17">0.004 </text>
<text top="789" left="633" width="42" height="14" font="17">0.015 </text>
<text top="815" left="275" width="54" height="14" font="17">100000 </text>
<text top="815" left="447" width="42" height="14" font="17">0.031 </text>
<text top="815" left="633" width="42" height="14" font="17">0.017 </text>
<text top="841" left="275" width="54" height="14" font="17">500000 </text>
<text top="841" left="447" width="42" height="14" font="17">0.141 </text>
<text top="841" left="633" width="42" height="14" font="17">0.059 </text>
<text top="867" left="271" width="63" height="14" font="17">1000000 </text>
<text top="867" left="447" width="42" height="14" font="17">0.348 </text>
<text top="867" left="633" width="42" height="14" font="17">0.129 </text>
<text top="893" left="271" width="63" height="14" font="17">5000000 </text>
<text top="893" left="447" width="42" height="14" font="17">4.677 </text>
<text top="893" left="633" width="42" height="14" font="17">0.588 </text>
<text top="919" left="267" width="71" height="14" font="17">10000000 </text>
<text top="919" left="443" width="50" height="14" font="17">15.538 </text>
<text top="919" left="633" width="42" height="14" font="17">1.771 </text>
<text top="945" left="369" width="238" height="15" font="9">Table 3. 16 nodes for MPI program </text>
<text top="230" left="227" width="176" height="15" font="9">// merge and free memory </text>
<text top="258" left="173" width="25" height="15" font="9">      </text>
<text top="258" left="227" width="224" height="15" font="9"> data = merge(chunk, s, other, o); </text>
<text top="287" left="173" width="29" height="15" font="9">       </text>
<text top="287" left="227" width="86" height="15" font="9">free(chunk); </text>
<text top="315" left="173" width="29" height="15" font="9">       </text>
<text top="315" left="227" width="79" height="15" font="9">free(other); </text>
<text top="343" left="173" width="29" height="15" font="9">       </text>
<text top="343" left="227" width="94" height="15" font="9">chunk = data; </text>
<text top="372" left="173" width="29" height="15" font="9">       </text>
<text top="372" left="227" width="65" height="15" font="9">s = s + o; </text>
<text top="401" left="173" width="24" height="15" font="9">   } </text>
<text top="429" left="173" width="4" height="15" font="9"> </text>
</page>
<page number="37" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="24" size="12" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">25 </text>
<text top="165" left="162" width="4" height="13" font="24"> </text>
<text top="465" left="784" width="4" height="13" font="24"> </text>
<text top="487" left="357" width="262" height="15" font="9">Figure 5. Quick sortPerformance Chart </text>
<text top="516" left="162" width="5" height="16" font="1"> </text>
<text top="547" left="180" width="621" height="16" font="1">The above Table 3 and Figure 5 show the calculation time for two programs based on </text>
<text top="578" left="162" width="650" height="16" font="1">different size of data. Random seed is set to 896. The compiler and environment are same </text>
<text top="609" left="162" width="587" height="16" font="1">and time functions are only focus for calculation sorting procedures (ignore print </text>
<text top="640" left="162" width="651" height="16" font="1">functions). MPI program is using 16 nodes in this case. When the data size is fairly small, </text>
<text top="671" left="162" width="628" height="16" font="1">sequential version runs a little faster than MPI version. As the data size increases, MPI </text>
<text top="702" left="162" width="629" height="16" font="1">program dominates the sequential version. It’s 9 times faster than sequential quick sort </text>
<text top="733" left="162" width="215" height="16" font="1">when data size is 10 million.  </text>
<text top="764" left="162" width="5" height="16" font="1"> </text>
<text top="795" left="326" width="74" height="14" font="17">Number of </text>
<text top="820" left="346" width="36" height="14" font="17">Data </text>
<text top="820" left="438" width="53" height="14" font="17">1 Node </text>
<text top="820" left="519" width="64" height="14" font="17">4 Nodes  </text>
<text top="795" left="623" width="21" height="14" font="17">16 </text>
<text top="820" left="609" width="48" height="14" font="17">Nodes </text>
<text top="846" left="341" width="46" height="14" font="17">10000 </text>
<text top="846" left="443" width="42" height="14" font="17">0.007 </text>
<text top="846" left="528" width="42" height="14" font="17">0.003 </text>
<text top="846" left="612" width="42" height="14" font="17">0.015 </text>
<text top="872" left="336" width="54" height="14" font="17">100000 </text>
<text top="872" left="443" width="42" height="14" font="17">0.057 </text>
<text top="872" left="528" width="42" height="14" font="17">0.027 </text>
<text top="872" left="612" width="42" height="14" font="17">0.017 </text>
<text top="898" left="336" width="54" height="14" font="17">500000 </text>
<text top="898" left="443" width="42" height="14" font="17">0.187 </text>
<text top="898" left="528" width="42" height="14" font="17">0.083 </text>
<text top="898" left="612" width="42" height="14" font="17">0.059 </text>
<text top="924" left="332" width="62" height="14" font="17">1000000 </text>
<text top="924" left="443" width="42" height="14" font="17">0.392 </text>
<text top="924" left="528" width="42" height="14" font="17">0.247 </text>
<text top="924" left="612" width="42" height="14" font="17">0.129 </text>
<text top="950" left="332" width="62" height="14" font="17">5000000 </text>
<text top="950" left="443" width="42" height="14" font="17">2.673 </text>
<text top="950" left="528" width="42" height="14" font="17">1.454 </text>
<text top="950" left="612" width="42" height="14" font="17">0.588 </text>
<text top="976" left="328" width="71" height="14" font="17">10000000 </text>
<text top="976" left="443" width="42" height="14" font="17">7.128 </text>
<text top="976" left="528" width="42" height="14" font="17">2.691 </text>
<text top="976" left="612" width="42" height="14" font="17">1.771 </text>
<text top="1002" left="352" width="273" height="15" font="9">Table 4. Each node has only one process </text>
</page>
<page number="38" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">26 </text>
<text top="166" left="162" width="4" height="15" font="9"> </text>
<text top="211" left="300" width="371" height="17" font="18"><b>Performance for Different Number of Nodes</b></text>
<text top="372" left="237" width="8" height="14" font="17">0</text>
<text top="358" left="237" width="8" height="14" font="17">1</text>
<text top="344" left="237" width="8" height="14" font="17">2</text>
<text top="330" left="237" width="8" height="14" font="17">3</text>
<text top="316" left="237" width="8" height="14" font="17">4</text>
<text top="302" left="237" width="8" height="14" font="17">5</text>
<text top="287" left="237" width="8" height="14" font="17">6</text>
<text top="273" left="237" width="8" height="14" font="17">7</text>
<text top="259" left="237" width="8" height="14" font="17">8</text>
<text top="419" left="255" width="11" height="14" font="19">10</text>
<text top="407" left="267" width="11" height="14" font="19">00</text>
<text top="396" left="278" width="6" height="14" font="19">0</text>
<text top="424" left="316" width="11" height="14" font="19">10</text>
<text top="412" left="328" width="11" height="14" font="19">00</text>
<text top="401" left="339" width="11" height="14" font="19">00</text>
<text top="424" left="383" width="11" height="14" font="19">50</text>
<text top="412" left="394" width="11" height="14" font="19">00</text>
<text top="401" left="406" width="11" height="14" font="19">00</text>
<text top="430" left="442" width="11" height="14" font="19">10</text>
<text top="418" left="454" width="11" height="14" font="19">00</text>
<text top="407" left="465" width="11" height="14" font="19">00</text>
<text top="395" left="477" width="6" height="14" font="19">0</text>
<text top="430" left="508" width="11" height="14" font="19">50</text>
<text top="418" left="520" width="11" height="14" font="19">00</text>
<text top="407" left="532" width="11" height="14" font="19">00</text>
<text top="395" left="543" width="6" height="14" font="19">0</text>
<text top="435" left="569" width="11" height="14" font="19">10</text>
<text top="424" left="581" width="11" height="14" font="19">00</text>
<text top="412" left="592" width="11" height="14" font="19">00</text>
<text top="401" left="604" width="11" height="14" font="19">00</text>
<text top="459" left="421" width="68" height="14" font="20"><b>Data Size</b></text>
<text top="370" left="227" width="0" height="14" font="21"><b>C</b></text>
<text top="360" left="227" width="0" height="14" font="21"><b>a</b></text>
<text top="352" left="227" width="0" height="14" font="21"><b>lc</b></text>
<text top="340" left="227" width="0" height="14" font="21"><b>ul</b></text>
<text top="326" left="227" width="0" height="14" font="21"><b>a</b></text>
<text top="319" left="227" width="0" height="14" font="21"><b>ti</b></text>
<text top="310" left="227" width="0" height="14" font="21"><b>on</b></text>
<text top="292" left="227" width="0" height="14" font="21"><b> Ti</b></text>
<text top="274" left="227" width="0" height="14" font="21"><b>m</b></text>
<text top="260" left="227" width="0" height="14" font="21"><b>e</b></text>
<text top="293" left="704" width="46" height="14" font="17">1 Node</text>
<text top="316" left="704" width="53" height="14" font="17">4 Nodes</text>
<text top="340" left="704" width="61" height="14" font="17">16 Nodes</text>
<text top="483" left="781" width="5" height="16" font="1"> </text>
<text top="509" left="286" width="403" height="15" font="9">Figure 6. Performance Chart for Different Number of Nodes </text>
<text top="538" left="162" width="5" height="16" font="1"> </text>
<text top="566" left="180" width="621" height="20" font="7">It’s also obvious to see improved performance by adding nodes to MPI program from </text>
<text top="600" left="162" width="651" height="16" font="1">the above table. We use only one process per node, in the following part different number </text>
<text top="631" left="162" width="494" height="16" font="1">of processes per node is used to analyze its impact on performance.  </text>
<text top="662" left="162" width="5" height="16" font="1"> </text>
<text top="895" left="783" width="5" height="16" font="1"> </text>
<text top="922" left="294" width="388" height="16" font="1">Table 5 Different number of processes in fixed nodes </text>
</page>
<page number="39" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">27 </text>
<text top="183" left="264" width="443" height="17" font="18"><b>Performance for Multiple Processes on Fixed Nodes</b></text>
<text top="345" left="231" width="8" height="14" font="17">0</text>
<text top="326" left="231" width="8" height="14" font="17">5</text>
<text top="307" left="223" width="16" height="14" font="17">10</text>
<text top="288" left="223" width="16" height="14" font="17">15</text>
<text top="269" left="223" width="16" height="14" font="17">20</text>
<text top="249" left="223" width="16" height="14" font="17">25</text>
<text top="230" left="223" width="16" height="14" font="17">30</text>
<text top="391" left="249" width="11" height="14" font="19">10</text>
<text top="379" left="261" width="11" height="14" font="19">00</text>
<text top="368" left="272" width="6" height="14" font="19">0</text>
<text top="397" left="308" width="11" height="14" font="19">10</text>
<text top="385" left="320" width="11" height="14" font="19">00</text>
<text top="374" left="331" width="11" height="14" font="19">00</text>
<text top="397" left="373" width="11" height="14" font="19">50</text>
<text top="385" left="385" width="11" height="14" font="19">00</text>
<text top="374" left="396" width="11" height="14" font="19">00</text>
<text top="402" left="431" width="11" height="14" font="19">10</text>
<text top="391" left="443" width="11" height="14" font="19">00</text>
<text top="380" left="454" width="11" height="14" font="19">00</text>
<text top="368" left="466" width="6" height="14" font="19">0</text>
<text top="402" left="497" width="11" height="14" font="19">50</text>
<text top="391" left="509" width="11" height="14" font="19">00</text>
<text top="380" left="520" width="11" height="14" font="19">00</text>
<text top="368" left="532" width="6" height="14" font="19">0</text>
<text top="408" left="555" width="11" height="14" font="19">10</text>
<text top="396" left="567" width="11" height="14" font="19">00</text>
<text top="385" left="578" width="11" height="14" font="19">00</text>
<text top="373" left="590" width="11" height="14" font="19">00</text>
<text top="432" left="410" width="68" height="14" font="20"><b>Data Size</b></text>
<text top="343" left="213" width="0" height="14" font="21"><b>C</b></text>
<text top="333" left="213" width="0" height="14" font="21"><b>a</b></text>
<text top="325" left="213" width="0" height="14" font="21"><b>lc</b></text>
<text top="313" left="213" width="0" height="14" font="21"><b>ul</b></text>
<text top="299" left="213" width="0" height="14" font="21"><b>a</b></text>
<text top="291" left="213" width="0" height="14" font="21"><b>ti</b></text>
<text top="282" left="213" width="0" height="14" font="21"><b>on</b></text>
<text top="264" left="213" width="0" height="14" font="21"><b> Ti</b></text>
<text top="247" left="213" width="0" height="14" font="21"><b>m</b></text>
<text top="233" left="213" width="0" height="14" font="21"><b>e</b></text>
<text top="264" left="690" width="66" height="14" font="17">1 Process</text>
<text top="288" left="690" width="81" height="14" font="17">4 Processes</text>
<text top="311" left="690" width="89" height="14" font="17">16 Processes</text>
<text top="456" left="795" width="5" height="16" font="1"> </text>
<text top="482" left="336" width="305" height="15" font="9">Figure 7. Performance for Multiple Processes </text>
<text top="511" left="162" width="4" height="15" font="9"> </text>
<text top="539" left="180" width="617" height="16" font="1">In this test, an interesting phenomenon is appeared from Figure 7. By adding number </text>
<text top="570" left="162" width="604" height="16" font="1">of processes from 1 to 4, the program becomes faster especially even faster than 16 </text>
<text top="598" left="162" width="598" height="20" font="7">nodes’ case in the previous test.  At the same time, a continuous adding number of </text>
<text top="633" left="162" width="643" height="16" font="1">processes to these four nodes cause drastically degrading in the performance. The reason </text>
<text top="664" left="162" width="410" height="16" font="1">can be explained in the following performance test case. </text>
<text top="695" left="180" width="5" height="16" font="1"> </text>
<text top="725" left="280" width="74" height="14" font="17">Number of </text>
<text top="751" left="299" width="36" height="14" font="17">Data </text>
<text top="725" left="411" width="12" height="14" font="17">2 </text>
<text top="751" left="388" width="58" height="14" font="17">Process </text>
<text top="725" left="496" width="12" height="14" font="17">4 </text>
<text top="751" left="465" width="74" height="14" font="17">Processes </text>
<text top="725" left="583" width="12" height="14" font="17">8 </text>
<text top="751" left="553" width="78" height="14" font="17">Processes  </text>
<text top="725" left="666" width="21" height="14" font="17">16 </text>
<text top="751" left="639" width="74" height="14" font="17">Processes </text>
<text top="777" left="282" width="71" height="14" font="17">10000000 </text>
<text top="777" left="397" width="42" height="14" font="17">2.871 </text>
<text top="777" left="481" width="42" height="14" font="17">1.435 </text>
<text top="777" left="569" width="42" height="14" font="17">0.833 </text>
<text top="777" left="655" width="42" height="14" font="17">0.587 </text>
<text top="803" left="247" width="501" height="15" font="9">Table 6. Different number of processes running on the head node of cluster </text>
<text top="832" left="162" width="23" height="16" font="1">     </text>
<text top="863" left="180" width="629" height="16" font="1">According to the implementation of Open MPI [5], the running processes are launched </text>
<text top="894" left="162" width="600" height="16" font="1">and scheduled based on number of slots in the computer. The slots are Open MPI's </text>
<text top="925" left="162" width="638" height="16" font="1">representation of how many processors (cores) are available on a given computer. Since </text>
<text top="956" left="162" width="614" height="16" font="1">the head node of rock cluster has 16 cores, our last case is within each core there is a </text>
<text top="987" left="162" width="647" height="16" font="1">process running on it. In this case, Open MPI steps into an ―aggressive mode‖ which will </text>
<text top="1018" left="162" width="496" height="16" font="1">fully utilize the resource of CPUs and provide the best performance. </text>
</page>
<page number="40" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="25" size="16" family="Times" color="#000000"/>
	<fontspec id="26" size="10" family="Times" color="#000000"/>
	<fontspec id="27" size="11" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">28 </text>
<text top="166" left="180" width="597" height="16" font="1">If we continue adding processes to each node in the cluster, a ―oversubscribing‖ is </text>
<text top="197" left="162" width="649" height="16" font="1">activated when more processes are running than there are processors available (i.e., every </text>
<text top="228" left="162" width="626" height="16" font="1">slave node has more than 4 processes running on it). MPI processes will automatically </text>
<text top="259" left="162" width="646" height="16" font="1">run in degraded mode and frequently yield the processor to its peers, thereby allowing all </text>
<text top="290" left="162" width="634" height="16" font="1">processes to make progress. In this mode, the message passing communication is also a </text>
<text top="321" left="162" width="631" height="16" font="1">very large overhead as data increases. We should avoid this case in the development of </text>
<text top="352" left="162" width="120" height="16" font="1">real application. </text>
<text top="383" left="162" width="5" height="16" font="1"> </text>
<text top="442" left="162" width="428" height="16" font="4"><b>2.6.5 Combine MPI with OpenGL--Julia Set Generator </b></text>
<text top="500" left="180" width="632" height="16" font="1">In the context of complex dynamics, a topic of mathematics, the Julia set and the Fatou </text>
<text top="531" left="162" width="638" height="16" font="1">set are two complementary sets defined from a function. Informally, the Fatou set of the </text>
<text top="562" left="162" width="606" height="16" font="1">function consists of values with the property that all nearby values behave similarly </text>
<text top="593" left="162" width="632" height="16" font="1">under repeated iteration of the function, and the Julia set consists of values such that an </text>
<text top="624" left="162" width="595" height="16" font="1">arbitrarily small perturbation can cause drastic changes in the sequence of iterated </text>
<text top="655" left="162" width="633" height="16" font="1">function values. Thus the behavior of the function on the Fatou set is 'regular', while on </text>
<text top="686" left="162" width="262" height="16" font="1">the Julia set its behavior is 'chaotic'. </text>
<text top="717" left="180" width="546" height="16" font="1">The Julia set of a function ƒ is commonly denoted <i>J</i>(ƒ), and the Fatou set is </text>
<text top="748" left="162" width="532" height="16" font="1">denoted <i>F</i>(ƒ)[10].These eponymous fractals were the invention of French </text>
<text top="779" left="162" width="644" height="16" font="1">mathematician Gaston Julia. The fractal exists in the complex plane, a coordinate system </text>
<text top="810" left="162" width="637" height="16" font="1">where the &#34;x&#34; component of a point's location corresponds to a real number, and the &#34;y&#34; </text>
<text top="841" left="162" width="599" height="16" font="1">component corresponds to an imaginary number (i.e., a single number <i>x</i> such that <i>x</i></text>
<text top="837" left="761" width="6" height="11" font="26">2</text>
<text top="841" left="767" width="21" height="16" font="1"> is </text>
<text top="872" left="162" width="648" height="16" font="1">less than zero). Each point in the complex plane is a complex number of the form <i>z = a + </i></text>
<text top="903" left="162" width="504" height="16" font="25"><i>bi</i>. A <i>Julia</i> set (technically a <i>filled-in</i> Julia set) is the set of all points z</text>
<text top="910" left="666" width="6" height="11" font="26">0</text>
<text top="903" left="672" width="116" height="16" font="1"> in the complex </text>
<text top="934" left="162" width="214" height="16" font="1">plane for which the sequence </text>
<text top="965" left="162" width="5" height="16" font="1"> </text>
<text top="997" left="432" width="9" height="19" font="5"><b>z</b></text>
<text top="1006" left="441" width="22" height="12" font="27"><b>n+1</b></text>
<text top="997" left="463" width="32" height="19" font="5"><b> = z</b></text>
<text top="1006" left="495" width="8" height="12" font="27"><b>n</b></text>
<text top="993" left="502" width="7" height="12" font="27"><b>2</b></text>
<text top="997" left="509" width="37" height="19" font="5"><b> + c </b></text>
</page>
<page number="41" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">29 </text>
<text top="166" left="162" width="554" height="16" font="1">has a finite limit (i.e., does not get arbitrarily large as <i>n</i> approaches infinity). </text>
<text top="197" left="162" width="617" height="16" font="1">Geometrically this recurrence pushes points around on the complex plane, since each </text>
<text top="228" left="162" width="634" height="16" font="1">iteration will produces a new complex number / point on the plane. Points included in a </text>
<text top="259" left="162" width="646" height="16" font="1">Julia set will hover around the origin, while points not in the set will shoot off to infinity. </text>
<text top="290" left="162" width="602" height="16" font="1">Different constants <i>c</i> specify a particular Julia set, and can be thought of as placing </text>
<text top="321" left="162" width="652" height="16" font="1">differently shaped boundaries on the plane which prevent points inside the boundary from </text>
<text top="352" left="162" width="360" height="16" font="1">escaping.  The part of MPI code is given below:   </text>
<text top="383" left="162" width="5" height="16" font="1"> </text>
<text top="760" left="783" width="11" height="18" font="7"> </text>
<text top="789" left="162" width="14" height="16" font="1">   </text>
<text top="820" left="162" width="5" height="16" font="1"> </text>
<text top="851" left="162" width="5" height="16" font="1"> </text>
<text top="882" left="162" width="5" height="16" font="1"> </text>
<text top="913" left="162" width="5" height="16" font="1"> </text>
<text top="945" left="162" width="5" height="16" font="1"> </text>
<text top="976" left="162" width="5" height="16" font="1"> </text>
<text top="1007" left="162" width="5" height="16" font="1"> </text>
<text top="1038" left="162" width="5" height="16" font="1"> </text>
<text top="420" left="173" width="172" height="15" font="9">MPI_Init(&amp;argc, &amp;argv); </text>
<text top="448" left="173" width="378" height="15" font="9">MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank); </text>
<text top="477" left="173" width="389" height="15" font="9">MPI_Comm_size(MPI_COMM_WORLD, &amp;num_procs); </text>
<text top="506" left="173" width="239" height="15" font="9">/*Evenly divide up the data space*/ </text>
<text top="534" left="173" width="453" height="15" font="9">avg_amt_data = (row_width * column_length) / (num_procs - 1);     </text>
<text top="562" left="173" width="473" height="15" font="9">/*Any leftovers are to be given to the last process (and the master must </text>
<text top="591" left="173" width="312" height="15" font="9">* be able to receive this amount of data back*/ </text>
<text top="619" left="173" width="342" height="15" font="9">if (my_rank == (num_procs - 1) || my_rank == 0) { </text>
<text top="648" left="227" width="443" height="15" font="9">my_amt_data = avg_amt_data + ((row_width * column_length) % </text>
<text top="676" left="173" width="4" height="15" font="9"> </text>
<text top="676" left="227" width="125" height="15" font="9"> (num_procs - 1)); </text>
<text top="705" left="191" width="16" height="15" font="9">}  </text>
<text top="733" left="173" width="42" height="15" font="9">else { </text>
<text top="762" left="227" width="209" height="15" font="9">my_amt_data = avg_amt_data; </text>
<text top="790" left="173" width="29" height="15" font="9">    } </text>
<text top="819" left="173" width="263" height="15" font="9">MPI_Barrier(MPI_COMM_WORLD); </text>
<text top="847" left="173" width="135" height="15" font="9">if (my_rank == 0) { </text>
<text top="876" left="227" width="241" height="15" font="9">/*Start performance measurement*/ </text>
<text top="904" left="173" width="37" height="15" font="9">         </text>
<text top="904" left="227" width="413" height="15" font="9">jultimer = (struct itimerval *) malloc(sizeof(struct itimerval)); </text>
<text top="932" left="173" width="37" height="15" font="9">         </text>
<text top="932" left="227" width="260" height="15" font="9">start_timer(ITIMER_REAL, jultimer); </text>
<text top="961" left="173" width="37" height="15" font="9">         </text>
<text top="961" left="227" width="297" height="15" font="9">array_length = row_width * column_length; </text>
<text top="989" left="173" width="4" height="15" font="9"> </text>
<text top="989" left="227" width="365" height="15" font="9">data_array = (int *) malloc(sizeof(int) * array_length); </text>
<text top="1018" left="173" width="4" height="15" font="9"> </text>
<text top="1018" left="227" width="296" height="15" font="9">/*Recieve results from the other processes*/ </text>
<text top="1046" left="173" width="4" height="15" font="9"> </text>
</page>
<page number="42" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="28" size="16" family="Times" color="#c0c0c0"/>
	<fontspec id="29" size="14" family="Times" color="#c0c0c0"/>
	<fontspec id="30" size="14" family="Times" color="#000080"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">30 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="1006" left="784" width="5" height="16" font="1"> </text>
<text top="1032" left="381" width="215" height="15" font="9">Code 8. MPI code for Julia Sets </text>
<text top="203" left="174" width="239" height="15" font="9">for (i = 1; i &lt; num_procs - 1; i++) { </text>
<text top="232" left="228" width="426" height="15" font="9">MPI_Recv(&amp;data_array[(i - 1) * avg_amt_data], avg_amt_data, </text>
<text top="260" left="228" width="346" height="15" font="9">MPI_INT, i, tag, MPI_COMM_WORLD, &amp;status); </text>
<text top="289" left="174" width="12" height="15" font="9">} </text>
<text top="317" left="174" width="584" height="15" font="9">/*Receive the extra-large results from the last process, who has * calculated the average </text>
<text top="346" left="174" width="237" height="15" font="9">amount of data plus any leftovers*/ </text>
<text top="374" left="174" width="423" height="15" font="9">MPI_Recv(&amp;data_array[(i - 1) * avg_amt_data], my_amt_data, </text>
<text top="403" left="174" width="346" height="15" font="9">MPI_INT, i, tag, MPI_COMM_WORLD, &amp;status); </text>
<text top="431" left="174" width="4" height="15" font="9"> </text>
<text top="431" left="228" width="4" height="15" font="9"> </text>
<text top="456" left="174" width="259" height="18" font="14">//…….OpenGL rendering work……..; </text>
<text top="488" left="174" width="12" height="15" font="9">} </text>
<text top="516" left="174" width="34" height="15" font="9">else  </text>
<text top="545" left="174" width="12" height="15" font="9">{ </text>
<text top="573" left="228" width="371" height="15" font="9">data_array = (int *) malloc(sizeof(int) * my_amt_data); </text>
<text top="602" left="174" width="21" height="15" font="9">     </text>
<text top="602" left="228" width="387" height="15" font="9">x = (float) ((avg_amt_data * (my_rank - 1)) / row_width); </text>
<text top="630" left="174" width="21" height="15" font="9">     </text>
<text top="630" left="228" width="396" height="15" font="9">y = (float) ((avg_amt_data * (my_rank - 1)) % row_width); </text>
<text top="659" left="174" width="21" height="15" font="9">     </text>
<text top="659" left="228" width="234" height="15" font="9">for (i = 0; i &lt; my_amt_data; i++) { </text>
<text top="687" left="174" width="4" height="15" font="9"> </text>
<text top="687" left="228" width="4" height="15" font="9"> </text>
<text top="687" left="282" width="280" height="15" font="9">data_array[i] = calculatePointValue(x, y); </text>
<text top="716" left="174" width="4" height="15" font="9"> </text>
<text top="716" left="228" width="37" height="15" font="9">         </text>
<text top="716" left="282" width="64" height="15" font="9">y += 1.0; </text>
<text top="744" left="174" width="4" height="15" font="9"> </text>
<text top="744" left="228" width="37" height="15" font="9">         </text>
<text top="744" left="282" width="193" height="15" font="9">if (y &gt;= (float) row_width) { </text>
<text top="773" left="174" width="4" height="15" font="9"> </text>
<text top="773" left="228" width="4" height="15" font="9"> </text>
<text top="773" left="282" width="4" height="15" font="9"> </text>
<text top="773" left="336" width="64" height="15" font="9">x += 1.0; </text>
<text top="801" left="174" width="4" height="15" font="9"> </text>
<text top="801" left="228" width="4" height="15" font="9"> </text>
<text top="801" left="282" width="37" height="15" font="9">         </text>
<text top="801" left="336" width="55" height="15" font="9">y = 0.0; </text>
<text top="830" left="174" width="4" height="15" font="9"> </text>
<text top="830" left="228" width="37" height="15" font="9">         </text>
<text top="830" left="282" width="12" height="15" font="9">} </text>
<text top="858" left="174" width="5" height="16" font="1"> </text>
<text top="858" left="228" width="13" height="16" font="1"> }</text>
<text top="858" left="241" width="5" height="16" font="28"> </text>
<text top="859" left="282" width="4" height="15" font="9"> </text>
<text top="889" left="174" width="33" height="15" font="29">        </text>
<text top="889" left="207" width="150" height="15" font="9">MPI_Send(data_array,</text>
<text top="889" left="357" width="4" height="15" font="29"> </text>
<text top="889" left="361" width="94" height="15" font="9">my_amt_data,</text>
<text top="889" left="455" width="4" height="15" font="29"> </text>
<text top="889" left="459" width="69" height="15" font="9">MPI_INT,</text>
<text top="889" left="528" width="4" height="15" font="29"> </text>
<text top="889" left="533" width="24" height="15" font="9">tag,</text>
<text top="889" left="557" width="4" height="15" font="29"> </text>
<text top="889" left="561" width="8" height="15" font="30">0</text>
<text top="889" left="569" width="4" height="15" font="9">,</text>
<text top="889" left="573" width="4" height="15" font="29"> </text>
<text top="889" left="578" width="173" height="15" font="9">MPI_COMM_WORLD); </text>
<text top="917" left="174" width="12" height="15" font="9">} </text>
<text top="946" left="174" width="4" height="15" font="9"> </text>
</page>
<page number="43" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">31 </text>
<text top="166" left="162" width="23" height="16" font="28">     </text>
<text top="558" left="712" width="5" height="16" font="1"> </text>
<text top="1028" left="712" width="5" height="16" font="1"> </text>
<text top="1054" left="400" width="194" height="16" font="1">Figure 8. Julia Sets results </text>
</page>
<page number="44" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">32 </text>
<text top="757" left="785" width="5" height="16" font="1"> </text>
<text top="784" left="385" width="225" height="16" font="1">Figure 9. Iteration=3000 times </text>
<text top="840" left="273" width="58" height="14" font="17">Iteration </text>
<text top="814" left="430" width="75" height="14" font="17">Sequential </text>
<text top="840" left="404" width="128" height="14" font="17">Implementation (s) </text>
<text top="840" left="574" width="159" height="14" font="17">MPI Implementation (s) </text>
<text top="866" left="283" width="37" height="14" font="17">3500 </text>
<text top="866" left="443" width="50" height="14" font="17">22.211 </text>
<text top="866" left="629" width="50" height="14" font="17">11.012 </text>
<text top="892" left="283" width="37" height="14" font="17">8000 </text>
<text top="892" left="443" width="50" height="14" font="17">50.577 </text>
<text top="892" left="629" width="50" height="14" font="17">22.450 </text>
<text top="918" left="279" width="46" height="14" font="17">30000 </text>
<text top="918" left="439" width="58" height="14" font="17">196.154 </text>
<text top="918" left="629" width="50" height="14" font="17">85.271 </text>
<text top="944" left="263" width="451" height="16" font="1">Table 7. Performance for Sequential and MPI Implementation </text>
<text top="976" left="180" width="612" height="16" font="1">The above table showed parallel implementation run much faster than the sequential </text>
<text top="1006" left="162" width="300" height="16" font="1">version in generating time consumption.  </text>
<text top="1037" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="45" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">33 </text>
<text top="222" left="293" width="416" height="22" font="8"><b>3. GPU Parallel Programming—CUDA  </b></text>
<text top="262" left="162" width="5" height="16" font="1"> </text>
<text top="292" left="162" width="5" height="16" font="1"> </text>
<text top="324" left="162" width="5" height="16" font="1"> </text>
<text top="383" left="162" width="217" height="19" font="5"><b>3.1 CUDA Introduction </b></text>
<text top="445" left="180" width="579" height="16" font="1">Compute United Device Architecture (CUDA) is NVIDIA’s parallel computing </text>
<text top="476" left="162" width="639" height="16" font="1">architecture [11]. It enables dramatic increases in computing performance by harnessing </text>
<text top="507" left="162" width="637" height="16" font="1">the power of the GPU. This computing engine makes developer accessible to the virtual </text>
<text top="538" left="162" width="608" height="16" font="1">instruction set and memory of the parallel computational elements in CUDA GPUs. </text>
<text top="569" left="162" width="633" height="16" font="1">Using CUDA, the latest NVIDIA GPUs become accessible for computation like CPUs. </text>
<text top="600" left="162" width="620" height="16" font="1">Unlike CPUs however, GPUs have a parallel throughput architecture that emphasizes </text>
<text top="631" left="162" width="616" height="16" font="1">executing many concurrent threads slowly, rather than executing a single thread very </text>
<text top="662" left="162" width="597" height="16" font="1">quickly. This approach of solving general purpose problems on GPUs is known as </text>
<text top="693" left="162" width="68" height="16" font="1">GPGPU. </text>
<text top="724" left="180" width="622" height="16" font="1">CUDA has several advantages over traditional general purpose computation on GPUs </text>
<text top="756" left="162" width="230" height="16" font="1">(GPGPU) using graphics APIs. </text>
<text top="782" left="189" width="8" height="22" font="12"></text>
<text top="787" left="197" width="5" height="17" font="13"> </text>
<text top="788" left="216" width="498" height="16" font="1">Scattered reads – code can read from arbitrary addresses in memory. </text>
<text top="814" left="189" width="8" height="22" font="12"></text>
<text top="820" left="197" width="5" height="17" font="13"> </text>
<text top="820" left="216" width="572" height="16" font="1">Shared memory – CUDA exposes a fast shared memory region (up to 48KB in </text>
<text top="851" left="216" width="561" height="16" font="1">size) that can be shared amongst threads. This can be used as a user-managed </text>
<text top="882" left="216" width="562" height="16" font="1">cache, enabling higher bandwidth than is possible using texture lookups. [12] </text>
<text top="909" left="189" width="8" height="22" font="12"></text>
<text top="914" left="197" width="5" height="17" font="13"> </text>
<text top="914" left="216" width="402" height="16" font="1">Faster downloads and read backs to and from the GPU. </text>
</page>
<page number="46" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="31" size="16" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">34 </text>
<text top="194" left="162" width="291" height="19" font="5"><b>3.2 CUDA Programming Model </b></text>
<text top="256" left="180" width="627" height="16" font="1">CUDA can be used in two different ways, (1) via the runtime API, which provides a C </text>
<text top="287" left="162" width="652" height="16" font="1">like set of routines and extensions, and (2), via the driver API, which provides lower level </text>
<text top="318" left="162" width="638" height="16" font="1">control over the hardware but requires more code and programming effort. In my paper, </text>
<text top="350" left="162" width="588" height="16" font="1">CUDA runtime API is adopted because it provides implicit initialization, context </text>
<text top="381" left="162" width="559" height="16" font="1">management, and module management for applications and it’s easier to use. </text>
<text top="412" left="162" width="5" height="16" font="1"> </text>
<text top="470" left="162" width="105" height="16" font="4"><b>3.2.1 Kernels </b></text>
<text top="528" left="180" width="627" height="16" font="1">CUDA C extends C by allowing the programmer to define C functions, called <i>kernels</i>, </text>
<text top="559" left="162" width="607" height="16" font="1">that, when called, are executed N times in parallel by N different <i>CUDA threads</i>, as </text>
<text top="590" left="162" width="637" height="16" font="1">opposed to only once like regular C functions. A kernel is defined using the <b>__global__ </b></text>
<text top="621" left="162" width="608" height="16" font="1">declaration specifier and the number of CUDA threads that execute that kernel for a </text>
<text top="652" left="162" width="617" height="16" font="1">given kernel call is specified using a new <b>&lt;&lt;&lt;…&gt;&gt;&gt; </b>execution configuration syntax. </text>
<text top="683" left="162" width="642" height="16" font="1">Each thread that executes the kernel is given a unique <i>thread ID </i>that is accessible within </text>
<text top="714" left="162" width="369" height="16" font="1">the kernel through the built-in <b>threadIdx </b>variable. </text>
<text top="745" left="162" width="5" height="16" font="1"> </text>
<text top="804" left="162" width="196" height="16" font="4"><b>3.2.2 Thread Hierarchies </b></text>
<text top="861" left="180" width="625" height="16" font="1">For convenience, <b>threadIdx </b>is a 3-component vector, so that threads can be identified </text>
<text top="892" left="162" width="643" height="16" font="1">using a one-dimensional, two-dimensional, or three-dimensional <i>thread index</i>, forming a </text>
<text top="923" left="162" width="628" height="16" font="1">one-dimensional, two-dimensional, or three-dimensional <i>thread block</i>. This provides a </text>
<text top="954" left="162" width="613" height="16" font="1">natural way to invoke computation across the elements in a domain such as a vector, </text>
<text top="985" left="162" width="143" height="16" font="1">matrix, or volume.  </text>
</page>
<page number="47" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">35 </text>
<text top="166" left="180" width="611" height="16" font="1">The index of a thread and its thread ID relate to each other in a straightforward way: </text>
<text top="197" left="162" width="646" height="16" font="1">For a one-dimensional block, they are the same; for a two-dimensional block of size <i>(Dx, </i></text>
<text top="228" left="162" width="640" height="16" font="25"><i>Dy)</i>, the thread ID of a thread of index <i>(x, y) </i>is <i>(x + y Dx)</i>; for a three-dimensional block </text>
<text top="259" left="162" width="635" height="16" font="1">of size <i>(Dx, Dy, Dz)</i>, the thread ID of a thread of index <i>(x, y, z) </i>is <i>(x + y Dx + z Dx Dy</i>). </text>
<text top="290" left="162" width="643" height="16" font="1">As an example, the following code adds two matrices <i>A </i>and <i>B </i>of size <i>NxN </i>and stores the </text>
<text top="321" left="162" width="154" height="16" font="1">result into matrix <i>C</i>:  </text>
<text top="850" left="784" width="5" height="16" font="1"> </text>
<text top="876" left="389" width="199" height="15" font="9">Code 9. CUDA Sample Code </text>
<text top="905" left="162" width="5" height="16" font="1"> </text>
<text top="936" left="162" width="594" height="16" font="1">There is a limit to the number of threads per block, since all threads of a block are </text>
<text top="968" left="162" width="592" height="16" font="1">expected to reside on the same processor core and must share the limited memory </text>
<text top="999" left="162" width="639" height="16" font="1">resources of that core. On current GPUs, a thread block may contain up to 1024 threads. </text>
<text top="359" left="174" width="135" height="15" font="9">// Kernel definition  </text>
<text top="387" left="174" width="376" height="15" font="9">__global__ void MatAdd(float A[N][N], float B[N][N],  </text>
<text top="416" left="174" width="105" height="15" font="9">float C[N][N])  </text>
<text top="444" left="174" width="16" height="15" font="9">{  </text>
<text top="472" left="228" width="132" height="15" font="9">int i = threadIdx.x;  </text>
<text top="501" left="228" width="132" height="15" font="9">int j = threadIdx.y;  </text>
<text top="529" left="228" width="175" height="15" font="9">C[i][j] = A[i][j] + B[i][j];  </text>
<text top="558" left="174" width="16" height="15" font="9">}  </text>
<text top="586" left="174" width="4" height="15" font="9"> </text>
<text top="615" left="174" width="74" height="15" font="9">int main()  </text>
<text top="643" left="174" width="16" height="15" font="9">{  </text>
<text top="672" left="228" width="21" height="15" font="9">...  </text>
<text top="700" left="174" width="4" height="15" font="9"> </text>
<text top="700" left="228" width="381" height="15" font="9">// Kernel invocation with one block of N * N * 1 threads  </text>
<text top="729" left="228" width="135" height="15" font="9">int numBlocks = 1;  </text>
<text top="757" left="228" width="203" height="15" font="9">dim3 threadsPerBlock(N, N);  </text>
<text top="785" left="228" width="378" height="15" font="9">MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);  </text>
<text top="814" left="174" width="16" height="15" font="9">}  </text>
</page>
<page number="48" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">36 </text>
<text top="166" left="180" width="614" height="16" font="1">However, a kernel can be executed by multiple equally-shaped thread blocks, so that </text>
<text top="197" left="162" width="640" height="16" font="1">the total number of threads is equal to the number of threads per block times the number </text>
<text top="228" left="162" width="75" height="16" font="1">of blocks. </text>
<text top="797" left="689" width="5" height="16" font="1"> </text>
<text top="824" left="356" width="281" height="15" font="9">Figure 10. CUDA Thread Hierarchies[30] </text>
<text top="853" left="180" width="603" height="16" font="1">The number of threads per block and the number of blocks per grid specified in the </text>
<text top="880" left="162" width="628" height="20" font="31"><b>&lt;&lt;&lt;…&gt;&gt;&gt; </b>syntax can be of type <b>int </b>or <b>dim3</b>. Two-dimensional blocks or grids can be </text>
<text top="915" left="162" width="256" height="16" font="1">specified as in the example above.  </text>
<text top="946" left="180" width="625" height="16" font="1">Each block within the grid can be identified by a one-dimensional or two-dimensional </text>
<text top="977" left="162" width="644" height="16" font="1">index accessible within the kernel through the built-in <b>blockIdx </b>variable. The dimension </text>
<text top="1008" left="162" width="652" height="16" font="1">of the thread block is accessible within the kernel through the built-in <b>blockDim </b>variable. </text>
</page>
<page number="49" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">37 </text>
<text top="166" left="180" width="605" height="16" font="1">Thread blocks are required to execute independently: It must be possible to execute </text>
<text top="197" left="162" width="634" height="16" font="1">them in any order, in parallel or in series. This independence requirement allows thread </text>
<text top="228" left="162" width="470" height="16" font="1">blocks to be scheduled in any order across any number of cores.  </text>
<text top="259" left="180" width="607" height="16" font="1">Threads within a block can cooperate by sharing data through some <i>shared memory </i></text>
<text top="290" left="162" width="622" height="16" font="1">and by synchronizing their execution to coordinate memory accesses. More precisely, </text>
<text top="321" left="162" width="608" height="16" font="1">one can specify synchronization points in the kernel by calling the <b>__syncthreads() </b></text>
<text top="352" left="162" width="650" height="16" font="1">intrinsic function; <b>__syncthreads() </b>acts as a barrier at which all threads in the block must </text>
<text top="383" left="162" width="279" height="16" font="1">wait before any is allowed to proceed. </text>
<text top="415" left="162" width="5" height="16" font="1"> </text>
<text top="473" left="162" width="205" height="16" font="4"><b>3.2.3 Memory Hierarchies </b></text>
<text top="531" left="180" width="620" height="16" font="1">CUDA threads may access data from multiple memory spaces during their execution. </text>
<text top="562" left="162" width="85" height="16" font="1">Each thread</text>
<text top="560" left="247" width="4" height="19" font="14"> </text>
<text top="562" left="251" width="541" height="16" font="1">has private local memory. Each thread block has shared memory visible to </text>
<text top="593" left="162" width="651" height="16" font="1">all threads of the block and with the same lifetime as the block. All threads have access to </text>
<text top="624" left="162" width="191" height="16" font="1">the same global memory.  </text>
<text top="655" left="180" width="614" height="16" font="1">There are also two additional read-only memory spaces accessible by all threads: the </text>
<text top="686" left="162" width="626" height="16" font="1">constant and texture memory spaces. The global, constant, and texture memory spaces </text>
<text top="717" left="162" width="588" height="16" font="1">are optimized for different memory usages. Texture memory also offers different </text>
<text top="748" left="162" width="540" height="16" font="1">addressing modes, as well as data filtering, for some specific data formats. </text>
<text top="779" left="180" width="622" height="16" font="1">The global, constant, and texture memory spaces are persistent across kernel launches </text>
<text top="810" left="162" width="180" height="16" font="1">by the same application. </text>
<text top="841" left="180" width="5" height="16" font="1"> </text>
</page>
<page number="50" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">38 </text>
<text top="361" left="743" width="5" height="16" font="1"> </text>
<text top="711" left="711" width="5" height="16" font="1"> </text>
<text top="737" left="342" width="291" height="15" font="9">Figure 11. CUDA Memory Hierarchies[30] </text>
<text top="766" left="162" width="5" height="16" font="1"> </text>
<text top="825" left="162" width="411" height="19" font="5"><b>3.3 CUDA Basic Program—GPU Vector Add </b></text>
<text top="888" left="180" width="616" height="16" font="1">In this section, a simple CUDA program of GPU vector sum is implemented to show </text>
<text top="919" left="162" width="363" height="16" font="1">some basic program skills and features in CUDA. </text>
<text top="950" left="180" width="615" height="16" font="1">The CUDA runtime allows these blocks to be split into <i>threads</i>. Recall that when we </text>
<text top="981" left="162" width="624" height="16" font="1">launched multiple parallel blocks, we changed the first argument in the angle brackets </text>
<text top="1012" left="162" width="611" height="16" font="1">from 1 to the number of blocks we wanted to launch. For example, when we studied </text>
</page>
<page number="51" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">39 </text>
<text top="166" left="162" width="634" height="16" font="1">vector addition, we launched a block for each element in the vector of size N by calling </text>
<text top="197" left="162" width="35" height="16" font="1">this: </text>
<text top="228" left="180" width="292" height="16" font="1">add&lt;&lt;&lt;N,1&gt;&gt;&gt;( dev_a, dev_b, dev_c ); </text>
<text top="259" left="162" width="646" height="16" font="1">Inside the angle brackets, the second parameter actually represents the number of threads </text>
<text top="290" left="162" width="652" height="16" font="1">per block we want the CUDA runtime to create on our behalf. To this point, we have only </text>
<text top="321" left="162" width="645" height="16" font="1">ever launched one thread per block. In the previous example, we launched the following: </text>
<text top="352" left="180" width="338" height="16" font="1">N blocks x 1 thread/block = N parallel threads </text>
<text top="383" left="162" width="619" height="16" font="1">So really, we could have launched N/2 blocks with two threads per block, N/4 blocks </text>
<text top="415" left="162" width="287" height="16" font="1">with four threads per block, and so on.  </text>
<text top="446" left="180" width="629" height="16" font="1">We will start by addressing the two changes of note when moving from parallel blocks </text>
<text top="477" left="162" width="646" height="16" font="1">to parallel threads. Our kernel invocation will change from one that launches N blocks of </text>
<text top="508" left="162" width="135" height="16" font="1">one thread apiece: </text>
<text top="539" left="180" width="319" height="16" font="1">add&lt;&lt;&lt;N,1&gt;&gt;&gt;( dev _ a, dev _ b, dev _ c ); </text>
<text top="570" left="162" width="419" height="16" font="1">to a version that launches N threads, all within one block: </text>
<text top="601" left="180" width="319" height="16" font="1">add&lt;&lt;&lt;1,N&gt;&gt;&gt;( dev _ a, dev _ b, dev _ c ); </text>
<text top="632" left="162" width="609" height="16" font="1">The only other change arises in the method by which we index our data. Previously, </text>
<text top="663" left="162" width="579" height="16" font="1">within our kernel we indexed the input and output data by block index. <b>int </b>tid = </text>
<text top="694" left="162" width="646" height="16" font="1">blockIdx.x; The punch line here should not be a surprise. Now that we have only a single </text>
<text top="725" left="162" width="650" height="16" font="1">block, we have to index the data by thread index. <b>int </b>tid = threadIdx.x; These are the only </text>
<text top="756" left="162" width="633" height="16" font="1">two changes required to move from a parallel block implementation to a parallel thread </text>
<text top="787" left="162" width="490" height="16" font="1">implementation. The main function of source code is shown below: </text>
</page>
<page number="52" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="32" size="14" family="Times" color="#000000"/>
	<fontspec id="33" size="14" family="Times" color="#000000"/>
	<fontspec id="34" size="14" family="Times" color="#000000"/>
	<fontspec id="35" size="14" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">40 </text>
<text top="582" left="770" width="5" height="16" font="1"> </text>
<text top="608" left="162" width="5" height="16" font="1"> </text>
<text top="639" left="162" width="5" height="16" font="1"> </text>
<text top="671" left="162" width="5" height="16" font="1"> </text>
<text top="702" left="162" width="5" height="16" font="1"> </text>
<text top="733" left="162" width="5" height="16" font="1"> </text>
<text top="764" left="162" width="5" height="16" font="1"> </text>
<text top="795" left="162" width="5" height="16" font="1"> </text>
<text top="826" left="162" width="5" height="16" font="1"> </text>
<text top="857" left="162" width="5" height="16" font="1"> </text>
<text top="888" left="162" width="5" height="16" font="1"> </text>
<text top="919" left="162" width="5" height="16" font="1"> </text>
<text top="950" left="162" width="5" height="16" font="1"> </text>
<text top="981" left="162" width="5" height="16" font="1"> </text>
<text top="1012" left="162" width="5" height="16" font="1"> </text>
<text top="1043" left="390" width="196" height="15" font="9">Code 10. CUDA Vector Add </text>
<text top="172" left="173" width="122" height="15" font="32"><b>int </b>main( <b>void </b>) { </text>
<text top="200" left="227" width="140" height="15" font="32"><b>int </b>a[N], b[N], c[N]; </text>
<text top="229" left="227" width="192" height="15" font="32"><b>int </b>*dev_a, *dev_b, *dev_c; </text>
<text top="257" left="227" width="235" height="15" font="33"><i>// allocate the memory on the GPU </i></text>
<text top="286" left="227" width="473" height="15" font="9">HANDLE_ERROR( cudaMalloc( (<b>void</b>**)&amp;dev_a, N * <b>sizeof</b>(<b>int</b>) ) ); </text>
<text top="314" left="227" width="474" height="15" font="9">HANDLE_ERROR( cudaMalloc( (<b>void</b>**)&amp;dev_b, N * <b>sizeof</b>(<b>int</b>) ) ); </text>
<text top="342" left="227" width="473" height="15" font="9">HANDLE_ERROR( cudaMalloc( (<b>void</b>**)&amp;dev_c, N * <b>sizeof</b>(<b>int</b>) ) ); </text>
<text top="367" left="227" width="265" height="18" font="34"><i>// fill the arrays ‘a’ and ‘b’ on the CPU </i></text>
<text top="399" left="227" width="164" height="15" font="32"><b>for </b>(<b>int </b>i=0; i&lt;N; i++) { </text>
<text top="428" left="281" width="54" height="15" font="9">a[i] = i; </text>
<text top="456" left="281" width="76" height="15" font="9">b[i] = i * i; </text>
<text top="485" left="227" width="12" height="15" font="9">} </text>
<text top="510" left="227" width="275" height="18" font="34"><i>// copy the arrays ‘a’ and ‘b’ to the GPU </i></text>
<text top="542" left="227" width="410" height="15" font="9">HANDLE_ERROR( cudaMemcpy( dev_a, a, N * <b>sizeof</b>(<b>int</b>), </text>
<text top="570" left="227" width="214" height="15" font="9">cudaMemcpyHostToDevice ) ); </text>
<text top="599" left="173" width="5" height="16" font="1"> </text>
<text top="645" left="227" width="412" height="15" font="9">HANDLE_ERROR( cudaMemcpy( dev_b, b, N * <b>sizeof</b>(<b>int</b>), </text>
<text top="674" left="227" width="214" height="15" font="9">cudaMemcpyHostToDevice ) ); </text>
<text top="702" left="227" width="277" height="15" font="32"><b>add&lt;&lt;&lt;1,N&gt;&gt;&gt;( dev_a, dev_b, dev_c ); </b></text>
<text top="730" left="227" width="410" height="15" font="9">HANDLE_ERROR( cudaMemcpy( c, dev_c, N * <b>sizeof</b>(<b>int</b>), </text>
<text top="759" left="227" width="214" height="15" font="9">cudaMemcpyDeviceToHost ) ); </text>
<text top="787" left="227" width="138" height="15" font="33"><i>// display the results </i></text>
<text top="813" left="227" width="29" height="18" font="35"><b>…..</b> </text>
<text top="844" left="227" width="273" height="15" font="33"><i>// free the memory allocated on the GPU </i></text>
<text top="873" left="227" width="128" height="15" font="9">cudaFree( dev_a ); </text>
<text top="901" left="227" width="129" height="15" font="9">cudaFree( dev_b ); </text>
<text top="930" left="227" width="128" height="15" font="9">cudaFree( dev_c ); </text>
<text top="958" left="227" width="67" height="15" font="32"><b>return </b>0; </text>
<text top="987" left="173" width="12" height="15" font="9">} </text>
<text top="1015" left="173" width="5" height="16" font="1"> </text>
</page>
<page number="53" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">41 </text>
<text top="167" left="162" width="436" height="19" font="5"><b>3.4 CUDA Implementation of Fluid Simulation   </b></text>
<text top="229" left="180" width="573" height="16" font="1">Building animation tools for fluid like motions is an important and challenging </text>
<text top="260" left="162" width="652" height="16" font="1">problem with many applications in computer graphics. In this section, a CUDA optimized </text>
<text top="291" left="162" width="568" height="16" font="1">fluid simulation application is presented alone with performance analysis. The </text>
<text top="323" left="162" width="580" height="16" font="1">implementation method is based on Physics fluid Equations and interpolation in </text>
<text top="353" left="162" width="102" height="16" font="1">Mathematics  </text>
<text top="385" left="162" width="5" height="16" font="1"> </text>
<text top="443" left="162" width="175" height="16" font="4"><b>3.4.1 Fluid Simulation </b></text>
<text top="501" left="180" width="608" height="16" font="1">Fluid<b> </b>simulation is an increasingly popular tool in computer graphics for generating </text>
<text top="532" left="162" width="574" height="16" font="1">realistic animations of water, smoke, explosions, and related phenomena. Fluid </text>
<text top="563" left="162" width="629" height="16" font="1">simulation is a useful building block that is the basis for simulating a variety of natural </text>
<text top="594" left="162" width="593" height="16" font="1">phenomena. Because of the large amount of parallelism in graphics hardware, it’s </text>
<text top="625" left="162" width="564" height="16" font="1">reasonable to implement the GPU based fluid solver with the help of CUDA.  </text>
<text top="656" left="180" width="627" height="16" font="1">Given some input configuration of fluid and scene geometry, a fluid simulator evolves </text>
<text top="687" left="162" width="638" height="16" font="1">the motion of the fluid forward in time, making use of the mathematics equations which </text>
<text top="718" left="162" width="641" height="16" font="1">describe the physics of fluids. The fluids dynamics described here is limited on a ―stable </text>
<text top="745" left="162" width="635" height="20" font="7">method‖ based fluid from Stam’s paper [25] and a continuous volume of fluid on a two-</text>
<text top="780" left="162" width="293" height="16" font="1">dimensional regular domain is adopted.  </text>
<text top="811" left="162" width="5" height="16" font="1"> </text>
<text top="870" left="162" width="187" height="16" font="4"><b>3.4.2 Mathematics Core </b></text>
<text top="927" left="180" width="616" height="16" font="1">To use the physics of fluid flows which have been developed since the time of Euler, </text>
<text top="955" left="162" width="633" height="20" font="7">Navier and Stokes (from the 1750’s to the 1850’s). These developments have led to the </text>
<text top="989" left="162" width="625" height="16" font="1">so-called Navier-Stokes Equations, a precise mathematical model for most fluid flows </text>
<text top="1021" left="162" width="630" height="16" font="1">occurring in Nature. Dynamical models of fluids based on the Navier-Stokes equations </text>
<text top="1051" left="162" width="616" height="16" font="1">were first implemented in two-dimensions. Both Yaeger and Upson and Gamitoet al. </text>
</page>
<page number="54" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">42 </text>
<text top="166" left="162" width="570" height="16" font="1">used a vortex method coupled with a Poisson solver to create two-dimensional </text>
<text top="197" left="162" width="645" height="16" font="1">animations of fluids [24, 8].Later, Stam’s stable fluid model is given and be widely used. </text>
<text top="228" left="162" width="432" height="16" font="1">The physics of fluids can be described in math as followed: </text>
<text top="394" left="765" width="5" height="16" font="1"> </text>
<text top="420" left="162" width="642" height="16" font="1">A vector field is a mapping of a vector-valued function onto a parameterized space, such </text>
<text top="451" left="162" width="624" height="16" font="1">as a Cartesian coordinate system. The velocity vector field of our fluid is defined such </text>
<text top="482" left="162" width="652" height="16" font="1">that for every position f(x) = (x, y), there is an associated velocity at time t, and u (f(x), t). </text>
<text top="514" left="162" width="617" height="16" font="1">Notice that the top Equation is actually two equations, because u is a vector quantity: </text>
<text top="680" left="715" width="5" height="16" font="1"> </text>
<text top="707" left="162" width="472" height="16" font="1">Thus, there are three unknowns (u, v, and p) and three equations. </text>
<text top="738" left="162" width="5" height="16" font="1"> </text>
<text top="796" left="162" width="219" height="16" font="4"><b>3.4.3 Fluids Representation  </b></text>
<text top="854" left="180" width="601" height="16" font="1">Mathematical equations for fluids are useful when thinking about fluids in general. </text>
<text top="885" left="162" width="639" height="16" font="1">However, in practice we need a finite representation for our fluids. The following figure </text>
<text top="916" left="162" width="167" height="16" font="1">explains the approach: </text>
</page>
<page number="55" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">43 </text>
<text top="593" left="715" width="5" height="16" font="1"> </text>
<text top="619" left="269" width="457" height="15" font="9">Figure 12. Velocity and density are defined in the center of each cell </text>
<text top="648" left="180" width="5" height="16" font="1"> </text>
<text top="679" left="180" width="602" height="16" font="1"> We dice up a finite region of space into identical cells and sample the fluid at each </text>
<text top="707" left="162" width="623" height="20" font="7">cell’s center. Both the density and the velocity are defined at the cell centers. The grid </text>
<text top="741" left="162" width="631" height="16" font="1">contains an extra layer of cells to account for the boundary conditions. The key to fluid </text>
<text top="772" left="162" width="637" height="16" font="1">simulation is to take steps in time and, at each time step, correctly determine the current </text>
<text top="804" left="162" width="648" height="16" font="1">velocity field. We can do this by solving a set of equations that describes the evolution of </text>
<text top="835" left="162" width="389" height="16" font="1">the velocity field over time, under a variety of forces. </text>
<text top="866" left="162" width="5" height="16" font="1"> </text>
<text top="924" left="162" width="450" height="16" font="4"><b>3.4.4 Algorithm Cores based on Navier-Strokes Equations </b></text>
<text top="978" left="180" width="599" height="20" font="7">In physics it’s common to make simplifying assumptions when modeling complex </text>
<text top="1013" left="162" width="639" height="16" font="1">phenomena. Fluid simulation is no exception. We assume an incompressible fluid in the </text>
<text top="1044" left="162" width="634" height="16" font="1">following implementation. Based on Navier-Strokes Equations, we take right hand side </text>
</page>
<page number="56" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">44 </text>
<text top="166" left="162" width="601" height="16" font="1">of equation into four parts—Advection, Pressure, Diffusion and External Forces as </text>
<text top="197" left="162" width="105" height="16" font="1">shown below: </text>
<text top="309" left="180" width="112" height="16" font="1">                         </text>
<text top="309" left="639" width="5" height="16" font="1"> </text>
<text top="336" left="162" width="643" height="16" font="1">According to Helmholtz-Hodge Decomposition Theorem [27], a vector field w on D can </text>
<text top="367" left="162" width="273" height="16" font="1">be uniquely decomposed in the form: </text>
<text top="439" left="667" width="5" height="16" font="1"> </text>
<text top="467" left="162" width="643" height="16" font="1">Where u has zero divergence and is parallel to ∂D; that is, u ⋅ n = 0 on ∂D. This theorem </text>
<text top="500" left="162" width="636" height="16" font="1">states that any vector field can be decomposed into the sum of two other vector fields: a </text>
<text top="532" left="162" width="598" height="16" font="1">divergence-free vector field, and the gradient of a scalar field. We use a projection </text>
<text top="575" left="162" width="64" height="16" font="1">operator </text>
<text top="575" left="246" width="411" height="16" font="1"> and combine it with  Navier-Strokes equation, we have: </text>
<text top="690" left="162" width="63" height="16" font="1">              </text>
<text top="690" left="706" width="5" height="16" font="1"> </text>
<text top="717" left="162" width="533" height="16" font="1">Because u is divergence-free, so is the derivative on the left-hand side, so </text>
<text top="764" left="338" width="428" height="16" font="1"> Also, by the definition of  projection we can conclude that </text>
<text top="812" left="260" width="171" height="16" font="1">. Then we finally have: </text>
<text top="917" left="162" width="130" height="16" font="1">                             </text>
<text top="917" left="659" width="5" height="16" font="1"> </text>
<text top="944" left="162" width="635" height="16" font="1">Which defines four operations—Advection, Diffusion, Projection and External Forces.  </text>
<text top="975" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="57" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="36" size="19" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">45 </text>
<text top="167" left="162" width="96" height="19" font="5"><b>Advection </b></text>
<text top="471" left="672" width="5" height="16" font="1"> </text>
<text top="498" left="406" width="184" height="19" font="36">Figure 13. Advection </text>
<text top="533" left="495" width="4" height="15" font="9"> </text>
<text top="562" left="180" width="573" height="16" font="1">The velocity of a fluid causes the fluid to transport objects, densities, and other </text>
<text top="593" left="162" width="616" height="16" font="1">quantities along with the flow. Imagine blowing dust into a moving fluid. The dust is </text>
<text top="621" left="162" width="624" height="20" font="7">transported, or advected, along the fluid’s velocity field. In fact, the velocity of a fluid </text>
<text top="655" left="162" width="626" height="16" font="1">carries itself along just as it carries the small particles. The first term on the right-hand </text>
<text top="687" left="162" width="604" height="16" font="1">side of Equation represents this self-advection of the velocity field and is called the </text>
<text top="718" left="162" width="116" height="16" font="1">advection term. </text>
<text top="749" left="180" width="621" height="16" font="1">For Advection step, the key idea behind this technique is that moving densities would </text>
<text top="780" left="162" width="630" height="16" font="1">be easy to solve if the density were modeled as a set of particles. In this case we would </text>
<text top="811" left="162" width="645" height="16" font="1">simply have to trace the particles though the velocity field. For each grid cell of the latter </text>
<text top="838" left="162" width="643" height="20" font="7">we trace the cell’s center position backwards through the velocity field. We then linearly </text>
<text top="873" left="162" width="628" height="16" font="1">interpolate from the grid of previous density values and assign this value to the current </text>
<text top="904" left="162" width="68" height="16" font="1">grid cell. </text>
<text top="935" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="58" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="37" size="16" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">46 </text>
<text top="167" left="162" width="88" height="19" font="5"><b>Diffusion </b></text>
<text top="229" left="180" width="604" height="16" font="1">The Diffusion accounts for possible diffusion at a rate diff, when diff&gt;0 the density </text>
<text top="260" left="162" width="634" height="16" font="1">will spread across the grid cells. According to stam’s paper, an assumption is made that </text>
<text top="291" left="162" width="641" height="16" font="1">only direct neighbors are considered in the diffusion step for each cell in the fluid model </text>
<text top="323" left="162" width="216" height="16" font="1">as shown in following figure: </text>
<text top="564" left="668" width="5" height="16" font="1"> </text>
<text top="590" left="427" width="143" height="15" font="9">Figure 14. Diffusion  </text>
<text top="619" left="162" width="5" height="16" font="1"> </text>
<text top="646" left="180" width="572" height="20" font="7">The cell’s density will decrease by losing density to its neighbors, but will also </text>
<text top="681" left="162" width="640" height="16" font="1">increase due to densities flowing in from the neighbors, which results in a net difference </text>
<text top="712" left="162" width="19" height="16" font="1">of </text>
<text top="743" left="162" width="509" height="16" font="1">x0[IX(i-1,j)]+x0[IX(i+1,j)]+x0[IX(i,j-1)]+x0[IX(i,j+1)]-4*x0[IX(i,j)]. </text>
<text top="774" left="162" width="630" height="16" font="1">This can be considered as a linear system for x[IX(i,j)], we write it in a matrix notation </text>
<text top="805" left="459" width="59" height="16" font="37"><i><b>Au </b></i>= <i><b>b</b></i>. </text>
<text top="837" left="162" width="618" height="16" font="1">Based on this notation, an iterative solver which works well in practice named Gauss-</text>
<text top="868" left="162" width="633" height="16" font="1">Seidel relaxation [26] is applied here to make the computation stable when facing large </text>
<text top="899" left="162" width="458" height="16" font="1">diffusion rate. This method can be well parallelized by CUDA. </text>
<text top="930" left="162" width="5" height="16" font="1"> </text>
<text top="961" left="162" width="5" height="16" font="1"> </text>
<text top="992" left="162" width="5" height="16" font="1"> </text>
<text top="1023" left="162" width="5" height="16" font="1"> </text>
<text top="1054" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="59" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">47 </text>
<text top="167" left="162" width="99" height="19" font="5"><b>Projection </b></text>
<text top="229" left="180" width="613" height="16" font="1">Just as we described above, Hodge decomposition method is used and the projection </text>
<text top="260" left="162" width="601" height="16" font="1">step should be implemented in order to get our mass conserving field. We have the </text>
<text top="291" left="162" width="217" height="16" font="1">following equation and chart: </text>
<text top="351" left="618" width="5" height="16" font="1"> </text>
<text top="618" left="810" width="5" height="16" font="1"> </text>
<text top="635" left="367" width="242" height="16" font="1">Figure 15. Mass conserving field </text>
<text top="655" left="162" width="5" height="16" font="1"> </text>
<text top="676" left="180" width="632" height="16" font="1">This routine forces the velocity to be mass conserving. This is an important property of </text>
<text top="707" left="162" width="627" height="16" font="1">real fluids which should be enforced. Visually it forces the flow to have many vortices </text>
<text top="738" left="162" width="632" height="16" font="1">which produce realistic swirly-like flows. The idea is to make it mass conserving in the </text>
<text top="769" left="162" width="624" height="16" font="1">last step. This decomposition can be optimized by CUDA by using separate threads to </text>
<text top="800" left="162" width="477" height="16" font="1">calculate the iteration instead of making multiple layers of loops.  </text>
<text top="831" left="162" width="5" height="16" font="1"> </text>
<text top="890" left="162" width="376" height="16" font="4"><b>3.4.5 Implementation and Performance Analysis </b></text>
<text top="944" left="180" width="625" height="20" font="7">We follow the previous section’s algorithms and the pesudocode is given as followed: </text>
<text top="979" left="180" width="106" height="16" font="1">u = advect(u); </text>
<text top="1010" left="180" width="109" height="16" font="1">u = diffuse(u); </text>
<text top="1041" left="180" width="133" height="16" font="1">u = addForces(u); </text>
</page>
<page number="60" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">48 </text>
<text top="166" left="180" width="350" height="16" font="1">u = subtractPressureGradient(u, p);  //projection </text>
<text top="197" left="162" width="372" height="16" font="1">Diffusion part of  CUDA code is also given below: </text>
<text top="576" left="783" width="5" height="16" font="1"> </text>
<text top="603" left="162" width="5" height="16" font="1"> </text>
<text top="634" left="162" width="5" height="16" font="1"> </text>
<text top="665" left="162" width="5" height="16" font="1"> </text>
<text top="696" left="162" width="5" height="16" font="1"> </text>
<text top="727" left="162" width="5" height="16" font="1"> </text>
<text top="758" left="162" width="5" height="16" font="1"> </text>
<text top="789" left="380" width="217" height="15" font="9">Code 11. CUDA Diffusion code </text>
<text top="818" left="162" width="322" height="16" font="1">Results are shown in the following pictures: </text>
<text top="849" left="162" width="5" height="16" font="1"> </text>
<text top="234" left="173" width="600" height="15" font="9">__global__ void gpuKernelDiffuse (int N,int b, float *gpuX, float *gpuX0, float diff, float </text>
<text top="262" left="173" width="150" height="15" font="9">dt, int *gpuBoundary) </text>
<text top="291" left="173" width="12" height="15" font="9">{ </text>
<text top="319" left="173" width="93" height="15" font="9">         int i,j,k; </text>
<text top="348" left="173" width="190" height="15" font="9">         float a = dt*diff*N*N; </text>
<text top="376" left="173" width="132" height="15" font="9">         int thisEntry;  </text>
<text top="405" left="173" width="216" height="15" font="9">         // Gauss Seidel Relaxation </text>
<text top="433" left="173" width="188" height="15" font="9">         for(k = 0;k &lt; 20;k++)  </text>
<text top="461" left="173" width="49" height="15" font="9">         { </text>
<text top="490" left="173" width="428" height="15" font="9">                 thisEntry = blockIdx.x*BLOCK_SIZE + threadIdx.x; </text>
<text top="518" left="173" width="215" height="15" font="9">                 j = thisEntry / (N+2); </text>
<text top="547" left="173" width="224" height="15" font="9">                 i = thisEntry % (N+2); </text>
<text top="575" left="173" width="198" height="15" font="9">                // check boundaries </text>
<text top="604" left="173" width="526" height="15" font="9">                 if (i == 0 || i == N+1 || j == 0 || j == N+1 || gpuBoundary[thisEntry])  </text>
<text top="632" left="173" width="82" height="15" font="9">                 { </text>
<text top="661" left="173" width="264" height="15" font="9">                         gpuX[thisEntry] = 0.0f; </text>
<text top="689" left="173" width="82" height="15" font="9">                 } </text>
<text top="718" left="173" width="82" height="15" font="9">                 } </text>
</page>
<page number="61" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">49 </text>
<text top="536" left="756" width="5" height="16" font="1"> </text>
<text top="563" left="180" width="5" height="16" font="1"> </text>
<text top="953" left="756" width="5" height="16" font="1"> </text>
<text top="979" left="315" width="363" height="15" font="9">Figure 16. Simulation with raindrops and wave effects </text>
<text top="1008" left="180" width="631" height="16" font="1">We also add extra features to the simulation like weather in order to better see the fluid </text>
<text top="1039" left="162" width="652" height="16" font="1">simulation. The rain and waves affects where easy to implement but hard to design. In the </text>
</page>
<page number="62" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">50 </text>
<text top="166" left="162" width="644" height="16" font="1">current implementation the waves originate from a single row of sin wave density values </text>
<text top="197" left="162" width="636" height="16" font="1">that are being pushed towards the center of the surface by force vectors that are injected </text>
<text top="228" left="162" width="144" height="16" font="1">into the simulation. </text>
<text top="259" left="180" width="583" height="16" font="1">The CUDA version can outperform the sequential version in several parts of our </text>
<text top="290" left="162" width="632" height="16" font="1">implementation as shown in the following chart. The running time is calculated in each </text>
<text top="321" left="162" width="634" height="16" font="1">frame focusing on the physical functions (diffusion+advection+projection). It’s clear to </text>
<text top="352" left="162" width="493" height="16" font="1">see CUDA parallel program can outperform the sequential version.  </text>
<text top="758" left="783" width="5" height="16" font="1"> </text>
<text top="785" left="346" width="302" height="16" font="1">Figure 17. Performance for each function </text>
<text top="816" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="63" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">51 </text>
<text top="249" left="182" width="631" height="22" font="8"><b>4. Parallel Visualization—Tiled Display Visualization System </b></text>
<text top="290" left="326" width="325" height="22" font="8"><b>Integrated with Multiple GPUs </b></text>
<text top="330" left="162" width="5" height="16" font="1"> </text>
<text top="361" left="162" width="5" height="16" font="1"> </text>
<text top="392" left="162" width="5" height="16" font="1"> </text>
<text top="451" left="162" width="151" height="19" font="5"><b>4.1 Introduction </b></text>
<text top="513" left="180" width="633" height="16" font="1">High quality virtual reality used in movie industry or in scientific visualization requires </text>
<text top="544" left="162" width="620" height="16" font="1">machines able to draw billions of pixels per second. End users are not yet satisfied by </text>
<text top="572" left="162" width="603" height="20" font="7">today’s most expensive 3D hardware and programmers have to limit the number of </text>
<text top="606" left="162" width="651" height="16" font="1">objects in the scenes. With the power of parallel API such as CUDA and Pthreads and the </text>
<text top="638" left="162" width="643" height="16" font="1">powerful cluster alone with high performance graphic APIs—OpenGL alone with GLSL </text>
<text top="669" left="162" width="564" height="16" font="1">shaders; it’s possible to develop a high end machine on PC or workstation 3D </text>
<text top="700" left="162" width="152" height="16" font="1">components Engine. </text>
<text top="731" left="162" width="5" height="16" font="1"> </text>
<text top="790" left="162" width="121" height="19" font="5"><b>4.2 OpenGL  </b></text>
<text top="848" left="180" width="614" height="20" font="7">OpenGL stands for Open Graphics Library. It’s is a standard specification defining a </text>
<text top="883" left="162" width="611" height="16" font="1">cross-language, cross-platform API for writing applications that produce 2D and 3D </text>
<text top="914" left="162" width="638" height="16" font="1">computer graphics. The interface consists of over 250 different function calls which can </text>
<text top="945" left="162" width="644" height="16" font="1">be used to draw complex three-dimensional scenes from simple primitives. OpenGL was </text>
<text top="976" left="162" width="652" height="16" font="1">developed by Silicon Graphics Inc. (SGI) in 1992 [19] and is widely used in CAD, virtual </text>
<text top="1007" left="162" width="620" height="16" font="1">reality, scientific visualization, information visualization, flight simulation, and video </text>
<text top="1038" left="162" width="55" height="16" font="1">games. </text>
</page>
<page number="64" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">52 </text>
<text top="194" left="162" width="266" height="19" font="5"><b>4.3 GLSL Shading Language </b></text>
<text top="256" left="180" width="590" height="16" font="1">The OpenGL Shading Language is actually two closely related languages.  These </text>
<text top="287" left="162" width="626" height="16" font="1">languages are used to create shaders for the programmable processors contained in the </text>
<text top="318" left="162" width="622" height="16" font="1">OpenGL processing pipeline. Unless otherwise noted in this paper, a language feature </text>
<text top="350" left="162" width="608" height="16" font="1">applies to all languages, and common usage will refer to these languages as a single </text>
<text top="381" left="162" width="629" height="16" font="1">language.  The specific languages will be referred to by the name of the processor they </text>
<text top="412" left="162" width="194" height="16" font="1">target: vertex or fragment. </text>
<text top="443" left="180" width="617" height="16" font="1">Any OpenGL state used by the shader is automatically tracked and made available to </text>
<text top="474" left="162" width="633" height="16" font="1">shaders. This automatic state tracking mechanism allows the application to use existing </text>
<text top="505" left="162" width="642" height="16" font="1">OpenGL state commands for state management and have the current values of such state </text>
<text top="536" left="162" width="347" height="16" font="1">automatically available for use in a shader [20]. </text>
<text top="567" left="162" width="23" height="16" font="1">     </text>
<text top="626" left="162" width="124" height="19" font="5"><b>4.4 Equalizer </b></text>
<text top="688" left="180" width="629" height="16" font="1">There are several library candidates in doing large tiled display system. Chromium is a </text>
<text top="719" left="162" width="609" height="16" font="1">representative client and server based system for interactive rendering on clusters of </text>
<text top="750" left="162" width="613" height="16" font="1">workstations. It provides Streaming graphics pipeline based on the industry standard </text>
<text top="781" left="162" width="634" height="16" font="1">OpenGL API and support for multiple physical display devices clustered together, such </text>
<text top="812" left="162" width="594" height="16" font="1">as &#34;power wall&#34; displays. The best feature for Chromium is that user can run their </text>
<text top="843" left="162" width="645" height="16" font="1">OpenGL application without any modification by Chromium. However, there are several </text>
<text top="875" left="162" width="634" height="16" font="1">obstacles for using it. First, it has limited OpenGL extension support and compatibility. </text>
<text top="905" left="162" width="595" height="16" font="1">Chromium can only support OpenGL1.5 or lower version. Only the fixed pipeline </text>
<text top="937" left="162" width="602" height="16" font="1">functions are supported in the OpenGL program. Second, Chromium applied SPUs </text>
<text top="968" left="162" width="646" height="16" font="1">method to transmit data and implemented a fake OpenGL library instead of system’s real </text>
<text top="999" left="162" width="583" height="16" font="1">OpenGL library, the overhead are sometimes very high in doing some large data </text>
<text top="1026" left="162" width="628" height="20" font="7">rendering cases. Third, it doesn’t provide parallel programming APIs for developers to </text>
</page>
<page number="65" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">53 </text>
<text top="162" left="162" width="631" height="20" font="7">doing parallel programs. It’s more served as an application can be used in visualizing a </text>
<text top="197" left="162" width="650" height="16" font="1">sequential OpenGL program in a tiled display system other than a library can be used in a </text>
<text top="228" left="162" width="254" height="16" font="1">parallel application development.   </text>
<text top="259" left="180" width="624" height="16" font="1">Compared with Chromium, Equalizer is the standard middleware to create and deploy </text>
<text top="290" left="162" width="611" height="16" font="1">parallel OpenGL-based applications. It enables applications to benefit from multiple </text>
<text top="321" left="162" width="609" height="16" font="1">graphics cards, processors and computers to scale the rendering performance, visual </text>
<text top="352" left="162" width="635" height="16" font="1">quality and display size. An Equalizer application runs unmodified on any visualization </text>
<text top="383" left="162" width="567" height="16" font="1">system, from a simple workstation to large scale graphics clusters, multi-GPU </text>
<text top="415" left="162" width="614" height="16" font="1">workstations and Virtual Reality installations. It supports latest OpenGL version and </text>
<text top="446" left="162" width="618" height="16" font="1">extension including GLSL shading language. Equalizer also provides an API to write </text>
<text top="477" left="162" width="590" height="16" font="1">parallel, scalable visualization applications which are configured at run-time by a </text>
<text top="508" left="162" width="630" height="16" font="1">resource server. The core generic engine can implement sort-first, parallel sort-last and </text>
<text top="539" left="162" width="180" height="16" font="1">stereo compositing [16]. </text>
<text top="570" left="162" width="5" height="16" font="1"> </text>
<text top="629" left="162" width="334" height="19" font="5"><b>4.5 Principles for Parallel Rendering </b></text>
<text top="691" left="180" width="630" height="16" font="1">The typical OpenGL application, for example GLUT, has an event loop which redraws </text>
<text top="722" left="162" width="645" height="16" font="1">the scene, updates data based on received events, and eventually redraws a new frame. A </text>
<text top="753" left="162" width="612" height="16" font="1">parallel rendering application uses the same basic execution model and extends it by </text>
<text top="784" left="162" width="604" height="16" font="1">separating the rendering code from the main event loop. The rendering code is then </text>
<text top="815" left="162" width="613" height="16" font="1">executed in parallel on different resources, depending on the configuration chosen at </text>
<text top="846" left="162" width="596" height="16" font="1">runtime.  The basic mode for doing parallel programming is adopt by Equalizer as </text>
<text top="877" left="162" width="73" height="16" font="1">followed: </text>
</page>
<page number="66" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">54 </text>
<text top="566" left="729" width="5" height="16" font="1"> </text>
<text top="592" left="388" width="199" height="15" font="9">Figure 18. Parallel Rendering </text>
<text top="621" left="162" width="4" height="15" font="9"> </text>
<text top="678" left="162" width="244" height="19" font="5"><b>4.6 Equalizer Architecture </b></text>
<text top="740" left="180" width="633" height="16" font="1">The architecture of Equalizer library is based on the client and server model. The client </text>
<text top="771" left="162" width="604" height="16" font="1">library exposes all functionality discussed in this document to the programmer, and </text>
<text top="802" left="162" width="640" height="16" font="1">provides communication between the different Equalizer processes. Collage library uses </text>
<text top="833" left="162" width="581" height="16" font="1">a peer to peer communication structure to provide optimal performance scalable </text>
<text top="864" left="162" width="575" height="16" font="1">rendering. The application, clients and server’s roles are described as followed: </text>
<text top="891" left="189" width="8" height="22" font="12"></text>
<text top="896" left="197" width="5" height="17" font="13"> </text>
<text top="897" left="216" width="554" height="16" font="1">The application connects to an Equalizer server and receives a configuration.</text>
<text top="893" left="771" width="4" height="19" font="10"> </text>
<text top="897" left="775" width="15" height="16" font="1">It </text>
<text top="928" left="216" width="437" height="16" font="1">reacts on events, updates its data and controls the rendering. </text>
<text top="954" left="189" width="8" height="22" font="12"></text>
<text top="959" left="197" width="5" height="17" font="13"> </text>
<text top="960" left="216" width="581" height="16" font="1">Each Equalizer server is responsible for managing one visualization system. It’s </text>
<text top="991" left="216" width="497" height="16" font="1">responsible to control and launch the application’s rendering clients. </text>
<text top="1018" left="189" width="8" height="22" font="12"></text>
<text top="1023" left="197" width="5" height="17" font="13"> </text>
<text top="1023" left="216" width="592" height="16" font="1">The render client implements the rendering part of an application. Its execution is </text>
<text top="1055" left="216" width="596" height="16" font="1">passive; it has no main loop and is completely driven by Equalizer. It executes the </text>
</page>
<page number="67" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">55 </text>
<text top="166" left="216" width="582" height="16" font="1">rendering tasks received from the server by calling the appropriate task methods </text>
<text top="197" left="216" width="241" height="16" font="1">in the correct thread and context. </text>
<text top="490" left="672" width="5" height="16" font="1"> </text>
<text top="516" left="371" width="235" height="15" font="9">Figure 19. Equalizer Libraries [31] </text>
<text top="545" left="162" width="5" height="16" font="1"> </text>
<text top="604" left="162" width="204" height="19" font="5"><b>4.6 Galaxy Simulation </b></text>
<text top="666" left="180" width="594" height="16" font="1">Gravitational N-body simulation, which is numerical solutions of the equations of </text>
<text top="697" left="162" width="640" height="16" font="1">motions for N particles interacting gravitationally, are widely used tools in astrophysics, </text>
<text top="728" left="162" width="631" height="16" font="1">with applications from few body or solar system like systems all the way up to galactic </text>
<text top="759" left="162" width="643" height="16" font="1">and cosmological scales. The following section provides a way to implement an N-Body </text>
<text top="790" left="162" width="605" height="16" font="1">based galaxy simulation with CUDA enabled in this parallel rendering tiled display </text>
<text top="821" left="162" width="59" height="16" font="1">system. </text>
<text top="853" left="162" width="5" height="16" font="1"> </text>
<text top="884" left="162" width="5" height="16" font="1"> </text>
<text top="915" left="162" width="5" height="16" font="1"> </text>
<text top="946" left="162" width="5" height="16" font="1"> </text>
<text top="977" left="162" width="5" height="16" font="1"> </text>
<text top="1008" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="68" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="38" size="18" family="Times" color="#000000"/>
	<fontspec id="39" size="12" family="Symbol" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">56 </text>
<text top="166" left="162" width="296" height="16" font="4"><b> 4.6.1 Parallel Programming Interface </b></text>
<text top="224" left="180" width="604" height="16" font="1">Equalizer provides the natural execution framework for any multi-GPU application </text>
<text top="255" left="162" width="609" height="16" font="1">and does not impose any specific rendering framework, such as a scenegraph, to the </text>
<text top="286" left="162" width="626" height="16" font="1">application. It follows the natural execution model of any multi-GPU application, thus </text>
<text top="317" left="162" width="620" height="16" font="1">making it as easy as possible to modify existing applications for parallel rendering on </text>
<text top="348" left="162" width="156" height="16" font="1">visualization clusters.</text>
<text top="342" left="318" width="5" height="23" font="38"> </text>
<text top="348" left="323" width="11" height="16" font="1">It</text>
<text top="342" left="334" width="5" height="23" font="38"> </text>
<text top="348" left="339" width="430" height="16" font="1">uses a callback-driven interface. Applications provide their </text>
<text top="379" left="162" width="648" height="16" font="1">rendering methods, which are called by the Equalizer framework according to the current </text>
<text top="410" left="162" width="222" height="16" font="1">configuration and system load.</text>
<text top="404" left="384" width="5" height="23" font="38"> </text>
<text top="410" left="389" width="5" height="16" font="1"> </text>
<text top="442" left="180" width="548" height="16" font="1">Equalizer abstracts common graphic entities into C++ classes, for example: </text>
<text top="470" left="189" width="7" height="18" font="39"></text>
<text top="474" left="196" width="4" height="14" font="17"> </text>
<text top="473" left="216" width="285" height="16" font="4"><b>Node</b> - a single computer in the cluster </text>
<text top="501" left="189" width="7" height="18" font="39"></text>
<text top="505" left="196" width="4" height="14" font="17"> </text>
<text top="504" left="216" width="316" height="16" font="4"><b>Pipe</b> - a graphics card and rendering thread </text>
<text top="532" left="189" width="7" height="18" font="39"></text>
<text top="536" left="196" width="4" height="14" font="17"> </text>
<text top="535" left="216" width="239" height="16" font="4"><b>Window</b> - an OpenGL drawable </text>
<text top="563" left="189" width="7" height="18" font="39"></text>
<text top="567" left="196" width="4" height="14" font="17"> </text>
<text top="566" left="216" width="286" height="16" font="4"><b>Channel</b> - a viewport within a window </text>
<text top="597" left="162" width="604" height="16" font="1">The application subclasses these entities, and overrides task methods to provide the </text>
<text top="628" left="162" width="211" height="16" font="1">application's rendering code. </text>
<text top="659" left="162" width="5" height="16" font="1"> </text>
<text top="717" left="162" width="207" height="16" font="4"><b>4.6.2 Programming Model </b></text>
<text top="775" left="180" width="601" height="16" font="1">The following programming model is used in the Galaxy simulation visualization.  </text>
<text top="806" left="180" width="5" height="16" font="1"> </text>
</page>
<page number="69" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">57 </text>
<text top="416" left="797" width="5" height="16" font="1"> </text>
<text top="443" left="365" width="246" height="15" font="9">Figure 20. Programming Model [31] </text>
<text top="471" left="162" width="622" height="16" font="1">The Figure 18 shows Application and render client main loops for our system. All the </text>
<text top="502" left="162" width="634" height="16" font="1">methods in this graph are overrides by the application. The Equalizer library will create </text>
<text top="534" left="162" width="651" height="16" font="1">multiple threads by using Pthreads include pipe, window, channel, command and receiver </text>
<text top="565" left="162" width="634" height="16" font="1">threads in each node. All the rendering and event handling methods are provided by the </text>
<text top="596" left="162" width="84" height="16" font="1">developer.  </text>
<text top="627" left="162" width="5" height="16" font="1"> </text>
<text top="685" left="162" width="211" height="16" font="4"><b>4.6.3 Integrate with CUDA </b></text>
<text top="743" left="180" width="620" height="16" font="1">Equalizer uses Compounds to describe the execution of the rendering operations. The </text>
<text top="774" left="162" width="645" height="16" font="1">rendering is performed by Channels which are referenced by the compounds -- a channel </text>
<text top="805" left="162" width="586" height="16" font="1">belongs to a Window which again manages the GL context. Windows in turn are </text>
<text top="836" left="162" width="453" height="16" font="1">managed by a Pipe object which provides the threading logic.  </text>
<text top="867" left="180" width="590" height="16" font="1">When using CUDA one host thread can execute device code on exactly one GPU </text>
<text top="898" left="162" width="640" height="16" font="1">device; i.e., a host thread may have only one CUDA device context current at a time. To </text>
<text top="929" left="162" width="635" height="16" font="1">support multiple devices multiple host threads are thus required. This is a perfect match </text>
<text top="960" left="162" width="628" height="16" font="1">to the pipe abstraction of Equalizer. On the other hand, since GPU computing does not </text>
<text top="991" left="162" width="633" height="16" font="1">perform any rendering and as such does not rely on a drawable, the window abstraction </text>
<text top="1022" left="162" width="643" height="16" font="1">does not fit (software based rendering is the exception here, since this requires some soft </text>
<text top="1053" left="162" width="652" height="16" font="1">of framebuffer abstraction). Instead we use the pipe itself to execute the COMPUTE tasks </text>
</page>
<page number="70" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">58 </text>
<text top="166" left="162" width="628" height="16" font="1">defined in the compound description. This fits naturally to the design approach of both </text>
<text top="197" left="162" width="646" height="16" font="1">CUDA and OpenCL, and moreover we can avoid introducing another object hierarchy in </text>
<text top="228" left="162" width="626" height="16" font="1">parallel to the current pipe - window - channel model. The following graph showed an </text>
<text top="259" left="162" width="407" height="16" font="1">appropriate way of using CUDA with Equalizer library. </text>
<text top="486" left="783" width="5" height="16" font="1"> </text>
<text top="512" left="388" width="199" height="15" font="9">Figure 21. CUDA Integration </text>
<text top="541" left="180" width="5" height="16" font="1"> </text>
<text top="572" left="180" width="579" height="16" font="1">The specific attributes on the pipe can be used to set up the compute context for </text>
<text top="603" left="162" width="632" height="16" font="1">providing programming interface for CUDA. Then every node in the cluster can utilize </text>
<text top="634" left="162" width="616" height="16" font="1">its CUDA runtime library alone with its pipe thread. By using this method and above </text>
<text top="665" left="162" width="634" height="16" font="1">programming model, a multiple GPUs supported rendering system can be implemented </text>
<text top="696" left="162" width="196" height="16" font="1">with the help of Equalizer. </text>
<text top="1054" left="763" width="5" height="16" font="1"> </text>
</page>
<page number="71" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">59 </text>
<text top="166" left="388" width="200" height="15" font="9">Figure 22. Data Transmission </text>
<text top="195" left="162" width="5" height="16" font="1"> </text>
<text top="226" left="180" width="618" height="16" font="1">Data can either be replicated or partitioned on the participating nodes. In case of (full </text>
<text top="257" left="162" width="643" height="16" font="1">or partial) data replication Equalizer provides a solution to synchronize memory changes </text>
<text top="288" left="162" width="630" height="16" font="1">between participating nodes; i.e., to quickly transfer memory changes from the (GPU-) </text>
<text top="319" left="162" width="439" height="16" font="1">memory of one node to the (GPU-) memory of another node.</text>
<text top="312" left="601" width="5" height="23" font="38"> </text>
<text top="319" left="606" width="165" height="16" font="1">If data is replicated on </text>
<text top="350" left="162" width="599" height="16" font="1">multiple nodes, a subset of the data might subsequently have to be synchronized at </text>
<text top="381" left="162" width="623" height="16" font="1">runtime. To guarantee an optimal memory transfer performance a direct node-to-node </text>
<text top="412" left="162" width="646" height="16" font="1">communication model is established through shared memory proxy objects which handle </text>
<text top="443" left="162" width="606" height="16" font="1">the mapping and synchronization of a specific memory range. The memory transfer </text>
<text top="474" left="162" width="545" height="16" font="1">from/to the GPU is performed implicitly by the proxy objects as part of the </text>
<text top="505" left="162" width="220" height="16" font="1">map/sync/dirty/commit cycle. </text>
<text top="536" left="162" width="5" height="16" font="1"> </text>
<text top="595" left="162" width="177" height="16" font="4"><b>4.6.4 Astronomy Data  </b></text>
<text top="652" left="180" width="611" height="16" font="1">The file data contains a simple (free format) table of 7 columns and 81920 rows: the </text>
<text top="683" left="162" width="645" height="16" font="1">masses and six phase space coordinates (x, y, z, vx, vy, vz) of 81920 particles that define </text>
<text top="714" left="162" width="617" height="16" font="1">the initial conditions for a MW/Andromeda collision [17]. The galaxies with unequal </text>
<text top="745" left="162" width="646" height="16" font="1">masses, inclined geometries, and a bound orbit are all shown in the simulation. Using the </text>
<text top="776" left="162" width="620" height="16" font="1">structural and kinematic properties of the Milky Way and the Andromeda Galaxy, we </text>
<text top="808" left="162" width="625" height="16" font="1">present a possible merging scenario to explore whether the future merger of the Milky </text>
<text top="838" left="162" width="603" height="16" font="1">Way/Andromeda system will result in the spectacular tails seen in the Antennae, or </text>
<text top="870" left="162" width="248" height="16" font="1">merely a dull, amorphous merger. </text>
<text top="901" left="162" width="5" height="16" font="1"> </text>
<text top="959" left="162" width="172" height="16" font="4"><b>4.6.5 N-body Problem </b></text>
<text top="1017" left="180" width="633" height="16" font="1">An N-body simulation numerically approximates the evolution of a system of bodies in </text>
<text top="1048" left="162" width="632" height="16" font="1">which each body continuously interacts with every other body [13]. N-body simulation </text>
</page>
<page number="72" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">60 </text>
<text top="166" left="162" width="601" height="16" font="1">arises in many other computational science problems as well. For example, protein </text>
<text top="197" left="162" width="614" height="16" font="1">folding is studied using N-body simulation to calculate electrostatic [24] and Vender </text>
<text top="228" left="162" width="620" height="16" font="1">Waals forces. Turbulent fluid flow simulation and global illumination computation in </text>
<text top="259" left="162" width="578" height="16" font="1">computer graphics are other examples of problems that use N-body simulation.  </text>
<text top="290" left="180" width="582" height="16" font="1">The <i>all-pairs </i>approach [14] to N-body simulation is a brute-force technique that </text>
<text top="321" left="162" width="639" height="16" font="1">evaluates all pair-wise interactions among the <i>N </i>bodies. It is a relatively simple method, </text>
<text top="352" left="162" width="650" height="16" font="1">but one that is not generally used on its own in the simulation of large systems because of </text>
<text top="383" left="162" width="651" height="16" font="1">its <i>O</i>(<i>N</i>2) computational complexity. It’s very expensive to directly use all-pairs approach </text>
<text top="415" left="162" width="639" height="16" font="1">method for sequential N-body problem and should be optimized by using other methods </text>
<text top="446" left="162" width="537" height="16" font="1">like Barnes-Hut [23] method to improve the performance. However, GPU </text>
<text top="477" left="162" width="639" height="16" font="1">implementation can fully utilize its data parallel capacity to run all-pairs approach faster </text>
<text top="508" left="162" width="641" height="16" font="1">than other sequential version. Instead, the all-pairs approach is typically used as a kernel </text>
<text top="539" left="162" width="652" height="16" font="1">to determine the forces in close-range interactions. The all-pairs method is combined with </text>
<text top="570" left="162" width="643" height="16" font="1">a faster method based on a far-field approximation of longer-range forces, which is valid </text>
<text top="601" left="162" width="416" height="16" font="1">only between parts of the system that are well separated.  </text>
<text top="632" left="180" width="618" height="16" font="1">The all-pairs component of the algorithms just mentioned requires substantial time to </text>
<text top="663" left="162" width="559" height="16" font="1">compute and is therefore an interesting target for acceleration. Improving the </text>
<text top="694" left="162" width="651" height="16" font="1">performance of the all-pairs component will also improve the performance of the far-field </text>
<text top="725" left="162" width="651" height="16" font="1">component as well, because the balance between far-field and near-field (all-pairs) can be </text>
<text top="756" left="162" width="644" height="16" font="1">shifted to assign more work to a faster all-pairs component. Accelerating one component </text>
<text top="787" left="162" width="612" height="16" font="1">will offload work from the other components, so the entire application benefits from </text>
<text top="818" left="162" width="176" height="16" font="1">accelerating one kernel. </text>
<text top="849" left="162" width="636" height="16" font="1">    We use the gravitational potential to illustrate the basic form of computation in an all </text>
<text top="880" left="162" width="600" height="16" font="1">pairs N-body simulation. In the following computation, we use bold font to signify </text>
<text top="911" left="162" width="638" height="16" font="1">vectors (typically in 3D). Given <i>N </i>bodies with an initial position <b>x</b><i>i </i>and velocity <b>v</b><i>i </i>for 1 </text>
<text top="941" left="162" width="637" height="19" font="7">≤ <i>i </i>≤ <i>N</i>, the force vector <b>f</b><i>ij </i>on body <i>i </i>caused by its gravitational attraction to body <i>j</i> is </text>
<text top="977" left="162" width="173" height="16" font="1">given by the following: </text>
</page>
<page number="73" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">61 </text>
<text top="254" left="663" width="5" height="16" font="1"> </text>
<text top="281" left="162" width="635" height="16" font="1">where <i>mi </i>and <i>mj </i>are the masses of bodies <i>i </i>and <i>j</i>, respectively; <b>r</b><i>ij </i>= <b>x</b><i>j </i>− <b>x</b><i>i </i>is the vector </text>
<text top="312" left="162" width="638" height="16" font="1">from body <i>i </i>to body <i>j</i>; and <i>G </i>is the gravitational constant. The left factor, the magnitude </text>
<text top="343" left="162" width="635" height="16" font="1">of the force, is proportional to the product of the masses and diminishes with the square </text>
<text top="374" left="162" width="646" height="16" font="1">of the distance between bodies <i>i </i>and <i>j</i>. The right factor is the <i>direction </i>of the force, a unit </text>
<text top="405" left="162" width="633" height="16" font="1">vector from body <i>i </i>in the direction of body <i>j </i>(because gravitation is an attractive force). </text>
<text top="436" left="162" width="593" height="16" font="1">The total force  <b>F</b><i>i </i>on body <i>i</i>, due to its interactions with the other <i>N </i>− 1 bodies, is </text>
<text top="467" left="162" width="277" height="16" font="1">obtained by summing all interactions: </text>
<text top="498" left="162" width="5" height="16" font="1"> </text>
<text top="632" left="735" width="5" height="16" font="1"> </text>
<text top="658" left="180" width="630" height="16" font="1">As bodies approach each other, the force between them grows without bound, which is </text>
<text top="690" left="162" width="649" height="16" font="1">an undesirable situation for numerical integration. In astrophysical simulations, collisions </text>
<text top="721" left="162" width="650" height="16" font="1">between bodies are generally precluded; this is reasonable if the bodies represent galaxies </text>
<text top="753" left="162" width="623" height="16" font="1">that may pass right through each other. Therefore, a <i>softening factor </i>ε2 &gt; 0 is added, </text>
<text top="787" left="162" width="321" height="16" font="1">and the denominator is rewritten as follows: </text>
<text top="910" left="765" width="5" height="16" font="1"> </text>
<text top="936" left="162" width="619" height="16" font="1">To integrate over time, we need the acceleration <b>a</b><i>i </i>= <b>F</b><i>i</i>/<i>mi </i>to update the position and </text>
<text top="967" left="162" width="453" height="16" font="1">velocity of body <i>i</i>, and so we simplify the computation to this: </text>
</page>
<page number="74" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="40" size="14" family="Times" color="#221f1f"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">62 </text>
<text top="266" left="162" width="32" height="16" font="1">       </text>
<text top="266" left="747" width="5" height="16" font="1"> </text>
<text top="293" left="162" width="634" height="16" font="1">The integrator used to update the positions and velocities is a leapfrog-Verlet integrator </text>
<text top="324" left="162" width="589" height="16" font="1">[15] (Verlet 1967) because it is applicable to this problem and is computationally </text>
<text top="355" left="162" width="644" height="16" font="1">efficient (it has a high ratio of accuracy to computational cost). The choice of integration </text>
<text top="386" left="162" width="632" height="16" font="1">method in N-body problems usually depends on the nature of the system being studied. </text>
<text top="417" left="162" width="642" height="16" font="1">The integrator is included in our timings, but discussion of its implementation is omitted </text>
<text top="448" left="162" width="570" height="16" font="1">because its complexity is O (N) and its cost becomes insignificant as N<i> </i>grows. </text>
<text top="479" left="162" width="5" height="16" font="1"> </text>
<text top="538" left="162" width="286" height="16" font="4"><b>4.6.6 N-body CUDA Implementation </b></text>
<text top="595" left="162" width="534" height="16" font="1">    We take this problem as an N*N grid of all pair-wise forces interaction.</text>
<text top="596" left="696" width="4" height="15" font="40"> </text>
<text top="595" left="701" width="104" height="16" font="1">Then the total </text>
<text top="626" left="162" width="619" height="16" font="1">force <b>F</b><i>i </i>(or acceleration <b>a</b><i>i</i>) on body <i>i </i>is obtained from the sum of all entries in row <i>i.</i> </text>
<text top="657" left="162" width="603" height="16" font="1">Each entry can be computed independently, so there is O(N2) available parallelism.</text>
<text top="658" left="765" width="4" height="15" font="40"> </text>
<text top="657" left="769" width="30" height="16" font="1">We </text>
<text top="688" left="162" width="592" height="16" font="1">serialize some of the computations to achieve the data reuse needed to reach peak </text>
<text top="719" left="162" width="600" height="16" font="1">performance of the arithmetic units and to reduce the memory bandwidth required. </text>
<text top="750" left="162" width="633" height="16" font="1">    Consequently, we introduce the notion of a computational <i>tile</i>, a square region of the </text>
<text top="781" left="162" width="632" height="16" font="1">grid of pair-wise forces consisting of <i>p </i>rows and <i>p </i>columns. Only 2<i>p </i>body descriptions </text>
<text top="813" left="162" width="617" height="16" font="1">are required to evaluate all <i>p</i>2 interactions in the tile (<i>p </i>of which can be reused later). </text>
<text top="844" left="162" width="636" height="16" font="1">These body descriptions can be stored in shared memory or in registers. The total effect </text>
<text top="875" left="162" width="621" height="16" font="1">of the interactions in the tile on the <i>p </i>bodies is captured as an update to <i>p </i>acceleration </text>
<text top="906" left="162" width="61" height="16" font="1">vectors. </text>
</page>
<page number="75" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">63 </text>
<text top="167" left="162" width="271" height="19" font="5"><b>Body-Body Force Calculation </b></text>
<text top="229" left="180" width="602" height="16" font="1">The interaction between a pair of bodies is implemented as followed: computes the </text>
<text top="260" left="162" width="644" height="16" font="1">force on body <i>i </i>from its interaction with body <i>j </i>and updates acceleration <b>a</b><i>i </i>of body <i>i </i>as a </text>
<text top="291" left="162" width="645" height="16" font="1">result of this<i> </i>interaction. There are 20 floating-point operations in this code, counting the </text>
<text top="323" left="162" width="535" height="16" font="1">additions,<i> </i>multiplications, the sqrtf() call, and the division (or reciprocal).<i> </i></text>
<text top="353" left="162" width="5" height="16" font="1"> </text>
<text top="385" left="162" width="5" height="16" font="1"> </text>
<text top="416" left="162" width="5" height="16" font="1"> </text>
<text top="447" left="162" width="5" height="16" font="1"> </text>
<text top="478" left="162" width="5" height="16" font="1"> </text>
<text top="509" left="162" width="5" height="16" font="1"> </text>
<text top="540" left="162" width="5" height="16" font="1"> </text>
<text top="571" left="162" width="5" height="16" font="1"> </text>
<text top="602" left="162" width="5" height="16" font="1"> </text>
<text top="633" left="162" width="5" height="16" font="1"> </text>
<text top="664" left="162" width="5" height="16" font="1"> </text>
<text top="695" left="162" width="5" height="16" font="1"> </text>
<text top="726" left="162" width="5" height="16" font="1"> </text>
<text top="757" left="369" width="239" height="16" font="1">Code 12. Body-body calculation </text>
<text top="788" left="162" width="5" height="16" font="1"> </text>
<text top="847" left="162" width="206" height="19" font="5"><b>Tile Force Calculation </b></text>
<text top="910" left="180" width="573" height="16" font="1">A tile is evaluated by <i>p </i>threads performing the same sequence of operations on </text>
<text top="941" left="162" width="581" height="16" font="1">different data. Each thread updates the acceleration of one body as a result of its </text>
<text top="972" left="162" width="597" height="16" font="1">interaction with <i>p </i>other bodies. We load <i>p </i>body descriptions from the GPU device </text>
<text top="1003" left="162" width="613" height="16" font="1">memory into the shared memory provided to each <i>thread block </i>in the CUDA model. </text>
<text top="1034" left="162" width="588" height="16" font="1">Each thread in the block evaluates <i>p </i>successive interactions. The result of the tile </text>
<text top="373" left="173" width="123" height="15" font="9">__device__ float3 </text>
<text top="401" left="173" width="337" height="15" font="9">bodyBodyInteraction(float4 bi, float4 bj, float3 ai) </text>
<text top="430" left="173" width="12" height="15" font="9">{ </text>
<text top="458" left="173" width="21" height="15" font="9">     </text>
<text top="458" left="227" width="57" height="15" font="9">float3 r; </text>
<text top="486" left="173" width="21" height="15" font="9">     </text>
<text top="486" left="227" width="108" height="15" font="9">r.x = bj.x - bi.x; </text>
<text top="515" left="173" width="21" height="15" font="9">     </text>
<text top="515" left="227" width="108" height="15" font="9">r.y = bj.y - bi.y; </text>
<text top="543" left="173" width="21" height="15" font="9">     </text>
<text top="543" left="227" width="106" height="15" font="9">r.z = bj.z - bi.z; </text>
<text top="572" left="173" width="21" height="15" font="9">     </text>
<text top="572" left="227" width="297" height="15" font="9">float distSqr = r.x * r.x + r.y * r.y + r.z * r.z; </text>
<text top="600" left="173" width="21" height="15" font="9">     </text>
<text top="600" left="227" width="198" height="15" font="9">distSqr += softeningSquared; </text>
<text top="629" left="227" width="172" height="15" font="9">float dist = sqrtf(distSqr); </text>
<text top="657" left="173" width="17" height="15" font="9">    </text>
<text top="657" left="227" width="224" height="15" font="9">float distCube = dist * dist * dist; </text>
<text top="686" left="173" width="4" height="15" font="9"> </text>
<text top="686" left="227" width="196" height="15" font="9">if (distCube &lt; 1.0f) return ai; </text>
<text top="714" left="173" width="21" height="15" font="9">     </text>
<text top="714" left="227" width="184" height="15" font="9">float s = bi.w / distCube;     </text>
<text top="743" left="173" width="21" height="15" font="9">     </text>
<text top="743" left="227" width="133" height="15" font="9">ai.x += r.x * s * ep; </text>
<text top="771" left="173" width="21" height="15" font="9">     </text>
<text top="771" left="227" width="133" height="15" font="9">ai.y += r.y * s * ep; </text>
<text top="800" left="173" width="21" height="15" font="9">     </text>
<text top="800" left="227" width="131" height="15" font="9">ai.z += r.z * s * ep; </text>
<text top="819" left="173" width="17" height="15" font="9">    </text>
<text top="819" left="227" width="64" height="15" font="9">return ai; </text>
<text top="847" left="173" width="12" height="15" font="9">} </text>
<text top="876" left="173" width="4" height="15" font="9"> </text>
</page>
<page number="76" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="41" size="16" family="Times" color="#666600"/>
	<fontspec id="42" size="16" family="Times" color="#660066"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">64 </text>
<text top="166" left="162" width="630" height="16" font="1">calculation is <i>p </i>updated accelerations. Here we also use shared memory to improve the </text>
<text top="197" left="162" width="340" height="16" font="1">performance of the calculation in the program. </text>
<text top="228" left="180" width="599" height="16" font="1">Within these two parts, galaxy kernel part can be developed:  the whole number of </text>
<text top="259" left="162" width="621" height="16" font="1">bodies can be first divided into several tiles, for each tile ,do the tile calculation in the </text>
<text top="290" left="162" width="644" height="16" font="1">shared memory and for each body do the body-body calculation and finally updates each </text>
<text top="318" left="162" width="154" height="20" font="7">body’s acceleration.  </text>
<text top="352" left="180" width="600" height="16" font="1">Thread blocks are defined as having <i>p </i>threads that execute some number of tiles in </text>
<text top="383" left="162" width="568" height="16" font="1">sequence. Tiles are sized to balance parallelism with data reuse. The degree of </text>
<text top="415" left="162" width="646" height="16" font="1">parallelism (that is, the number of rows) must be sufficiently large so that multiple warps </text>
<text top="446" left="162" width="639" height="16" font="1">can be interleaved to hide latencies in the evaluation of interactions. The amount of data </text>
<text top="477" left="162" width="640" height="16" font="1">reuse grows with the number of columns, and this parameter also governs the size of the </text>
<text top="508" left="162" width="632" height="16" font="1">transfer of bodies from device memory into shared memory. Finally, the size of the tile </text>
<text top="539" left="162" width="641" height="16" font="1">also determines the register space and shared memory required. We invoke this program </text>
<text top="570" left="162" width="652" height="16" font="1">on a <i>grid </i>of thread blocks to compute the acceleration of all <i>N </i>bodies. Because there are <i>p</i> </text>
<text top="601" left="162" width="592" height="16" font="1">threads per block and one thread per body, the number of thread blocks needed to </text>
<text top="632" left="162" width="646" height="16" font="1">complete all <i>N </i>bodies is <i>N</i>/<i>p</i>, so we define a 1D grid of size <i>N</i>/<i>p</i>. The result is a total of <i>N </i></text>
<text top="663" left="162" width="553" height="16" font="1">threads that perform <i>N </i>force calculations each, for a total of <i>N</i>2 interactions. </text>
<text top="694" left="162" width="5" height="16" font="1"> </text>
<text top="752" left="162" width="232" height="16" font="4"><b>4.6.7 Galaxy Implementation  </b></text>
<text top="810" left="180" width="617" height="16" font="1">Since CUDA code is for doing the nbody computation and also provides data buffers </text>
<text top="841" left="162" width="604" height="16" font="1">for OpenGL rendering parts, we make a separate class for these data managements. </text>
<text top="872" left="162" width="647" height="16" font="1">Because of doing parallel rendering with Equalizer, some modifications should be added. </text>
<text top="903" left="162" width="595" height="16" font="1">A subclass named FramData is created for doing CUDA host data initialization. It </text>
<text top="934" left="162" width="125" height="16" font="1">inherited from eq</text>
<text top="934" left="287" width="10" height="16" font="41">::</text>
<text top="934" left="297" width="42" height="16" font="1">fabric</text>
<text top="934" left="339" width="10" height="16" font="41">::</text>
<text top="934" left="349" width="85" height="16" font="42">Serializable</text>
<text top="934" left="434" width="5" height="16" font="1">.</text>
<text top="934" left="439" width="5" height="16" font="42"> </text>
<text top="934" left="443" width="339" height="16" font="1"> Initially, the whole dataset is distributed to all </text>
<text top="965" left="162" width="636" height="16" font="1">nodes of the config using the common framedata mechanism. Each participating pipe is </text>
<text top="996" left="162" width="645" height="16" font="1">then responsible for updating and rendering a specific subset of the shared data. The data </text>
<text top="1028" left="162" width="617" height="16" font="1">synchronization is handled by a SharedData facade object owned by the pipe objects, </text>
</page>
<page number="77" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">65 </text>
<text top="166" left="162" width="610" height="16" font="1">which in turn uses a FrameData and SharedDataProxy objects to map remote shared </text>
<text top="197" left="162" width="609" height="16" font="1">memory. This approach requires a 2-stage initialisation phase, as each channel must </text>
<text top="228" left="162" width="627" height="16" font="1">receive the IDs of all the proxy objects through the framedata mechanism before using </text>
<text top="259" left="162" width="591" height="16" font="1">them. For rendering part, VBO is used for both CUDA computation and OpenGL </text>
<text top="290" left="162" width="634" height="16" font="1">rendering. GLSL vertext and fragment shaders are also used to get a better result. Since </text>
<text top="318" left="162" width="609" height="20" font="7">Equalizer doesn’t support GLUT library, several custom defined methods should be </text>
<text top="352" left="162" width="650" height="16" font="1">implemented for handling user events. For instance, mouse and keyboard events handling </text>
<text top="383" left="162" width="321" height="16" font="1">are added by overriding following methods: </text>
<text top="415" left="162" width="267" height="16" font="1">virtual void Config::handleEvents(); </text>
<text top="446" left="162" width="451" height="16" font="1">virtual bool Config::handleEvent( const ConfigEvent* event ) </text>
<text top="477" left="162" width="275" height="16" font="1">virtual void Pipe::initEventHandler(); </text>
<text top="508" left="162" width="279" height="16" font="1">virtual void Pipe::exitEventHandler(); </text>
<text top="539" left="162" width="306" height="16" font="1">virtual void Window::initEventHandler(); </text>
<text top="570" left="162" width="309" height="16" font="1">virtual void Window::exitEventHandler(); </text>
<text top="601" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="78" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">66 </text>
<text top="166" left="162" width="105" height="16" font="4"><b>4.6.8 Results  </b></text>
<text top="593" left="742" width="5" height="16" font="1"> </text>
<text top="609" left="486" width="5" height="16" font="1"> </text>
<text top="991" left="741" width="5" height="16" font="1"> </text>
<text top="1008" left="162" width="5" height="16" font="1"> </text>
<text top="1028" left="359" width="258" height="15" font="9">Figures 23. CUDA Galaxy Simulation </text>
<text top="1047" left="162" width="5" height="16" font="1"> </text>
</page>
<page number="79" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">67 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="215" left="162" width="234" height="19" font="5"><b>4.7 Performance Analysis </b></text>
<text top="277" left="180" width="619" height="16" font="1">There are several ways to improve the performance of the program—Approximation, </text>
<text top="308" left="162" width="244" height="16" font="1">Shared Memory and Unroll loop. </text>
<text top="339" left="162" width="5" height="16" font="1"> </text>
<text top="398" left="162" width="163" height="16" font="4"><b>4.7.1 Approximation </b></text>
<text top="455" left="180" width="620" height="16" font="1">Here, we tested one sixteenth, one eighth, and one quarter out of total N bodies. Sure, </text>
<text top="486" left="162" width="651" height="16" font="1">this gives much better performance. The reason is obvious. We reduced both computation </text>
<text top="517" left="162" width="629" height="16" font="1">and memory access time accordingly. Below code shows the changes in kernel code to </text>
<text top="548" left="162" width="604" height="16" font="1">accomodate this approximation. Parameter offset is controlled by application in the </text>
<text top="579" left="162" width="632" height="16" font="1">manner of modula increment (i.e. apprx = 16, then offset will be cycled from 0 to 15 as </text>
<text top="611" left="162" width="171" height="16" font="1">applicaton progresses.) </text>
<text top="642" left="162" width="5" height="16" font="1"> </text>
<text top="981" left="784" width="5" height="16" font="1"> </text>
<text top="1007" left="386" width="204" height="15" font="9">Code 13. Approximation code </text>
<text top="1036" left="162" width="5" height="16" font="1"> </text>
<text top="692" left="174" width="585" height="16" font="1">__global__ void galaxyKernel(float4* pos, float4 * pdata, float step, int offset,    </text>
<text top="713" left="174" width="75" height="16" font="1">int apprx) </text>
<text top="733" left="174" width="13" height="16" font="1">{ </text>
<text top="754" left="174" width="23" height="16" font="1">     </text>
<text top="754" left="228" width="406" height="16" font="1">// consider sub compute chunk instead of whole N body </text>
<text top="775" left="174" width="14" height="16" font="1">   </text>
<text top="775" left="228" width="253" height="16" font="1">unsigned int start = (y - x) / apprx; </text>
<text top="795" left="174" width="14" height="16" font="1">   </text>
<text top="795" left="228" width="288" height="16" font="1">unsigned int end = start * offset + start; </text>
<text top="816" left="174" width="14" height="16" font="1">   </text>
<text top="816" left="228" width="150" height="16" font="1">start = start * offset; </text>
<text top="837" left="174" width="14" height="16" font="1">   </text>
<text top="837" left="228" width="215" height="16" font="1">for (int i = start; i &lt; end; i++) </text>
<text top="858" left="174" width="9" height="16" font="1">  </text>
<text top="858" left="228" width="13" height="16" font="1">{ </text>
<text top="878" left="174" width="14" height="16" font="1">   </text>
<text top="878" left="228" width="5" height="16" font="1"> </text>
<text top="878" left="282" width="172" height="16" font="1">// compute acceleration </text>
<text top="899" left="174" width="14" height="16" font="1">   </text>
<text top="899" left="228" width="5" height="16" font="1"> </text>
<text top="899" left="282" width="18" height="16" font="1">... </text>
<text top="920" left="174" width="14" height="16" font="1">   </text>
<text top="920" left="228" width="13" height="16" font="1">} </text>
<text top="940" left="174" width="14" height="16" font="1">   </text>
<text top="940" left="228" width="18" height="16" font="1">... </text>
<text top="961" left="174" width="13" height="16" font="1">} </text>
<text top="982" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="80" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">68 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
<text top="224" left="162" width="171" height="16" font="4"><b>4.7.2 Shared Memory </b></text>
<text top="282" left="180" width="606" height="16" font="1">So far, simulation only uses global memory and register. Great deal of performance </text>
<text top="313" left="162" width="633" height="16" font="1">gain expected is to utilize fast shared memory. Therefore, in this phase of optimization, </text>
<text top="344" left="162" width="603" height="16" font="1">kernel includes shared memory access. So we modify our galaxycalculatn like this: </text>
<text top="375" left="180" width="5" height="16" font="1"> </text>
<text top="406" left="180" width="5" height="16" font="1"> </text>
<text top="437" left="180" width="5" height="16" font="1"> </text>
<text top="469" left="180" width="5" height="16" font="1"> </text>
<text top="500" left="180" width="5" height="16" font="1"> </text>
<text top="531" left="180" width="5" height="16" font="1"> </text>
<text top="562" left="180" width="5" height="16" font="1"> </text>
<text top="593" left="180" width="5" height="16" font="1"> </text>
<text top="624" left="180" width="5" height="16" font="1"> </text>
<text top="654" left="390" width="214" height="15" font="9">Code 14. Shared block memory </text>
<text top="683" left="162" width="5" height="16" font="1"> </text>
<text top="742" left="162" width="140" height="16" font="4"><b>4.7.3 Loop Unroll </b></text>
<text top="799" left="180" width="615" height="16" font="1">Another consideration is &#34;Loop Unrolling&#34;. As GPU Gems3 [13] indicates, there is a </text>
<text top="830" left="162" width="638" height="16" font="1">slight possible performance gain by unrolling loop. During computation of acceleration, </text>
<text top="862" left="162" width="614" height="16" font="1">each thread run through 256 bodies interaction for each tile. So, we surely can unroll </text>
<text top="893" left="162" width="585" height="16" font="1">some of it to improve the whole performance, the modification in our function is </text>
<text top="924" left="162" width="167" height="16" font="1">described as followed: </text>
<text top="385" left="173" width="116" height="15" font="9">__global__ void  </text>
<text top="413" left="173" width="411" height="15" font="9">galaxyKernel(float4* pos, float4 * pdata, unsigned int width,  </text>
<text top="442" left="173" width="4" height="15" font="9"> </text>
<text top="442" left="227" width="4" height="15" font="9"> </text>
<text top="442" left="281" width="4" height="15" font="9"> </text>
<text top="442" left="335" width="344" height="15" font="9"> unsigned int height, float step, int apprx, int offset) </text>
<text top="470" left="173" width="12" height="15" font="9">{ </text>
<text top="499" left="173" width="4" height="15" font="9"> </text>
<text top="499" left="227" width="120" height="15" font="9">// shared memory </text>
<text top="527" left="173" width="4" height="15" font="9"> </text>
<text top="527" left="227" width="257" height="15" font="9">extern __shared__ float4 shPosition[]; </text>
<text top="556" left="173" width="4" height="15" font="9"> </text>
<text top="556" left="227" width="134" height="15" font="9">// index of my body </text>
<text top="556" left="389" width="4" height="15" font="9"> </text>
<text top="584" left="173" width="4" height="15" font="9"> </text>
<text top="584" left="227" width="379" height="15" font="9">unsigned int x = blockIdx.x * blockDim.x + threadIdx.x; </text>
<text top="613" left="173" width="4" height="15" font="9"> </text>
<text top="610" left="227" width="37" height="18" font="14">…….</text>
<text top="612" left="264" width="5" height="16" font="1"> </text>
</page>
<page number="81" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">69 </text>
<text top="448" left="784" width="5" height="16" font="1"> </text>
<text top="474" left="385" width="206" height="15" font="9">Code 15. Loop unroll example </text>
<text top="503" left="162" width="5" height="16" font="1"> </text>
<text top="562" left="162" width="374" height="16" font="4"><b>4.7.4 Performance Increase as Block Size Varies </b></text>
<text top="619" left="180" width="586" height="16" font="1">The performance-tuning parameter is the value of p, the size of the tile. The total </text>
<text top="650" left="162" width="638" height="16" font="1">memory fetched by the program is N 2/p for each integration time step of the algorithm, </text>
<text top="682" left="162" width="643" height="16" font="1">so increasing p decreases memory traffic. There are 16 multiprocessors on the cluster. so </text>
<text top="712" left="162" width="611" height="16" font="1">p cannot be arbitrarily large; it must remain small enough so that N/p is 16 or larger. </text>
<text top="744" left="162" width="606" height="16" font="1">Otherwise, some multiprocessors will be idle. Another reason to keep <i>p </i>small is the </text>
<text top="775" left="162" width="618" height="16" font="1">concurrent assignment of thread blocks to multiprocessors. When a thread block uses </text>
<text top="806" left="162" width="625" height="16" font="1">only a portion of the resources on a multiprocessor (such as registers, thread slots, and </text>
<text top="837" left="162" width="582" height="16" font="1">shared memory), multiple thread blocks are placed on each multiprocessor. This </text>
<text top="868" left="162" width="607" height="16" font="1">technique provides more opportunity for the hardware to hide latencies of pipelined </text>
<text top="899" left="162" width="311" height="16" font="1">instruction execution and memory fetches. </text>
<text top="930" left="162" width="5" height="16" font="1"> </text>
<text top="961" left="162" width="5" height="16" font="1"> </text>
<text top="992" left="162" width="5" height="16" font="1"> </text>
<text top="1023" left="162" width="5" height="16" font="1"> </text>
<text top="1054" left="162" width="5" height="16" font="1"> </text>
<text top="172" left="174" width="141" height="15" font="9">unsigned int idx = 0; </text>
<text top="201" left="174" width="371" height="15" font="9">unsigned int loop = ((width * height) / apprx ) / BSIZE; </text>
<text top="229" left="174" width="183" height="15" font="9">for (int i = 0; i &lt; loop; i++) </text>
<text top="258" left="174" width="12" height="15" font="9">{ </text>
<text top="286" left="174" width="311" height="15" font="9">idx = threadIdx.y * blockDim.x + threadIdx.x; </text>
<text top="315" left="174" width="326" height="15" font="9">shPosition[idx] = pdata[idx + start + BSIZE * i]; </text>
<text top="343" left="174" width="114" height="15" font="9">__syncthreads(); </text>
<text top="371" left="174" width="266" height="15" font="9">acc = tile_calculation(myPosition, acc); </text>
<text top="400" left="174" width="118" height="15" font="9">__syncthreads();  </text>
<text top="429" left="174" width="12" height="15" font="9">} </text>
<text top="457" left="174" width="5" height="16" font="1"> </text>
</page>
<page number="82" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">70 </text>
<text top="166" left="162" width="325" height="16" font="4"><b>4.7.5 Improving Performance for Small N </b></text>
<text top="224" left="180" width="570" height="16" font="1">A final optimization that we implemented—using multiple threads per body— </text>
<text top="255" left="162" width="648" height="16" font="1">attempts to improve performance for <i>N </i>&lt; 4096. As <i>N </i>decreases, there is not enough work </text>
<text top="286" left="162" width="652" height="16" font="1">with one thread per body to adequately cover all the latencies in the GPU, so performance </text>
<text top="317" left="162" width="607" height="16" font="1">drops rapidly. We therefore increase the number of active threads by using multiple </text>
<text top="345" left="162" width="645" height="20" font="7">threads on each row of a body’s force calculation. If the additional threads are part of the </text>
<text top="379" left="162" width="646" height="16" font="1">same thread block, then the number of memory requests increases, as does the number of </text>
<text top="410" left="162" width="607" height="16" font="1">warps, so the latencies begin to be covered again. Our current register use limits the </text>
<text top="442" left="162" width="644" height="16" font="1">number of threads per block to 256 on the GPU (blocks of 512 threads fail to run), so we </text>
<text top="474" left="162" width="410" height="16" font="1">split each row into <i>q </i>segments, keeping <i>p </i>× <i>q </i>≤ 256.    </text>
</page>
<page number="83" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">71 </text>
<text top="249" left="332" width="332" height="22" font="8"><b>5. Future Work and Conclusion </b></text>
<text top="289" left="162" width="5" height="16" font="1"> </text>
<text top="319" left="162" width="5" height="16" font="1"> </text>
<text top="351" left="162" width="5" height="16" font="1"> </text>
<text top="410" left="162" width="156" height="19" font="5"><b>5.1 Future Work </b></text>
<text top="468" left="180" width="608" height="20" font="7">The Parallel Visualization system based on Equalizer is still a start point. It’s not an </text>
<text top="503" left="162" width="635" height="16" font="1">engine. Using OpenGL commands to build up complex objects with trillion of triangles </text>
<text top="534" left="162" width="624" height="16" font="1">are very difficult. A scene graph layer should be added in the next work step. Luckily, </text>
<text top="565" left="162" width="652" height="16" font="1">there is a good choice for our system. Open Scene Graph can be integrated with Equalizer </text>
<text top="592" left="162" width="614" height="20" font="7">library. It’s an open source high performance 3D graphics toolkit and wildly used by </text>
<text top="627" left="162" width="651" height="16" font="1">application developers in fields such as visual simulation, games, virtual reality, scientific </text>
<text top="658" left="162" width="649" height="16" font="1">visualization and modeling [21]. In addition, another important part—physics should also </text>
<text top="689" left="162" width="594" height="16" font="1">be considered in the visualization application. Bullet Physic Engine [22] is a good </text>
<text top="720" left="162" width="648" height="16" font="1">candidate in the future’s integrating work for the visualization system to provide physical </text>
<text top="751" left="162" width="607" height="16" font="1">features for every objects and collision detecting mechanism for the system. For the </text>
<text top="783" left="162" width="625" height="16" font="1">CUDA computation, the memory access mechanism should be optimized in the future </text>
<text top="813" left="162" width="649" height="16" font="1">work. CUDA based ray tracing method can also be implemented in the future’s rendering </text>
<text top="844" left="162" width="45" height="16" font="1">tasks. </text>
<text top="876" left="180" width="615" height="16" font="1">MPI, Pthreads and CUDA are all parallel programming APIs and providing different </text>
<text top="907" left="162" width="650" height="16" font="1">programming models for developer. They all showed great improvements in performance </text>
<text top="938" left="162" width="638" height="16" font="1">compared with sequential program. A deep performance review among them based on a </text>
<text top="969" left="162" width="469" height="16" font="1">same computing problem can be investigated in the future work. </text>
</page>
<page number="84" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">72 </text>
<text top="194" left="162" width="137" height="19" font="5"><b>5.2 Conclusion </b></text>
<text top="256" left="180" width="609" height="16" font="1">MPI and CUDA, considered as two different type of parallel programming APIs are </text>
<text top="287" left="162" width="638" height="16" font="1">deeply investigated in this paper. In CPU parallel programming, for distributed memory </text>
<text top="318" left="162" width="626" height="16" font="1">architecture, especially for a cluster, MPI based programs outperformed the sequential </text>
<text top="350" left="162" width="626" height="16" font="1">programs with very low overhead in sorting algorithms and mathematic problems. For </text>
<text top="381" left="162" width="624" height="16" font="1">shared memory architecture, pthreads based program can improve the performance by </text>
<text top="412" left="162" width="648" height="16" font="1">creating more threads without copying data for each other. In GPU programming, CUDA </text>
<text top="443" left="162" width="619" height="16" font="1">based program are perfectly worked for general computation task and showed greater </text>
<text top="474" left="162" width="646" height="16" font="1">performance compared with sequential program. It also provided a way to let GPU doing </text>
<text top="505" left="162" width="555" height="16" font="1">rendering task and general computation simultaneously in N-body problem.  </text>
<text top="536" left="180" width="614" height="16" font="1">A parallel visualization work of galaxy simulation based on N-body problem is done </text>
<text top="567" left="162" width="608" height="16" font="1">by combining CPU and GPU working together. By providing a client-server way of </text>
<text top="598" left="162" width="631" height="16" font="1">programming structure, the system used multi-threads for each nodes in the cluster and </text>
<text top="629" left="162" width="641" height="16" font="1">enabled CUDA computation in the rendering process. Our benchmark demonstrated this </text>
<text top="660" left="162" width="622" height="16" font="1">high resolution, tiled display visualization application with Multiple GPUs and GLSL </text>
<text top="691" left="162" width="629" height="16" font="1">shader supported. The performance is far outperformed with sequential OpenGL based </text>
<text top="722" left="162" width="111" height="16" font="1">application.      </text>
</page>
<page number="85" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">73 </text>
<text top="249" left="428" width="141" height="22" font="8"><b>Bibliography </b></text>
<text top="289" left="162" width="5" height="16" font="1"> </text>
<text top="319" left="162" width="5" height="16" font="1"> </text>
<text top="351" left="162" width="5" height="16" font="1"> </text>
<text top="382" left="180" width="619" height="16" font="1">[1]  Fung etal, &#34;Mediated Reality Using Computer Graphics Hardware for Computer </text>
<text top="413" left="180" width="612" height="16" font="1">Vision&#34;, <i>Proceedings of the International Symposium on Wearable Computing 2002 </i></text>
<text top="444" left="180" width="500" height="16" font="25"><i>(ISWC2002)</i>, Seattle, Washington, USA, Oct 7-10, 2002, pp. 83--89. </text>
<text top="475" left="180" width="610" height="16" font="1">[2]  P. Crowley, M. Fiuczynski, J. Baer, and B. Bershad, ―Characterizing Processor </text>
<text top="506" left="180" width="573" height="16" font="1">Architectures for Programmable Network Interfaces‖, <i>Proceedings of the 2000 </i></text>
<text top="537" left="180" width="529" height="16" font="25"><i>International Conference on Supercomputing</i>, Santa Fe, NM, May, 2000 </text>
<text top="568" left="180" width="581" height="16" font="1">[3]  B. Barney (2008), <i>Introduction to Parallel Computing</i> [Online]. Available: </text>
<text top="599" left="180" width="369" height="16" font="1">https://computing.llnl.gov/tutorials/parallel_comp/ </text>
<text top="630" left="180" width="477" height="16" font="1">[4]  <i>MPI: A Message-Passing Interface</i>, MPI standard 2.2, 2009. </text>
<text top="661" left="180" width="580" height="16" font="1">[5]  E. Gabriel, Graham E. Fagg, G. Bosilca, T. Angskun, Jack J. Dongarra and </text>
<text top="692" left="180" width="601" height="16" font="1">Jeffrey M. Squyres, ―Open MPI: Goals, Concept, and Design of a Next Generation </text>
<text top="723" left="180" width="627" height="16" font="1">MPI Implementation‖, <i>Proceedings, 11th European PVM/MPI Users' Group Meeting</i>, </text>
<text top="754" left="180" width="280" height="16" font="1">Budapest, Hungary, 2004, pp. 97-104. </text>
<text top="785" left="180" width="616" height="16" font="1">[6]  C. A. R. Hoare, ―Quicksort‖, <i>Computer Journal</i>, Vol. 5, No. 1, 1962, pp. 10-15. </text>
<text top="816" left="180" width="599" height="16" font="1">[7]  S. Akhter and J. Roberts, <i>Multi-Core Programming--Increasing Performance </i></text>
<text top="847" left="180" width="532" height="16" font="25"><i>through Software Multi-threading</i> (1st Edition), Intel Corporation, 2006.  </text>
<text top="878" left="180" width="606" height="16" font="1">[8]  J. X. Chen, N. da Vittoria Lobo, C. E. Hughes, and J. M. Moshell. ―Real-Time </text>
<text top="906" left="180" width="617" height="20" font="7">Fluid Simulation in a Dynamic Virtual Environment‖, <i>IEEE Computer Graphics and </i></text>
<text top="941" left="180" width="298" height="16" font="25"><i>Applications</i>, May-June 1997, pp 52–61. </text>
</page>
<page number="86" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="43" size="16" family="Times" color="#000000"/>
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">74 </text>
<text top="166" left="180" width="592" height="16" font="1">[9]  Rocks Cluster Distribution (2009), <i>About Rocks Cluster</i> [Online]. Available: </text>
<text top="197" left="180" width="298" height="16" font="1">http://www.rocksclusters.org/wordpress/ </text>
<text top="228" left="180" width="589" height="16" font="1">[10] Gaston Julia &#34;Mémoire sur l'iteration des fonctions rationnelles,&#34; <i>Journal de </i></text>
<text top="259" left="180" width="453" height="16" font="25"><i>Mathématiques Pures et Appliquées</i>, vol. 8, 1918, pp. 47–245. </text>
<text top="290" left="180" width="587" height="16" font="1">[11] P. N. Glaskowsky, ―NVIDIA’s Fermi: The First Complete GPU Computing </text>
<text top="318" left="180" width="407" height="20" font="7">Architecture‖, Nvidia Corp, Tech. Rep., April 12, 2011. </text>
<text top="352" left="180" width="592" height="16" font="1">[12] S, Mark, A. Schuster, A. Patney, &#34;Efficient computation of Sum-products on </text>
<text top="383" left="180" width="639" height="16" font="1">GPUs&#34;, <i>Proceeding of International Conference of Supercomputing</i>, 2008, pp.309-318. </text>
<text top="415" left="180" width="548" height="16" font="1">[13] H. Nguyen, editor, <i>GPU Gems 3</i>, Addison-Wesley Professional, 2007. </text>
<text top="446" left="180" width="618" height="16" font="1">[14] Scandal Project Organization, <i>Parallel N-Body Simulations </i>[Online]. Available: </text>
<text top="477" left="180" width="360" height="16" font="1">http://www.cs.cmu.edu/~scandal/alg/nbody.html. </text>
<text top="508" left="180" width="633" height="16" font="1">[15] J. Verlet, &#34;Computer Experiments on Classical Fluids.&#34; <i>Physical Review</i> Vol. 159, </text>
<text top="539" left="180" width="184" height="16" font="1">No. 1, 1967, pp. 98–103. </text>
<text top="570" left="180" width="592" height="16" font="1">[16] S. Molnar, M. Cox, D. Ellsworth, and H. Fuchs. ―A Sorting Classification of </text>
<text top="597" left="180" width="612" height="20" font="7">Parallel Rendering.‖ <i>IEEE Computer Graphics and Algorithms</i>, July 1994, pages 23-</text>
<text top="632" left="180" width="27" height="16" font="1">32. </text>
<text top="663" left="180" width="589" height="16" font="1">[17] J. Dubinski, J. C. Mihos and L. Hernquist, ―Using Tidal Tails to Probe Dark </text>
<text top="694" left="180" width="479" height="16" font="1">Matter Halos‖, <i>The Astrophysical Journal</i>, Vol. 462, pp. 576-583. </text>
<text top="725" left="180" width="499" height="16" font="1">[19] SGI Corp (2011), <i>SGI—OpenGL Overview</i> [Online]. Available: </text>
<text top="756" left="180" width="471" height="16" font="1">http://www.sgi.com/products/software/opengl/?/overview.html.   </text>
<text top="787" left="180" width="482" height="16" font="1">[20] <i>OpenGL Shading Language</i>, GLSL Version 1.50, July, 2009. </text>
<text top="818" left="180" width="610" height="16" font="1">[21] B. Kuehne and P. Martz, <i>OpenSceneGraph Reference Manual v2.2</i>, Blue Newt </text>
<text top="849" left="180" width="158" height="16" font="1">Software LLC, 2011. </text>
<text top="880" left="180" width="586" height="16" font="1">[22] K. Peter, M. Segal, and R. Westermann, &#34;UberFlow: A GPU-Based Particle </text>
<text top="911" left="180" width="593" height="16" font="1">Engine.&#34; <i>In Proceedings of the SIGGRAPH/Eurographics Workshop on Graphics </i></text>
<text top="942" left="180" width="227" height="16" font="25"><i>Hardware,</i> 2004, pp. 115–122. </text>
<text top="974" left="180" width="624" height="16" font="1">[23] J. Barnes and P. Hut, ―A Hierarchical O (n log n) Force Calculation Algorithm.‖, </text>
<text top="1004" left="180" width="200" height="16" font="25"><i>Nature,</i> 1984, pp. 324-330. </text>
</page>
<page number="87" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="495" width="7" height="13" font="0"> </text>
<text top="1101" left="488" width="20" height="14" font="0">75 </text>
<text top="166" left="180" width="609" height="16" font="1">[24] C. Sagui and T. A. Darden. ―Molecular dynamics simulations of biomolecules: </text>
<text top="197" left="180" width="634" height="16" font="1">Long-range electrostatic effects‖. <i>Ann. Rev. Biophys. Biomol. Struct,</i> Vol. 28, 1999, pp. </text>
<text top="228" left="180" width="69" height="16" font="1">155-179. </text>
<text top="259" left="180" width="591" height="16" font="1">[25] Dehnen, Walter. 2001. ―Towards Optimal Softening in 3D N-body Codes: I. </text>
<text top="290" left="180" width="625" height="16" font="1">Minimizing the Force Error.‖ <i>Monthly Notices of the Royal Astronomical Society </i>324, </text>
<text top="321" left="180" width="54" height="16" font="1">p. 273. </text>
<text top="352" left="180" width="570" height="16" font="1">[25] J. Stam, ―Real-Time Fluid Dynamics for Games‖, <i>GDC 2003 Conference </i></text>
<text top="383" left="180" width="475" height="16" font="25"><i>Proceedings: Game Developers Conference,</i> 2003, pp. 17pages. <i>  </i></text>
<text top="415" left="180" width="352" height="16" font="1">[26] Wikipedia, Gauss-Seidel method, [Online]  </text>
<text top="446" left="180" width="463" height="16" font="1">http://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method </text>
<text top="477" left="180" width="588" height="16" font="1">[27] George B. Arfken and Hans J. Weber, <i>Mathematical Methods for Physicists</i> </text>
<text top="508" left="180" width="414" height="16" font="1">International Edition, 6th edition, Academic Press, 2005. </text>
<text top="539" left="180" width="614" height="16" font="1">[28] M. N. Gamito, P. F. Lopes, and M. R. Gomes. ―Two dimensional Simulation of </text>
<text top="570" left="180" width="625" height="16" font="1">Gaseous Phenomena Using Vortex Particles‖, <i>In Proceedings of the 6th Eurographics </i></text>
<text top="601" left="180" width="618" height="16" font="25"><i>Workshop on Computer Animation and Simulation</i>, Springer-Verlag, 1995, pp. 3–15. </text>
<text top="632" left="180" width="615" height="16" font="1">[29] L. Yaeger and C. Upson. ―Combining Physical and Visual Simulation. Creation </text>
<text top="659" left="180" width="620" height="20" font="7">of the Planet Jupiter for the Film 2010‖, <i>ACM Computer Graphics (SIGGRAPH ’86)</i>, </text>
<text top="694" left="180" width="299" height="16" font="1">Vol. 20, No. 4, August 1986, pp. 85–93.  </text>
<text top="725" left="180" width="609" height="16" font="1">[30] Compute Uniﬁed Device Architecture (CUDA) Programming Guide. [Online]. </text>
<text top="756" left="180" width="536" height="16" font="1">Available: http://developer.nvidia.com/object/cuda.html : NVIDIA, 2007. </text>
<text top="787" left="180" width="587" height="16" font="1">[31] S. Eilemann, M. Makhinya, and R. Pajarola, ―Equalizer: A Scalable Parallel </text>
<text top="814" left="180" width="628" height="20" font="7">Rendering Framework‖, <i>IEEE Transactions on Visualization and Computer Graphics</i>, </text>
<text top="849" left="180" width="291" height="16" font="1">Vol. 15, No. 3, June, 2009, pp. 436-452.</text>
</page>
<page number="88" position="absolute" top="0" left="0" height="1188" width="918">
<text top="83" left="481" width="7" height="13" font="0"> </text>
<text top="1101" left="475" width="20" height="14" font="0">76 </text>
<text top="166" left="162" width="5" height="16" font="1"> </text>
</page>
</pdf2xml>
