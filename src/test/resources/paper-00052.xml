<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="0" size="21" family="Times" color="#231f20"/>
	<fontspec id="1" size="12" family="Times" color="#231f20"/>
	<fontspec id="2" size="12" family="Times" color="#231f20"/>
	<fontspec id="3" size="15" family="Times" color="#231f20"/>
	<fontspec id="4" size="10" family="Times" color="#231f20"/>
	<fontspec id="5" size="10" family="Times" color="#231f20"/>
	<fontspec id="6" size="10" family="Courier" color="#231f20"/>
<text top="69" left="202" width="427" height="22" font="0"><b>GPU Parallel Computation in Bioinspired</b></text>
<text top="96" left="202" width="222" height="22" font="0"><b>Algorithms. A review.</b></text>
<text top="154" left="202" width="469" height="13" font="1">M.G. Arenas and G. Romero and A.M. Mora and P.A. Castillo and J.J. Merelo</text>
<text top="335" left="202" width="498" height="13" font="2"><b>Abstract </b>As bioinspired methods usually need a high amount of computational</text>
<text top="353" left="202" width="498" height="13" font="1">resources, parallelization is an interesting alternative in order to decrease the exe-</text>
<text top="371" left="202" width="498" height="13" font="1">cution time and to provide accurate results. In this sense, recently there has been</text>
<text top="389" left="202" width="498" height="13" font="1">a growing interest in developing parallel algorithms using graphic processing units</text>
<text top="407" left="202" width="498" height="13" font="1">(GPU) also referred as GPU computation. Advances in the video gaming indus-</text>
<text top="425" left="202" width="498" height="13" font="1">try have led to the production of low-cost, high-performance graphics processing</text>
<text top="443" left="202" width="498" height="13" font="1">units that possess more memory bandwidth and computational capability than cen-</text>
<text top="461" left="202" width="498" height="13" font="1">tral processing units (CPUs). As GPUs are available in personal computers, and they</text>
<text top="479" left="202" width="498" height="13" font="1">are easy to use and manage through several GPU programming languages, graphics</text>
<text top="497" left="202" width="498" height="13" font="1">engines are being adopted widely in scientiﬁc computing applications, particularly</text>
<text top="515" left="202" width="497" height="13" font="1">in the ﬁelds of computational biology and bioinformatics. This chapter reviews the</text>
<text top="533" left="202" width="498" height="13" font="1">use of GPUs to solve scientiﬁc problems, giving an overview of current software</text>
<text top="551" left="202" width="51" height="13" font="1">systems.</text>
<text top="614" left="202" width="113" height="16" font="3"><b>1 Introduction</b></text>
<text top="658" left="202" width="498" height="13" font="1">General-purpose computing on graphics processing units (GPGPU) is the technique</text>
<text top="676" left="202" width="498" height="13" font="1">of using a GPU, which typically handles computation only for computer graphics,</text>
<text top="694" left="202" width="498" height="13" font="1">to perform computation in applications traditionally handled by the CPU. Recently</text>
<text top="712" left="202" width="498" height="13" font="1">there has been a growing interest in Graphics Processing Unit (GPU) computation.</text>
<text top="730" left="202" width="498" height="13" font="1">The fact that this kind of processors has the ability to perform restricted parallel</text>
<text top="748" left="202" width="498" height="13" font="1">processing has elicited considerable interest among researchers with applications</text>
<text top="766" left="202" width="243" height="13" font="1">requiring intensive parallel computation.</text>
<text top="784" left="220" width="480" height="13" font="1">GPUs are specialized stream processors, initially useful for rendering graphics</text>
<text top="802" left="202" width="498" height="13" font="1">applications. Typically, a GPU is able to perform graphics manipulations at a much</text>
<text top="838" left="202" width="343" height="11" font="4">M.G. Arenas, G. Romero, A.M. Mora, P.A. Castillo and J.J. Merelo</text>
<text top="853" left="202" width="497" height="11" font="4">Department of Architecture and Computer Technology. CITIC (University of Granada), e-mail:</text>
<text top="867" left="202" width="6" height="13" font="5">{</text>
<text top="868" left="208" width="284" height="10" font="6">mgarenas,gustavo,amorag,pedro,jmerelo</text>
<text top="867" left="492" width="6" height="13" font="5">}</text>
<text top="868" left="500" width="113" height="10" font="6">@geneura.ugr.es</text>
<text top="917" left="693" width="6" height="11" font="4">1</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="7" size="10" family="Times" color="#231f20"/>
<text top="42" left="202" width="6" height="11" font="4">2</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="273" left="202" width="497" height="11" font="7"><b>Fig. 1 </b>GPUs can be seen as SIMD multi-core processors. Internally the GPU contains a number of</text>
<text top="288" left="202" width="497" height="11" font="4">small processors that used to perform calculations. Depending on the GPU, the number of threads</text>
<text top="303" left="202" width="297" height="11" font="4">that can be executed in parallel is in the order of hundreds.</text>
<text top="355" left="202" width="498" height="13" font="1">higher speed than a general purpose CPU, since the graphics processor is specif-</text>
<text top="373" left="202" width="497" height="13" font="1">ically designed to handle certain primitive operations which occur frequently in</text>
<text top="391" left="202" width="498" height="13" font="1">graphics applications. Internally, the GPU contains a number of small processors</text>
<text top="409" left="202" width="498" height="13" font="1">that are used to perform calculations. Depending on the power of a GPU, the num-</text>
<text top="427" left="202" width="497" height="13" font="1">ber of threads that can be executed in parallel on such devices is currently in the</text>
<text top="445" left="202" width="498" height="13" font="1">order of hundreds and it is expected to multiply in a few months. Nowadays, de-</text>
<text top="463" left="202" width="497" height="13" font="1">velopers can write (easily) their own high-level programs on GPU. Due to the wide</text>
<text top="481" left="202" width="497" height="13" font="1">availability, programmability, and high-performance of these consumer-level GPUs,</text>
<text top="499" left="202" width="498" height="13" font="1">they are cost-effective for, not just game playing, but also scientiﬁc computing. Now,</text>
<text top="516" left="202" width="498" height="13" font="1">GPUs are exposed to the programmer as a set of general-purpose shared-memory</text>
<text top="534" left="202" width="498" height="13" font="1">SIMD (Single Instruction Multiple Data) multi-core processors (see Figure 1). This</text>
<text top="552" left="202" width="498" height="13" font="1">makes these architectures well suited to run large computational problems, such as</text>
<text top="570" left="202" width="188" height="13" font="1">those from bioinformatics area.</text>
<text top="588" left="220" width="480" height="13" font="1">Then, the goal of this article is to review the use of GPUs to solve bioinformatics</text>
<text top="606" left="202" width="498" height="13" font="1">problems, explaining the general approach to using a GPU and given an overview</text>
<text top="624" left="202" width="222" height="13" font="1">of currently usable software systems.</text>
<text top="642" left="220" width="480" height="13" font="1">To this end, the rest of this chapter is structured as follows: Section 2 presents</text>
<text top="660" left="202" width="497" height="13" font="1">GPUs as highly parallel devices architectures. Section 3 gives a background on the</text>
<text top="678" left="202" width="498" height="13" font="1">different higher level programming languages used to proﬁt GPUs. Finally, Section</text>
<text top="696" left="202" width="498" height="13" font="1">4 reviews the related works in Physicaly applications on GPUs, followed by a brief</text>
<text top="714" left="202" width="138" height="13" font="1">conclusion (Section 5).</text>
<text top="777" left="202" width="287" height="16" font="3"><b>2 Throughput, parallelism and GPUs</b></text>
<text top="821" left="202" width="498" height="13" font="1">Moore’s Law describes a long-term trend in the history of computing hardware:</text>
<text top="839" left="202" width="498" height="13" font="1">the number of transistors that can be placed inexpensively on an integrated circuit</text>
<text top="857" left="202" width="498" height="13" font="1">has doubled approximately every two years. The trend has continued for more than</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="693" width="6" height="11" font="4">3</text>
<text top="69" left="202" width="130" height="11" font="7"><b>Fig. 2 </b>CPU-GPU blocks</text>
<text top="84" left="202" width="151" height="11" font="4">arrangement: The GPU archi-</text>
<text top="99" left="202" width="147" height="11" font="4">tecture devotes more transis-</text>
<text top="114" left="202" width="117" height="11" font="4">tors to data processing.</text>
<text top="469" left="202" width="498" height="13" font="1">half a century and is not expected to stop (theoretically until not too many years</text>
<text top="487" left="202" width="498" height="13" font="1">above 2015). On 2005 Gordon Moore stated in an interview that his law cannot</text>
<text top="505" left="202" width="498" height="13" font="1">be sustained indeﬁnitely because transistors would eventually reach the limits of</text>
<text top="523" left="202" width="498" height="13" font="1">miniaturization at atomic levels. Maybe it is time for Koomey’s Law [19] to replace</text>
<text top="541" left="202" width="498" height="13" font="1">Moore’s Law. Koomey says that energy efﬁciency is doubled every 18 months. For</text>
<text top="559" left="202" width="497" height="13" font="1">ﬁxed computing load, the amount of battery you need will fall by a factor of two</text>
<text top="577" left="202" width="129" height="13" font="1">every year and a half.</text>
<text top="595" left="220" width="479" height="13" font="1">Parallel computation has recently become necessary to take full advantage of the</text>
<text top="613" left="202" width="498" height="13" font="1">gains allowed by Moore’s law. For years, processor makers consistently delivered</text>
<text top="631" left="202" width="498" height="13" font="1">increases in clock rates and instruction-level parallelism, so that single-threaded</text>
<text top="649" left="202" width="498" height="13" font="1">code executed faster on newer processors with no modiﬁcation. Now, to manage</text>
<text top="667" left="202" width="498" height="13" font="1">CPU power dissipation, processor makers favor multi-core chip designs, and soft-</text>
<text top="685" left="202" width="498" height="13" font="1">ware has to be written in a multi-threaded or multi-process manner to take full ad-</text>
<text top="702" left="202" width="148" height="13" font="1">vantage of the hardware.</text>
<text top="720" left="220" width="480" height="13" font="1">Graphics processors have rapidly matured over the last years, leaving behind their</text>
<text top="738" left="202" width="498" height="13" font="1">roots as ﬁxed function accelerators and growing into general purpose computational</text>
<text top="756" left="202" width="498" height="13" font="1">devices for highly parallel workloads. Some of the earliest academic work about</text>
<text top="774" left="202" width="497" height="13" font="1">GPUs as computational devices date back to University of Washington in 2002[42]</text>
<text top="792" left="202" width="147" height="13" font="1">and Stanford in 2004[5].</text>
<text top="810" left="220" width="480" height="13" font="1">GPUs are similar to multi-core CPUs but with two main differences (see Figure</text>
<text top="828" left="202" width="497" height="13" font="1">2). CPUs a made for speedup and GPUs for throughput. CPUs try to improve the</text>
<text top="846" left="202" width="498" height="13" font="1">execution of a single instruction stream while GPUs take the opposite route obtain-</text>
<text top="864" left="202" width="498" height="13" font="1">ing beneﬁts from massively threaded streams of instructions and/or data (SIMD).</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="8" size="10" family="Times" color="#231f20"/>
	<fontspec id="9" size="7" family="Times" color="#231f20"/>
<text top="42" left="202" width="6" height="11" font="4">4</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="74" left="202" width="498" height="13" font="1">The second difference is how threads are scheduled. The operating system schedule</text>
<text top="92" left="202" width="498" height="13" font="1">threads over different cores of a CPU in a pre-emptive fashion. GPUs have dedicated</text>
<text top="110" left="202" width="307" height="13" font="1">hardware for the cooperative scheduling of threads.</text>
<text top="127" left="220" width="480" height="13" font="1">Physically GPUs are huge in comparison with CPUs, see Table 1. Latest mi-</text>
<text top="145" left="202" width="498" height="13" font="1">croprocessors from the two main vendors, AMD and Intel, have about 1000 million</text>
<text top="163" left="202" width="498" height="13" font="1">transistors. Latest GPUs from AMD and NVIDIA are about 3000 million transistors.</text>
<text top="181" left="202" width="497" height="13" font="1">CPUs draw 130W at most, a limit established by the cost of commodity heat sink</text>
<text top="199" left="202" width="498" height="13" font="1">and fan. GPUs have increase power consumption and currently are in the neighbor-</text>
<text top="217" left="202" width="497" height="13" font="1">hood of 300W. This can be possible with the use of exotic cooling solutions. CPUs</text>
<text top="235" left="202" width="498" height="13" font="1">are built with the ﬁnest technology, read best lithography, while GPUs are made</text>
<text top="253" left="202" width="351" height="13" font="1">with budget in mind in more common and older processes.</text>
<text top="271" left="220" width="479" height="13" font="1">The world of graphics hardware is extremely opaque and does not have stan-</text>
<text top="289" left="202" width="497" height="13" font="1">dard terminology. Every company have a very different set of words to refer to the</text>
<text top="307" left="202" width="498" height="13" font="1">same underlying objects and principles. The marketing dictates big numbers and</text>
<text top="325" left="202" width="498" height="13" font="1">buzzwords instead of clear denominations. Many authors try to alleviate this lack of</text>
<text top="343" left="202" width="498" height="13" font="1">standard terms calling ’shader core’ to an Intel Execution Unit (EU), an AMD Single</text>
<text top="360" left="202" width="498" height="13" font="1">Instruction Multiple Data (SIMD) or an NVIDIA Streaming Multiprocessors (SM).</text>
<text top="378" left="202" width="498" height="13" font="1">Any of these refer to a single processor core inside of the GPU that can fetch, de-</text>
<text top="396" left="202" width="498" height="13" font="1">code, issue and execute several instructions. The shader core is composed of several</text>
<text top="414" left="202" width="497" height="13" font="1">’execution units’ or EU that can execute an individual vector operation equivalent to</text>
<text top="432" left="202" width="498" height="13" font="1">an AVX or SSE instruction. AMD call this kind of EU streaming processor (SP) and</text>
<text top="450" left="202" width="498" height="13" font="1">NVIDIA CUDA core. With this in mind the next Table 1 can be understood more</text>
<text top="468" left="202" width="38" height="13" font="1">easily.</text>
<text top="518" left="202" width="497" height="11" font="7"><b>Table 1 </b>CPU, GPU and APU comparison of best commodity desktop hardware available nowa-</text>
<text top="533" left="202" width="341" height="11" font="4">days. When a slash is used it refers to CPU/GPU parts respectively.</text>
<text top="553" left="243" width="67" height="11" font="4">manufacturer</text>
<text top="553" left="354" width="47" height="11" font="4">transistor</text>
<text top="553" left="415" width="16" height="11" font="4">die</text>
<text top="553" left="447" width="33" height="11" font="4">shader</text>
<text top="553" left="499" width="27" height="11" font="4">clock</text>
<text top="553" left="548" width="42" height="11" font="4">memory</text>
<text top="553" left="603" width="109" height="11" font="4">GFLOPS TDP price</text>
<text top="568" left="272" width="10" height="11" font="4">&amp;</text>
<text top="568" left="363" width="28" height="11" font="4">count</text>
<text top="568" left="413" width="20" height="11" font="4">size</text>
<text top="568" left="450" width="27" height="11" font="4">cores</text>
<text top="568" left="503" width="19" height="11" font="4">rate</text>
<text top="568" left="542" width="54" height="11" font="4">bandwidth</text>
<text top="568" left="609" width="34" height="11" font="4">(single</text>
<text top="583" left="261" width="32" height="11" font="4">model</text>
<text top="583" left="355" width="74" height="11" font="4">(million) (<i>mm</i></text>
<text top="581" left="429" width="5" height="8" font="9">2</text>
<text top="583" left="434" width="49" height="11" font="4">) (ALUs)</text>
<text top="583" left="496" width="34" height="11" font="4">(GHZ)</text>
<text top="583" left="552" width="34" height="11" font="4">(GB/s)</text>
<text top="583" left="601" width="107" height="11" font="4">precision) (W) (e)</text>
<text top="602" left="206" width="141" height="11" font="4">AMD Phenom II X6 1100T</text>
<text top="602" left="368" width="19" height="11" font="4">758</text>
<text top="602" left="413" width="19" height="11" font="4">258</text>
<text top="602" left="460" width="6" height="11" font="4">6</text>
<text top="602" left="495" width="36" height="11" font="4">2.6-3.7</text>
<text top="602" left="558" width="22" height="11" font="4">15.6</text>
<text top="602" left="612" width="28" height="11" font="4">57.39</text>
<text top="602" left="660" width="49" height="11" font="4">125 175</text>
<text top="618" left="229" width="96" height="11" font="4">Intel Core i7 990X</text>
<text top="618" left="365" width="25" height="11" font="4">1170</text>
<text top="618" left="413" width="19" height="11" font="4">240</text>
<text top="618" left="460" width="6" height="11" font="4">6</text>
<text top="618" left="489" width="48" height="11" font="4">3.46-3.73</text>
<text top="618" left="558" width="22" height="11" font="4">24.5</text>
<text top="618" left="609" width="35" height="11" font="4">107.58</text>
<text top="618" left="660" width="49" height="11" font="4">130 950</text>
<text top="637" left="238" width="78" height="11" font="4">AMD A8-3850</text>
<text top="637" left="368" width="19" height="11" font="4">758</text>
<text top="637" left="413" width="19" height="11" font="4">258</text>
<text top="637" left="449" width="29" height="11" font="4">4/400</text>
<text top="637" left="495" width="35" height="11" font="4">2.9/0.6</text>
<text top="637" left="558" width="22" height="11" font="4">29.8</text>
<text top="637" left="617" width="19" height="11" font="4">355</text>
<text top="637" left="660" width="49" height="11" font="4">100 135</text>
<text top="653" left="226" width="102" height="11" font="4">Intel Core i7 2600K</text>
<text top="653" left="368" width="19" height="11" font="4">995</text>
<text top="653" left="413" width="19" height="11" font="4">216</text>
<text top="653" left="452" width="23" height="11" font="4">4/48</text>
<text top="653" left="492" width="42" height="11" font="4">3.4/0.85</text>
<text top="653" left="558" width="22" height="11" font="4">24.5</text>
<text top="653" left="612" width="28" height="11" font="4">129.6</text>
<text top="653" left="663" width="13" height="11" font="4">95</text>
<text top="653" left="690" width="19" height="11" font="4">317</text>
<text top="673" left="216" width="122" height="11" font="4">AMD Radeon HD 6970</text>
<text top="673" left="365" width="25" height="11" font="4">2640</text>
<text top="673" left="413" width="19" height="11" font="4">389</text>
<text top="673" left="451" width="25" height="11" font="4">1536</text>
<text top="673" left="502" width="22" height="11" font="4">0.88</text>
<text top="673" left="560" width="19" height="11" font="4">176</text>
<text top="673" left="614" width="25" height="11" font="4">2703</text>
<text top="673" left="660" width="49" height="11" font="4">250 350</text>
<text top="688" left="205" width="143" height="11" font="4">NVIDIA GeForce GTX 580</text>
<text top="688" left="365" width="25" height="11" font="4">3000</text>
<text top="688" left="413" width="19" height="11" font="4">520</text>
<text top="688" left="454" width="19" height="11" font="4">512</text>
<text top="688" left="499" width="28" height="11" font="4">1.544</text>
<text top="688" left="555" width="28" height="11" font="4">192.4</text>
<text top="688" left="609" width="35" height="11" font="4">1581.1</text>
<text top="688" left="660" width="49" height="11" font="4">244 450</text>
<text top="736" left="220" width="480" height="13" font="1">Nowadays NVIDIA has the biggest GPU with superior performance in some</text>
<text top="754" left="202" width="497" height="13" font="1">workloads. AMD choose a very different compromise in the design of the GPU.</text>
<text top="772" left="202" width="498" height="13" font="1">AMD has more execution units but its memory hierarchy is weaker. This way soft-</text>
<text top="790" left="202" width="498" height="13" font="1">ware bounded by memory bandwidth or with strong ordering interdependencies</text>
<text top="808" left="202" width="498" height="13" font="1">prefers NVIDIA hardware. On the other side, loads capped by pure ALU execu-</text>
<text top="826" left="202" width="289" height="13" font="1">tion power use are faster on the AMD hardware.</text>
<text top="844" left="220" width="479" height="13" font="1">To make things a little more ”heterogeneous” now we can buy a CPU with an</text>
<text top="862" left="202" width="498" height="13" font="1">integrated GPU. AMD and Intel have just started selling this kind of combined pro-</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="693" width="6" height="11" font="4">5</text>
<text top="74" left="202" width="498" height="13" font="1">cessor and graphics card. The new term APU (Accelerated Processing Unit) has</text>
<text top="92" left="202" width="498" height="13" font="1">been coined for this kind of chips. The architectural names are Llano for AMD and</text>
<text top="110" left="202" width="498" height="13" font="1">Sandy Bridge for Intel. There are many reviews online these days. Most of them</text>
<text top="127" left="202" width="497" height="13" font="1">points that AMD’s CPU cores are slower than Intel’s ones but their GPU is faster.</text>
<text top="145" left="202" width="498" height="13" font="1">Which combination is better is not an easy question to answer. It must be backed by</text>
<text top="163" left="202" width="436" height="13" font="1">speciﬁc benchmarks, or better, the real application that we want it to run.</text>
<text top="181" left="220" width="479" height="13" font="1">Over time the use of GPUs has pass from odd to common in our systems. Ac-</text>
<text top="199" left="202" width="498" height="13" font="1">tually several time consuming processes has been parallelized inside our operating</text>
<text top="217" left="202" width="498" height="13" font="1">systems such as web page rendering. The only problem is that the speedup that</text>
<text top="235" left="202" width="497" height="13" font="1">graphics hardware can bring to us is not free. Every application that we want to</text>
<text top="253" left="202" width="498" height="13" font="1">accelerate must be rewritten. Furthermore, parallel software is not famous for been</text>
<text top="271" left="202" width="171" height="13" font="1">the easy easiest one to write.</text>
<text top="289" left="220" width="480" height="13" font="1">As an image is worth a thousand word, Figure 3a will show the internals of</text>
<text top="307" left="202" width="498" height="13" font="1">NVIDIA GF100 architecture. Every green square is an NVIDIA SM. The six blue</text>
<text top="325" left="202" width="498" height="13" font="1">squares on the sides are memory interfaces. As every one is 64-bit, the bus is 384 bits</text>
<text top="343" left="202" width="498" height="13" font="1">wide and can transfer 192.4GB/s connected to GDDR5 memory chips. On the right,</text>
<text top="360" left="202" width="498" height="13" font="1">Figure 3b, we can see a disclosed SM with its 32 CUDA cores. In total there are 512</text>
<text top="378" left="202" width="498" height="13" font="1">cores. The maximum theoretical throughput in simple precision is 1581.1GFLOPS.</text>
<text top="396" left="220" width="479" height="13" font="1">Last AMD GPU offer has a different architecture called Cayman as can be seen in</text>
<text top="414" left="202" width="498" height="13" font="1">Figure 4a. It has 24 SIMDs processors (orange squares). Every SIMD is composed</text>
<text top="432" left="202" width="497" height="13" font="1">by 16 SPs (red rectangles). Finally every SP is a 4-wide Very Long Instruction Word</text>
<text top="450" left="202" width="497" height="13" font="1">processor or VLIW4. This way 1536 instructions can be ﬁnalized every clock. Cay-</text>
<text top="468" left="202" width="498" height="13" font="1">man has for 64-bit dual channel memory controllers (gray rectangles at the bottom</text>
<text top="486" left="202" width="498" height="13" font="1">of Figure 4b) connected to 2 GDDR5 memory channels for a total bandwidth of</text>
<text top="504" left="202" width="498" height="13" font="1">176GB/s. The maximum theoretical throughput in simple precision for this AMD</text>
<text top="522" left="202" width="146" height="13" font="1">design is 2703GFLOPS.</text>
<text top="540" left="220" width="480" height="13" font="1">As CPU makers did some years ago, passing from single core to symmetric mul-</text>
<text top="558" left="202" width="498" height="13" font="1">tiprocessing system (SMP), and more recently to multicores, GPU makers follow</text>
<text top="576" left="202" width="498" height="13" font="1">the same trend. We can connect more than one graphic card to our computer to im-</text>
<text top="594" left="202" width="497" height="13" font="1">prove its GPU capacities or buy a card with 2 graphic chips inside. GPUs are so</text>
<text top="612" left="202" width="497" height="13" font="1">much powerful than CPUs that even a small cluster of a few GPUs can be faster</text>
<text top="630" left="202" width="498" height="13" font="1">than classic, and much more expensive, big cluster of processors. First cluster of</text>
<text top="647" left="202" width="498" height="13" font="1">this kind appear in the scientiﬁc literature from 2004 [10] with big success. Even</text>
<text top="665" left="202" width="498" height="13" font="1">some people have small GPU clusters at home with a couple of mighty graphics</text>
<text top="683" left="202" width="498" height="13" font="1">cards just to game. Connecting 2, 3 or 4 graphics card is called CrossFire by AMD</text>
<text top="701" left="202" width="280" height="13" font="1">and Scalable Link Interface (SLI) by NVIDIA.</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="6" height="11" font="4">6</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="415" left="333" width="177" height="11" font="4">(a) NVIDIA GF100 block diagram</text>
<text top="775" left="379" width="85" height="11" font="4">(b) NVIDIA SM</text>
<text top="803" left="202" width="186" height="11" font="7"><b>Fig. 3 </b>NVIDIA GF100 architecture.</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="10" size="15" family="Times" color="#231f20"/>
	<fontspec id="11" size="12" family="Times" color="#231f20"/>
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="693" width="6" height="11" font="4">7</text>
<text top="330" left="204" width="172" height="11" font="4">(a) AMD Cayman block diagram.</text>
<text top="330" left="464" width="86" height="11" font="4">(b) AMD SIMD.</text>
<text top="359" left="202" width="178" height="11" font="7"><b>Fig. 4 </b>AMD Cayman architecture.</text>
<text top="409" left="202" width="173" height="16" font="3"><b>3 GPUs Programming</b></text>
<text top="454" left="202" width="185" height="16" font="10"><i><b>3.1 Programming Model</b></i></text>
<text top="497" left="202" width="498" height="13" font="1">The way GPUs can be exploited is deeply rooted on its hardware. There exists sev-</text>
<text top="515" left="202" width="498" height="13" font="1">eral APIs. Every company has a proprietary one tied to their respective products.</text>
<text top="533" left="202" width="497" height="13" font="1">This way AMD started with Close to Metal and NVIDIA with CUDA. Over time an</text>
<text top="551" left="202" width="157" height="13" font="1">standard appear, OpenCL.</text>
<text top="569" left="220" width="479" height="13" font="1">With respect to the programming tools which available for developers, most the</text>
<text top="587" left="202" width="498" height="13" font="1">Application Program Interfaces (APIs) are based on C-like languages, but having</text>
<text top="605" left="202" width="498" height="13" font="1">some restrictions to improve the parallel execution, such as no recursion or limited</text>
<text top="623" left="202" width="498" height="13" font="1">pointers. Some of them use the open source compiler LLVM [17] from University</text>
<text top="641" left="202" width="62" height="13" font="1">of Illinois.</text>
<text top="659" left="220" width="480" height="13" font="1">From 2003 the two main GPU developers, ATI an NVIDIA, started selling hard-</text>
<text top="677" left="202" width="498" height="13" font="1">ware solutions that need to be programmed with proprietary APIs. Despite previous</text>
<text top="695" left="202" width="498" height="13" font="1">work, the ﬁrst widely supported GPUs were DX10 generation GeForce 8 series</text>
<text top="713" left="202" width="498" height="13" font="1">from NVIDIA, using the more mature <i>CUDA </i>API. On the other hand, the Radeon</text>
<text top="731" left="202" width="444" height="13" font="1">HD2xxx series from ATI, were programmed with the <i>Close To Metal </i>API.</text>
<text top="749" left="220" width="480" height="13" font="1">From operating system vendors there were efforts in the same direction. Some</text>
<text top="767" left="202" width="497" height="13" font="1">people at Apple betted on the potential of GPUs and started developing an open API,</text>
<text top="784" left="202" width="498" height="13" font="1">latter known as <i>OpenCL</i>. In the same time, Microsoft created the <i>DirectCompute</i></text>
<text top="802" left="202" width="109" height="13" font="1">API for Windows.</text>
<text top="820" left="220" width="480" height="13" font="1">OpenCL aimed to became the OpenGL of heterogeneous computing for paral-</text>
<text top="838" left="202" width="497" height="13" font="1">lel applications. It is a cross-platform API with a broad and inclusive approach to</text>
<text top="856" left="202" width="498" height="13" font="1">parallelism, both in software and in hardware. While explicitly targeting GPUs, it</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="6" height="11" font="4">8</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="69" left="202" width="148" height="11" font="7"><b>Fig. 5 </b>Hierarchy of comput-</text>
<text top="84" left="202" width="117" height="11" font="4">ing structure in a GPU.</text>
<text top="497" left="202" width="498" height="13" font="1">also considers multi-core CPUs and FPGAs. The applications are portable across</text>
<text top="515" left="202" width="498" height="13" font="1">different hardware platforms, varying performance while keeping functionality and</text>
<text top="533" left="202" width="397" height="13" font="1">correctness. The ﬁrst software implementations date back to 2009.</text>
<text top="551" left="220" width="480" height="13" font="1">Most companies support OpenCL across their products. Apart from AMD and</text>
<text top="569" left="202" width="497" height="13" font="1">NVIDIA we can use it on graphic hardware from S3 and VIA. Also IBM has a</text>
<text top="587" left="202" width="498" height="13" font="1">version of OpenCL for PowerPC and CELL processors. Intel is the only exception</text>
<text top="605" left="202" width="497" height="13" font="1">that still does not offer support but they will do in their next architectures for APUs,</text>
<text top="623" left="202" width="498" height="13" font="1">Ivy Bridge, and GPUs. Embedded world is also interested in OpenCL. Imagination</text>
<text top="641" left="202" width="497" height="13" font="1">Technologies offer support for the SGX545 graphics core. As does Samsung with</text>
<text top="659" left="202" width="209" height="13" font="1">their ARM based microprocessors.</text>
<text top="722" left="202" width="157" height="16" font="10"><i><b>3.2 Execution Model</b></i></text>
<text top="766" left="202" width="498" height="13" font="1">OpenCL, DirectCompute and CUDA are APIs designed for heterogeneous comput-</text>
<text top="784" left="202" width="498" height="13" font="1">ing with both a host CPU and an optional GPU device. The applications have serial</text>
<text top="802" left="202" width="497" height="13" font="1">portions, that are executed on the host CPU, and parallel portions, known as <i>ker-</i></text>
<text top="820" left="202" width="498" height="13" font="11"><i>nels</i>. The parallel kernels may execute on an OpenCL compatible device (CPU or</text>
<text top="838" left="202" width="497" height="13" font="1">GPU), but synchronization is enforced between kernels and serial code. OpenCL is</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="12" size="12" family="Times" color="#231f20"/>
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="693" width="6" height="11" font="4">9</text>
<text top="69" left="202" width="130" height="11" font="7"><b>Fig. 6 </b>Execution model:</text>
<text top="84" left="202" width="149" height="11" font="4">Each piece of data is a work-</text>
<text top="99" left="202" width="138" height="11" font="4">item (thread); a kernel has</text>
<text top="114" left="202" width="148" height="11" font="4">thousands of work-items and</text>
<text top="129" left="202" width="150" height="11" font="4">is organized into many work-</text>
<text top="144" left="202" width="146" height="11" font="4">groups (thread blocks); each</text>
<text top="159" left="202" width="135" height="11" font="4">work-group process many</text>
<text top="174" left="202" width="61" height="11" font="4">work-items.</text>
<text top="383" left="202" width="498" height="13" font="1">distinctly intended to handle both task and data parallel workloads, while CUDA</text>
<text top="401" left="202" width="370" height="13" font="1">and DirectCompute are primarily focused on data parallelism.</text>
<text top="419" left="220" width="479" height="13" font="1">A kernel applies a single stream of instructions to vast quantities of data that are</text>
<text top="437" left="202" width="497" height="13" font="1">organized as a 1-3 dimensional array (see Figures 5 and 6). Each piece of data is</text>
<text top="455" left="202" width="498" height="13" font="1">known as a work-item in OpenCL terminology, and kernels may have hundreds or</text>
<text top="473" left="202" width="498" height="13" font="1">thousands of work-items. The kernel itself is organized into many work-groups that</text>
<text top="491" left="202" width="498" height="13" font="1">are relatively limited in size; for example a kernel could have 32K work-items, but</text>
<text top="509" left="202" width="208" height="13" font="1">64 work-groups of 512 items each.</text>
<text top="526" left="220" width="491" height="13" font="1">Unlike traditional computation, arbitrary communication within a kernel is strongly</text>
<text top="544" left="202" width="498" height="13" font="1">limited. However, communication and synchronization is generally allowed locally</text>
<text top="562" left="202" width="497" height="13" font="1">within a work-group. So work-groups serve two purposes: ﬁrst, they break up a</text>
<text top="580" left="202" width="498" height="13" font="1">kernel into manageable chunks, and second, they deﬁne a limited scope for commu-</text>
<text top="598" left="202" width="52" height="13" font="1">nication.</text>
<text top="662" left="202" width="143" height="16" font="10"><i><b>3.3 Memory Model</b></i></text>
<text top="706" left="202" width="498" height="13" font="1">The memory model deﬁnes how data is stored and communicated within a device</text>
<text top="724" left="202" width="498" height="13" font="1">and between the device and the CPU. DirectCompute, CUDA and OpenCL share</text>
<text top="742" left="202" width="347" height="13" font="1">the same four memory types (with different terminology):</text>
<text top="771" left="202" width="498" height="15" font="12">• Global memory: it is available for both read and write access to any work-item</text>
<text top="790" left="220" width="109" height="13" font="1">and the host CPU.</text>
<text top="806" left="202" width="498" height="15" font="12">• Constant memory: is a read-only region for work-items on the GPU device, but</text>
<text top="825" left="220" width="479" height="13" font="1">the host CPU has full read and write access. Since the region is read-only, it is</text>
<text top="843" left="220" width="209" height="13" font="1">freely accessible to any work-item.</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="13" height="11" font="4">10</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="379" left="202" width="497" height="11" font="7"><b>Fig. 7 </b>Memory model deﬁnes how the data is stored and communicated between CPU and GPU.</text>
<text top="394" left="202" width="497" height="11" font="4">Global memory is RW for both CPU and work-items; constant memory is RW for CPU and RO for</text>
<text top="409" left="202" width="497" height="11" font="4">work-items; private memory is RW for a single work-item; local memory is RW for a work-group.</text>
<text top="460" left="202" width="498" height="15" font="12">• Private memory: is accessible to a single work-item for reads and writes and</text>
<text top="479" left="220" width="480" height="13" font="1">inaccessible for the CPU host. The vast majority of computation is done using</text>
<text top="497" left="220" width="469" height="13" font="1">private memory, thus in many ways it is the most critical term of performance.</text>
<text top="514" left="202" width="497" height="15" font="12">• Local memory: is accessible to a single work-group for reads and writes and is</text>
<text top="533" left="220" width="480" height="13" font="1">inaccessible for the CPU host. It is intended for shared variables and communica-</text>
<text top="551" left="220" width="480" height="13" font="1">tion between work-items and is shared between a limited number of work-items.</text>
<text top="615" left="202" width="242" height="16" font="3"><b>4 Bioinpired Methods on GPUs</b></text>
<text top="659" left="202" width="498" height="13" font="1">This section reviews different bioinspired approaches using GPUs found in bibli-</text>
<text top="677" left="202" width="498" height="13" font="1">ography, focusing mainly on Evolutionary Computation (EC) and Artiﬁcial Neural</text>
<text top="695" left="202" width="108" height="13" font="1">Networks (ANN).</text>
<text top="712" left="220" width="480" height="13" font="1">Alba et al. [1] reviewed and surveyed parallel metaheuristics on Evolution-</text>
<text top="730" left="202" width="498" height="13" font="1">ary Computation. They identiﬁed the majority of paradigms to be hosting paral-</text>
<text top="748" left="202" width="498" height="13" font="1">lel/distributed EAs, according to Flynn’s taxonomy, to fall under the MIMD (Mul-</text>
<text top="766" left="202" width="498" height="13" font="1">tiple Instruction Multiple Data) category. This argument is fairly valid as in the last</text>
<text top="784" left="202" width="497" height="13" font="1">two decades the most dominant platform hosting parallel/distributed EAs was clus-</text>
<text top="802" left="202" width="316" height="13" font="1">ters (also ﬁne-grained EAs on MPP are wildly used).</text>
<text top="820" left="220" width="480" height="13" font="1">The parallel EAs community has a long legacy with MIMD architectures com-</text>
<text top="838" left="202" width="497" height="13" font="1">pared to a very little contribution for SIMD (Single Instruction Multiple Data) sys-</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="687" width="13" height="11" font="4">11</text>
<text top="74" left="202" width="498" height="13" font="1">tem. This comes in part due to the dominance of MIMD architectures as compared</text>
<text top="92" left="202" width="88" height="13" font="1">to SIMD ones.</text>
<text top="110" left="220" width="385" height="13" font="1">Alba classiﬁes the main parallel metaheuristic models as follow:</text>
<text top="135" left="202" width="281" height="15" font="12">• Parallel Genetic Algorithms (Cant´u Paz [6])</text>
<text top="153" left="202" width="355" height="15" font="12">• Parallel Genetic Programming (F. Fern´andez, et al.[11]).</text>
<text top="171" left="202" width="304" height="15" font="12">• Parallel Evolution Strategies (G. Rudolph [40]).</text>
<text top="189" left="202" width="348" height="15" font="12">• Parallel Ant Colony Algorithms (S. Janson, et al. [18]).</text>
<text top="207" left="202" width="437" height="15" font="12">• Parallel Estimation of Distribution Algorithms (J. Madera, et al. [26]).</text>
<text top="225" left="202" width="290" height="15" font="12">• Parallel Scatter Search (F. Garcia, et al. [12]).</text>
<text top="243" left="202" width="422" height="15" font="12">• Parallel Variable Neighborhood Search (F. Garc´ıa-l´opez, et al.[13]).</text>
<text top="261" left="202" width="240" height="15" font="12">• Parallel Simulated Annealing ([14]) .</text>
<text top="279" left="202" width="272" height="15" font="12">• Parallel Tabu Search (T. Crainic, et al.[8]).</text>
<text top="297" left="202" width="497" height="15" font="12">• Parallel Greedy Randomized Adaptive Search Procedures (M. Resende and C.</text>
<text top="316" left="220" width="82" height="13" font="1">Ribeiro [39]).</text>
<text top="333" left="202" width="326" height="15" font="12">• Parallel Hybrid Metaheuristics (C. Cotta, et al. [7]).</text>
<text top="350" left="202" width="379" height="15" font="12">• Parallel MultiObjective Optimization (A. Nebro, et al. [32]).</text>
<text top="368" left="202" width="369" height="15" font="12">• Parallel Heterogeneous Metaheuristics (F. Luna, et al. [2]).</text>
<text top="396" left="220" width="480" height="13" font="1">Nevertheless, when the research community use GPGPU (General-Purpose Com-</text>
<text top="414" left="202" width="497" height="13" font="1">puting on Graphics Processing Units) the authors have developed algorithms us-</text>
<text top="432" left="202" width="498" height="13" font="1">ing three parallel approaches, master-slave model, ﬁne-grained model [20], coarse-</text>
<text top="450" left="202" width="498" height="13" font="1">grained model [27] [36] or hybridations that use two or more of the previous parallel</text>
<text top="468" left="202" width="498" height="13" font="1">approaches in a hierarchical way. All the EC approaches on GPUs are parallel, thus</text>
<text top="486" left="202" width="497" height="13" font="1">a classiﬁcation depending on the parallel model used is presented in this section. We</text>
<text top="504" left="202" width="498" height="13" font="1">will focus on master-slave [50], ﬁne-grained (cellular EAs), coarse-grained (Island</text>
<text top="522" left="202" width="401" height="13" font="1">Model or Deme Model) approaches; and a hierarchical model [51].</text>
<text top="540" left="220" width="480" height="13" font="1">As far as the ANN approaches, although the computation for ANN is inherently</text>
<text top="558" left="202" width="497" height="13" font="1">parallel, many algorithms require some steps that are difﬁcult to parallelize on the</text>
<text top="576" left="202" width="34" height="13" font="1">GPU.</text>
<text top="594" left="220" width="480" height="13" font="1">Most of these methods can be used with almost zero effort by using existing</text>
<text top="612" left="202" width="498" height="13" font="1">frameworks. The most complete and comprehensive review is from Parejo [34]. It</text>
<text top="630" left="202" width="498" height="13" font="1">is a comparative study of metaheuristic optimization frameworks. As criteria for</text>
<text top="647" left="202" width="498" height="13" font="1">comparison a set of 271 features grouped in 30 characteristics and 6 areas has</text>
<text top="665" left="202" width="498" height="13" font="1">been selected. These features include the different metaheuristic techniques cov-</text>
<text top="683" left="202" width="498" height="13" font="1">ered, mechanisms for solution encoding, constraint handling, neighborhood speci-</text>
<text top="701" left="202" width="498" height="13" font="1">ﬁcation, hybridization, parallel and distributed computation, software engineering</text>
<text top="719" left="202" width="291" height="13" font="1">best practices, documentation and user interface.</text>
<text top="783" left="202" width="216" height="16" font="10"><i><b>4.1 Master-slave Approaches</b></i></text>
<text top="827" left="202" width="498" height="13" font="1">Master-slave Evolutionary Algorithms are usually used for problems involving ex-</text>
<text top="845" left="202" width="498" height="13" font="1">pensive to compute ﬁtness function, where the master node runs the entire algorithm</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="13" height="11" font="4">12</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="74" left="202" width="498" height="13" font="1">while the slaves execute the ﬁtness evaluations. Hence, master-slave implementa-</text>
<text top="92" left="202" width="497" height="13" font="1">tions are more efﬁcient as the evaluations become more expensive and contribute a</text>
<text top="110" left="202" width="263" height="13" font="1">bigger portion in total runtime of algorithm.</text>
<text top="127" left="220" width="480" height="13" font="1">Wong et al. [48] proposed an EP algorithm for solving ﬁve simple test functions,</text>
<text top="145" left="202" width="498" height="13" font="1">called Fast Evolutionary Programming (FEP). In this master-slave approach, some</text>
<text top="163" left="202" width="498" height="13" font="1">actions are executed in the CPU (main loop of the algorithm and crossover operator),</text>
<text top="181" left="202" width="498" height="13" font="1">while evaluation and mutation are run in the GPU (no need of external information).</text>
<text top="199" left="202" width="497" height="13" font="1">The competition and selection of the individuals are performed on the CPU, while</text>
<text top="217" left="202" width="497" height="13" font="1">mutation, reproduction and evaluation are performed on the GPU. In this case, the</text>
<text top="235" left="202" width="498" height="13" font="1">reproduction step implies interaction among, at least, two individuals. A maximum</text>
<text top="253" left="202" width="498" height="13" font="1">speedup of x5.02 is obtained when the population size increases. This is the most</text>
<text top="271" left="202" width="498" height="13" font="1">common organization in GPU implementations, since no interaction among individ-</text>
<text top="289" left="202" width="458" height="13" font="1">uals is required during the evaluation, so this step can be fully parallelizable.</text>
<text top="307" left="220" width="480" height="13" font="1">A GP method proposed by Harding and Banzhaf [16] uses the GPU only for</text>
<text top="325" left="202" width="498" height="13" font="1">performing the evaluation, while the rest of the steps of the algorithm are run on</text>
<text top="343" left="202" width="498" height="13" font="1">the CPU. The authors tested real-coded expressions until 10000 nodes, boolean ex-</text>
<text top="360" left="202" width="498" height="13" font="1">pressions until 1500 nodes, and some real world problem where they evaluate ex-</text>
<text top="378" left="202" width="498" height="13" font="1">pressions until 10000 nodes. In some cases, the results yielded speedup of thousand</text>
<text top="396" left="202" width="36" height="13" font="1">times.</text>
<text top="414" left="220" width="480" height="13" font="1">Zhang et al. [51] adapt different EAs to a GPU using CUDA. The authors imple-</text>
<text top="432" left="202" width="498" height="13" font="1">mented an hierarchical parallel genetic algorithm using a deme model at the high</text>
<text top="450" left="202" width="497" height="13" font="1">level, and a master-slave schema at the low level. In this implementation, the CPU</text>
<text top="468" left="202" width="498" height="13" font="1">initializes the populations and distributes them to thread blocks in shared memory.</text>
<text top="486" left="202" width="498" height="13" font="1">Then, GPU threads within each block run a GA independently (selection, crossover,</text>
<text top="504" left="202" width="497" height="13" font="1">mutation and evaluation), and migrates individuals to other thread blocks in its</text>
<text top="522" left="202" width="366" height="13" font="1">neighborhood. In this case, no speedup results were reported.</text>
<text top="540" left="220" width="479" height="13" font="1">Recently, there are other papers related with this approach, like Tsutsui et al.</text>
<text top="558" left="202" width="497" height="13" font="1">paper [44]. This chapter uses a master-slave approach with an ACO algorithm [9]</text>
<text top="576" left="202" width="497" height="13" font="1">with Tabu Search [15]. Tsutsui uses an Intel Core i7 965 (3.2 GHz) processor and a</text>
<text top="594" left="202" width="498" height="13" font="1">single NVIDIA GeForce GTX480 GPU. They compare CPU and GPU implemen-</text>
<text top="612" left="202" width="498" height="13" font="1">tations with and the results showed that GPU computation with MATA ( an efﬁcient</text>
<text top="630" left="202" width="497" height="13" font="1">method for thread assignment cost which they call Move-Cost Adjusted Thread As-</text>
<text top="647" left="202" width="459" height="13" font="1">signment) showed a promising speedup compared to computation with CPU.</text>
<text top="711" left="202" width="219" height="16" font="10"><i><b>4.2 Fine-grained Approaches</b></i></text>
<text top="755" left="202" width="497" height="13" font="1">Traditionally, ﬁne-grained Evolutionary Algorithms or Cellular Evolutionary Al-</text>
<text top="773" left="202" width="498" height="13" font="1">gorithms (cEAs) have not received as much attention as other types of EAs. This</text>
<text top="791" left="202" width="498" height="13" font="1">is mainly due to the necessity of special hardware (i.e. a relatively large supply</text>
<text top="809" left="202" width="498" height="13" font="1">of processors in the underlying architecture). On the contrary, the legacy of paral-</text>
<text top="827" left="202" width="498" height="13" font="1">lel/distributed architectures has shown dominance of loosely coupled systems which</text>
<text top="845" left="202" width="498" height="13" font="1">are not adequate for ﬁne-grained EAs. The reason behind that is the high cost of</text>
<text top="863" left="202" width="498" height="13" font="1">building massively parallel architectures which normally attracted fewer researchers</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="13" size="13" family="Symbol" color="#231f20"/>
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="687" width="13" height="11" font="4">13</text>
<text top="74" left="202" width="498" height="13" font="1">to work on one grained EAs. A review of the trends in parallel architecture proph-</text>
<text top="92" left="202" width="497" height="13" font="1">esizes a radical change in position of ﬁne-grained EAs among other parallel EAs.</text>
<text top="110" left="202" width="167" height="13" font="1">This is due to three reasons:</text>
<text top="138" left="202" width="403" height="15" font="12">• Growing trend of massive number of processors on chip or card.</text>
<text top="156" left="202" width="498" height="15" font="12">• The very high inter-processors speed which is a major factor affecting the efﬁ-</text>
<text top="175" left="220" width="164" height="13" font="1">ciency of ﬁne-grained EAs.</text>
<text top="192" left="202" width="498" height="15" font="12">• The huge drop of cost of these architectures which will attract a wide base of</text>
<text top="211" left="220" width="164" height="13" font="1">researchers and developers.</text>
<text top="241" left="220" width="479" height="13" font="1">For this kind of algorithms, each individual is the parent at the beginning of the</text>
<text top="259" left="202" width="498" height="13" font="1">algorithm wile the second parent is selected by applying some selection function</text>
<text top="277" left="202" width="497" height="13" font="1">for its neighboring. As a result cEAs provide automatic niching effect, avoiding an</text>
<text top="295" left="202" width="113" height="13" font="1">early convergence.</text>
<text top="313" left="220" width="479" height="13" font="1">Yu [49] recommends the use of GA with 2D structured population also called cel-</text>
<text top="331" left="202" width="498" height="13" font="1">lular Genetic Algorithm (cGA) for implementation of ﬁne-grained GAs over a GPU</text>
<text top="349" left="202" width="491" height="13" font="1">(SIMT architecture). The 2D structure of cGA maps well to the GPU architecture.</text>
<text top="367" left="220" width="480" height="13" font="1">In this scheme, Wong et al. [46, 47] proposed a parallel hybrid GA (HGA) where</text>
<text top="384" left="202" width="498" height="13" font="1">the whole evolutionary process is run on the GPU, and only the random number gen-</text>
<text top="402" left="202" width="497" height="13" font="1">eration is done in CPU. Each GA individual is set to each GPU, and each one selects</text>
<text top="420" left="202" width="498" height="13" font="1">probabilistically an individual in its neighborhood to mate with. Just one offspring</text>
<text top="438" left="202" width="498" height="13" font="1">individual is generated, and replaces the old one in that GPU. The authors compare</text>
<text top="456" left="202" width="498" height="13" font="1">HGA with a standard GA run in a CPU and the FEP [48] algorithm. Using a new</text>
<text top="474" left="202" width="498" height="13" font="1">pseudo-deterministic selection method, the amount of random numbers transferred</text>
<text top="492" left="202" width="497" height="13" font="1">from the CPU is reduced.HGA reaches speedup of 5.30 when compared against the</text>
<text top="510" left="202" width="112" height="13" font="1">sequential version.</text>
<text top="528" left="220" width="479" height="13" font="1">Yu et al. [49] implemented the ﬁrst real cellular EA using GPU, for solving the</text>
<text top="546" left="202" width="498" height="13" font="1">Colville minimization problem. They place the population in a toroidal 2D grid and</text>
<text top="564" left="202" width="497" height="13" font="1">use the classical Von Newmann neighborhood structure with ﬁve cells. They store</text>
<text top="582" left="202" width="498" height="13" font="1">chromosomes and their ﬁtness values in texture memory on the graphic card, and</text>
<text top="600" left="202" width="498" height="13" font="1">both, ﬁtness evaluation and genetic operations, are implemented entirely with frag-</text>
<text top="618" left="202" width="498" height="13" font="1">ment programs executed in parallel on GPU. Real-coded individuals of a population</text>
<text top="636" left="202" width="300" height="13" font="1">are represented as a set of 2D texture maps. <i>BLX</i></text>
<text top="635" left="506" width="12" height="15" font="12">−</text>
<text top="630" left="521" width="9" height="20" font="13">α</text>
<text top="636" left="536" width="164" height="13" font="1">crossover and non-uniform</text>
<text top="654" left="202" width="498" height="13" font="1">mutation are run as tiny programs on every pixel at each step in a SIMD-like fashion,</text>
<text top="671" left="202" width="497" height="13" font="1">solving some function optimization problems and reaching a speedup of x15 with</text>
<text top="689" left="202" width="497" height="13" font="1">a population of 512x512 individuals. They store a set of random numbers at the</text>
<text top="707" left="202" width="498" height="13" font="1">beginning of the evolution process to solve the random number generation problem</text>
<text top="725" left="202" width="173" height="13" font="1">when using GPU processors.</text>
<text top="743" left="220" width="480" height="13" font="1">Luo et al. [23] implemented a cellular algorithm on GPU to solve three different</text>
<text top="761" left="202" width="498" height="13" font="1">SAT problems using a greedy local search (GSAT) [41] and a cellular GA (cGA).</text>
<text top="779" left="202" width="498" height="13" font="1">They saved local minimums using a random walk strategy, jumping to other search</text>
<text top="797" left="202" width="498" height="13" font="1">space location. The cellular GA adopts a 2D toroidal grid, using the Moore neigh-</text>
<text top="815" left="202" width="498" height="13" font="1">borhood, stored on texture GPU memory. This implementation generates the ran-</text>
<text top="833" left="202" width="498" height="13" font="1">dom numbers in the GPU (using a generated seed on the CPU at the beginning of</text>
<text top="851" left="202" width="439" height="13" font="1">the process). The GPU version reduces in about 6 times the running time.</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="13" height="11" font="4">14</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="74" left="220" width="480" height="13" font="1">Li et al. [21] proposed a cellular algorithm on GPU for solving some common</text>
<text top="92" left="202" width="498" height="13" font="1">approximation functions. The authors reported experiments using big populations</text>
<text top="110" left="202" width="482" height="13" font="1">(up to 10000 individuals) reaching speedups of x73.6 for some implementations.</text>
<text top="127" left="220" width="480" height="13" font="1">In [22] the authors propose a ﬁne-grained parallel immune algorithm (FGIA)</text>
<text top="145" left="202" width="497" height="13" font="1">based on GPU acceleration, which maps parallel IA algorithm to GPU using CUDA.</text>
<text top="163" left="202" width="497" height="13" font="1">The results show that the proposed method (even increasing the population size)</text>
<text top="181" left="202" width="130" height="13" font="1">reduces running time.</text>
<text top="199" left="220" width="479" height="13" font="1">Alba et al. [45] use CUDA and store individuals and their ﬁtness values in the</text>
<text top="217" left="202" width="498" height="13" font="1">GPU global memory. Both, ﬁtness evaluation and genetic operators, are run on GPU</text>
<text top="235" left="202" width="497" height="13" font="1">(no CPU is used). They use a pseudo random number generator provided by the</text>
<text top="253" left="202" width="498" height="13" font="1">SDK of CUDA named Merseinne Twister. Their experiments include some gen-</text>
<text top="271" left="202" width="498" height="13" font="1">eral discrete and continuous optimization problems, and they compare physical ef-</text>
<text top="289" left="202" width="413" height="13" font="1">ﬁciency and numerical efﬁcacy with respect to CPU implementation.</text>
<text top="352" left="202" width="347" height="16" font="10"><i><b>4.3 Coarse-grained Approaches (island model)</b></i></text>
<text top="396" left="202" width="498" height="13" font="1">Coarse grained algorithms are the most common among parallel EAs. Generally,</text>
<text top="414" left="202" width="498" height="13" font="1">coarse-grained algorithms require less tightly coupled parallel architectures, as com-</text>
<text top="432" left="202" width="498" height="13" font="1">pared to ﬁne-grained. Coarse grained EAs divide the main population into sub-</text>
<text top="450" left="202" width="498" height="13" font="1">populations (also known as Islands) where the sub-populations evolve concurrently.</text>
<text top="468" left="202" width="424" height="13" font="1">This basic feature of coarse-grained EAs hits a physical limit of GPUs.</text>
<text top="486" left="220" width="480" height="13" font="1">In order to run a coarse-grained EA using a GPU, several kernels simultaneously</text>
<text top="504" left="202" width="498" height="13" font="1">are run where each kernel handles a sub-population is not possible. This limitation</text>
<text top="522" left="202" width="498" height="13" font="1">of GPU would mean the conventional mechanics of coarse-grained EAs would need</text>
<text top="540" left="202" width="223" height="13" font="1">to be changed if GPU would be used.</text>
<text top="558" left="220" width="480" height="13" font="1">With regard to the last topology (ﬁne-grained EAs), one of the ﬁrst island models</text>
<text top="576" left="202" width="498" height="13" font="1">on GPU approaches was published on the GPU competition of GECCO 2009 [35]. It</text>
<text top="594" left="202" width="497" height="13" font="1">presents some technical details of an island model entirely hard-coded on GPU, with</text>
<text top="612" left="202" width="498" height="13" font="1">a ring-like topology. Nevertheless, the evolutionary operators implemented on GPU</text>
<text top="630" left="202" width="498" height="13" font="1">are only speciﬁc to the GECCO competition, and the validity of the experiments just</text>
<text top="647" left="202" width="231" height="13" font="1">works on a small number of problems.</text>
<text top="665" left="220" width="480" height="13" font="1">Tsutsui et al. [43] propose run a coarse-grained GA on GPU to solve the quadratic</text>
<text top="683" left="202" width="498" height="13" font="1">assignment problem (QAP) using CUDA. This is one of the hardest optimization</text>
<text top="701" left="202" width="498" height="13" font="1">problems in permutation domains. Their model generates the initial population on</text>
<text top="719" left="202" width="498" height="13" font="1">CPU and copied it to the GPU VRAM; then, each subpopulation in a GPU (NVIDIA</text>
<text top="737" left="202" width="498" height="13" font="1">GeForce GTX285) is evolved. At some generations, individuals in subpopulations</text>
<text top="755" left="202" width="498" height="13" font="1">are shufﬂed via the GPU VRAM. Results showed a speedup from x3 to x12 (using</text>
<text top="773" left="202" width="368" height="13" font="1">eight QAP instances), compared to the Intel i7 965 processor.</text>
<text top="791" left="220" width="480" height="13" font="1">The model by Luong et al. [25] is based on a re-design of the island model.</text>
<text top="809" left="202" width="498" height="13" font="1">Three different schemes are proposed: The ﬁrst one implements a coarse-grained</text>
<text top="827" left="202" width="498" height="13" font="1">EA using a master-slave model to run the evaluation step on GPU. The second one</text>
<text top="845" left="202" width="498" height="13" font="1">distributes the EA population on GPUs, while the third proposal extends the second</text>
<text top="863" left="202" width="497" height="13" font="1">one using fast on-chip memory. Second and third approaches reduce the CPU/GPU</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="687" width="13" height="11" font="4">15</text>
<text top="74" left="202" width="498" height="13" font="1">memory latency, although their parameters (number of islands, migration topology,</text>
<text top="92" left="202" width="498" height="13" font="1">frequency and number of migrants) must be adapted to the GPU features. Sequential</text>
<text top="110" left="202" width="497" height="13" font="1">and parallel implementations are compared, obtaining a speedup of x1757 using the</text>
<text top="127" left="202" width="91" height="13" font="1">third approach.</text>
<text top="145" left="220" width="480" height="13" font="1">Posp´ıchal et al. [37, 38] propose a parallel GA with island model running on</text>
<text top="163" left="202" width="498" height="13" font="1">GPU. The authors map threads to individuals, thus, threads-individuals can be syn-</text>
<text top="181" left="202" width="498" height="13" font="1">chronized easily in order to maintain data consistency, and on-chip hardware sched-</text>
<text top="199" left="202" width="497" height="13" font="1">uler can swiftly swap existing islands between multiprocessors to hide memory la-</text>
<text top="217" left="202" width="498" height="13" font="1">tency. Fast, shared memory within the multiprocessor is used to maintain popula-</text>
<text top="235" left="202" width="497" height="13" font="1">tions. Since the population size is limited to 16KB per island on most GPUs, if the</text>
<text top="253" left="202" width="497" height="13" font="1">population is larger, slower main memory has to be used. The migration process is</text>
<text top="271" left="202" width="498" height="13" font="1">based on an asynchronous unidirectional ring that requires an inter-island commu-</text>
<text top="289" left="202" width="497" height="13" font="1">nication (slower main memory has to be used). The authors report speedups up to</text>
<text top="307" left="202" width="487" height="13" font="1">7000 times higher on GPU compared to CPU sequential version of the algorithm.</text>
<text top="370" left="202" width="174" height="16" font="10"><i><b>4.4 Hybrid Approaches</b></i></text>
<text top="414" left="202" width="498" height="13" font="1">The hybrid model simply utilizes two or more of the master-slave, coarse-grained</text>
<text top="432" left="202" width="497" height="13" font="1">and ﬁne-grained in a hierarchical method. At the higher level, an island model al-</text>
<text top="450" left="202" width="498" height="13" font="1">gorithm runs while at the lower level the demes (another name for sub-populations)</text>
<text top="468" left="202" width="497" height="13" font="1">themselves are running in parallel (ﬁne-grained, master-slave or even another island</text>
<text top="486" left="202" width="498" height="13" font="1">model with high migration rates). Hybrid models are not the most common in legacy</text>
<text top="504" left="202" width="71" height="13" font="1">EAs due to:</text>
<text top="530" left="202" width="498" height="15" font="12">• The need for additional new parameters to account for a more complex topology</text>
<text top="549" left="220" width="56" height="13" font="1">structure.</text>
<text top="566" left="202" width="497" height="15" font="12">• The need for hierarchal parallel architectures to host hybrid algorithms, while</text>
<text top="585" left="220" width="341" height="13" font="1">such hierarchal parallel architectures are not so common.</text>
<text top="602" left="202" width="326" height="15" font="12">• The high complexity of programming such models.</text>
<text top="630" left="220" width="479" height="13" font="1">Nevertheless, for the GPUs, hybrid EAs are a perfect candidate to exploit the</text>
<text top="647" left="202" width="498" height="13" font="1">hierarchal memory and ﬂexible block sizing in GPUs by well structured populations.</text>
<text top="665" left="220" width="479" height="13" font="1">The design and implementation of a hybrid EA plus local search to solve MAX-</text>
<text top="683" left="202" width="498" height="13" font="1">SAT over GPUs was thoroughly discussed in [31]. Manuwar et al. uses a hierarchical</text>
<text top="701" left="202" width="498" height="13" font="1">algorithm of 2D structured sub-populations arranged as islands in a 2D grid. There-</text>
<text top="719" left="202" width="497" height="13" font="1">fore, each individual has 4 neighboring individuals (north, south, east and west)</text>
<text top="737" left="202" width="498" height="13" font="1">and each sub-population has 4 neighboring sub-populations (north, south, east and</text>
<text top="755" left="202" width="498" height="13" font="1">west). Instead of using a conventional algorithm for migration between the sub-</text>
<text top="773" left="202" width="497" height="13" font="1">populations, they introduced a new technique that they call diffusion. Diffusion is</text>
<text top="791" left="202" width="498" height="13" font="1">more suitable for implementation of cGAs based pGA over a GPU. In the proposed</text>
<text top="809" left="202" width="497" height="13" font="1">implementation, the host processor (CPU) acts as a controller while an nVidia Tesla</text>
<text top="827" left="202" width="498" height="13" font="1">C1060 GPU provides the required computational resources. All the conﬁgurations,</text>
<text top="845" left="202" width="497" height="13" font="1">memory allocations, initializations are performed over the host processor. After the</text>
<text top="863" left="202" width="498" height="13" font="1">initialization stage, data is transferred to the device and the code enters a loop. The</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="14" size="9" family="Times" color="#231f20"/>
<text top="42" left="202" width="13" height="11" font="4">16</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="74" left="202" width="497" height="13" font="1">loop keeps on repeating until the maximum number of generation criteria is satis-</text>
<text top="92" left="202" width="498" height="13" font="1">ﬁed. Results were collected over a system with nVidia Tesla C1060 GPU mounted</text>
<text top="110" left="202" width="198" height="13" font="1">on a motherboard with Intel <i>Core</i></text>
<text top="107" left="400" width="17" height="10" font="14"><i>T M</i></text>
<text top="110" left="418" width="59" height="13" font="11"><i>i</i>7 920@2</text>
<text top="118" left="477" width="223" height="7" font="12">.67<i>GH z </i>as the host CPU. C1060 have</text>
<text top="127" left="202" width="498" height="13" font="1">4GB of device memory, 30 streaming MultiProcessors (MPs), and the total number</text>
<text top="145" left="202" width="497" height="13" font="1">of processing cores is 240. The maximum amount of shared memory per block is</text>
<text top="163" left="202" width="498" height="13" font="1">16KB and clock rate is 1.30GHz. They compare the results of the algorithms over</text>
<text top="181" left="202" width="497" height="13" font="1">nVidia with several optimizations for local search, mutation, recombination, selec-</text>
<text top="199" left="202" width="498" height="13" font="1">tion and diffusion (migration) with different implementations using serial imple-</text>
<text top="217" left="202" width="498" height="13" font="1">mentation, OpenMP implementation over Intel and over Ultra Spark architectures.</text>
<text top="235" left="202" width="497" height="13" font="1">The found that the maximum speedup is for larger problems, and it is up to 25x if</text>
<text top="253" left="202" width="497" height="13" font="1">compared the serial implementation over Intel Core 2 Duo 3.3GHz (Sduo) with the</text>
<text top="271" left="202" width="145" height="13" font="1">NVidia implementation.</text>
<text top="334" left="202" width="425" height="16" font="10"><i><b>4.5 Artiﬁcial Neural Networks implementations on GPUs</b></i></text>
<text top="378" left="202" width="498" height="13" font="1">Artiﬁcial neural networks attempt to capture the adaptability of biological neurons</text>
<text top="396" left="202" width="498" height="13" font="1">in a mathematical model for information processing. ANNs are very powerful tools</text>
<text top="414" left="202" width="498" height="13" font="1">that are highly parallelizable but also computationally expensive and match well</text>
<text top="432" left="202" width="498" height="13" font="1">with the GPU computing architecture. As a workhorse of the computational intel-</text>
<text top="450" left="202" width="498" height="13" font="1">ligence ﬁeld, there exists a high demand for this acceleration. As a highly analytic</text>
<text top="468" left="202" width="498" height="13" font="1">structure, neural networks can be reduced to a series of matrix operations, and thus</text>
<text top="486" left="202" width="498" height="13" font="1">are easily parallelized, as the GPU is highly optimized to perform these kinds of</text>
<text top="504" left="202" width="95" height="13" font="1">operations [30].</text>
<text top="522" left="220" width="480" height="13" font="1">Several authors provide tips for ensuring efﬁcient implementation of algorithms</text>
<text top="540" left="202" width="158" height="13" font="1">on GPU’s [33, 24, 28, 29].</text>
<text top="558" left="220" width="480" height="13" font="1">Zhongwen uses the GPU to ﬁrst extract a set of characteristics from image data,</text>
<text top="576" left="202" width="460" height="13" font="1">then applies a pre-trained MLP to these characteristics for classiﬁcation [24].</text>
<text top="594" left="220" width="480" height="13" font="1">Bernhard [3] proposes a different approach, implementing spiking neural net-</text>
<text top="612" left="202" width="185" height="13" font="1">works for image segmentation.</text>
<text top="630" left="220" width="480" height="13" font="1">In general, signiﬁcant performance gains can be elicited from implementing neu-</text>
<text top="647" left="202" width="498" height="13" font="1">ral network algorithms on graphics processing units. However, these implementa-</text>
<text top="665" left="202" width="162" height="13" font="1">tions are difﬁcult to obtain.</text>
<text top="683" left="220" width="479" height="13" font="1">Finally, several developers provide libraries and tools to help practitioners to</text>
<text top="701" left="202" width="242" height="13" font="1">develop ANN applications on GPUs [4].</text>
<text top="765" left="202" width="109" height="16" font="3"><b>5 Conclusions</b></text>
<text top="809" left="202" width="498" height="13" font="1">Parallel EAs have been using traditional clusters and MPP for over two decades.</text>
<text top="827" left="202" width="498" height="13" font="1">However, in this decade other architectures like GPUs are becoming increasingly</text>
<text top="845" left="202" width="498" height="13" font="1">adopted for general purpose parallel processing. As the legacy parallel EAs were not</text>
<text top="863" left="202" width="498" height="13" font="1">designed mainly for data-parallel architectures, current implementations of parallel</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="687" width="13" height="11" font="4">17</text>
<text top="74" left="202" width="498" height="13" font="1">EAs, if ported with outchange, show minor performance gains even with the high</text>
<text top="92" left="202" width="125" height="13" font="1">throughput of GPUs.</text>
<text top="110" left="220" width="479" height="13" font="1">In this chapter we have reviewed the use of GPUs to implement bioinspired al-</text>
<text top="127" left="202" width="498" height="13" font="1">gorithms to solve optimization problems. We have commented the GPU comput-</text>
<text top="145" left="202" width="498" height="13" font="1">ing general approach, and given an overview of currently usable programming lan-</text>
<text top="163" left="202" width="159" height="13" font="1">guages and software tools.</text>
<text top="181" left="220" width="480" height="13" font="1">Most of the bio-inspired methods use the GPU mainly to speed up just the ﬁtness</text>
<text top="199" left="202" width="498" height="13" font="1">evaluation (usually the most time-expensive process). In most of the EC approaches,</text>
<text top="217" left="202" width="498" height="13" font="1">competition and selection are performed by CPU, while ﬁtness evaluation, mutation</text>
<text top="235" left="202" width="497" height="13" font="1">and reproduction are performed on GPU (which is a massively parallel machine with</text>
<text top="253" left="202" width="498" height="13" font="1">shared memory). GPU allows processors to communicate with any other processors</text>
<text top="271" left="202" width="484" height="13" font="1">directly, thus more ﬂexible ﬁne-grained algorithms can be implemented on GPU.</text>
<text top="289" left="220" width="480" height="13" font="1">In general, approaches found in literature obtain speedups up to several thousands</text>
<text top="307" left="202" width="498" height="13" font="1">times higher on GPU compared to CPU sequential versions of the same algorithms.</text>
<text top="325" left="220" width="479" height="13" font="1">However, as the programming tools improve, newer EC approaches run the</text>
<text top="343" left="202" width="485" height="13" font="1">whole optimization algorithm on the GPU side, with no need of CPU interaction.</text>
<text top="385" left="202" width="497" height="11" font="7"><b>Acknowledgements </b>This work has been supported in part by the CEI BioTIC GENIL (CEB09-</text>
<text top="399" left="202" width="498" height="11" font="4">0010) MICINN CEI Program (PYR-2010-13 and PYR-2010-29) project, UGR PR-PP2011-5, the</text>
<text top="414" left="202" width="497" height="11" font="4">Junta de Andaluc´ıa TIC-3903 and P08-TIC-03928 projects, and the Ja´en University UJA-08-16-30</text>
<text top="429" left="202" width="38" height="11" font="4">project.</text>
<text top="444" left="220" width="479" height="11" font="4">The authors are very grateful to the anonymous referees whose comments and suggestions have</text>
<text top="459" left="202" width="180" height="11" font="4">contributed to improve this chapter.</text>
<text top="521" left="202" width="83" height="16" font="3"><b>References</b></text>
<text top="564" left="208" width="449" height="11" font="4">1. Alba, E.: Parallel Metaheuristics: A New Class of Algorithms. Wiley (2005). URL</text>
<text top="564" left="661" width="38" height="10" font="6">http:</text>
<text top="579" left="226" width="457" height="10" font="6">//eu.wiley.com/WileyCDA/WileyTitle/productCd-0471678066.html</text>
<text top="579" left="682" width="3" height="11" font="4">.</text>
<text top="594" left="226" width="134" height="11" font="4">ISBN: 978-0-471-67806-9</text>
<text top="609" left="208" width="491" height="11" font="4">2. Alba, E., Nebro, A.J., Luna, F.: Advances in parallel heterogeneous genetic algorithms for</text>
<text top="624" left="226" width="474" height="11" font="4">continuous optimization. International Journal of Applied Mathematics and Computer Science</text>
<text top="638" left="226" width="115" height="11" font="7"><b>14</b>(3), 101–117 (2004)</text>
<text top="653" left="208" width="491" height="11" font="4">3. Bernhard, F., Keriven, R.: Spiking neurons on gpus. In International Conference on Com-</text>
<text top="668" left="226" width="474" height="11" font="4">putational Science. Workshop General purpose computation on graphics hardware (GPGPU):</text>
<text top="683" left="226" width="301" height="11" font="4">Methods, algorithms and applications, Reading, UK (2006)</text>
<text top="698" left="208" width="67" height="11" font="4">4. billconan,</text>
<text top="698" left="307" width="50" height="11" font="4">kavinguy:</text>
<text top="698" left="389" width="22" height="11" font="4">Ann</text>
<text top="698" left="443" width="41" height="11" font="4">libraries</text>
<text top="698" left="516" width="10" height="11" font="4">to</text>
<text top="698" left="557" width="39" height="11" font="4">develop</text>
<text top="698" left="628" width="13" height="11" font="4">on</text>
<text top="698" left="672" width="27" height="11" font="4">gpus.</text>
<text top="713" left="226" width="323" height="11" font="4">http://www.codeproject.com/KB/graphics/GPUNN.aspx (2011)</text>
<text top="728" left="208" width="491" height="11" font="4">5. Buck, I., Foley, T., Horn, D., Sugerman, J., Fatahalian, K., Houston, M., Hanrahan, P.: Brook</text>
<text top="743" left="226" width="474" height="11" font="4">for gpus: stream computing on graphics hardware. ACM Trans. Graph. <b>23</b>, 777–786 (2004).</text>
<text top="758" left="226" width="262" height="11" font="4">DOI http://doi.acm.org/10.1145/1015706.1015800.</text>
<text top="758" left="501" width="25" height="11" font="4">URL</text>
<text top="759" left="532" width="167" height="10" font="6">http://doi.acm.org/10.</text>
<text top="774" left="226" width="151" height="10" font="6">1145/1015706.1015800</text>
<text top="788" left="208" width="491" height="11" font="4">6. Cant ´u-Paz, E.: A survey of parallel genetic algorithms. CALCULATEURS PARALLELES,</text>
<text top="803" left="226" width="251" height="11" font="4">RESEAUX ET SYSTEMS REPARTIS <b>10 </b>(1998)</text>
<text top="818" left="208" width="491" height="11" font="4">7. Cotta, C., g. Talbi, E., Alba, E.: E.: Parallel hybrid metaheuristics. In: Parallel Metaheuristics,</text>
<text top="833" left="226" width="308" height="11" font="4">a New Class of Algorithms, pp. 347–370. John Wiley (2005)</text>
<text top="848" left="208" width="476" height="11" font="4">8. Crainic, T.G., Gendreau, M.: Towards a taxonomy of parallel tabu search heuristics (1997)</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="13" height="11" font="4">18</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="75" left="208" width="491" height="11" font="4">9. Dorigo, M., Di Caro, G.: The ant colony optimization meta-heuristic, pp. 11–32. McGraw-Hill</text>
<text top="90" left="226" width="264" height="11" font="4">Ltd., UK, Maidenhead, UK, England (1999). URL</text>
<text top="91" left="494" width="205" height="10" font="6">http://dl.acm.org/citation.</text>
<text top="106" left="226" width="151" height="10" font="6">cfm?id=329055.329062</text>
<text top="120" left="202" width="497" height="11" font="4">10. Fan, Z., Qiu, F., Kaufman, A., Yoakum-Stover, S.: Gpu cluster for high performance comput-</text>
<text top="135" left="226" width="473" height="11" font="4">ing. SC Conference <b>0</b>, 47 (2004). DOI http://doi.ieeecomputersociety.org/10.1109/SC.2004.</text>
<text top="150" left="226" width="13" height="11" font="4">26</text>
<text top="165" left="202" width="497" height="11" font="4">11. Fern´andez, F., Tomassini, M., Vanneschi, L.: An empirical study of multipopulation genetic</text>
<text top="180" left="226" width="433" height="11" font="4">programming. Genetic Programming and Evolvable Machines <b>4</b>, 21–51 (2003). URL</text>
<text top="180" left="662" width="38" height="10" font="6">http:</text>
<text top="195" left="226" width="273" height="10" font="6">//dx.doi.org/10.1023/A:1021873026259</text>
<text top="195" left="499" width="148" height="11" font="4">. 10.1023/A:1021873026259</text>
<text top="210" left="202" width="497" height="11" font="4">12. Garc´ıa-L´opez, F., Meli´an-Batista, B., Moreno-P´erez, J.A., Moreno-Vega, J.M.: Paralleliza-</text>
<text top="224" left="226" width="474" height="11" font="4">tion of the scatter search for the p-median problem. Parallel Computing <b>29</b>(5), 575 – 589</text>
<text top="240" left="226" width="279" height="11" font="4">(2003). DOI 10.1016/S0167-8191(03)00043-7. URL</text>
<text top="240" left="509" width="189" height="10" font="6">http://www.sciencedirect.</text>
<text top="255" left="226" width="311" height="10" font="6">com/science/article/pii/S0167819103000437</text>
<text top="255" left="537" width="163" height="11" font="4">. ¡ce:title¿Parallel computing in</text>
<text top="269" left="226" width="90" height="11" font="4">logistics¡/ce:title¿</text>
<text top="284" left="202" width="497" height="11" font="4">13. Garc´ıa-l ´opez, F., Meli´an-batista, B., Moreno-p´erez, J.A., Moreno-vega, J.M.: The parallel</text>
<text top="299" left="226" width="474" height="11" font="4">variable neighborhood search for the p-median problem. Journal of Heuristics <b>8</b>, 200–2 (2004)</text>
<text top="314" left="202" width="497" height="11" font="4">14. Genetic, D.B., Miki, M., Hiroyasu, T., Yoshida, T., Fushimi, T.: Parallel simulated annealing</text>
<text top="329" left="226" width="474" height="11" font="4">with adaptive temperature. In: Proceedings of IEEE International Conference on Systems,</text>
<text top="344" left="226" width="218" height="11" font="4">Man and Cybernetics 2002, pp. 1–6 (2002)</text>
<text top="359" left="202" width="498" height="11" font="4">15. Glover, F., Laguna, M.: Tabu Search. Kluwer Academic Publishers, Norwell, MA, USA</text>
<text top="374" left="226" width="34" height="11" font="4">(1997)</text>
<text top="389" left="202" width="497" height="11" font="4">16. Harding, S., Banzhaf, W.: Fast genetic programming and artiﬁcial developmental systems on</text>
<text top="404" left="226" width="474" height="11" font="4">gpus. In: High Performance Computing Systems and Applications, 2007. HPCS 2007. 21st</text>
<text top="419" left="226" width="207" height="11" font="4">International Symposium on, p. 2 (2007)</text>
<text top="434" left="202" width="497" height="11" font="4">17. Illinois, U.: The LLVM Compiler Infrastructure. University of Illinois at Urbana-Champaign.</text>
<text top="449" left="226" width="110" height="11" font="4">http://llvm.org (2011)</text>
<text top="464" left="202" width="497" height="11" font="4">18. Janson, S., Merkle, D., Middendorf, M.: Parallel ant colony algorithms. Tech. rep., Parallel</text>
<text top="479" left="226" width="413" height="11" font="4">Metaheuristics, Wiley Book Series on Parallel and Distributed Computing (2005)</text>
<text top="494" left="202" width="497" height="11" font="4">19. Koomey, J.G., Berard, S., Sanchez, M., Wong, H.: Implications of historical trends in the elec-</text>
<text top="509" left="226" width="474" height="11" font="4">trical efﬁciency of computing. IEEE Annals of the History of Computing <b>33</b>, 46–54 (2011).</text>
<text top="523" left="226" width="329" height="11" font="4">DOI http://doi.ieeecomputersociety.org/10.1109/MAHC.2010.28</text>
<text top="538" left="202" width="497" height="11" font="4">20. Li, J., Wang, X., He, R., Chi, Z.: An efﬁcient ﬁne-grained parallel genetic algorithm based on</text>
<text top="553" left="226" width="474" height="11" font="4">GPU-Accelerated. In: Network and Parallel Computing Workshops, 2007. NPC Workshops.</text>
<text top="568" left="226" width="306" height="11" font="4">IFIP International Conference on, pp. 855–862 (2007). DOI</text>
<text top="567" left="534" width="133" height="13" font="5">{10.1109/NPC.2007.108}</text>
<text top="583" left="202" width="497" height="11" font="4">21. Li, J., Wang, X., He, R., Chi, Z.: An efﬁcient ﬁne-grained parallel genetic algorithm based on</text>
<text top="598" left="226" width="474" height="11" font="4">GPU-Accelerated. In: Network and Parallel Computing Workshops, 2007. NPC Workshops.</text>
<text top="613" left="226" width="275" height="11" font="4">IFIP International Conference on, pp. 855–862 (2007)</text>
<text top="628" left="202" width="498" height="11" font="4">22. Li, J., Zhang, L., Liu, L.: A parallel immune algorithm based on ﬁne-grained model with</text>
<text top="643" left="226" width="474" height="11" font="4">gpu-acceleration. In: Proceedings of the 2009 Fourth International Conference on Innova-</text>
<text top="658" left="226" width="474" height="11" font="4">tive Computing, Information and Control, ICICIC ’09, pp. 683–686. IEEE Computer Soci-</text>
<text top="673" left="226" width="474" height="11" font="4">ety, Washington, DC, USA (2009). DOI http://dx.doi.org/10.1109/ICICIC.2009.44. URL</text>
<text top="688" left="226" width="304" height="10" font="6">http://dx.doi.org/10.1109/ICICIC.2009.44</text>
<text top="703" left="202" width="497" height="11" font="4">23. Luo, Z., Liu, H.: Cellular genetic algorithms and local search for 3-SAT problem on graphic</text>
<text top="718" left="226" width="259" height="11" font="4">hardware. In: IEEE CEC06, pp. 2988–2992 (2006)</text>
<text top="733" left="202" width="497" height="11" font="4">24. Luo, Z., Liu, H., X.Wu: Artiﬁcial neural network computation on graphic process unit. Pro-</text>
<text top="748" left="226" width="474" height="11" font="4">ceedings of the 2005 IEEE International Joint Conference on Neural Networks, vol. 1, pp.622-</text>
<text top="763" left="226" width="174" height="11" font="4">626, ISBN: 0-7803-9048-2 (2005)</text>
<text top="777" left="202" width="497" height="11" font="4">25. Luong, T.V., Melab, N., Talbi, E.G.: GPU-based Island Model for Evolutionary Algorithms.</text>
<text top="792" left="226" width="451" height="11" font="4">In: Genetic and Evolutionary Computation Conference (GECCO). Portland, USA (2010)</text>
<text top="807" left="202" width="497" height="11" font="4">26. Madera, J., Alba, E., Ochoa, A.: A parallel island model for estimation of distribution algo-</text>
<text top="822" left="226" width="474" height="11" font="4">rithms. In: J. Lozano, P. Larra´naga, I. Inza, E. Bengoetxea (eds.) Towards a New Evolutionary</text>
<text top="837" left="226" width="474" height="11" font="4">Computation, <i>Studies in Fuzziness and Soft Computing</i>, vol. 192, pp. 159–186. Springer Berlin</text>
<text top="852" left="226" width="100" height="11" font="4">/ Heidelberg (2006)</text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="15" size="10" family="Symbol" color="#231f20"/>
<text top="42" left="202" width="328" height="11" font="4">GPU Parallel Computation in Bioinspired Algorithms. A review.</text>
<text top="42" left="687" width="13" height="11" font="4">19</text>
<text top="75" left="202" width="497" height="11" font="4">27. Maitre, O., Baumes, L.A., Lachiche, N., Corma, A., Collet, P.: Coarse grain parallelization</text>
<text top="90" left="226" width="290" height="11" font="4">of evolutionary algorithms on gpgpu cards with easea.</text>
<text top="90" left="528" width="172" height="11" font="4">In: Proceedings of the 11th An-</text>
<text top="105" left="226" width="474" height="11" font="4">nual conference on Genetic and evolutionary computation, GECCO ’09, pp. 1403–1410.</text>
<text top="120" left="226" width="474" height="11" font="4">ACM, New York, NY, USA (2009). DOI http://doi.acm.org/10.1145/1569901.1570089. URL</text>
<text top="136" left="226" width="319" height="10" font="6">http://doi.acm.org/10.1145/1569901.1570089</text>
<text top="149" left="202" width="497" height="11" font="4">28. Martinez-Zarzuela, M., , Diaz-Pernas, F., Diez, J., Anton, M.: Fuzzy art neural network paral-</text>
<text top="164" left="226" width="297" height="11" font="4">lel computing on the gpu. LNCS 4507, pp.463-470 (2007)</text>
<text top="179" left="202" width="497" height="11" font="4">29. Martinez-Zarzuela, M., , Diaz-Pernas, F., Diez, J., Anton, M., Gonzalez, D., Boto, D., Lopez,</text>
<text top="194" left="226" width="474" height="11" font="4">F., DelaTorre, I.: Multi-scale neural texture classiﬁcation using the gpu as a stream processing</text>
<text top="208" left="226" width="309" height="11" font="4">engine. Machine Vision and Applicactions, (In press) (2010)</text>
<text top="223" left="202" width="497" height="11" font="4">30. Meuth, R.J., Wunsch, D.C.: A survey of neural computation on graphics processing hardware.</text>
<text top="238" left="226" width="474" height="11" font="4">IEEE 22nd International Symposium on Intelligent Control (ISIC 2007). pp. 524 - 527, ISSN</text>
<text top="253" left="226" width="230" height="11" font="4">1085-1992, ISBN 978-1-4244-0441-4 (2007)</text>
<text top="267" left="202" width="497" height="11" font="4">31. Munawar, A., Wahib, M., Munetomo, M., Akama, K.: Hybrid of genetic algorithm and local</text>
<text top="282" left="226" width="474" height="11" font="4">search to solve max-sat problem using nvidia cuda framework. Genetic Programming and</text>
<text top="297" left="226" width="207" height="11" font="4">Evolvable Machines <b>10</b>, 391–415 (2009)</text>
<text top="311" left="202" width="497" height="11" font="4">32. Nebro, A.J., Durillo, J.J., Luna, F., Dorronsoro, B., Alba, E.: Mocell: A cellular genetic algo-</text>
<text top="326" left="226" width="474" height="11" font="4">rithm for multiobjective optimization. International Journal of Intelligent Systems pp. 25–36</text>
<text top="341" left="226" width="34" height="11" font="4">(2007)</text>
<text top="356" left="202" width="497" height="11" font="4">33. Oh, K.S., Jung, K.: Gpu implementation of neural networks. Pattern Recognition, vol. 37, n.6,</text>
<text top="371" left="226" width="111" height="11" font="4">pp. 1311-1314 (2004)</text>
<text top="385" left="202" width="497" height="11" font="4">34. Parejo, J., Ruiz-Cort´es, A., Lozano, S., Fernandez, P.: Metaheuristic optimization frame-</text>
<text top="400" left="226" width="200" height="11" font="4">works: a survey and benchmarking.</text>
<text top="400" left="447" width="252" height="11" font="4">Soft Computing - A Fusion of Foundations,</text>
<text top="415" left="226" width="229" height="11" font="4">Methodologies and Applications pp. 1–35.</text>
<text top="415" left="470" width="25" height="11" font="4">URL</text>
<text top="415" left="501" width="197" height="10" font="6">http://dx.doi.org/10.1007/</text>
<text top="430" left="226" width="131" height="10" font="6">s00500-011-0754-8</text>
<text top="430" left="356" width="153" height="11" font="4">. 10.1007/s00500-011-0754-8</text>
<text top="444" left="202" width="498" height="11" font="4">35. Pospichal, P., Jaros., J.: Gpu-based acceleration of the genetic algorithm. Tech. rep., GECOO</text>
<text top="459" left="226" width="97" height="11" font="4">competition (2009)</text>
<text top="473" left="202" width="497" height="11" font="4">36. Pospichal, P., Jaros, J., Schwarz, J.: Parallel genetic algorithm on the cuda architecture. In:</text>
<text top="488" left="226" width="474" height="11" font="4">C. Di Chio, S. Cagnoni, C. Cotta, M. Ebner, A. Ek´art, A. Esparcia-Alcazar, C.K. Goh,</text>
<text top="503" left="226" width="139" height="11" font="4">J. Merelo, F. Neri, M. <i>Preu</i></text>
<text top="499" left="364" width="7" height="17" font="15">β</text>
<text top="503" left="373" width="327" height="11" font="4">, J. Togelius, G. Yannakakis (eds.) Applications of Evolutionary</text>
<text top="518" left="226" width="474" height="11" font="4">Computation, <i>Lecture Notes in Computer Science</i>, vol. 6024, pp. 442–451. Springer Berlin /</text>
<text top="533" left="226" width="93" height="11" font="4">Heidelberg (2010)</text>
<text top="548" left="202" width="497" height="11" font="4">37. Posp´ıchal, P., Jaros, J., Schwarz, J.: Parallel genetic algorithm on the cuda architecture. In:</text>
<text top="563" left="226" width="474" height="11" font="4">C.D.C. et al. (ed.) Applications of Evolutionary Computation, <i>Lecture Notes in Computer</i></text>
<text top="577" left="226" width="351" height="11" font="8"><i>Science</i>, vol. 6024, pp. 442–451. Springer Berlin / Heidelberg (2010)</text>
<text top="592" left="202" width="497" height="11" font="4">38. Posp´ıchal, P., Schwarz, J., Jaroˇs, J.: Parallel genetic algorithm solving 0/1 knapsack problem</text>
<text top="607" left="226" width="474" height="11" font="4">running on the gpu. In: 16th International Conference on Soft Computing MENDEL 2010,</text>
<text top="622" left="226" width="252" height="11" font="4">pp. 64–70. Brno University of Technology (2010)</text>
<text top="636" left="202" width="497" height="11" font="4">39. Resende, M.G.C., Ribeiro, C.C.: Parallel greedy randomized adaptive search procedures</text>
<text top="651" left="226" width="34" height="11" font="4">(2004)</text>
<text top="665" left="202" width="497" height="11" font="4">40. Rudolph, G.: Parallel approaches to stochastic global optimization. In: In Parallel Computing:</text>
<text top="680" left="226" width="474" height="11" font="4">From Theory to Sound Practice, W. Joosen and E. Milgrom, Eds., IOS, pp. 256–267. IOS</text>
<text top="695" left="226" width="63" height="11" font="4">Press (1992)</text>
<text top="710" left="202" width="497" height="11" font="4">41. Selman, B., Kautz, H.: Domain-independent extensions to gsat: Solving large structured sat-</text>
<text top="725" left="226" width="317" height="11" font="4">isﬁability problems. In: PROC. IJCAI-93, pp. 290–295 (1993)</text>
<text top="739" left="202" width="497" height="11" font="4">42. Thompson, C.J., Hahn, S., Oskin, M.: Using modern graphics architectures for general-</text>
<text top="754" left="226" width="474" height="11" font="4">purpose computing: a framework and analysis. In: Proceedings of the 35th annual ACM/IEEE</text>
<text top="769" left="226" width="474" height="11" font="4">international symposium on Microarchitecture, MICRO 35, pp. 306–317. IEEE Computer</text>
<text top="784" left="226" width="259" height="11" font="4">Society Press, Los Alamitos, CA, USA (2002).</text>
<text top="784" left="500" width="25" height="11" font="4">URL</text>
<text top="784" left="532" width="167" height="10" font="6">http://portal.acm.org/</text>
<text top="799" left="226" width="220" height="10" font="6">citation.cfm?id=774861.774894</text>
<text top="813" left="202" width="498" height="11" font="4">43. Tsutsui, S., Fujimoto, N.: Solving quadratic assignment problems by genetic algorithms with</text>
<text top="828" left="226" width="443" height="11" font="4">gpu computation: a case study. In: GECCO09, pp. 2523–2530. ACM, NY, USA (2009)</text>
<text top="842" left="202" width="497" height="11" font="4">44. Tsutsui, S., Fujimoto, N.: Aco with tabu search on a gpu for solving qaps using move-cost</text>
<text top="857" left="226" width="474" height="11" font="4">adjusted thread assignment. In: N. Krasnogor, P.L. Lanzi, A. Engelbrecht, D. Pelta, C. Ger-</text>
<text top="872" left="226" width="474" height="11" font="4">shenson, G. Squillero, A. Freitas, M. Ritchie, M. Preuss, C. Gagne, Y.S. Ong, G. Raidl,</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1188" width="918">
<text top="42" left="202" width="13" height="11" font="4">20</text>
<text top="42" left="606" width="94" height="11" font="4">M.G. Arenas et al.</text>
<text top="75" left="226" width="474" height="11" font="4">M. Gallager, J. Lozano, C. Coello-Coello, D.L. Silva, N. Hansen, S. Meyer-Nieberg, J. Smith,</text>
<text top="90" left="226" width="474" height="11" font="4">G. Eiben, E. Bernado-Mansilla, W. Browne, L. Spector, T. Yu, J. Clune, G. Hornby, M.L.</text>
<text top="105" left="226" width="474" height="11" font="4">Wong, P. Collet, S. Gustafson, J.P. Watson, M. Sipper, S. Poulding, G. Ochoa, M. Schoenauer,</text>
<text top="120" left="226" width="474" height="11" font="4">C. Witt, A. Auger (eds.) GECCO ’11: Proceedings of the 13th annual conference on Genetic</text>
<text top="135" left="226" width="390" height="11" font="4">and evolutionary computation, pp. 1547–1554. ACM, Dublin, Ireland (2011)</text>
<text top="150" left="202" width="497" height="11" font="4">45. Vidal, P., Alba, E.: Cellular genetic algorithm on graphic processing units. In: J.G. et al. (ed.)</text>
<text top="165" left="226" width="474" height="11" font="4">Nature Inspired Cooperative Strategies for Optimization (NICSO 2010), <i>Studies in Computa-</i></text>
<text top="180" left="226" width="398" height="11" font="8"><i>tional Intelligence</i>, vol. 284, pp. 223–232. Springer Berlin / Heidelberg (2010)</text>
<text top="195" left="202" width="497" height="11" font="4">46. Wong, M., Wong, T.: Parallel hybrid genetic algorithms on Consumer-Level graphics hard-</text>
<text top="210" left="226" width="237" height="11" font="4">ware. In: IEEE CEC06, pp. 2973–2980 (2006)</text>
<text top="224" left="202" width="497" height="11" font="4">47. Wong, M., Wong, T.: Implementation of parallel genetic algorithms on graphics processing</text>
<text top="240" left="226" width="474" height="11" font="4">units. In: M.G. et al. (ed.) Intelligent and Evolutionary Systems, <i>Studies in Computational</i></text>
<text top="255" left="226" width="365" height="11" font="8"><i>Intelligence</i>, vol. 187, pp. 197–216. Springer Berlin / Heidelberg (2009)</text>
<text top="269" left="202" width="497" height="11" font="4">48. Wong, M., Wong, T., Fok, K.: Parallel evolutionary algorithms on graphics processing unit.</text>
<text top="284" left="226" width="273" height="11" font="4">In: IEEE CEC05, vol. 3, pp. 2286–2293 Vol. 3 (2005)</text>
<text top="299" left="202" width="497" height="11" font="4">49. Yu, Q., Chen, C., Pan, Z.: Parallel genetic algorithms on programmable graphics hardware.</text>
<text top="314" left="226" width="474" height="11" font="4">In: L.W. et al. (ed.) Advances in Natural Computation, <i>Lecture Notes in Computer Science</i>,</text>
<text top="329" left="226" width="318" height="11" font="4">vol. 3612, pp. 1051–1059. Springer Berlin / Heidelberg (2005)</text>
<text top="344" left="202" width="497" height="11" font="4">50. Zhang, S., He, Z.: Implementation of parallel genetic algorithm based on cuda. In: Z. Cai,</text>
<text top="359" left="226" width="474" height="11" font="4">Z. Li, Z. Kang, Y. Liu (eds.) Advances in Computation and Intelligence, <i>Lecture Notes in</i></text>
<text top="374" left="226" width="392" height="11" font="8"><i>Computer Science</i>, vol. 5821, pp. 24–30. Springer Berlin / Heidelberg (2009)</text>
<text top="389" left="202" width="497" height="11" font="4">51. Zhang, S., He, Z.: Implementation of parallel genetic algorithm based on cuda. In: Z.C. et al.</text>
<text top="404" left="226" width="474" height="11" font="4">(ed.) Advances in Computation and Intelligence, <i>Lecture Notes in Computer Science</i>, vol.</text>
<text top="419" left="226" width="270" height="11" font="4">5821, pp. 24–30. Springer Berlin / Heidelberg (2009)</text>
</page>
</pdf2xml>
