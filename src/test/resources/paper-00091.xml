<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="0" size="25" family="Times" color="#000000"/>
	<fontspec id="1" size="13" family="Times" color="#000000"/>
	<fontspec id="2" size="7" family="Times" color="#000000"/>
	<fontspec id="3" size="7" family="Times" color="#000000"/>
	<fontspec id="4" size="13" family="Times" color="#000000"/>
	<fontspec id="5" size="13" family="Times" color="#0000ff"/>
	<fontspec id="6" size="13" family="Times" color="#000000"/>
	<fontspec id="7" size="13" family="Times" color="#000000"/>
	<fontspec id="8" size="13" family="Times" color="#000000"/>
	<fontspec id="9" size="10" family="Helvetica" color="#000000"/>
<text top="125" left="137" width="652" height="30" font="0"><b>Rapid CT reconstruction on GPU-enabled HPC clusters </b></text>
<text top="174" left="139" width="90" height="17" font="1"><b>D. Thompson </b></text>
<text top="172" left="230" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="235" width="110" height="17" font="1"><b>, Ya. I. Nesterets </b></text>
<text top="172" left="344" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="349" width="97" height="17" font="1"><b>, T.E. Gureyev </b></text>
<text top="172" left="446" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="451" width="103" height="17" font="1"><b>, A. Sakellariou </b></text>
<text top="172" left="554" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="559" width="100" height="17" font="1"><b>, A. Khassapov </b></text>
<text top="172" left="659" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="664" width="112" height="17" font="1"><b>, and J.A. Taylor </b></text>
<text top="172" left="776" width="5" height="11" font="2"><b>a</b></text>
<text top="174" left="780" width="4" height="17" font="1"><b> </b></text>
<text top="207" left="139" width="7" height="11" font="3"><i>a </i></text>
<text top="209" left="147" width="638" height="17" font="4"><i>Commonwealth Scientific and Industrial Research Organisation (CSIRO), Private Bag 33, Clayton South </i></text>
<text top="226" left="379" width="166" height="17" font="4"><i>MDC, VIC 3169, Australia </i></text>
<text top="244" left="355" width="45" height="17" font="4"><i>Email: </i></text>
<text top="244" left="399" width="166" height="17" font="5"><i>darren.thompson@csiro.au</i></text>
<text top="244" left="565" width="4" height="17" font="4"><i> </i></text>
<text top="279" left="135" width="656" height="17" font="1"><b>Abstract:  </b>Computed Tomography (CT) reconstruction is a computationally and data-intensive process </text>
<text top="296" left="135" width="657" height="17" font="6">applied across many fields of scientific endeavor, including medical and materials science, as a non- </text>
<text top="313" left="135" width="654" height="17" font="6">invasive imaging technique. A typical CT dataset obtained with a CCD-based X-ray detector, such as that at </text>
<text top="332" left="135" width="228" height="17" font="6">the Australian Synchrotron with 4K</text>
<text top="331" left="363" width="429" height="20" font="6">×4K pixels captured over multiple-view angles, is in the order of </text>
<text top="349" left="135" width="656" height="17" font="6">128GB. The reconstructed output volume is in the order 256GB. CT data sizes increase at 1.5 times the </text>
<text top="366" left="135" width="656" height="17" font="6">number of pixels in the detector, while the data-processing load generally increases as the square of the </text>
<text top="383" left="135" width="655" height="17" font="6">number of pixels, hence data storage, management and throughput capabilities become paramount. From a </text>
<text top="401" left="135" width="654" height="17" font="6">computational perspective, CT reconstruction is particularly well suited to mass parallelisation whereby the </text>
<text top="418" left="135" width="660" height="17" font="6">problem can be decomposed into many smaller independent parts. We have achieved significant </text>
<text top="435" left="135" width="655" height="17" font="6">performance gains by adapting our XLI software algorithms to a two-level parallelisation scheme, utilising </text>
<text top="452" left="135" width="654" height="17" font="6">multiple CPU cores and multiple GPUs on a single machine. In turn, where data sizes become prohibitively </text>
<text top="470" left="135" width="656" height="17" font="6">large to be processed on a single machine, we have developed an integrated CT reconstruction software </text>
<text top="487" left="135" width="654" height="17" font="6">system that is able to scale up and be deployed onto large GPU-enabled HPC clusters. We present here the </text>
<text top="504" left="135" width="655" height="17" font="6">results of reconstructing large CT datasets using our XLI software on both the CSIRO GPU cluster and the </text>
<text top="521" left="135" width="656" height="17" font="6">new MASSIVE-1 cluster located at the Australian Synchrotron. Both of these clusters provide high-end </text>
<text top="539" left="135" width="654" height="17" font="6">compute nodes with multiple GPUs coupled by high-speed interconnect and IO capabilities which combine </text>
<text top="556" left="135" width="655" height="17" font="6">to allow rapid CT reconstruction. Provided in this paper are examples of the application of the developed </text>
<text top="573" left="135" width="654" height="17" font="6">tools to the reconstruction of large CT datasets collected both at synchrotrons and with laboratory-based CT </text>
<text top="590" left="135" width="63" height="17" font="6">scanners.  </text>
<text top="617" left="135" width="69" height="17" font="7"><i><b>Keywords: </b></i></text>
<text top="617" left="243" width="529" height="17" font="4"><i>CT reconstruction, GPU, high performance computing, clusters, parallel programming </i></text>
<text top="50" left="130" width="596" height="20" font="8">19th International Congress on Modelling and Simulation, Perth, Australia, 12–16 December 2011 </text>
<text top="68" left="130" width="204" height="20" font="8">http://mssanz.org.au/modsim2011</text>
<text top="1208" left="436" width="20" height="16" font="9">620</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="10" size="13" family="Times" color="#0000ff"/>
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="107" left="135" width="151" height="17" font="1"><b>1.  INTRODUCTION </b></text>
<text top="133" left="135" width="655" height="17" font="6">Computed Tomography (CT) reconstruction has become a common non-invasive tool for the visualisation </text>
<text top="150" left="135" width="656" height="17" font="6">of the internal structure of objects which are opaque to visible light. X-ray CT is widely used across a </text>
<text top="168" left="135" width="655" height="17" font="6">diverse range of disciplines, from medicine to materials science. It is a computationally and data-intensive </text>
<text top="185" left="135" width="655" height="17" font="6">process requiring significant computational resources. Our group within the Commonwealth Scientific and </text>
<text top="202" left="135" width="657" height="17" font="6">Industrial Research Organisation (CSIRO), Australia, has for over ten years been developing our XLI </text>
<text top="219" left="135" width="5" height="17" font="6">(</text>
<text top="219" left="140" width="369" height="17" font="10">http://www-ts.imaging.net/Services/AppInfo/X-TRACT.aspx</text>
<text top="219" left="509" width="289" height="17" font="6">) application for X-ray image analysis, </text>
<text top="236" left="135" width="450" height="17" font="6">processing and simulation of which CT reconstruction is a major function. </text>
<text top="263" left="135" width="659" height="17" font="6">CT reconstruction belongs to the class of computational problems which are often referred to as </text>
<text top="280" left="135" width="655" height="17" font="6">“embarrassingly parallel” and described by Forster (1995). Essentially, such problems can be decomposed </text>
<text top="297" left="135" width="657" height="17" font="6">into smaller independent units and computed in parallel. In recent years, several research groups and </text>
<text top="314" left="135" width="656" height="17" font="6">commercial enterprises have exploited this property to develop rapid CT reconstruction using specialised </text>
<text top="332" left="135" width="654" height="17" font="6">parallelised hardware such as Field-Programmable Gate Arrays (FPGAs) and Cell Broadband Engines (Cell </text>
<text top="349" left="135" width="659" height="17" font="6">BE), see Leeser, et al. (2005), Kachelrieß, et al. (2006) and Scherl, et al. (2007). However, such </text>
<text top="366" left="135" width="657" height="17" font="6">implementations can be limited due to the expense of the hardware and the complexity in developing </text>
<text top="383" left="135" width="650" height="17" font="6">software. In this period, Graphics Processing Units (GPUs) have become widely popular in both mass-</text>
<text top="401" left="135" width="657" height="17" font="6">market and High Performance Computing (HPC) systems. Originally, GPUs were designed to perform </text>
<text top="418" left="135" width="656" height="17" font="6">high-speed graphics rendering for computer gaming via their massively parallel, multi-core architectures, </text>
<text top="435" left="135" width="655" height="17" font="6">combined with optimised caches and memory. However, their usage has been subsequently expanded and </text>
<text top="452" left="135" width="655" height="17" font="6">adapted to general computational problems with the release of development APIs such as NVidia’s CUDA </text>
<text top="470" left="135" width="5" height="17" font="6">(</text>
<text top="470" left="140" width="317" height="17" font="10">http://www.nvidia.com/object/cuda_home_new.html</text>
<text top="470" left="457" width="354" height="17" font="6">) and OpenCL from Khronos Group </text>
<text top="487" left="135" width="5" height="17" font="6">(</text>
<text top="487" left="140" width="148" height="17" font="10">http://www.khronos.org/</text>
<text top="487" left="288" width="497" height="17" font="6">). The availability of large numbers of processing cores on a single consumer-</text>
<text top="504" left="135" width="660" height="17" font="6">level machine equipped with a GPU has enabled particular classes of algorithms including CT </text>
<text top="521" left="135" width="654" height="17" font="6">reconstruction to be mass-parallelized. This has resulted in speed-ups in the range of an order of magnitude </text>
<text top="539" left="135" width="656" height="17" font="6">or more, previously only achievable on customised hardware or HPC systems. Many groups have taken </text>
<text top="556" left="135" width="655" height="17" font="6">advantage of these relatively inexpensive devices, leveraging general purpose development platforms and </text>
<text top="573" left="135" width="654" height="17" font="6">tools to develop their own GPU-based CT reconstruction implementations, eg. Xu &amp; Mueller (2007), Sharp, </text>
<text top="590" left="135" width="272" height="17" font="6">et al. (2007) and Hintermüller, et al. (2010).  </text>
<text top="617" left="135" width="655" height="17" font="6">Even with the performance gains achieved in CT reconstruction with the use of GPUs, datasets generated </text>
<text top="634" left="135" width="654" height="17" font="6">by synchrotrons and laboratory-based CT scanners are generally beyond the memory and IO capabilities of </text>
<text top="651" left="135" width="654" height="17" font="6">most single machine systems to process in a reasonable time. Currently, such datasets can be of the order of </text>
<text top="668" left="135" width="655" height="17" font="6">hundreds of gigabytes or terabytes and are rapidly increasing in size with detector advances and upgrades. </text>
<text top="686" left="135" width="655" height="17" font="6">In order to rapidly perform CT reconstructions on such data volumes we have developed our XLI software </text>
<text top="703" left="135" width="655" height="17" font="6">to be deployable on GPU-enabled HPC clusters. In the HPC cluster environment we have at our disposal </text>
<text top="720" left="135" width="655" height="17" font="6">many nodes, each providing multiple cores, GPUs and many gigabytes of RAM, coupled with high-speed </text>
<text top="737" left="135" width="658" height="17" font="6">storage and interconnect. This permits us to once again use the embarrassingly parallel property to </text>
<text top="755" left="135" width="655" height="17" font="6">introduce a second level of parallelisation such that the CT reconstruction task is first split and distributed </text>
<text top="772" left="135" width="655" height="17" font="6">across the available cores on the cluster nodes prior to the second level of high-speed GPU parallelisation. </text>
<text top="789" left="135" width="655" height="17" font="6">Such a scheme is scalable for increasing data volumes, given RAM, IO and interconnect specifications are </text>
<text top="806" left="135" width="160" height="17" font="6">balanced to meet demand. </text>
<text top="833" left="135" width="655" height="17" font="6">In this paper we present the results and analysis of XLI’s GPU-based FB[ CT reconstruction algorithm on </text>
<text top="850" left="135" width="431" height="17" font="6">two large HPC clusters, namely the 128-node CSIRO GPU cluster (</text>
<text top="850" left="566" width="219" height="17" font="10">http://www.csiro.au/resources/GPU-</text>
<text top="867" left="135" width="71" height="17" font="10">cluster.html</text>
<text top="867" left="206" width="374" height="17" font="6">) located in Canberra, Australia and at the MASSIVE cluster (</text>
<text top="867" left="580" width="162" height="17" font="10">http://www.massive.org.au</text>
<text top="867" left="742" width="43" height="17" font="6">), a 48-</text>
<text top="884" left="135" width="443" height="17" font="6">node GPU-enabled HPC cluster located at the Australian Synchrotron (</text>
<text top="884" left="578" width="185" height="17" font="10">http://www.synchrotron.org.au</text>
<text top="884" left="763" width="27" height="17" font="6">) in </text>
<text top="902" left="135" width="136" height="17" font="6">Melbourne, Australia. </text>
<text top="937" left="135" width="370" height="17" font="1"><b>2.  PARALLEL-BEAM COMPUTED TOMOGRAPHY </b></text>
<text top="963" left="135" width="654" height="17" font="6">In order to understand the possible ways in which CT reconstruction can be implemented and parallelised, it </text>
<text top="980" left="135" width="656" height="17" font="6">is necessary to give at least a brief overview of the typical setups used for the acquisition of CT data. </text>
<text top="998" left="135" width="655" height="17" font="6">Schematic representation of the imaging geometry for the so-called parallel-beam tomography is shown in </text>
<text top="1015" left="135" width="655" height="17" font="6">Figure 1. Here <i>S</i> designates an X-ray source which, in the case of the parallel-beam tomography, is located </text>
<text top="1032" left="135" width="654" height="17" font="6">at a large distance from the object. Alternatively, the incident beam is collimated by some additional device. </text>
<text top="1049" left="135" width="498" height="17" font="6">O is an object and D is a position-sensitive detector (for example, a CCD camera). </text>
<text top="1208" left="436" width="20" height="16" font="9">621</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="11" size="7" family="Times" color="#000000"/>
	<fontspec id="12" size="24" family="Times" color="#000000"/>
	<fontspec id="13" size="8" family="Times" color="#000000"/>
	<fontspec id="14" size="15" family="Times" color="#000000"/>
	<fontspec id="15" size="15" family="Times" color="#000000"/>
	<fontspec id="16" size="15" family="Times" color="#000000"/>
	<fontspec id="17" size="23" family="Times" color="#000000"/>
	<fontspec id="18" size="28" family="Times" color="#000000"/>
	<fontspec id="19" size="8" family="Times" color="#000000"/>
	<fontspec id="20" size="16" family="Times" color="#000000"/>
	<fontspec id="21" size="16" family="Times" color="#000000"/>
	<fontspec id="22" size="14" family="Times" color="#000000"/>
	<fontspec id="23" size="14" family="Times" color="#000000"/>
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="397" left="715" width="4" height="17" font="6"> </text>
<text top="421" left="135" width="478" height="17" font="6">Let the object be described by a 3D distribution of some physical parameter, </text>
<text top="421" left="668" width="5" height="17" font="6">)</text>
<text top="421" left="654" width="4" height="17" font="6">,</text>
<text top="421" left="640" width="4" height="17" font="6">,</text>
<text top="421" left="627" width="5" height="17" font="6">(</text>
<text top="421" left="661" width="6" height="17" font="4"><i>z</i></text>
<text top="421" left="647" width="7" height="17" font="4"><i>y</i></text>
<text top="421" left="633" width="7" height="17" font="4"><i>x</i></text>
<text top="421" left="619" width="4" height="17" font="4"><i>f</i></text>
<text top="421" left="676" width="114" height="17" font="6">. In parallel-beam </text>
<text top="444" left="135" width="212" height="17" font="6">geometry, projection of the object,</text>
<text top="444" left="422" width="5" height="17" font="6">)</text>
<text top="444" left="403" width="4" height="17" font="6">,</text>
<text top="444" left="381" width="10" height="17" font="6">)(</text>
<text top="444" left="350" width="5" height="17" font="6">(</text>
<text top="444" left="411" width="7" height="17" font="4"><i>y</i></text>
<text top="444" left="392" width="7" height="17" font="4"><i>x</i></text>
<text top="444" left="373" width="4" height="17" font="4"><i>f</i></text>
<text top="442" left="419" width="4" height="20" font="6">′</text>
<text top="442" left="400" width="4" height="20" font="6">′</text>
<text top="452" left="364" width="5" height="12" font="11">θ</text>
<text top="444" left="355" width="9" height="17" font="1"><b>P</b></text>
<text top="444" left="430" width="147" height="17" font="6">, at an angular position </text>
<text top="442" left="577" width="213" height="21" font="6">θ, is mathematically expressed by </text>
<text top="465" left="135" width="286" height="17" font="6">the following linear integral (X-ray transform), </text>
<text top="504" left="252" width="22" height="33" font="12"> </text>
<text top="494" left="251" width="8" height="14" font="13">∞</text>
<text top="534" left="255" width="8" height="14" font="13">∞</text>
<text top="534" left="248" width="6" height="14" font="13">−</text>
<text top="494" left="266" width="8" height="14" font="13">∞</text>
<text top="534" left="269" width="8" height="14" font="13">∞</text>
<text top="534" left="263" width="6" height="14" font="13">−</text>
<text top="519" left="155" width="6" height="14" font="13">θ</text>
<text top="508" left="488" width="9" height="23" font="14">θ</text>
<text top="508" left="437" width="10" height="23" font="14">−</text>
<text top="508" left="425" width="9" height="23" font="14">θ</text>
<text top="508" left="379" width="10" height="23" font="14">−</text>
<text top="508" left="352" width="9" height="23" font="14">δ</text>
<text top="507" left="323" width="4" height="23" font="14">′</text>
<text top="508" left="234" width="10" height="23" font="14">=</text>
<text top="507" left="219" width="4" height="23" font="14">′</text>
<text top="507" left="197" width="4" height="23" font="14">′</text>
<text top="509" left="533" width="7" height="20" font="15"><i>z</i></text>
<text top="509" left="516" width="8" height="20" font="15"><i>x</i></text>
<text top="509" left="451" width="7" height="20" font="15"><i>z</i></text>
<text top="509" left="390" width="8" height="20" font="15"><i>x</i></text>
<text top="509" left="368" width="8" height="20" font="15"><i>x</i></text>
<text top="509" left="335" width="7" height="20" font="15"><i>z</i></text>
<text top="509" left="314" width="8" height="20" font="15"><i>y</i></text>
<text top="509" left="297" width="8" height="20" font="15"><i>x</i></text>
<text top="509" left="280" width="5" height="20" font="15"><i>f</i></text>
<text top="509" left="210" width="8" height="20" font="15"><i>y</i></text>
<text top="509" left="188" width="8" height="20" font="15"><i>x</i></text>
<text top="509" left="166" width="5" height="20" font="15"><i>f</i></text>
<text top="509" left="524" width="9" height="20" font="14">d</text>
<text top="509" left="507" width="9" height="20" font="14">d</text>
<text top="509" left="497" width="6" height="20" font="14">)</text>
<text top="509" left="461" width="24" height="20" font="14">cos</text>
<text top="509" left="401" width="21" height="20" font="14">sin</text>
<text top="509" left="376" width="3" height="20" font="14">'</text>
<text top="509" left="360" width="6" height="20" font="14">(</text>
<text top="509" left="343" width="6" height="20" font="14">)</text>
<text top="509" left="327" width="4" height="20" font="14">,</text>
<text top="509" left="305" width="4" height="20" font="14">,</text>
<text top="509" left="289" width="6" height="20" font="14">(</text>
<text top="509" left="223" width="6" height="20" font="14">)</text>
<text top="509" left="201" width="4" height="20" font="14">,</text>
<text top="509" left="175" width="12" height="20" font="14">)(</text>
<text top="509" left="138" width="17" height="20" font="14">(<b>P</b></text>
<text top="515" left="544" width="59" height="17" font="6">. (1) </text>
<text top="559" left="135" width="518" height="17" font="6">If projections are collected at multiple angular positions of the object in the interval </text>
<text top="557" left="653" width="137" height="21" font="6">θ∈[0, π), then the 3D </text>
<text top="576" left="135" width="659" height="17" font="6">distribution of the object function <i>f</i> can be calculated using the well-known filtered backprojection </text>
<text top="593" left="135" width="399" height="17" font="6">reconstruction algorithm (FBP),  Herman (1980), Natterer (1986), </text>
<text top="629" left="266" width="6" height="33" font="17">[</text>
<text top="629" left="415" width="6" height="33" font="17">]</text>
<text top="625" left="236" width="6" height="39" font="18">(</text>
<text top="625" left="419" width="6" height="39" font="18">)</text>
<text top="633" left="225" width="7" height="33" font="12"></text>
<text top="622" left="226" width="6" height="14" font="13">π</text>
<text top="657" left="437" width="6" height="14" font="13">=</text>
<text top="656" left="434" width="3" height="14" font="13">′</text>
<text top="646" left="502" width="6" height="14" font="13">θ</text>
<text top="646" left="472" width="6" height="14" font="13">+</text>
<text top="646" left="465" width="6" height="14" font="13">θ</text>
<text top="646" left="436" width="6" height="14" font="13">=</text>
<text top="645" left="433" width="3" height="14" font="13">′</text>
<text top="648" left="339" width="6" height="14" font="13">θ</text>
<text top="635" left="254" width="6" height="14" font="13">−</text>
<text top="636" left="524" width="9" height="23" font="14">θ</text>
<text top="635" left="404" width="4" height="23" font="14">′</text>
<text top="635" left="381" width="4" height="23" font="14">′</text>
<text top="636" left="281" width="14" height="23" font="14">ξ′</text>
<text top="636" left="211" width="10" height="23" font="14">=</text>
<text top="663" left="226" width="5" height="12" font="13">0</text>
<text top="647" left="486" width="14" height="12" font="13">cos</text>
<text top="647" left="450" width="13" height="12" font="13">sin</text>
<text top="648" left="314" width="5" height="12" font="13">1</text>
<text top="636" left="259" width="5" height="12" font="13">1</text>
<text top="648" left="250" width="5" height="12" font="13">1</text>
<text top="637" left="515" width="9" height="20" font="14">d</text>
<text top="637" left="408" width="6" height="20" font="14">)</text>
<text top="637" left="385" width="4" height="20" font="14">,</text>
<text top="637" left="359" width="12" height="20" font="14">)(</text>
<text top="637" left="322" width="6" height="20" font="14">(</text>
<text top="637" left="298" width="4" height="20" font="14">|</text>
<text top="637" left="274" width="4" height="20" font="14">|</text>
<text top="637" left="200" width="6" height="20" font="14">)</text>
<text top="637" left="184" width="4" height="20" font="14">,</text>
<text top="637" left="166" width="4" height="20" font="14">,</text>
<text top="637" left="151" width="6" height="20" font="14">(</text>
<text top="657" left="445" width="5" height="12" font="19"><i>y</i></text>
<text top="657" left="428" width="5" height="12" font="19"><i>y</i></text>
<text top="647" left="479" width="4" height="12" font="19"><i>z</i></text>
<text top="647" left="444" width="5" height="12" font="19"><i>x</i></text>
<text top="647" left="428" width="5" height="12" font="19"><i>x</i></text>
<text top="637" left="394" width="8" height="20" font="15"><i>y</i></text>
<text top="637" left="372" width="8" height="20" font="15"><i>x</i></text>
<text top="637" left="350" width="5" height="20" font="15"><i>f</i></text>
<text top="637" left="192" width="7" height="20" font="15"><i>z</i></text>
<text top="637" left="175" width="8" height="20" font="15"><i>y</i></text>
<text top="637" left="158" width="8" height="20" font="15"><i>x</i></text>
<text top="637" left="142" width="5" height="20" font="15"><i>f</i></text>
<text top="637" left="328" width="11" height="20" font="16"><b>P</b></text>
<text top="637" left="304" width="11" height="20" font="16"><b>F</b></text>
<text top="637" left="240" width="11" height="20" font="16"><b>F</b></text>
<text top="644" left="537" width="74" height="17" font="6">, (2) </text>
<text top="689" left="135" width="50" height="17" font="6">where <b>F</b></text>
<text top="696" left="185" width="5" height="11" font="11">1</text>
<text top="689" left="189" width="452" height="17" font="6"> is the one-dimensional (1D) Fourier transform with respect to the variable </text>
<text top="687" left="641" width="78" height="21" font="6">ξ′ dual to <i>x</i>′. </text>
<text top="715" left="135" width="577" height="17" font="6">From the algorithmic point of view, the FBP reconstruction can be divided into two main steps: </text>
<text top="742" left="162" width="628" height="20" font="6">•  1D ramp filtering of the object's projections in the Fourier space, which is expressed in (2) by the </text>
<text top="762" left="189" width="439" height="17" font="6">direct Fourier transform of the projections, subsequent multiplication by </text>
<text top="760" left="653" width="4" height="20" font="14">|</text>
<text top="760" left="629" width="4" height="20" font="14">|</text>
<text top="758" left="635" width="9" height="24" font="20">ξ</text>
<text top="758" left="646" width="4" height="23" font="14">′</text>
<text top="762" left="660" width="129" height="17" font="6"> (the ramp filter) and </text>
<text top="783" left="189" width="205" height="17" font="6">the inverse 1D Fourier transform; </text>
<text top="810" left="162" width="426" height="20" font="6">•  backprojection, represented by the integral over the rotation angle </text>
<text top="809" left="588" width="52" height="21" font="6">θ in (2). </text>
<text top="839" left="135" width="578" height="17" font="6">The axial slices of the reconstructed object are defined by the 2D sections of the 3D function </text>
<text top="837" left="776" width="6" height="20" font="14">)</text>
<text top="837" left="761" width="4" height="20" font="14">,</text>
<text top="837" left="744" width="4" height="20" font="14">,</text>
<text top="837" left="728" width="6" height="20" font="14">(</text>
<text top="837" left="768" width="7" height="20" font="15"><i>z</i></text>
<text top="837" left="752" width="8" height="20" font="15"><i>y</i></text>
<text top="837" left="735" width="8" height="20" font="15"><i>x</i></text>
<text top="837" left="719" width="5" height="20" font="15"><i>f</i></text>
<text top="839" left="785" width="4" height="17" font="6"> </text>
<text top="865" left="135" width="189" height="17" font="6">from (2) with fixed <i>y</i> equal to</text>
<text top="862" left="387" width="8" height="20" font="21"><i>y</i></text>
<text top="862" left="364" width="13" height="20" font="21"><i>m</i></text>
<text top="862" left="328" width="8" height="20" font="21"><i>y</i></text>
<text top="873" left="336" width="8" height="12" font="19"><i>m</i></text>
<text top="861" left="376" width="11" height="24" font="20">Δ</text>
<text top="861" left="350" width="10" height="24" font="20">=</text>
<text top="865" left="399" width="321" height="17" font="6">, where <i>m</i> = 0,1,…,<i>M</i>, are integer slice indices and </text>
<text top="862" left="734" width="8" height="20" font="15"><i>y</i></text>
<text top="861" left="723" width="11" height="23" font="14">Δ</text>
<text top="865" left="746" width="45" height="17" font="6"> is the </text>
<text top="888" left="135" width="444" height="17" font="6">vertical resolution of the CT system. These slices are contained in planes </text>
<text top="885" left="609" width="37" height="20" font="15"><i>const</i></text>
<text top="885" left="583" width="8" height="20" font="15"><i>y</i></text>
<text top="884" left="595" width="10" height="23" font="14">=</text>
<text top="888" left="652" width="137" height="17" font="6"> that are orthogonal to </text>
<text top="909" left="135" width="655" height="17" font="6">the axis <i>y</i> around which the object is rotated during the CT scan (see Figure 1). The reconstruction of each </text>
<text top="926" left="135" width="657" height="17" font="6">such slice can be performed independently from that of all other slices which implies a very simple </text>
<text top="943" left="135" width="654" height="17" font="6">parallelisation scheme for the complete 3D reconstruction. In other words, as mentioned in the Introduction, </text>
<text top="961" left="135" width="655" height="17" font="6">the conventional parallel-beam CT reconstruction problem, as defined by (2), is “embarrassingly parallel”, </text>
<text top="978" left="135" width="657" height="17" font="6">i.e. it naturally splits into independent reconstruction tasks for each axial slice of the sample with no </text>
<text top="995" left="135" width="296" height="17" font="6">interaction required between these parallel tasks. </text>
<text top="1021" left="135" width="654" height="17" font="6">It is the backprojection step of the CT reconstruction algorithm (defined by the integration over the rotation </text>
<text top="1039" left="135" width="658" height="17" font="6">angle in (2) after other operations have been completed) that takes most of the reconstruction time. </text>
<text top="1056" left="135" width="659" height="17" font="6">Fortunately, the backprojection can be efficiently parallelised due to the fact that this operation is </text>
<text top="1073" left="135" width="659" height="17" font="6">essentially independent for different voxels in the reconstructed object and can be carried out in parallel.  </text>
<text top="1090" left="135" width="662" height="17" font="1"><b>Error! Reference source not found.</b> shows a schematic representation of the “voxel-driven” </text>
<text top="1108" left="135" width="655" height="17" font="6">backprojection. For each voxel of the reconstructed object (gray dot represents its centre), the contribution </text>
<text top="1125" left="135" width="655" height="17" font="6">of each projection to this voxel is calculated by finding the corresponding projection of the voxel onto the </text>
<text top="382" left="205" width="512" height="17" font="1"><b>Figure 1. </b>Schematic diagram of the imaging system used for computed tomography.<b> </b></text>
<text top="303" left="706" width="15" height="18" font="22"><i>z'</i> </text>
<text top="219" left="710" width="15" height="18" font="22"><i>x'</i> </text>
<text top="135" left="635" width="7" height="18" font="22"><i>y</i></text>
<text top="134" left="643" width="4" height="23" font="14">′</text>
<text top="135" left="647" width="5" height="18" font="23"> </text>
<text top="171" left="628" width="16" height="18" font="22"><i>D</i> </text>
<text top="259" left="524" width="15" height="18" font="22"><i>z'</i> </text>
<text top="110" left="387" width="12" height="18" font="22"><i>y</i> </text>
<text top="122" left="518" width="12" height="18" font="22"><i>x</i> </text>
<text top="158" left="539" width="15" height="18" font="22"><i>x'</i> </text>
<text top="207" left="554" width="11" height="18" font="22"><i>z</i> </text>
<text top="146" left="419" width="16" height="18" font="22"><i>O</i> </text>
<text top="207" left="504" width="13" height="18" font="22"><i>θ</i> </text>
<text top="229" left="500" width="16" height="18" font="22"><i>θ'</i> </text>
<text top="146" left="231" width="13" height="18" font="22"><i>S</i> </text>
<text top="242" left="288" width="9" height="23" font="14">ρ</text>
<text top="244" left="297" width="5" height="18" font="23"> </text>
<text top="295" left="433" width="15" height="18" font="22"><i>R</i> </text>
<text top="1208" left="436" width="20" height="16" font="9">622</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="24" size="11" family="Times" color="#000000"/>
	<fontspec id="25" size="11" family="Times" color="#000000"/>
	<fontspec id="26" size="12" family="Times" color="#000000"/>
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="107" left="135" width="655" height="17" font="6">detector plane (gray dot) and estimating the projection value at this point using known projection values at </text>
<text top="124" left="135" width="385" height="17" font="6">the neighbouring grid points (e.g. using bi-linear interpolation). </text>
<text top="453" left="715" width="4" height="17" font="6"> </text>
<text top="476" left="135" width="654" height="17" font="6">Our GPU-based implementations of the FBP reconstruction algorithm further parallelise the backprojection </text>
<text top="493" left="135" width="654" height="17" font="6">task for each axial slice which represents the most computationally intensive part of the CT reconstruction. </text>
<text top="510" left="135" width="687" height="17" font="6">For this purpose we use NVidia's CUDA computing architecture </text>
<text top="527" left="135" width="655" height="17" font="6">(http://www.nvidia.com/object/cuda_home_new.html) to create GPU-oriented execution code (kernels) for </text>
<text top="545" left="135" width="655" height="17" font="6">the backprojection operations. Each computation thread of the backprojection kernel in the GPU calculates </text>
<text top="566" left="135" width="215" height="17" font="6">the value of the object function </text>
<text top="564" left="434" width="6" height="20" font="20">)</text>
<text top="564" left="412" width="5" height="20" font="20">,</text>
<text top="564" left="385" width="5" height="20" font="20">,</text>
<text top="564" left="365" width="6" height="20" font="20">(</text>
<text top="575" left="427" width="5" height="12" font="19"><i>n</i></text>
<text top="575" left="402" width="8" height="12" font="19"><i>m</i></text>
<text top="575" left="380" width="3" height="12" font="19"><i>l</i></text>
<text top="564" left="419" width="7" height="20" font="21"><i>z</i></text>
<text top="564" left="394" width="8" height="20" font="21"><i>y</i></text>
<text top="564" left="372" width="8" height="20" font="21"><i>x</i></text>
<text top="564" left="355" width="5" height="20" font="21"><i>f</i></text>
<text top="566" left="444" width="123" height="17" font="6"> in a single pixel </text>
<text top="564" left="613" width="6" height="20" font="20">)</text>
<text top="564" left="590" width="5" height="20" font="20">,</text>
<text top="564" left="569" width="6" height="20" font="20">(</text>
<text top="575" left="605" width="5" height="12" font="19"><i>n</i></text>
<text top="575" left="585" width="3" height="12" font="19"><i>l</i></text>
<text top="564" left="598" width="7" height="20" font="21"><i>z</i></text>
<text top="564" left="577" width="8" height="20" font="21"><i>x</i></text>
<text top="566" left="621" width="88" height="17" font="6"> in the slice </text>
<text top="575" left="751" width="8" height="12" font="19"><i>m</i></text>
<text top="564" left="743" width="8" height="20" font="21"><i>y</i></text>
<text top="564" left="714" width="8" height="20" font="21"><i>y</i></text>
<text top="563" left="727" width="10" height="24" font="20">=</text>
<text top="566" left="762" width="30" height="17" font="6"> by </text>
<text top="589" left="135" width="658" height="17" font="6">evaluating the corresponding “outer” backprojection integral in (2). A CUDA kernel (a code whose </text>
<text top="606" left="135" width="655" height="17" font="6">execution is initiated by a CPU thread or process and which runs on a GPU device) implements the SIMD </text>
<text top="624" left="135" width="656" height="17" font="6">(Single Instruction Multiple Data) strategy: namely, the same code runs on all the processor cores of the </text>
<text top="641" left="135" width="654" height="17" font="6">GPU but is applied to different input data and produces different output data. Both the input and output data </text>
<text top="658" left="135" width="655" height="17" font="6">usually have the form of a 1D, 2D or 3D-array. Each individual run of the code on a single GPU core is </text>
<text top="675" left="135" width="655" height="17" font="6">called a device thread. For the backprojection operation, the total number of device threads involved in the </text>
<text top="693" left="135" width="654" height="17" font="6">reconstruction of a single axial slice is equal to (or sometimes larger than) the number of pixels in the slice. </text>
<text top="710" left="135" width="654" height="17" font="6">The device threads have a two-level hierarchy (a block of threads and a grid of blocks, respectively) which </text>
<text top="727" left="135" width="655" height="17" font="6">specifies the order of the threads execution and possibilities for data interchange between different threads. </text>
<text top="744" left="135" width="654" height="17" font="6">This thread hierarchy is directly related to the hardware design of the NVidia GPUs. For details on this, the </text>
<text top="762" left="135" width="655" height="17" font="6">reader is referred to the official CUDA Programming Guide, see NVidia (2011). We only mention that an </text>
<text top="779" left="135" width="655" height="17" font="6">NVidia GPU contains one or more multiprocessors (MPs) and a global memory accessible by all the MPs. </text>
<text top="796" left="135" width="656" height="17" font="6">Each MP, in its turn, contain multiple processor cores with associated registers, shared memory and two </text>
<text top="813" left="135" width="655" height="17" font="6">types of cached memories including constant memory and texture memory. Threads of a block (its size is </text>
<text top="831" left="135" width="656" height="17" font="6">currently limited to 512 threads) are executed on the same MP. That is, different MPs execute different </text>
<text top="848" left="135" width="654" height="17" font="6">blocks of threads. This implies certain segmentation of the input and output data corresponding to different </text>
<text top="865" left="135" width="656" height="17" font="6">blocks. For instance, in our implementation of the cone-beam backprojection, each block of GPU device </text>
<text top="884" left="135" width="255" height="17" font="6">threads reconstructs a square fragment (16</text>
<text top="883" left="389" width="178" height="20" font="6">×16 pixels) of the axial slice. </text>
<text top="910" left="135" width="658" height="17" font="6">Thus, in addition to the higher-level parallelisation described above, we have implemented additional </text>
<text top="927" left="135" width="657" height="17" font="6">independent parallelisation of the most computationally demanding part of the CT reconstruction, the </text>
<text top="944" left="135" width="656" height="17" font="6">backprojection operation. This “lower-level” parallelisation allows us to take advantage of the many-core </text>
<text top="961" left="135" width="657" height="17" font="6">hardware architecture of the GPUs to achieve a much higher degree of parallelisation than is typically </text>
<text top="979" left="135" width="660" height="17" font="6">available with conventional CPUs. A relatively straightforward implementation of this lower-level </text>
<text top="996" left="135" width="655" height="17" font="6">parallelisation has been made possible by NVidia’s CUDA programming language and tools which can be </text>
<text top="1013" left="135" width="407" height="17" font="6">integrated with the popular C++ development tools and compilers.  </text>
<text top="1039" left="135" width="654" height="17" font="6">It should be noted that our XLI application also contains a GPU-enabled implementation of the well-known </text>
<text top="1057" left="135" width="655" height="17" font="6">Feldkamp-Davis-Kress (FDK) reconstruction algorithm for cone-beam CT, see Feldkamp et al. (1984) and </text>
<text top="1074" left="135" width="575" height="17" font="6">Nesterets et al. (2009). However, we do not present any analysis of this algorithm in this paper.<b> </b></text>
<text top="329" left="658" width="12" height="15" font="24"><i>z'</i> </text>
<text top="260" left="668" width="13" height="15" font="24"><i>x'</i> </text>
<text top="219" left="578" width="6" height="15" font="24"><i>y</i></text>
<text top="218" left="584" width="3" height="19" font="26">′</text>
<text top="219" left="588" width="4" height="15" font="25"> </text>
<text top="210" left="629" width="15" height="17" font="4"><i>D</i> </text>
<text top="156" left="378" width="10" height="15" font="24"><i>y</i> </text>
<text top="168" left="434" width="10" height="15" font="24"><i>x</i> </text>
<text top="204" left="466" width="9" height="15" font="24"><i>z</i> </text>
<text top="193" left="351" width="15" height="17" font="4"><i>O</i> </text>
<text top="194" left="210" width="12" height="17" font="4"><i>S</i> </text>
<text top="308" left="279" width="7" height="19" font="26">ρ</text>
<text top="310" left="287" width="4" height="15" font="25"> </text>
<text top="367" left="443" width="12" height="15" font="24"><i>R</i> </text>
<text top="286" left="685" width="9" height="15" font="24"><i>z</i> </text>
<text top="285" left="665" width="10" height="15" font="24"><i>θ</i> </text>
<text top="430" left="248" width="428" height="17" font="1"><b>Figure 2. </b>Schematic representation of the voxel-driven backprojection<b> </b></text>
<text top="1208" left="436" width="20" height="16" font="9">623</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="27" size="9" family="Times" color="#000000"/>
	<fontspec id="28" size="9" family="Times" color="#000000"/>
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="107" left="135" width="282" height="17" font="1"><b>3.  PERFORMANCE AND SCALABITIY </b></text>
<text top="133" left="135" width="656" height="17" font="6">We begin this section with an analysis of the performance of the GPU-based XLI implementation of the </text>
<text top="150" left="135" width="656" height="17" font="6">FBP CT reconstruction algorithm. CT reconstructions have been performed in a single-thread execution </text>
<text top="167" left="135" width="654" height="17" font="6">mode, using a high-performance Dell Precision T7400 workstation running the Microsoft Windows XP x64 </text>
<text top="185" left="135" width="656" height="17" font="6">operating system and equipped with a quad-core Xeon E5420 processor (2.5 GHz), 1333 MHz front-side </text>
<text top="202" left="135" width="654" height="17" font="6">bus and 16 GB of RAM (666 MHz). Attached was a GeForce GTX260 GPU (with 192 processor cores and </text>
<text top="220" left="135" width="315" height="17" font="6">896 MB memory onboard) connected via PCI-E 2.0 </text>
<text top="219" left="450" width="55" height="20" font="6">×16 bus. </text>
<text top="247" left="135" width="596" height="17" font="6">The FBP CT reconstruction algorithm as implemented by XLI consists of the following four steps: </text>
<text top="273" left="162" width="338" height="20" font="6">•  Reading a single sinogram file from the hard drive. </text>
<text top="291" left="162" width="423" height="20" font="6">•  Ramp-filtering the sinogram in Fourier space using FFT on CPU. </text>
<text top="310" left="162" width="552" height="20" font="6">•  Backprojection on GPU, resulting in reconstruction of a single axial slice of the object. </text>
<text top="328" left="162" width="415" height="20" font="6">•  Writing the resultant axial slice to the hard drive as a single file. </text>
<text top="346" left="188" width="4" height="17" font="6"> </text>
<text top="363" left="135" width="654" height="17" font="6">Total reconstruction times together with the execution times for each reconstruction step are summarised in </text>
<text top="382" left="135" width="154" height="17" font="6">Table 1 below. The 512</text>
<text top="381" left="289" width="500" height="20" font="6">×512×512 volume has been reconstructed from 180 projections, with 512×512 </text>
<text top="399" left="135" width="654" height="17" font="6">pixels in each projection. Reconstruction of a volume with twice the linear size needed twice the number of </text>
<text top="416" left="135" width="340" height="17" font="6">projections, with twice the linear size of the projections. </text>
<text top="442" left="137" width="649" height="13" font="27"><b>Table 1. </b>GPU-based (NVIDIA GeForce GTX260) FBP CT reconstruction times performed on a local machine (Dell Precision T7400)<b> </b></text>
<text top="481" left="135" width="72" height="13" font="28">Reconstructed </text>
<text top="495" left="135" width="39" height="13" font="28">volume </text>
<text top="481" left="240" width="63" height="13" font="28">Total time, s </text>
<text top="481" left="334" width="76" height="13" font="28">Backprojection </text>
<text top="495" left="334" width="35" height="13" font="28">time, s </text>
<text top="481" left="430" width="54" height="13" font="28">Sinograms </text>
<text top="495" left="430" width="74" height="13" font="28">reading time, s </text>
<text top="481" left="525" width="69" height="13" font="28">Slices writing </text>
<text top="495" left="525" width="35" height="13" font="28">time, s </text>
<text top="481" left="620" width="80" height="13" font="28">Total read/write </text>
<text top="495" left="620" width="35" height="13" font="28">time, s </text>
<text top="481" left="715" width="33" height="13" font="28">Other  </text>
<text top="499" left="715" width="80" height="13" font="28">operations time, </text>
<text top="513" left="715" width="8" height="13" font="28">s </text>
<text top="534" left="135" width="18" height="13" font="28">512</text>
<text top="533" left="153" width="52" height="16" font="28">×512×512 </text>
<text top="533" left="240" width="27" height="13" font="28">35.1  </text>
<text top="533" left="334" width="66" height="13" font="28">10.0 (28.5%) </text>
<text top="533" left="430" width="66" height="13" font="28">16.2 (46.3%) </text>
<text top="533" left="525" width="60" height="13" font="28">4.6 (13.1%) </text>
<text top="533" left="620" width="66" height="13" font="28">20.8 (59.4%) </text>
<text top="533" left="715" width="60" height="13" font="28">4.3 (12.1%) </text>
<text top="554" left="135" width="24" height="13" font="28">1024</text>
<text top="553" left="159" width="64" height="16" font="28">×1024×1024 </text>
<text top="553" left="240" width="33" height="13" font="28">207.1  </text>
<text top="553" left="334" width="69" height="13" font="28">84.6 (40.9%)  </text>
<text top="553" left="430" width="66" height="13" font="28">57.4 (27.7%) </text>
<text top="553" left="525" width="66" height="13" font="28">30.9 (14.9%) </text>
<text top="553" left="620" width="66" height="13" font="28">88.3 (42.6%) </text>
<text top="553" left="715" width="66" height="13" font="28">34.2 (16.5%) </text>
<text top="574" left="135" width="24" height="13" font="28">2048</text>
<text top="573" left="159" width="64" height="16" font="28">×2048×2048 </text>
<text top="573" left="240" width="39" height="13" font="28">2,732.3 </text>
<text top="573" left="334" width="81" height="13" font="28">1,286.4 (47.1%) </text>
<text top="573" left="430" width="66" height="13" font="28">258.2 (9.4%) </text>
<text top="573" left="525" width="72" height="13" font="28">617.1 (22.6%) </text>
<text top="573" left="620" width="72" height="13" font="28">875.3 (32.0%) </text>
<text top="573" left="715" width="72" height="13" font="28">570.6 (20.9%) </text>
<text top="594" left="135" width="4" height="17" font="6"> </text>
<text top="621" left="135" width="655" height="17" font="6">Analysis of Table 1 shows that the backprojection step of our GPU-based CT reconstruction algorithm is </text>
<text top="638" left="135" width="654" height="17" font="6">roughly equivalent to the combined input and output IO steps where IO is performed on a local hard drive. </text>
<text top="655" left="135" width="658" height="17" font="6">With increasing reconstruction volumes it can be noted that the backprojection step quickly becomes </text>
<text top="672" left="135" width="343" height="17" font="6">dominant due the algorithmic complexity bounds of <i>O</i>(<i>N</i></text>
<text top="670" left="477" width="5" height="11" font="11">4</text>
<text top="672" left="482" width="39" height="17" font="6">), <i>O</i>(<i>N</i></text>
<text top="670" left="521" width="5" height="11" font="11">3</text>
<text top="672" left="526" width="60" height="17" font="6">) and <i>O</i>(<i>N</i></text>
<text top="670" left="586" width="5" height="11" font="11">2</text>
<text top="672" left="591" width="198" height="17" font="6">log<i>N</i>) for the backprojection, IO </text>
<text top="690" left="135" width="224" height="17" font="6">and filtering operations respectively. </text>
<text top="716" left="135" width="206" height="17" font="6">One quickly notices that the <i>O</i>(<i>N</i></text>
<text top="714" left="341" width="5" height="11" font="11">4</text>
<text top="716" left="346" width="445" height="17" font="6">) bound for the backprojection step makes CT reconstruction relatively </text>
<text top="733" left="135" width="657" height="17" font="6">infeasible even on GPU-enabled machines in the single-threaded execution model as described above. </text>
<text top="750" left="135" width="576" height="17" font="6">Reconstruction volumes such as those generated by synchrotrons can be of the order of 4096</text>
<text top="748" left="711" width="7" height="11" font="11">3 </text>
<text top="750" left="719" width="71" height="17" font="6">voxels and </text>
<text top="768" left="135" width="654" height="17" font="6">larger and would require many hours or days of computation time. Aside from the time constraint, the only </text>
<text top="785" left="135" width="655" height="17" font="6">other factors affecting scalability of the algorithm is that of RAM availability on the CPU and GPU. The </text>
<text top="802" left="135" width="654" height="17" font="6">FBP algorithm requires only enough RAM to store at any time only two 2D arrays of data in CPU and GPU </text>
<text top="820" left="135" width="612" height="17" font="6">memory, that of the input sinogram and reconstructed slice. For example, an axial slice of size 4096</text>
<text top="820" left="747" width="42" height="20" font="6">×4096 </text>
<text top="838" left="135" width="655" height="17" font="6">containing single-precision floating-point numbers, occupies 64MB of RAM. As such the FBP algorithm </text>
<text top="855" left="135" width="655" height="17" font="6">has a relatively small memory footprint which makes it theoretically possible to reconstruct slices of up to </text>
<text top="873" left="135" width="23" height="17" font="6">16k</text>
<text top="872" left="157" width="380" height="20" font="6">×16k or fewer pixels with as little as 2GB of CPU/GPU RAM. </text>
<text top="900" left="135" width="654" height="17" font="6">To be able to rapidly reconstruct large data volumes it is necessary to exploit the “embarrassingly parallel” </text>
<text top="917" left="135" width="655" height="17" font="6">property of the CT reconstruction algorithm as mentioned in Section 2. As reconstructions are performed </text>
<text top="934" left="135" width="656" height="17" font="6">slice-by-slice and are independent from one another, it allows us to efficiently distribute slices across a </text>
<text top="951" left="135" width="571" height="17" font="6">cluster for reconstruction in parallel amongst the total pool of available CPU cores and GPUs.  </text>
<text top="977" left="135" width="655" height="17" font="6">Moreover, cluster-based reconstruction imposes some additional scalability constraints to those mentioned </text>
<text top="995" left="135" width="656" height="17" font="6">above. In the cluster implementation, an XLI “worker” process is generally created for every CPU core </text>
<text top="1012" left="135" width="658" height="17" font="6">across the desired number of nodes. As such a compute node must have enough RAM for N input </text>
<text top="1029" left="135" width="656" height="17" font="6">sinograms and reconstructed slices, where N is the number of worker processes to execute on that node. </text>
<text top="1046" left="135" width="654" height="17" font="6">The GPU memory constraint remains the same as before – our implementation requires worker processes to </text>
<text top="1064" left="135" width="655" height="17" font="6">“share” attached GPUs whereby processes attain an exclusive lock on an available GPU for the purpose of </text>
<text top="1081" left="135" width="655" height="17" font="6">the backprojection step of a slice, then relinquishing it upon completion for other processes. This scheme </text>
<text top="1098" left="135" width="655" height="17" font="6">does lead to some latency in the algorithm with processes competing for GPU resources. However, for the </text>
<text top="1115" left="135" width="616" height="17" font="6">tested datasets this latency is relatively insignificant compared to the IO overhead as described below. </text>
<text top="1208" left="436" width="20" height="16" font="9">624</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="29" size="13" family="Times" color="#000000"/>
	<fontspec id="30" size="7" family="Times" color="#000000"/>
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="107" left="135" width="654" height="17" font="6">A significant constraint to scalability in the cluster implementation is currently due to IO. Unlike the single </text>
<text top="124" left="135" width="658" height="17" font="6">machine model which performs all IO on a local hard disk, the cluster model requires the use of a </text>
<text top="141" left="135" width="655" height="17" font="6">centralised data store in which all nodes have access for reading and writing. Such a data store is usually </text>
<text top="158" left="135" width="654" height="17" font="6">provided by a Network Attached Storage (NAS) system. This leads to IO performance being constrained by </text>
<text top="176" left="135" width="655" height="17" font="6">interconnect performance and network load. Unlike the local model, the cluster model’s IO component of </text>
<text top="193" left="135" width="658" height="17" font="6">the CT reconstruction algorithm is generally dominant for the reconstruction volumes we have used, </text>
<text top="210" left="135" width="659" height="17" font="6">resulting in performance of the algorithm being IO bound. Of course, due to the more significant </text>
<text top="227" left="135" width="656" height="17" font="6">performance bound on the backprojection step, increases in reconstruction volumes will quickly result in </text>
<text top="245" left="135" width="655" height="17" font="6">the algorithm becoming compute-bound once again. This is an important consideration in choosing cluster </text>
<text top="262" left="135" width="658" height="17" font="6">specifications such that compute and IO performance are ideally balanced for optimal results where </text>
<text top="279" left="135" width="73" height="17" font="6">practicable. </text>
<text top="305" left="135" width="655" height="17" font="6">We carried out comparative performance tests of GPU-based FBP CT reconstruction on the CSIRO GPU </text>
<text top="323" left="135" width="161" height="17" font="6">cluster and the MASSIVE</text>
<text top="321" left="296" width="2" height="11" font="11"> </text>
<text top="323" left="298" width="492" height="17" font="6">cluster. The CSIRO GPU cluster has 128 dual 4-core Xeon E5462 nodes, each </text>
<text top="340" left="135" width="655" height="17" font="6">with 32 GB of RAM and two NVidia Tesla S2050 GPUs. Data storage is provided by an 80 TB Hitatchi </text>
<text top="357" left="135" width="657" height="17" font="6">NAS file system and interconnect between the nodes and storage is DDR Inifiniband (4 Gbit/s). The </text>
<text top="374" left="135" width="654" height="17" font="6">MASSIVE cluster has 42 dual 6-core Xeon nodes, each with 48 GB of RAM and two NVidia Tesla M2070 </text>
<text top="392" left="135" width="655" height="17" font="6">GPUs. Data storage is a 58 TB IBM GPFS parallel file system and interconnect between nodes and storage </text>
<text top="409" left="135" width="282" height="17" font="6">is 4x QDR Gigabyte/s Infiniband (32 Gbits/s). </text>
<text top="435" left="135" width="657" height="17" font="6">Both clusters are configured as dynamically provisioned dual-boot systems for simultaneous use of the </text>
<text top="452" left="135" width="658" height="17" font="6">Windows HPC 2008 R2 cluster operating system and Linux. XLI is currently designed for use with </text>
<text top="470" left="135" width="93" height="17" font="6">WinHPC only. </text>
<text top="754" left="782" width="4" height="17" font="6"> </text>
<text top="777" left="135" width="653" height="17" font="1"><b>Figure 3. </b>Total GPU-based, FBP CT reconstruction times between CSIRO GPU and MASSIVE cluster of a </text>
<text top="794" left="309" width="305" height="17" font="6">2K reconstruction volume (720 input projections).<b> </b></text>
<text top="1088" left="782" width="4" height="17" font="6"> </text>
<text top="1111" left="135" width="653" height="17" font="1"><b>Figure 4. </b>Total GPU-based, FBP CT reconstruction times between CSIRO GPU and MASSIVE cluster of a </text>
<text top="1128" left="305" width="313" height="17" font="6">4K reconstruction volume (1441 input projections).<b> </b></text>
<text top="691" left="205" width="8" height="15" font="6">1</text>
<text top="640" left="197" width="15" height="15" font="6">10</text>
<text top="588" left="190" width="23" height="15" font="6">100</text>
<text top="537" left="182" width="30" height="15" font="6">1000</text>
<text top="711" left="222" width="8" height="15" font="6">0</text>
<text top="711" left="276" width="15" height="15" font="6">20</text>
<text top="711" left="334" width="15" height="15" font="6">40</text>
<text top="711" left="392" width="15" height="15" font="6">60</text>
<text top="711" left="449" width="15" height="15" font="6">80</text>
<text top="711" left="503" width="23" height="15" font="6">100</text>
<text top="711" left="560" width="23" height="15" font="6">120</text>
<text top="711" left="618" width="23" height="15" font="6">140</text>
<text top="651" left="173" width="0" height="15" font="29"><b>Time (s) log</b></text>
<text top="583" left="177" width="0" height="10" font="30"><b>10</b></text>
<text top="734" left="401" width="53" height="15" font="1"><b>Workers</b></text>
<text top="510" left="304" width="310" height="15" font="1"><b>2k FBP CT Reconstruction, CSIRO GPU vs MASSIVE</b></text>
<text top="627" left="696" width="67" height="15" font="6">CSIRO GPU</text>
<text top="654" left="696" width="55" height="15" font="6">MASSIVE</text>
<text top="1025" left="212" width="8" height="15" font="6">1</text>
<text top="986" left="205" width="15" height="15" font="6">10</text>
<text top="948" left="197" width="23" height="15" font="6">100</text>
<text top="909" left="190" width="30" height="15" font="6">1000</text>
<text top="871" left="182" width="38" height="15" font="6">10000</text>
<text top="1045" left="230" width="8" height="15" font="6">0</text>
<text top="1045" left="305" width="15" height="15" font="6">50</text>
<text top="1045" left="381" width="23" height="15" font="6">100</text>
<text top="1045" left="460" width="23" height="15" font="6">150</text>
<text top="1045" left="539" width="23" height="15" font="6">200</text>
<text top="1045" left="618" width="23" height="15" font="6">250</text>
<text top="985" left="173" width="0" height="15" font="29"><b>Time (s) log</b></text>
<text top="917" left="177" width="0" height="10" font="30"><b>10</b></text>
<text top="1067" left="405" width="53" height="15" font="1"><b>Workers</b></text>
<text top="844" left="306" width="306" height="15" font="1"><b>4k FBP CT Reconstruction CSIRO GPU vs MASSIVE</b></text>
<text top="961" left="696" width="67" height="15" font="6">CSIRO GPU</text>
<text top="988" left="696" width="55" height="15" font="6">MASSIVE</text>
<text top="1208" left="436" width="20" height="16" font="9">625</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1263" width="892">
<text top="54" left="135" width="456" height="17" font="6">Thompson <i>et al.</i>, Rapid CT Reconstruction on GPU-enabled HPC Clusters  </text>
<text top="107" left="135" width="479" height="17" font="6">Figure 3 and Figure 4 above show the total reconstruction times for identical 2k</text>
<text top="105" left="614" width="5" height="11" font="11">3</text>
<text top="107" left="618" width="171" height="17" font="6"> (720 input projections) and </text>
<text top="124" left="135" width="15" height="17" font="6">4k</text>
<text top="122" left="150" width="5" height="11" font="11">3</text>
<text top="124" left="155" width="635" height="17" font="6"> (1441 input projections) volumes on both clusters for an increasing number of workers. Each point on </text>
<text top="141" left="135" width="657" height="17" font="6">the graph represents a single reconstruction job using the total number of CPU cores available for the </text>
<text top="158" left="135" width="654" height="17" font="6">desired number of nodes. In the case of the CSIRO GPU cluster, 8 workers per node are executed while on </text>
<text top="176" left="135" width="657" height="17" font="6">the MASSIVE cluster, 12 workers per node are created. The 2k volume was reconstructed from 720, </text>
<text top="194" left="135" width="30" height="17" font="6">2048</text>
<text top="193" left="165" width="627" height="20" font="6">×2048 pixel input projections, 16 MB per projection, ~11GB total. Similarly the 4k volume was </text>
<text top="212" left="135" width="185" height="17" font="6">reconstructed from 1441, 4096</text>
<text top="212" left="320" width="365" height="20" font="6">×4096 pixel projections, 64MB per projection, ~90GB total. </text>
<text top="239" left="135" width="655" height="17" font="6">Notably, the MASSIVE cluster is significantly quicker than the CSIRO GPU cluster across both datasets. </text>
<text top="256" left="135" width="656" height="17" font="6">We attribute this primarily to the substantially higher IO performance of the GPFS file system and, to a </text>
<text top="273" left="135" width="656" height="17" font="6">lesser degree, to the higher speed interconnect. From a computational perspective, the MASSIVE cluster </text>
<text top="290" left="135" width="654" height="17" font="6">would hold a slight advantage over the CSIRO GPU cluster due to more cores per node and more powerful </text>
<text top="308" left="135" width="650" height="17" font="6">GPUs, but these alone would not be enough to explain the displayed difference. Both clusters achieve near-</text>
<text top="325" left="135" width="658" height="17" font="6">linear scaling, however both also exhibit a leveling-off of reconstruction times at a finite number of </text>
<text top="342" left="135" width="655" height="17" font="6">workers. On the CSIRO GPU cluster this appears to be around 9 nodes (72 workers) and around 14 nodes </text>
<text top="359" left="135" width="659" height="17" font="6">(168 workers) on the MASSIVE cluster. We believe this corresponds to the saturation of network </text>
<text top="377" left="135" width="657" height="17" font="6">bandwidth to the attached storage which subsequently imposes a finite bound on the scalability of the </text>
<text top="394" left="135" width="66" height="17" font="6">algorithm. </text>
<text top="429" left="135" width="141" height="17" font="1"><b>4.  CONCLUSIONS </b></text>
<text top="455" left="135" width="656" height="17" font="6">We have demonstrated that rapid FBP CT reconstruction of large datasets is possible on a GPU-enabled </text>
<text top="473" left="135" width="655" height="17" font="6">HPC cluster leading to our goal of near-realtime reconstruction. Our algorithms exploit the embarrassingly </text>
<text top="490" left="135" width="654" height="17" font="6">parallel nature of CT reconstruction, allowing us to split the problem at a higher level into independent </text>
<text top="507" left="135" width="655" height="17" font="6">tasks for distribution and execution amongst available CPU cores on the cluster. A second, lower level of </text>
<text top="524" left="135" width="655" height="17" font="6">parallelisation is also attained using the multiple-cores of attached GPUs to significantly speed up the core </text>
<text top="542" left="135" width="658" height="17" font="6">backprojection step. We have found that near-linear scalability can be achieved subject to sufficient </text>
<text top="559" left="135" width="371" height="17" font="6">bandwidth existing between compute nodes and data storage. </text>
<text top="594" left="135" width="170" height="17" font="1"><b>ACKNOWLEDGMENTS </b></text>
<text top="620" left="135" width="658" height="17" font="6">The authors wish to acknowledge the National eResearch Architecture Taskforce (NeAT) which has </text>
<text top="638" left="135" width="272" height="17" font="6">provided major funding towards this project. </text>
<text top="673" left="135" width="105" height="17" font="1"><b>REFERENCES </b></text>
<text top="699" left="135" width="650" height="17" font="6">Feldkamp, L., Davis, L., &amp; Kress, J. (1984). Practical cone-beam algorithm. <i>J. Opt. Soc. Am A</i> <i>, 1</i>, 612-619. </text>
<text top="716" left="135" width="484" height="17" font="6">Forster, I. (1995). <i>Designing and Building Parallel Programs.</i> Addison Wesley. </text>
<text top="734" left="135" width="661" height="17" font="6">Herman, G. (1980). <i>Image Reconstruction from Projections. The Fundementals of Computerized </i></text>
<text top="751" left="162" width="259" height="17" font="4"><i>Tomography.</i> New York: Academic Press. </text>
<text top="768" left="135" width="657" height="17" font="6">Hintermüller, C., Marone, F., Isenegger, A., &amp; Stampanoni, M. (2010). Image processing pipeline for </text>
<text top="785" left="162" width="562" height="17" font="6">synchrotron-radiation-based tomographic microscopy. <i>J. Synchrotron Rad.</i> <i>, 17</i> (4), 550-559. </text>
<text top="803" left="135" width="661" height="17" font="6">Kachelrieß, M., Knaup, M., &amp; Bockenbach, O. (2006). Hyperfast parallel-beam and cone-beam </text>
<text top="820" left="162" width="565" height="17" font="6">backprojection using the cell general purpose hardware. <i>Medical Physics</i> <i>, 34</i> (4), 1474-1486. </text>
<text top="837" left="135" width="654" height="17" font="6">Leeser, M., Coric, S., Miller, E., Yu, E., &amp; Trepanier, M. (2005). Parallel-Beam Backprojection: An FPGA </text>
<text top="854" left="162" width="551" height="17" font="6">Implementation Optimized for Medical Imaging. <i>J. VLSI Signal Process.</i> <i>, 39</i> (3), 295-311. </text>
<text top="872" left="135" width="530" height="17" font="6">Natterer, F. (1986). <i>The Mathematics of Computerized Tomography.</i> New York: Wiley. </text>
<text top="889" left="135" width="656" height="17" font="6">Nesterets, Y. I., &amp; Gureyev, T. E. (2009). High-performance tomographic reconstruction using graphics </text>
<text top="906" left="162" width="631" height="17" font="6">processing units. In R. S. Anderssen, R. D. Braddock, &amp; L. Newham (Ed.), <i>18th World IMACS </i></text>
<text top="923" left="162" width="596" height="17" font="4"><i>Congress and MODSIM09 International Congress on Modelling and Simulation</i>, (pp. 1045-1051). </text>
<text top="941" left="135" width="698" height="17" font="6">NVIDIA. (2011). <i>NVIDIA Programming Guide.</i> Retrieved from </text>
<text top="958" left="162" width="621" height="17" font="6">http://developer.download.nvidia.com/compute/cuda/4_0/toolkit/docs/CUDA_C_Programming_Guide.</text>
<text top="975" left="162" width="28" height="17" font="6">pdf. </text>
<text top="992" left="135" width="661" height="17" font="6">Scherl, H., Koerner, M., Hofmann, H., Eckert, W., Kowarschik, M., &amp; Hornegger, J. (2007). </text>
<text top="1009" left="162" width="629" height="17" font="6">Implementation of the FDK algorithm for cone-beam CT on the cell broadband engine architecture. </text>
<text top="1027" left="162" width="175" height="17" font="4"><i>Proc. SPIE , 6510</i> (651058). </text>
<text top="1044" left="135" width="656" height="17" font="6">Sharp, G., Kandasamy, N., Singh, H., &amp; Folkert, M. (2007). GPU-based streaming architectures for fast </text>
<text top="1061" left="162" width="629" height="17" font="6">cone-beam CT image reconstruction and demons deformable registration. <i>Phys. Med. Biol.</i> <i>, 52</i> (19), </text>
<text top="1078" left="162" width="73" height="17" font="6">5771-5783. </text>
<text top="1096" left="135" width="658" height="17" font="6">Xu, F., &amp; Mueller, K. (2007). Real-time 3D computed tomographic reconstruction using commodity </text>
<text top="1113" left="162" width="450" height="17" font="6">graphics hardware. <i>Physics in Medicine and Biology</i> <i>, 52</i> (12), 3405-3419. </text>
<text top="1130" left="135" width="4" height="17" font="6"> </text>
<text top="1208" left="436" width="20" height="16" font="9">626</text>
</page>
</pdf2xml>
