<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="0" size="15" family="Times" color="#000000"/>
	<fontspec id="1" size="12" family="Times" color="#000000"/>
	<fontspec id="2" size="12" family="Times" color="#000000"/>
	<fontspec id="3" size="9" family="Times" color="#000000"/>
<text top="125" left="135" width="623" height="13" font="0"><b>TOWARDS AD-HOC GPU ACCELERATION OF PARALLEL EIGENSYSTEM</b></text>
<text top="146" left="374" width="145" height="13" font="0"><b>COMPUTATIONS</b></text>
<text top="189" left="304" width="284" height="14" font="1">Michael T. Garba and Horacio Gonz´alez–V´elez</text>
<text top="207" left="369" width="155" height="14" font="1">IDEAS Research Institute</text>
<text top="225" left="368" width="156" height="14" font="1">Robert Gordon University</text>
<text top="242" left="403" width="87" height="14" font="1">Aberdeen, UK</text>
<text top="260" left="302" width="40" height="14" font="1">Email:</text>
<text top="259" left="346" width="245" height="15" font="1">{m.t.garba,h.gonzalez-velez}@rgu.ac.uk</text>
<text top="318" left="87" width="89" height="11" font="2"><b>KEYWORDS</b></text>
<text top="343" left="87" width="338" height="14" font="1">GPU, Eigensystems, CUDA, Parallel Computing, Com-</text>
<text top="361" left="87" width="154" height="14" font="1">putational Linear Algebra</text>
<text top="409" left="87" width="81" height="11" font="2"><b>ABSTRACT</b></text>
<text top="435" left="87" width="338" height="14" font="1">This paper explores the early implementation of high-</text>
<text top="453" left="87" width="338" height="14" font="1">performance routines for the solution of multiple large</text>
<text top="471" left="87" width="338" height="14" font="1">Hermitian eigenvector and eigenvalue systems on a</text>
<text top="489" left="87" width="338" height="14" font="1">Graphics Processing Unit (GPU). We report a perfor-</text>
<text top="507" left="87" width="338" height="14" font="1">mance increase of up to two orders of magnitude over the</text>
<text top="525" left="87" width="46" height="14" font="1">original</text>
<text top="527" left="138" width="53" height="11" font="3">EISPACK</text>
<text top="525" left="196" width="229" height="14" font="1">routines with a NVIDIA Tesla C2050</text>
<text top="543" left="87" width="338" height="14" font="1">GPU, potentially allowing an order of magnitude in-</text>
<text top="561" left="87" width="338" height="14" font="1">crease in the complexity or resolution of a neutron scat-</text>
<text top="579" left="87" width="169" height="14" font="1">tering modeling application.</text>
<text top="627" left="87" width="119" height="11" font="2"><b>INTRODUCTION</b></text>
<text top="652" left="87" width="338" height="14" font="1">Eigenvector and eigenvalue determination are a recur-</text>
<text top="670" left="87" width="338" height="14" font="1">rent problem in computational modelling applications</text>
<text top="688" left="87" width="338" height="14" font="1">for which a number of broadly accepted libraries ex-</text>
<text top="706" left="87" width="338" height="14" font="1">ist. However, as increasingly elaborate models become</text>
<text top="724" left="87" width="338" height="14" font="1">of practical value to scientiﬁc and engineering applica-</text>
<text top="742" left="87" width="338" height="14" font="1">tions, the demands of solving larger systems typically</text>
<text top="760" left="87" width="338" height="14" font="1">require high performance computing with large high-</text>
<text top="778" left="87" width="243" height="14" font="1">performance clusters or supercomputers.</text>
<text top="797" left="102" width="323" height="14" font="1">As an emerging parallel architecture for high-</text>
<text top="815" left="87" width="338" height="14" font="1">performance computing, the Graphics Processing Unit</text>
<text top="833" left="87" width="338" height="14" font="1">(GPU) has the potential to enable a new generation of ap-</text>
<text top="851" left="87" width="338" height="14" font="1">plications for desktop machines and small clusters. Orig-</text>
<text top="869" left="87" width="338" height="14" font="1">inally intended for intensive high-end 3D graphics and</text>
<text top="887" left="87" width="338" height="14" font="1">gaming, GPUs have demonstrated cluster-level perfor-</text>
<text top="905" left="87" width="338" height="14" font="1">mance at a fraction of the cost and energy consumption</text>
<text top="923" left="87" width="338" height="14" font="1">of traditional CPUs for certain general purpose applica-</text>
<text top="941" left="87" width="338" height="14" font="1">tions. GPU advances are expected to sustain the trend</text>
<text top="958" left="87" width="338" height="14" font="1">of Moore’s law that conventional CPUs are straining to</text>
<text top="976" left="87" width="56" height="14" font="1">maintain.</text>
<text top="996" left="102" width="324" height="14" font="1">Conversely, the shift towards GPU computing is a</text>
<text top="1014" left="87" width="338" height="14" font="1">drastic architectural change that has left a void in the</text>
<text top="1031" left="87" width="338" height="14" font="1">space of application software and support libraries that</text>
<text top="1049" left="87" width="338" height="14" font="1">are able to leverage the full capabilities of the platform.</text>
<text top="1067" left="87" width="338" height="14" font="1">While the solution to computational modelling prob-</text>
<text top="1085" left="87" width="338" height="14" font="1">lems—which were impractical on the desktop and uneco-</text>
<text top="1103" left="87" width="338" height="14" font="1">nomical on the supercomputer—may very well become</text>
<text top="1121" left="87" width="338" height="14" font="1">the dominant GPU applications of the future, effective</text>
<text top="318" left="468" width="338" height="14" font="1">GPU programming remains an open problem in compu-</text>
<text top="336" left="468" width="96" height="14" font="1">tational science.</text>
<text top="354" left="483" width="324" height="14" font="1">With NVIDIA’s CUDA, AMD’s Firestream, Mi-</text>
<text top="372" left="468" width="338" height="14" font="1">crosoft’s DirectCompute and the vendor-neutral OpenCL</text>
<text top="390" left="468" width="338" height="14" font="1">platform, signiﬁcant resources are being directed towards</text>
<text top="408" left="468" width="338" height="14" font="1">developing a supporting ecosystem for GPU computing</text>
<text top="426" left="468" width="338" height="14" font="1">in the form of libraries, speciﬁcations, and tools that are</text>
<text top="444" left="468" width="169" height="14" font="1">at various levels of maturity.</text>
<text top="462" left="483" width="324" height="14" font="1">Driven by our own immediate need for high perfor-</text>
<text top="480" left="468" width="338" height="14" font="1">mance solvers for modelling Inelastic Neutron Scattering</text>
<text top="498" left="468" width="338" height="14" font="1">(INS), this paper describes the early stages of our appli-</text>
<text top="516" left="468" width="338" height="14" font="1">cation of GPUs to the solution of Hermitian eigensys-</text>
<text top="534" left="468" width="110" height="14" font="1">tems, based on the</text>
<text top="536" left="582" width="53" height="11" font="3">EISPACK</text>
<text top="534" left="638" width="168" height="14" font="1">library and using the CUDA</text>
<text top="552" left="468" width="338" height="14" font="1">platform. Our work may arguably shed some light on a</text>
<text top="570" left="468" width="338" height="14" font="1">computational problem of even wider signiﬁcance than</text>
<text top="588" left="468" width="212" height="14" font="1">the intended modelling application.</text>
<text top="630" left="468" width="108" height="11" font="2"><b>BACKGROUND</b></text>
<text top="656" left="468" width="53" height="11" font="3">EISPACK</text>
<text top="654" left="521" width="113" height="14" font="1">, and its successor</text>
<text top="656" left="640" width="50" height="11" font="3">LAPACK</text>
<text top="654" left="690" width="116" height="14" font="1">, provide extensive</text>
<text top="672" left="468" width="338" height="14" font="1">linear algebra routines in mathematical and scientiﬁc</text>
<text top="690" left="468" width="338" height="14" font="1">computing. Originally developed in the US in the sev-</text>
<text top="708" left="468" width="338" height="14" font="1">enties (Smith et al., 1976), the accuracy and numerical</text>
<text top="726" left="468" width="64" height="14" font="1">stability of</text>
<text top="728" left="535" width="53" height="11" font="3">EISPACK</text>
<text top="726" left="591" width="215" height="14" font="1">has been established through diverse</text>
<text top="744" left="468" width="338" height="14" font="1">application over the past 30+ years, leading to a number</text>
<text top="762" left="468" width="310" height="14" font="1">of developments in the ﬁeld (Dongarra et al., 1998).</text>
<text top="780" left="483" width="323" height="14" font="1">We have developed an initial high performance paral-</text>
<text top="798" left="468" width="80" height="14" font="1">lel version of</text>
<text top="800" left="552" width="56" height="11" font="3">SCATTER</text>
<text top="798" left="613" width="193" height="14" font="1">(Roach et al., 2007), a new INS</text>
<text top="816" left="468" width="338" height="14" font="1">modelling tool, that has demonstrated linear scaling up</text>
<text top="834" left="468" width="338" height="14" font="1">to 1024 nodes on the Huygens prototype supercomputer</text>
<text top="852" left="468" width="338" height="14" font="1">in the SARA facilities in the Netherlands (Garba et al.,</text>
<text top="870" left="468" width="338" height="14" font="1">2010). Central to this parallel version are phonon mode</text>
<text top="888" left="468" width="275" height="14" font="1">calculations carried out with the support of</text>
<text top="890" left="749" width="53" height="11" font="3">EISPACK</text>
<text top="888" left="802" width="4" height="14" font="1">.</text>
<text top="906" left="468" width="118" height="14" font="1">However, not every</text>
<text top="908" left="590" width="56" height="11" font="3">SCATTER</text>
<text top="906" left="651" width="155" height="14" font="1">deployment may have ac-</text>
<text top="924" left="468" width="338" height="14" font="1">cess to major supercomputing installations and it is clear</text>
<text top="942" left="468" width="338" height="14" font="1">that more affordable computational power is required on</text>
<text top="959" left="468" width="338" height="14" font="1">the lower end of the computing scale (Bethel et al., 2011).</text>
<text top="978" left="483" width="323" height="14" font="1">Furthermore, GPU modules are becoming a frequent</text>
<text top="996" left="468" width="338" height="14" font="1">presence in high performance computing platforms and</text>
<text top="1014" left="468" width="106" height="14" font="1">the application of</text>
<text top="1016" left="579" width="56" height="11" font="3">SCATTER</text>
<text top="1014" left="640" width="166" height="14" font="1">to progressively more com-</text>
<text top="1031" left="468" width="338" height="14" font="1">plex models on larger installations will require reason-</text>
<text top="1049" left="468" width="338" height="14" font="1">able usage of these resources. As a result, an efﬁcient</text>
<text top="1067" left="468" width="338" height="14" font="1">GPU implementation of the most computationally inten-</text>
<text top="1085" left="468" width="97" height="14" font="1">sive parts of the</text>
<text top="1087" left="569" width="56" height="11" font="3">SCATTER</text>
<text top="1085" left="630" width="176" height="14" font="1">routine will alleviate this im-</text>
<text top="1103" left="468" width="338" height="14" font="1">perative demand. Of particular interest are solvers for</text>
<text top="1121" left="468" width="338" height="14" font="1">the class of Hermitian eigensystems that occur in INS</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="4" size="12" family="Times" color="#000000"/>
<text top="92" left="87" width="338" height="14" font="1">modelling, arising from the quantum mechanical deter-</text>
<text top="109" left="87" width="338" height="14" font="1">mination of phonon modes and their associated scattering</text>
<text top="127" left="87" width="204" height="14" font="1">contributions (Roach et al., 2010).</text>
<text top="147" left="102" width="324" height="14" font="1">For numerically intensive tasks, GPUs have substan-</text>
<text top="164" left="87" width="338" height="14" font="1">tial computing potential (Tomov et al., 2010a). How-</text>
<text top="182" left="87" width="338" height="14" font="1">ever, complex control ﬂow with conditional branching</text>
<text top="200" left="87" width="338" height="14" font="1">and thread divergence incur a noticeable performance</text>
<text top="218" left="87" width="338" height="14" font="1">penalty (Nvidia Corporation, 2009). To achieve reason-</text>
<text top="236" left="87" width="338" height="14" font="1">able performance beneﬁts, it is necessary to augment tra-</text>
<text top="254" left="87" width="338" height="14" font="1">ditional development techniques with low-level knowl-</text>
<text top="272" left="87" width="338" height="14" font="1">edge of the underlying GPU architecture (Kirk and Wen-</text>
<text top="290" left="87" width="68" height="14" font="1">mei, 2010).</text>
<text top="309" left="102" width="324" height="14" font="1">The Compute Uniﬁed Device Architecture (CUDA) is</text>
<text top="327" left="87" width="338" height="14" font="1">NVIDIA’s platform for GPU computing, providing com-</text>
<text top="345" left="87" width="338" height="14" font="1">pilation tools, libraries and a runtime system. CUDA al-</text>
<text top="363" left="87" width="338" height="14" font="1">lows the execution of <i>kernels</i>, written in CUDA C, on the</text>
<text top="381" left="87" width="338" height="14" font="1">GPU device. A kernel executes as a conﬁgurable grid of</text>
<text top="399" left="87" width="338" height="14" font="1">independent thread blocks that may contain up to 1024</text>
<text top="417" left="87" width="268" height="14" font="1">threads in second generation CUDA devices.</text>
<text top="436" left="102" width="324" height="14" font="1">A <i>Single Instruction Multiple Thread (SIMT) </i>abstrac-</text>
<text top="454" left="87" width="338" height="14" font="1">tion, where threads within a block execute identical in-</text>
<text top="472" left="87" width="338" height="14" font="1">structions and may operate on different memory loca-</text>
<text top="490" left="87" width="338" height="14" font="1">tions, allows ﬁne-grained data parallelism within blocks</text>
<text top="508" left="87" width="225" height="14" font="1">and task parallelism at kernel level</text>
<text top="508" left="326" width="99" height="14" font="1">(Nickolls et al.,</text>
<text top="526" left="87" width="39" height="14" font="1">2008).</text>
<text top="526" left="141" width="284" height="14" font="1">Thread blocks are divided into <i>warps </i>of 32</text>
<text top="543" left="87" width="338" height="14" font="1">threads. For a given block, only one of these warps is</text>
<text top="561" left="87" width="338" height="14" font="1">scheduled to execute on the actual hardware at any given</text>
<text top="579" left="87" width="44" height="14" font="1">instant.</text>
<text top="598" left="102" width="323" height="14" font="1">GPU memory is hierarchically organised and indepen-</text>
<text top="616" left="87" width="338" height="14" font="1">dent from host memory. Global Memory, high-latency</text>
<text top="634" left="87" width="338" height="14" font="1">and high-bandwidth DRAM, is the primary memory</text>
<text top="652" left="87" width="338" height="14" font="1">available on the device and is accessible by all executing</text>
<text top="670" left="87" width="338" height="14" font="1">kernels as well as for host to GPU data transfer. Limited</text>
<text top="688" left="87" width="338" height="14" font="1">high-speed Shared Memory, essentially a user-managed</text>
<text top="706" left="87" width="338" height="14" font="1">cache, exists locally on each streaming multiprocessor to</text>
<text top="724" left="87" width="338" height="14" font="1">allow the explicit avoidance of expensive off-chip global</text>
<text top="742" left="87" width="338" height="14" font="1">memory accesses. Also present are register, texture and</text>
<text top="760" left="87" width="338" height="14" font="1">constant memories with various performance character-</text>
<text top="778" left="87" width="34" height="14" font="1">istics.</text>
<text top="797" left="102" width="323" height="14" font="1">Memory transfer contention and bandwidth represent</text>
<text top="815" left="87" width="338" height="14" font="1">the predominant bottlenecks to GPU performance. A</text>
<text top="833" left="87" width="338" height="14" font="1">critical performance consideration is that high cost global</text>
<text top="851" left="87" width="338" height="14" font="1">memory operations can be performed simultaneously or</text>
<text top="869" left="87" width="59" height="13" font="4"><i>coalesced</i></text>
<text top="869" left="150" width="275" height="14" font="1">for a thread warp if certain access constraints</text>
<text top="887" left="87" width="338" height="14" font="1">are satisﬁed. In practice, signiﬁcant efforts are usually</text>
<text top="904" left="87" width="338" height="14" font="1">dedicated to optimising memory access patterns of this</text>
<text top="922" left="87" width="338" height="14" font="1">kind by what is frequently a hit-or-miss approach in-</text>
<text top="940" left="87" width="338" height="14" font="1">volving conﬂicting trade-offs to maximise the <i>compute</i></text>
<text top="958" left="87" width="240" height="13" font="4"><i>to global memory access (CGMA) ratio</i></text>
<text top="958" left="331" width="95" height="14" font="1">(Kirk and Wen-</text>
<text top="976" left="87" width="338" height="14" font="1">mei, 2010). The GPU architecture and best practices for</text>
<text top="994" left="87" width="338" height="14" font="1">achieving good performance are extensively documented</text>
<text top="1012" left="87" width="138" height="14" font="1">in the CUDA platform.</text>
<text top="1060" left="87" width="76" height="11" font="2"><b>METHODS</b></text>
<text top="1085" left="87" width="338" height="14" font="1">Despite a number of emerging GPU numerical libraries,</text>
<text top="1103" left="87" width="338" height="14" font="1">no open library for eigensystem analysis is available to</text>
<text top="1121" left="87" width="338" height="14" font="1">completely meet the application requirements. There-</text>
<text top="92" left="468" width="338" height="14" font="1">fore, a basic port of the required functional subset of</text>
<text top="112" left="468" width="53" height="11" font="3">EISPACK</text>
<text top="109" left="525" width="197" height="14" font="1">to the GPU has been undertaken.</text>
<text top="127" left="483" width="187" height="14" font="1">Admittedly, the more modern</text>
<text top="129" left="677" width="50" height="11" font="3">LAPACK</text>
<text top="127" left="728" width="78" height="14" font="1">—which has</text>
<text top="145" left="468" width="112" height="14" font="1">largely superseded</text>
<text top="147" left="585" width="53" height="11" font="3">EISPACK</text>
<text top="145" left="638" width="168" height="14" font="1">—may have formed a func-</text>
<text top="163" left="468" width="338" height="14" font="1">tionally superior basis. However, the inherent architec-</text>
<text top="181" left="468" width="273" height="14" font="1">tural complexity and reliance on an efﬁcient</text>
<text top="183" left="747" width="33" height="11" font="3">BLAS</text>
<text top="181" left="785" width="21" height="14" font="1">im-</text>
<text top="199" left="468" width="338" height="14" font="1">plementation implies a long-term effort that the imme-</text>
<text top="217" left="468" width="283" height="14" font="1">diacy of our requirements does not allow. The</text>
<text top="219" left="756" width="50" height="11" font="3">MAGMA</text>
<text top="235" left="468" width="338" height="14" font="1">library is such an effort that is in the early stages of pro-</text>
<text top="253" left="468" width="338" height="14" font="1">viding hybrid multicore-CPU/GPU implementations of</text>
<text top="273" left="468" width="50" height="11" font="3">LAPACK</text>
<text top="271" left="522" width="185" height="14" font="1">routines (Tomov et al., 2010b).</text>
<text top="289" left="483" width="324" height="14" font="1">The challenges of achieving efﬁcient performance on a</text>
<text top="307" left="468" width="338" height="14" font="1">GPU architecture may justify the extended effort of cus-</text>
<text top="325" left="468" width="338" height="14" font="1">tom algorithms developed speciﬁcally for the strengths of</text>
<text top="343" left="468" width="338" height="14" font="1">the platform (Vzquez et al., 2010). However, we main-</text>
<text top="361" left="468" width="240" height="14" font="1">tain the original algorithms of the legacy</text>
<text top="363" left="711" width="53" height="11" font="3">EISPACK</text>
<text top="361" left="767" width="39" height="14" font="1">imple-</text>
<text top="378" left="468" width="179" height="14" font="1">mentation for several reasons:</text>
<text top="407" left="469" width="338" height="14" font="1">(a) This work is motivated by a very practical applica-</text>
<text top="425" left="493" width="110" height="14" font="1">tion for which the</text>
<text top="427" left="608" width="53" height="11" font="3">EISPACK</text>
<text top="425" left="667" width="140" height="14" font="1">eigensolver has proven</text>
<text top="443" left="493" width="57" height="14" font="1">adequate.</text>
<text top="471" left="468" width="41" height="14" font="1">(b) As</text>
<text top="473" left="515" width="53" height="11" font="3">EISPACK</text>
<text top="471" left="574" width="232" height="14" font="1">has been in production use for nearly</text>
<text top="489" left="493" width="314" height="14" font="1">40 years, the numerical characteristics and accuracy</text>
<text top="507" left="493" width="314" height="14" font="1">have been established by exhaustive application and</text>
<text top="525" left="493" width="44" height="14" font="1">testing.</text>
<text top="553" left="469" width="338" height="14" font="1">(c) The problem of creating a data-parallel GPU version</text>
<text top="571" left="493" width="314" height="14" font="1">is conceptually similar to that of creating a vector-</text>
<text top="589" left="493" width="143" height="14" font="1">processor version of the</text>
<text top="591" left="640" width="53" height="11" font="3">EISPACK</text>
<text top="589" left="697" width="109" height="14" font="1">routines. A vector</text>
<text top="607" left="493" width="314" height="14" font="1">implementation was created for for the IBM 3090-</text>
<text top="624" left="493" width="208" height="14" font="1">VF by Cline and Meyering (1991).</text>
<text top="653" left="468" width="250" height="14" font="1">(d) While alternative algorithms used in</text>
<text top="655" left="724" width="50" height="11" font="3">LAPACK</text>
<text top="653" left="780" width="26" height="14" font="1">may</text>
<text top="670" left="493" width="314" height="14" font="1">possess superior cache usage characteristics and per-</text>
<text top="688" left="493" width="314" height="14" font="1">formance in modern processor conﬁgurations, they</text>
<text top="706" left="493" width="314" height="14" font="1">provide this at the expense of software complexity</text>
<text top="724" left="493" width="161" height="14" font="1">and reliance on an efﬁcient</text>
<text top="726" left="658" width="33" height="11" font="3">BLAS</text>
<text top="724" left="695" width="98" height="14" font="1">implementation.</text>
<text top="753" left="483" width="23" height="14" font="1">The</text>
<text top="755" left="512" width="53" height="11" font="3">EISPACK</text>
<text top="753" left="570" width="236" height="14" font="1">implementation provides the ch driver</text>
<text top="771" left="468" width="338" height="14" font="1">for double-precision Hermitian matrices and its three</text>
<text top="789" left="468" width="257" height="14" font="1">subroutine dependencies shown in Table 1.</text>
<text top="829" left="468" width="140" height="11" font="2"><b>IMPLEMENTATION</b></text>
<text top="852" left="468" width="17" height="14" font="1">As</text>
<text top="854" left="488" width="53" height="11" font="3">EISPACK</text>
<text top="852" left="544" width="262" height="14" font="1">is implemented in Fortran, these routines re-</text>
<text top="870" left="468" width="338" height="14" font="1">quire source-level translation with the f2c tool (Feldman,</text>
<text top="888" left="468" width="338" height="14" font="1">1990) into equivalent C sources for compatibility with</text>
<text top="906" left="468" width="338" height="14" font="1">the C-based CUDA SDK (Figure 1). Thence, the sub-</text>
<text top="924" left="468" width="338" height="14" font="1">routines from Table 1 have served as the basis for the</text>
<text top="942" left="468" width="323" height="14" font="1">creation of three functionally equivalent GPU kernels.</text>
<text top="960" left="483" width="323" height="14" font="1">Performance gains emerge as data-parallel intensive</text>
<text top="978" left="468" width="338" height="14" font="1">loops are distributed between cooperating threads in a</text>
<text top="996" left="468" width="338" height="14" font="1">block and synchronisation constructs inserted to avoid</text>
<text top="1014" left="468" width="338" height="14" font="1">race conditions between thread warps. These loops are</text>
<text top="1031" left="468" width="338" height="14" font="1">identiﬁed from source-level line-proﬁling on the origi-</text>
<text top="1049" left="468" width="117" height="14" font="1">nal CPU version of</text>
<text top="1051" left="589" width="53" height="11" font="3">EISPACK</text>
<text top="1049" left="642" width="164" height="14" font="1">, the assumption being that</text>
<text top="1067" left="468" width="338" height="14" font="1">CPU performance is strongly indicative of potential per-</text>
<text top="1085" left="468" width="338" height="14" font="1">formance bottlenecks in the GPU kernels. This is a nec-</text>
<text top="1103" left="468" width="338" height="14" font="1">essary workaround as CUDA proﬁling tools provide rel-</text>
<text top="1121" left="468" width="157" height="14" font="1">atively basic functionality.</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="5" size="10" family="Times" color="#000000"/>
	<fontspec id="6" size="8" family="Times" color="#000000"/>
<text top="96" left="227" width="55" height="12" font="5">EISPACK</text>
<text top="113" left="226" width="56" height="12" font="5">( F o r t r a n )</text>
<text top="186" left="227" width="55" height="12" font="5">EISPACK</text>
<text top="202" left="244" width="18" height="12" font="5">(C)</text>
<text top="149" left="254" width="22" height="12" font="5"> f2c</text>
<text top="261" left="165" width="71" height="12" font="5">c h   w r a p p e r</text>
<text top="277" left="191" width="18" height="12" font="5">(C)</text>
<text top="261" left="268" width="78" height="12" font="5">GPU Kernels</text>
<text top="277" left="276" width="61" height="12" font="5">(CUDA C)</text>
<text top="322" left="87" width="138" height="14" font="1">Figure 1: The Fortran</text>
<text top="324" left="231" width="53" height="11" font="3">EISPACK</text>
<text top="322" left="289" width="136" height="14" font="1">source translated to C</text>
<text top="340" left="87" width="257" height="14" font="1">with f2c forms the basis of the CUDA Port</text>
<text top="398" left="102" width="324" height="14" font="1">A number of thread blocks independently handle the</text>
<text top="415" left="87" width="338" height="14" font="1">solution of multiple eigensystems in parallel. In our im-</text>
<text top="433" left="87" width="338" height="14" font="1">plementation, a thread block or cooperative thread array</text>
<text top="451" left="87" width="338" height="14" font="1">(CTA) is mapped to an input problem set, allowing paral-</text>
<text top="469" left="87" width="338" height="14" font="1">lelism at both independent block and cooperative thread</text>
<text top="487" left="87" width="38" height="14" font="1">levels.</text>
<text top="505" left="102" width="297" height="14" font="1">Some performance optimisations applied include:</text>
<text top="535" left="88" width="338" height="14" font="1">(a) Asynchronous transfers to and from the Host over</text>
<text top="553" left="112" width="314" height="14" font="1">multiple streams allow concurrent kernel execution</text>
<text top="571" left="112" width="119" height="14" font="1">and overlapped I/O.</text>
<text top="600" left="87" width="338" height="14" font="1">(b) Algorithm reorganisation for improved coalesced</text>
<text top="618" left="112" width="314" height="14" font="1">memory access. Transposed matrix layout in some</text>
<text top="636" left="112" width="314" height="14" font="1">subtasks is necessary to achieve higher memory</text>
<text top="654" left="112" width="116" height="14" font="1">transfer bandwidth.</text>
<text top="683" left="88" width="338" height="14" font="1">(c) Improved register memory usage by the elimination</text>
<text top="700" left="112" width="314" height="14" font="1">(or reuse when appropriate) of extraneous register</text>
<text top="718" left="112" width="314" height="14" font="1">variables to improve GPU occupancy and facilitate</text>
<text top="736" left="112" width="290" height="14" font="1">latency hiding on the streaming multiprocessors.</text>
<text top="765" left="87" width="338" height="14" font="1">(d) Use of explicit caching in shared memory to limit</text>
<text top="783" left="112" width="188" height="14" font="1">costly global memory accesses.</text>
<text top="812" left="88" width="338" height="14" font="1">(e) Empirical determination of launch conﬁguration by</text>
<text top="830" left="112" width="314" height="14" font="1">trial and error. While, the guidelines recommend that</text>
<text top="848" left="112" width="314" height="14" font="1">thread blocks sizes should be multiples of a warp to</text>
<text top="866" left="112" width="314" height="14" font="1">allow latency hiding for multiple warps, it is neces-</text>
<text top="884" left="112" width="314" height="14" font="1">sary to determine actual optimal block sizes by test-</text>
<text top="902" left="112" width="314" height="14" font="1">ing. The different kernels performed optimally at</text>
<text top="919" left="112" width="156" height="14" font="1">distinct block dimensions.</text>
<text top="972" left="87" width="67" height="11" font="2"><b>RESULTS</b></text>
<text top="996" left="87" width="338" height="14" font="1">Performance evaluations are carried out on a 64-bit Dell</text>
<text top="1014" left="87" width="338" height="14" font="1">Precision T7500 Server with 4 Intel Xeon 2GHz CPU</text>
<text top="1031" left="87" width="338" height="14" font="1">cores, 4GB RAM and a NVIDIA Tesla C2050 GPU with</text>
<text top="1049" left="87" width="338" height="14" font="1">a PCI express interface running Version 3.2 of the CUDA</text>
<text top="1067" left="87" width="217" height="14" font="1">SDK on 64-bit Ubuntu 10.04 Linux.</text>
<text top="1085" left="102" width="324" height="14" font="1">The second generation NVIDIA Tesla C2050 GPU is</text>
<text top="1103" left="87" width="338" height="14" font="1">designed speciﬁcally for scientiﬁc and numerical com-</text>
<text top="1121" left="87" width="338" height="14" font="1">puting applications. 14 streaming multiprocessors (SM),</text>
<text top="90" left="477" width="47" height="14" font="1">Routine</text>
<text top="90" left="545" width="70" height="14" font="1">Description</text>
<text top="111" left="477" width="33" height="14" font="1">htridi</text>
<text top="111" left="545" width="271" height="14" font="1">Reduction of complex Hermitian matrix to</text>
<text top="129" left="545" width="271" height="14" font="1">real symmetric tridiagonal matrix via unitary</text>
<text top="147" left="545" width="159" height="14" font="1">similarity transformations.</text>
<text top="168" left="477" width="24" height="14" font="1">tql2</text>
<text top="169" left="545" width="271" height="14" font="1">Eigenvalues and eigenvectors of symmetric</text>
<text top="187" left="545" width="194" height="14" font="1">tridiagonal matrix by ql method.</text>
<text top="204" left="477" width="37" height="14" font="1">htribk</text>
<text top="205" left="545" width="271" height="14" font="1">Eigenvectors of complex Hermitian matrix</text>
<text top="223" left="545" width="271" height="14" font="1">by back transformation of corresponding real</text>
<text top="241" left="545" width="178" height="14" font="1">symmetric tridiagonal matrix.</text>
<text top="274" left="468" width="338" height="14" font="1">Table 1: Relevant Hermitian Eigensystem routines in</text>
<text top="294" left="468" width="53" height="11" font="3">EISPACK</text>
<text top="323" left="477" width="60" height="14" font="1">Parameter</text>
<text top="323" left="732" width="34" height="14" font="1">Value</text>
<text top="345" left="477" width="149" height="14" font="1">Number of CUDA Cores</text>
<text top="345" left="732" width="22" height="14" font="1">448</text>
<text top="363" left="477" width="163" height="14" font="1">Frequency of CUDA Cores</text>
<text top="363" left="732" width="54" height="14" font="1">1.15GHz</text>
<text top="382" left="477" width="237" height="14" font="1">Double Precision ﬂoating point perfor-</text>
<text top="400" left="477" width="81" height="14" font="1">mance (peak)</text>
<text top="382" left="732" width="66" height="14" font="1">515 Gﬂops</text>
<text top="418" left="477" width="237" height="14" font="1">Single Precision ﬂoating point perfor-</text>
<text top="436" left="477" width="81" height="14" font="1">mance (peak)</text>
<text top="418" left="732" width="68" height="14" font="1">1.03 Tﬂops</text>
<text top="455" left="477" width="150" height="14" font="1">Total Dedicated Memory</text>
<text top="455" left="732" width="82" height="14" font="1">3GB GDDR5</text>
<text top="487" left="484" width="306" height="14" font="1">Table 2: NVIDIA Tesla C2050 GPU Speciﬁcations</text>
<text top="535" left="468" width="338" height="14" font="1">each providing 32 streaming processors (SP), offer 448</text>
<text top="553" left="468" width="338" height="14" font="1">parallel cores in total. While many earlier GPUs com-</text>
<text top="571" left="468" width="338" height="14" font="1">pletely lacked double precision support, the Tesla GPU</text>
<text top="589" left="468" width="338" height="14" font="1">provides improved double-precision ﬂoating point per-</text>
<text top="607" left="468" width="60" height="14" font="1">formance.</text>
<text top="625" left="483" width="323" height="14" font="1">The execution times for 1000 N -order input matrices</text>
<text top="643" left="468" width="27" height="14" font="1">with</text>
<text top="645" left="501" width="53" height="11" font="3">EISPACK</text>
<text top="643" left="559" width="22" height="14" font="1">and</text>
<text top="645" left="587" width="50" height="11" font="3">LAPACK</text>
<text top="643" left="643" width="163" height="14" font="1">on a single CPU core and</text>
<text top="661" left="468" width="338" height="14" font="1">on the GPU are shown in Figure 2. GPU times are col-</text>
<text top="679" left="468" width="338" height="14" font="1">lected via the platform timers and are inclusive of mem-</text>
<text top="697" left="468" width="131" height="14" font="1">ory transfer overhead.</text>
<text top="715" left="483" width="170" height="14" font="1">Within a critical window (N</text>
<text top="714" left="659" width="147" height="15" font="1">= 512 − 2048), the cur-</text>
<text top="733" left="468" width="338" height="14" font="1">rent GPU routine yields performance increases of be-</text>
<text top="751" left="468" width="36" height="14" font="1">tween</text>
<text top="750" left="507" width="173" height="15" font="1">50 − 100× over the previous</text>
<text top="753" left="685" width="53" height="11" font="3">EISPACK</text>
<text top="751" left="741" width="65" height="14" font="1">implemen-</text>
<text top="769" left="468" width="338" height="14" font="1">tation, a result of performance gains at both thread and</text>
<text top="787" left="468" width="338" height="14" font="1">block levels. As the matrix order increases, the GPU</text>
<text top="805" left="468" width="338" height="14" font="1">memory is able to accommodate fewer matrices to pro-</text>
<text top="823" left="468" width="338" height="14" font="1">vide any block-level performance advantage and execu-</text>
<text top="841" left="468" width="338" height="14" font="1">tion resources begin to idle. Therefore, the scalability of</text>
<text top="858" left="468" width="338" height="14" font="1">the approach is restricted for higher values of N by the</text>
<text top="876" left="468" width="338" height="14" font="1">hard limit that memory places on GPU occupancy despite</text>
<text top="894" left="468" width="329" height="14" font="1">the still-observable beneﬁts of thread-level parallelism.</text>
<text top="912" left="483" width="75" height="14" font="1">The superior</text>
<text top="914" left="561" width="50" height="11" font="3">LAPACK</text>
<text top="912" left="615" width="192" height="14" font="1">cache behaviour delivers consis-</text>
<text top="930" left="468" width="189" height="14" font="1">tently higher performance over</text>
<text top="932" left="663" width="53" height="11" font="3">EISPACK</text>
<text top="930" left="721" width="85" height="14" font="1">for larger val-</text>
<text top="948" left="468" width="258" height="14" font="1">ues of N. While equivalent routines in both</text>
<text top="950" left="730" width="50" height="11" font="3">LAPACK</text>
<text top="948" left="785" width="22" height="14" font="1">and</text>
<text top="968" left="468" width="53" height="11" font="3">EISPACK</text>
<text top="966" left="525" width="132" height="14" font="1">are of storage order O</text>
<text top="965" left="657" width="15" height="15" font="1">(n</text>
<text top="964" left="672" width="6" height="11" font="6">2</text>
<text top="965" left="679" width="10" height="15" font="1">),</text>
<text top="968" left="693" width="50" height="11" font="3">LAPACK</text>
<text top="966" left="747" width="59" height="14" font="1">reuses the</text>
<text top="984" left="468" width="338" height="14" font="1">same input matrix memory for output and is therefore</text>
<text top="1002" left="468" width="140" height="14" font="1">more memory efﬁcient.</text>
<text top="1044" left="468" width="91" height="11" font="2"><b>DISCUSSION</b></text>
<text top="1067" left="468" width="338" height="14" font="1">For the intended neutron scattering application, good per-</text>
<text top="1085" left="468" width="338" height="14" font="1">formance within the critical window will be sufﬁcient to</text>
<text top="1103" left="468" width="338" height="14" font="1">allow an order of magnitude advance in the size, com-</text>
<text top="1121" left="468" width="270" height="14" font="1">plexity or grid reﬁnement of the INS models.</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="7" size="11" family="Times" color="#000000"/>
	<fontspec id="8" size="11" family="Times" color="#000000"/>
<text top="536" left="173" width="10" height="13" font="7"> 1</text>
<text top="482" left="166" width="17" height="13" font="7"> 10</text>
<text top="427" left="159" width="24" height="13" font="7"> 100</text>
<text top="372" left="152" width="31" height="13" font="7"> 1000</text>
<text top="317" left="145" width="38" height="13" font="7"> 10000</text>
<text top="263" left="138" width="45" height="13" font="7"> 100000</text>
<text top="208" left="145" width="38" height="13" font="7"> 1e+06</text>
<text top="153" left="145" width="38" height="13" font="7"> 1e+07</text>
<text top="99" left="145" width="38" height="13" font="7"> 1e+08</text>
<text top="550" left="189" width="24" height="13" font="7"> 128</text>
<text top="550" left="294" width="24" height="13" font="7"> 256</text>
<text top="550" left="398" width="24" height="13" font="7"> 512</text>
<text top="550" left="499" width="31" height="13" font="7"> 1024</text>
<text top="550" left="604" width="31" height="13" font="7"> 2048</text>
<text top="550" left="709" width="31" height="13" font="7"> 4096</text>
<text top="386" left="114" width="0" height="13" font="8">Execution Time (seconds)</text>
<text top="571" left="443" width="87" height="13" font="7">Matrix Order N</text>
<text top="112" left="286" width="88" height="13" font="7">CPU EISPACK</text>
<text top="126" left="288" width="86" height="13" font="7">CPU LAPACK</text>
<text top="140" left="235" width="140" height="13" font="7">Tesla C2050 - EISPACK</text>
<text top="428" left="209" width="14" height="13" font="7">32</text>
<text top="374" left="310" width="21" height="13" font="7">314</text>
<text top="307" left="411" width="28" height="13" font="7">5154</text>
<text top="245" left="512" width="35" height="13" font="7">71504</text>
<text top="192" left="613" width="42" height="13" font="7">651953</text>
<text top="140" left="714" width="48" height="13" font="7">5824843</text>
<text top="461" left="222" width="14" height="13" font="7">30</text>
<text top="413" left="323" width="21" height="13" font="7">228</text>
<text top="365" left="424" width="28" height="13" font="7">1712</text>
<text top="315" left="525" width="35" height="13" font="7">13750</text>
<text top="267" left="626" width="42" height="13" font="7">107150</text>
<text top="218" left="731" width="42" height="13" font="7">829380</text>
<text top="515" left="225" width="7" height="13" font="7">4</text>
<text top="477" left="326" width="14" height="13" font="7">20</text>
<text top="434" left="427" width="21" height="13" font="7">124</text>
<text top="390" left="532" width="21" height="13" font="7">781</text>
<text top="335" left="633" width="28" height="13" font="7">7998</text>
<text top="232" left="731" width="42" height="13" font="7">612060</text>
<text top="608" left="87" width="628" height="14" font="1">Figure 2: Execution time for 1000 double precision Hermitian matrices of order N with (i) the current</text>
<text top="610" left="719" width="53" height="11" font="3">EISPACK</text>
<text top="608" left="777" width="29" height="14" font="1">CPU</text>
<text top="626" left="87" width="120" height="14" font="1">implementation, (ii)</text>
<text top="628" left="210" width="50" height="11" font="3">LAPACK</text>
<text top="626" left="264" width="146" height="14" font="1">on CPU and (iii) the test</text>
<text top="628" left="414" width="53" height="11" font="3">EISPACK</text>
<text top="626" left="471" width="296" height="14" font="1">implementation on a NVIDIA Tesla C2050 GPU.</text>
<text top="689" left="102" width="324" height="14" font="1">In the long-term, it is expected that subsequent GPU</text>
<text top="707" left="87" width="338" height="14" font="1">models will offer improved memory characteristics and</text>
<text top="725" left="87" width="338" height="14" font="1">deliver higher performance. Furthermore, the need for</text>
<text top="743" left="87" width="75" height="14" font="1">migration to</text>
<text top="745" left="168" width="50" height="11" font="3">LAPACK</text>
<text top="743" left="224" width="202" height="14" font="1">as larger systems are modeled is</text>
<text top="761" left="87" width="47" height="14" font="1">evident.</text>
<text top="780" left="102" width="324" height="14" font="1">The intention of this work has been to create an efﬁ-</text>
<text top="798" left="87" width="277" height="14" font="1">cient GPU port that meets the need created by</text>
<text top="800" left="369" width="56" height="11" font="3">SCATTER</text>
<text top="816" left="87" width="280" height="14" font="1">and that is based on the established numerical</text>
<text top="818" left="372" width="53" height="11" font="3">EISPACK</text>
<text top="834" left="87" width="338" height="14" font="1">code. We anticipate the emergence of standard numer-</text>
<text top="851" left="87" width="338" height="14" font="1">ical libraries for the GPU that are based on efﬁcient al-</text>
<text top="869" left="87" width="338" height="14" font="1">gorithms oriented towards the particular strengths of the</text>
<text top="887" left="87" width="237" height="14" font="1">platform. A very recent release of the</text>
<text top="889" left="330" width="50" height="11" font="3">MAGMA</text>
<text top="887" left="385" width="40" height="14" font="1">library</text>
<text top="905" left="87" width="338" height="14" font="1">introduces a Hermitian eigensolver for hybrid multicore-</text>
<text top="923" left="87" width="338" height="14" font="1">CPU-GPU conﬁgurations that is based on an alterna-</text>
<text top="941" left="87" width="338" height="14" font="1">tive divide-and-conquer algorithm. The suitability of this</text>
<text top="961" left="87" width="50" height="11" font="3">LAPACK</text>
<text top="959" left="137" width="288" height="14" font="1">-based version is being evaluated. However, our</text>
<text top="977" left="87" width="191" height="14" font="1">initial observations indicate that</text>
<text top="979" left="282" width="50" height="11" font="3">MAGMA</text>
<text top="977" left="336" width="89" height="14" font="1">performance is</text>
<text top="995" left="87" width="338" height="14" font="1">optimised for very large values of N , outside the critical</text>
<text top="1013" left="87" width="177" height="14" font="1">window identiﬁed previously.</text>
<text top="1060" left="87" width="110" height="11" font="2"><b>CONCLUSIONS</b></text>
<text top="1085" left="87" width="338" height="14" font="1">The particular applicability of INS to the study of nano-</text>
<text top="1103" left="87" width="338" height="14" font="1">materials has led to increasing popularity for structural</text>
<text top="1121" left="87" width="338" height="14" font="1">determination in the materials science community. Li-</text>
<text top="689" left="468" width="338" height="14" font="1">braries of mathematical routines remain the foundation</text>
<text top="707" left="468" width="338" height="14" font="1">of these applications and it is important to establish and</text>
<text top="725" left="468" width="218" height="14" font="1">maintain efﬁcient implementations.</text>
<text top="725" left="700" width="107" height="14" font="1">We have demon-</text>
<text top="743" left="468" width="338" height="14" font="1">strated the substantial performance potential of the GPU</text>
<text top="761" left="468" width="338" height="14" font="1">in INS modelling and similar applications that rely on</text>
<text top="779" left="468" width="208" height="14" font="1">signiﬁcant numerical computation.</text>
<text top="797" left="483" width="323" height="14" font="1">The current implementation remains in the tuning and</text>
<text top="815" left="468" width="338" height="14" font="1">testing stages and performance improvements are prob-</text>
<text top="833" left="468" width="338" height="14" font="1">able. Testing and deployment in a multi-GPU cluster</text>
<text top="851" left="468" width="338" height="14" font="1">conﬁguration is intended during re-integration of the new</text>
<text top="869" left="468" width="163" height="14" font="1">eigenanalysis routines with</text>
<text top="871" left="635" width="33" height="11" font="3">GULP</text>
<text top="869" left="668" width="26" height="14" font="1">, the</text>
<text top="871" left="698" width="56" height="11" font="3">SCATTER</text>
<text top="869" left="758" width="48" height="14" font="1">host ap-</text>
<text top="887" left="468" width="338" height="14" font="1">plication (Gale and Rohl, 2003), before simulations with</text>
<text top="905" left="468" width="196" height="14" font="1">actual INS models are evaluated.</text>
<text top="923" left="483" width="324" height="14" font="1">Further work will investigate other computationally in-</text>
<text top="941" left="468" width="338" height="14" font="1">tensive aspects of INS modelling that will beneﬁt from</text>
<text top="959" left="468" width="338" height="14" font="1">GPU acceleration. This includes derivation of the dy-</text>
<text top="977" left="468" width="273" height="14" font="1">namical matrix and nearest-neighbour search.</text>
<text top="996" left="483" width="324" height="14" font="1">The challenge of determining optimal parameters for</text>
<text top="1014" left="468" width="338" height="14" font="1">launch conﬁguration and performance tuning presents an</text>
<text top="1031" left="468" width="338" height="14" font="1">opportunity to apply heuristic techniques. Ultimately,</text>
<text top="1049" left="468" width="338" height="14" font="1">we seek to investigate deployment of the neutron scatter-</text>
<text top="1067" left="468" width="338" height="14" font="1">ing program for complex models in large dynamic GPU-</text>
<text top="1085" left="468" width="338" height="14" font="1">accelerated heterogeneous environments and techniques</text>
<text top="1103" left="468" width="338" height="14" font="1">for improving co-operative CPU-GPU throughput. This</text>
<text top="1121" left="468" width="163" height="14" font="1">will combine CPU, GPU-</text>
<text top="1123" left="631" width="53" height="11" font="3">EISPACK</text>
<text top="1121" left="691" width="116" height="14" font="1">and, prospectively,</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1263" width="892">
	<fontspec id="9" size="11" family="Times" color="#000000"/>
<text top="92" left="87" width="338" height="14" font="1">MAGMA in an adaptive framework that optimizes for</text>
<text top="109" left="87" width="338" height="14" font="1">performance by balancing between alternative execution</text>
<text top="127" left="87" width="338" height="14" font="1">paths. Multiple implementations of GPU kernels, opti-</text>
<text top="145" left="87" width="338" height="14" font="1">mised for various problem scales, become a means of</text>
<text top="163" left="87" width="215" height="14" font="1">achieving this performance balance.</text>
<text top="208" left="87" width="174" height="11" font="2"><b>ACKNOWLEDGEMENTS</b></text>
<text top="233" left="87" width="338" height="14" font="1">The authors would like to thank NVIDIA Corporation</text>
<text top="251" left="87" width="338" height="14" font="1">for the donation through the Professor Partnership pro-</text>
<text top="269" left="87" width="338" height="14" font="1">gramme of the GPU Tesla equipment employed in this</text>
<text top="287" left="87" width="338" height="14" font="1">work. Our appreciation to Julian Gale of Curtin Univer-</text>
<text top="305" left="87" width="338" height="14" font="1">sity, Australia and Daniel L. Roach of Salford University</text>
<text top="323" left="87" width="87" height="14" font="1">for making the</text>
<text top="325" left="177" width="33" height="11" font="3">GULP</text>
<text top="323" left="214" width="22" height="14" font="1">and</text>
<text top="325" left="239" width="56" height="11" font="3">SCATTER</text>
<text top="323" left="299" width="127" height="14" font="1">source code available</text>
<text top="365" left="87" width="100" height="11" font="2"><b>REFERENCES</b></text>
<text top="398" left="87" width="338" height="12" font="7">Bethel, E., van Rosendale, J., Southard, D., Gaither, K., Childs,</text>
<text top="414" left="102" width="324" height="12" font="7">H., Brugger, E., and Ahern, S. (2011). Visualization at Su-</text>
<text top="431" left="102" width="324" height="12" font="7">percomputing Centers: The Tale of Little Big Iron and the</text>
<text top="447" left="102" width="324" height="12" font="7">Three Skinny Guys. <i>IEEE Computer Graphics and Applica-</i></text>
<text top="463" left="102" width="26" height="12" font="9"><i>tions</i></text>
<text top="463" left="128" width="77" height="12" font="7">, 31(1):90–95.</text>
<text top="495" left="87" width="338" height="12" font="7">Cline, A. K. and Meyering, J. (1991). Converting eispack to run</text>
<text top="511" left="102" width="324" height="12" font="7">efﬁciently on a vector processor. Technical report, Pleasant</text>
<text top="528" left="102" width="170" height="12" font="7">Valley Software, Austin, Texas.</text>
<text top="559" left="87" width="338" height="12" font="7">Dongarra, J. J., Duff, I. S., Sorensen, D. C., and van der</text>
<text top="575" left="102" width="324" height="12" font="7">Vorst, H. A. (1998). <i>Numerical linear algebra for high-</i></text>
<text top="592" left="102" width="128" height="12" font="9"><i>performance computers</i></text>
<text top="592" left="230" width="113" height="12" font="7">. SIAM, 2nd edition.</text>
<text top="623" left="87" width="338" height="12" font="7">Feldman, S. (1990). A Fortran to C converter. In <i>ACM SIG-</i></text>
<text top="640" left="102" width="116" height="12" font="9"><i>PLAN Fortran Forum</i></text>
<text top="640" left="217" width="171" height="12" font="7">, volume 9, pages 21–22. ACM.</text>
<text top="671" left="87" width="338" height="12" font="7">Gale, J. and Rohl, A. (2003). The general utility lattice program</text>
<text top="687" left="102" width="260" height="12" font="7">(GULP). <i>Molecular Simulation</i>, 29(5):291–341.</text>
<text top="719" left="87" width="338" height="12" font="7">Garba, M., Gonz´alez-V´elez, H., and Roach, D. (2010). Parallel</text>
<text top="735" left="102" width="324" height="12" font="7">computational modelling of inelastic neutron scattering in</text>
<text top="752" left="102" width="324" height="12" font="7">multi-node and multi-core architectures. In <i>IEEE HPCC-10</i>,</text>
<text top="768" left="102" width="186" height="12" font="7">pages 509–514, Melbourne. IEEE.</text>
<text top="799" left="87" width="338" height="12" font="7">Kirk, D. and Wen-mei, W. (2010). <i>Programming massively par-</i></text>
<text top="816" left="102" width="213" height="12" font="9"><i>allel processors: A Hands-on approach</i></text>
<text top="816" left="314" width="111" height="12" font="7">. Morgan Kaufmann</text>
<text top="832" left="102" width="222" height="12" font="7">Publishers Inc. San Francisco, CA, USA.</text>
<text top="864" left="87" width="338" height="12" font="7">Nickolls, J., Buck, I., Garland, M., and Skadron, K. (2008).</text>
<text top="880" left="102" width="261" height="12" font="7">Scalable parallel programming with CUDA.</text>
<text top="880" left="387" width="35" height="12" font="9"><i>Queue</i></text>
<text top="880" left="422" width="3" height="12" font="7">,</text>
<text top="897" left="102" width="63" height="12" font="7">6(2):40–53.</text>
<text top="928" left="87" width="338" height="12" font="7">Nvidia Corporation (2009). NVIDIA CUDA C Programming</text>
<text top="944" left="102" width="123" height="12" font="7">Best Practices Guide.</text>
<text top="944" left="241" width="116" height="12" font="7">Manual Version 2.3.</text>
<text top="944" left="374" width="51" height="12" font="7">Available</text>
<text top="961" left="102" width="324" height="12" font="7">from: http://developer.nvidia.com/ (Last Ac-</text>
<text top="977" left="102" width="111" height="12" font="7">cessed: 1 Feb 2011).</text>
<text top="1009" left="87" width="338" height="12" font="7">Roach, D., Ross, K., and Gale, J. D. (2010). The application</text>
<text top="1025" left="102" width="324" height="12" font="7">of coherent inelastic neutron scattering to the study of poly-</text>
<text top="1041" left="102" width="324" height="12" font="7">crystalline materials. <i>Physical Review B</i>. Submitted for pub-</text>
<text top="1058" left="102" width="44" height="12" font="7">lication.</text>
<text top="1089" left="87" width="338" height="12" font="7">Roach, D. L., Gale, J., and Ross, D. (2007). Scatter: A New In-</text>
<text top="1106" left="102" width="324" height="12" font="7">elastic Neutron Scattering Simulation Subroutine for GULP.</text>
<text top="1122" left="102" width="76" height="12" font="9"><i>Neutron News</i></text>
<text top="1122" left="177" width="77" height="12" font="7">, 18(3):21–23.</text>
<text top="93" left="468" width="338" height="12" font="7">Smith, B. T., Boyle, J. M., Dongarra, J., Garbow, B. S., Ikebe,</text>
<text top="109" left="483" width="323" height="12" font="7">Y., Klema, V. C., and Moler, C. B. (1976). <i>Matrix Eigen-</i></text>
<text top="126" left="483" width="199" height="12" font="9"><i>system Routines - EISPACK Guide</i></text>
<text top="125" left="682" width="124" height="12" font="7">, volume 6 of <i>LNCS</i>.</text>
<text top="142" left="483" width="89" height="12" font="7">Springer-Verlag.</text>
<text top="170" left="468" width="338" height="12" font="7">Tomov, S., Dongarra, J., and Baboulin, M. (2010a). Towards</text>
<text top="187" left="483" width="323" height="12" font="7">dense linear algebra for hybrid GPU accelerated manycore</text>
<text top="203" left="483" width="258" height="12" font="7">systems. <i>Parallel Computing</i>, 36(5-6):232–240.</text>
<text top="232" left="468" width="338" height="12" font="7">Tomov, S., Nath, R., Ltaief, H., and Dongarra, J. (2010b).</text>
<text top="248" left="483" width="323" height="12" font="7">Dense linear algebra solvers for multicore with GPU acceler-</text>
<text top="264" left="483" width="324" height="12" font="7">ators. In <i>IPDPS 2010 Workshops</i>, pages 1–8, Atlanta. IEEE.</text>
<text top="293" left="468" width="338" height="12" font="7">Vzquez, F., Fernndez, J. J., and Garzn, E. M. (2010). A new</text>
<text top="309" left="483" width="324" height="12" font="7">approach for sparse matrix vector product on nvidia gpus.</text>
<text top="326" left="483" width="308" height="12" font="9"><i>Concurrency and Computation: Practice and Experience</i></text>
<text top="326" left="791" width="3" height="12" font="7">.</text>
<text top="375" left="468" width="174" height="11" font="2"><b>AUTHOR BIOGRAPHIES</b></text>
<text top="398" left="468" width="338" height="14" font="2"><b>Michael T. Garba </b>has a background in Electrical</text>
<text top="416" left="468" width="338" height="14" font="1">Engineering and holds a Masters degree in Computing</text>
<text top="434" left="468" width="338" height="14" font="1">from Robert Gordon University, Aberdeen where he is</text>
<text top="452" left="468" width="338" height="14" font="1">currently working towards a PhD. His research interests</text>
<text top="470" left="468" width="338" height="14" font="1">are in high performance parallel computing, emerging</text>
<text top="488" left="468" width="338" height="14" font="1">parallel architectures and computational nanoscience.</text>
<text top="506" left="468" width="249" height="14" font="1">His email is m.t.garba@rgu.ac.uk.</text>
<text top="541" left="468" width="96" height="11" font="2"><b>Horacio Gonz ´</b></text>
<text top="541" left="558" width="49" height="11" font="2"><b>alez–V´</b></text>
<text top="541" left="601" width="205" height="14" font="2"><b>elez. </b>is a lecturer with the Robert</text>
<text top="559" left="468" width="338" height="14" font="1">Gordon University, where he conducts research in paral-</text>
<text top="577" left="468" width="338" height="14" font="1">lel and distributed computing. He holds a doctoral degree</text>
<text top="595" left="468" width="338" height="14" font="1">in informatics from the University of Edinburgh, where</text>
<text top="613" left="468" width="338" height="14" font="1">he was also a research fellow. He has held different po-</text>
<text top="631" left="468" width="338" height="14" font="1">sitions in marketing and systems engineering at Sun Mi-</text>
<text top="649" left="468" width="338" height="14" font="1">crosystems and Silicon Graphics. His recent research has</text>
<text top="667" left="468" width="338" height="14" font="1">been funded by the EPSRC and NESTA in the UK, the</text>
<text top="685" left="468" width="338" height="14" font="1">European Commission, and NVIDIA. His VCard can be</text>
<text top="703" left="468" width="326" height="16" font="1">found at http://member.acm.org/˜horacio.</text>
</page>
</pdf2xml>
