<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="0" size="15" family="Times" color="#000000"/>
<text top="251" left="236" width="446" height="16" font="0">Generating, Optimizing, and Scheduling a Compiler Level</text>
<text top="281" left="316" width="287" height="16" font="0">Representation of Stream Parallelism</text>
<text top="317" left="450" width="18" height="16" font="0">by</text>
<text top="353" left="393" width="132" height="16" font="0">Jeffrey M. Fiﬁeld</text>
<text top="389" left="333" width="252" height="16" font="0">B.S., University of Michigan, 2000</text>
<text top="425" left="332" width="254" height="16" font="0">M.S., University of Colorado, 2006</text>
<text top="574" left="370" width="178" height="16" font="0">A thesis submitted to the</text>
<text top="610" left="324" width="270" height="16" font="0">Faculty of the Graduate School of the</text>
<text top="646" left="302" width="315" height="16" font="0">University of Colorado in partial fulﬁllment</text>
<text top="682" left="328" width="263" height="16" font="0">of the requirements for the degree of</text>
<text top="718" left="382" width="154" height="16" font="0">Doctor of Philosophy</text>
<text top="754" left="339" width="241" height="16" font="0">Department of Computer Science</text>
<text top="789" left="443" width="36" height="16" font="0">2011</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1188" width="918">
<text top="275" left="389" width="140" height="16" font="0">This thesis entitled:</text>
<text top="297" left="113" width="691" height="16" font="0">Generating, Optimizing, and Scheduling a Compiler Level Representation of Stream Parallelism</text>
<text top="319" left="358" width="203" height="16" font="0">written by Jeffrey M. Fiﬁeld</text>
<text top="340" left="244" width="430" height="16" font="0">has been approved for the Department of Computer Science</text>
<text top="499" left="405" width="109" height="16" font="0">Dirk Grunwald</text>
<text top="630" left="415" width="88" height="16" font="0">Jeremy Siek</text>
<text top="729" left="623" width="34" height="16" font="0">Date</text>
<text top="895" left="130" width="657" height="16" font="0">The ﬁnal copy of this thesis has been examined by the signatories, and we ﬁnd that both the</text>
<text top="917" left="131" width="655" height="16" font="0">content and the form meet acceptable presentation standards of scholarly work in the above</text>
<text top="939" left="382" width="154" height="16" font="0">mentioned discipline.</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="795" width="15" height="16" font="0">iii</text>
<text top="128" left="108" width="328" height="16" font="0">Fiﬁeld, Jeffrey M. (Ph.D., Computer Science)</text>
<text top="172" left="108" width="691" height="16" font="0">Generating, Optimizing, and Scheduling a Compiler Level Representation of Stream Parallelism</text>
<text top="215" left="108" width="249" height="16" font="0">Thesis directed by Dirk Grunwald</text>
<text top="285" left="151" width="659" height="16" font="0">Stream parallelism is often cited as a powerful programming model for expressing paral-</text>
<text top="321" left="108" width="702" height="16" font="0">lel computation for multi-core and heterogeneous computers. It allows programmers to concisely</text>
<text top="357" left="108" width="702" height="16" font="0">describe the concurrency and communication requirements found in a program and it allows com-</text>
<text top="393" left="108" width="702" height="16" font="0">pilers and runtime systems to easily generate efﬁcient code targeting parallel hardware. This type</text>
<text top="429" left="108" width="702" height="16" font="0">of stream parallelism is often restricted to use the Synchronous Dataﬂow (SDF) model and imple-</text>
<text top="465" left="108" width="702" height="16" font="0">mented using static compilation and scheduling techniques. While powerful, SDF and the associ-</text>
<text top="501" left="108" width="702" height="16" font="0">ated static methods have real limitations when applied to general purpose programing on general</text>
<text top="537" left="108" width="132" height="16" font="0">purpose hardware.</text>
<text top="573" left="151" width="659" height="16" font="0">To increase generality, we can deﬁne stream parallelism as a graph of processes communicat-</text>
<text top="609" left="108" width="702" height="16" font="0">ing with one another over unidirectional data channels. Although dynamic scheduling techniques</text>
<text top="645" left="108" width="702" height="16" font="0">have been developed for this more general model, the powerful compiler transformations that are</text>
<text top="681" left="108" width="702" height="16" font="0">available under the SDF model no longer apply. This is made worse by the fact that general</text>
<text top="717" left="108" width="702" height="16" font="0">purpose models are typically implemented as software frameworks on top of high-level general</text>
<text top="753" left="108" width="137" height="16" font="0">purpose languages.</text>
<text top="789" left="151" width="659" height="16" font="0">The Stream and Kernel Intermediate Representation (SKIR) is a compiler level representa-</text>
<text top="825" left="108" width="702" height="16" font="0">tion of stream parallelism for general purpose languages. A SKIR compiler is able to recognize</text>
<text top="861" left="108" width="702" height="16" font="0">and take advantage of SDF style parallelism while allowing more general programs. This thesis</text>
<text top="897" left="108" width="702" height="16" font="0">presents the SKIR program representation and describes how it can be used as compiler target for</text>
<text top="933" left="108" width="702" height="16" font="0">several different high level languages. We show a dynamic scheduling mechanism for SKIR pro-</text>
<text top="969" left="108" width="702" height="16" font="0">grams based on the concepts of coroutines and task stealing. We also propose code optimizations to</text>
<text top="1005" left="108" width="702" height="16" font="0">reduce runtime overhead associated with dynamic scheduling. Such techniques are not possible in</text>
<text top="1041" left="108" width="702" height="16" font="0">a high-level software framework and provide performance that meets or exceeds the performance</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="796" width="14" height="16" font="0">iv</text>
<text top="128" left="108" width="633" height="16" font="0">of existing systems while providing greater generality and portability than static methods.</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">v</text>
<text top="252" left="425" width="69" height="16" font="0">Contents</text>
<text top="366" left="113" width="64" height="16" font="0">Chapter</text>
<text top="420" left="108" width="9" height="16" font="0">1</text>
<text top="420" left="135" width="89" height="16" font="0">Introduction</text>
<text top="420" left="801" width="9" height="16" font="0">1</text>
<text top="456" left="135" width="22" height="16" font="0">1.1</text>
<text top="456" left="176" width="600" height="16" font="0">Streaming Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="456" left="801" width="9" height="16" font="0">3</text>
<text top="492" left="135" width="22" height="16" font="0">1.2</text>
<text top="492" left="176" width="337" height="16" font="0">Limitations of Existing Programming Methods</text>
<text top="492" left="529" width="247" height="16" font="0">. . . . . . . . . . . . . . . . . . .</text>
<text top="492" left="801" width="9" height="16" font="0">5</text>
<text top="528" left="176" width="36" height="16" font="0">1.2.1</text>
<text top="528" left="234" width="542" height="16" font="0">Dynamic Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="528" left="801" width="9" height="16" font="0">6</text>
<text top="564" left="176" width="36" height="16" font="0">1.2.2</text>
<text top="564" left="234" width="542" height="16" font="0">Portability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="564" left="792" width="18" height="16" font="0">10</text>
<text top="600" left="135" width="22" height="16" font="0">1.3</text>
<text top="600" left="176" width="600" height="16" font="0">Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="600" left="792" width="18" height="16" font="0">11</text>
<text top="654" left="108" width="9" height="16" font="0">2</text>
<text top="654" left="135" width="390" height="16" font="0">Language Constructs for Stream Parallel Computation</text>
<text top="654" left="792" width="18" height="16" font="0">15</text>
<text top="690" left="135" width="22" height="16" font="0">2.1</text>
<text top="690" left="176" width="600" height="16" font="0">Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="690" left="792" width="18" height="16" font="0">16</text>
<text top="726" left="135" width="22" height="16" font="0">2.2</text>
<text top="726" left="176" width="600" height="16" font="0">Streams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="726" left="792" width="18" height="16" font="0">21</text>
<text top="762" left="135" width="22" height="16" font="0">2.3</text>
<text top="762" left="176" width="600" height="16" font="0">Stream Graph Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="762" left="792" width="18" height="16" font="0">22</text>
<text top="798" left="135" width="22" height="16" font="0">2.4</text>
<text top="798" left="176" width="81" height="16" font="0">Scheduling</text>
<text top="798" left="274" width="502" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="798" left="792" width="18" height="16" font="0">24</text>
<text top="852" left="108" width="9" height="16" font="0">3</text>
<text top="852" left="135" width="431" height="16" font="0">The Stream and Kernel Intermediate Representation (SKIR)</text>
<text top="852" left="792" width="18" height="16" font="0">25</text>
<text top="888" left="135" width="22" height="16" font="0">3.1</text>
<text top="888" left="176" width="600" height="16" font="0">Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="888" left="792" width="18" height="16" font="0">25</text>
<text top="924" left="135" width="22" height="16" font="0">3.2</text>
<text top="924" left="176" width="600" height="16" font="0">SKIR Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="924" left="792" width="18" height="16" font="0">26</text>
<text top="960" left="176" width="36" height="16" font="0">3.2.1</text>
<text top="960" left="234" width="542" height="16" font="0">Hierarchical Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="960" left="792" width="18" height="16" font="0">32</text>
<text top="996" left="135" width="22" height="16" font="0">3.3</text>
<text top="996" left="176" width="600" height="16" font="0">SKIR Streams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="996" left="792" width="18" height="16" font="0">33</text>
<text top="1032" left="135" width="22" height="16" font="0">3.4</text>
<text top="1032" left="176" width="600" height="16" font="0">SKIR Memory Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="1032" left="792" width="18" height="16" font="0">34</text>
<text top="1068" left="135" width="22" height="16" font="0">3.5</text>
<text top="1068" left="176" width="600" height="16" font="0">SKIR Program Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="1068" left="792" width="18" height="16" font="0">36</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="1" size="12" family="Times" color="#000000"/>
<text top="85" left="796" width="14" height="16" font="0">vi</text>
<text top="128" left="176" width="36" height="16" font="0">3.5.1</text>
<text top="128" left="234" width="542" height="16" font="0">Example 1: Static Stream Graph . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="128" left="792" width="18" height="16" font="0">36</text>
<text top="164" left="176" width="36" height="16" font="0">3.5.2</text>
<text top="164" left="234" width="542" height="16" font="0">Example 2: Dynamic Stream Graph . . . . . . . . . . . . . . . . . . . . .</text>
<text top="164" left="792" width="18" height="16" font="0">36</text>
<text top="200" left="135" width="22" height="16" font="0">3.6</text>
<text top="200" left="176" width="600" height="16" font="0">Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="200" left="792" width="18" height="16" font="0">39</text>
<text top="254" left="108" width="9" height="16" font="0">4</text>
<text top="254" left="135" width="309" height="16" font="0">Compiling High-Level Languages to SKIR</text>
<text top="254" left="792" width="18" height="16" font="0">41</text>
<text top="290" left="135" width="22" height="16" font="0">4.1</text>
<text top="290" left="176" width="600" height="16" font="0">Compiler Intrinsics: C Language . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="290" left="792" width="18" height="16" font="0">41</text>
<text top="326" left="176" width="36" height="16" font="0">4.1.1</text>
<text top="326" left="234" width="64" height="16" font="0">Example</text>
<text top="326" left="314" width="462" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="326" left="792" width="18" height="16" font="0">42</text>
<text top="362" left="176" width="36" height="16" font="0">4.1.2</text>
<text top="362" left="234" width="542" height="16" font="0">Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="362" left="792" width="18" height="16" font="0">42</text>
<text top="398" left="176" width="36" height="16" font="0">4.1.3</text>
<text top="398" left="234" width="542" height="16" font="0">Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="398" left="792" width="18" height="16" font="0">44</text>
<text top="434" left="135" width="22" height="16" font="0">4.2</text>
<text top="434" left="176" width="115" height="16" font="0">User Library: C</text>
<text top="433" left="289" width="17" height="13" font="1">++</text>
<text top="434" left="328" width="448" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="434" left="792" width="18" height="16" font="0">44</text>
<text top="470" left="176" width="36" height="16" font="0">4.2.1</text>
<text top="470" left="234" width="64" height="16" font="0">Example</text>
<text top="470" left="314" width="462" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="470" left="792" width="18" height="16" font="0">45</text>
<text top="506" left="176" width="36" height="16" font="0">4.2.2</text>
<text top="506" left="234" width="542" height="16" font="0">Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="506" left="792" width="18" height="16" font="0">47</text>
<text top="542" left="135" width="22" height="16" font="0">4.3</text>
<text top="542" left="176" width="600" height="16" font="0">Stream Language Front-end: StreamIt . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="542" left="792" width="18" height="16" font="0">50</text>
<text top="578" left="176" width="36" height="16" font="0">4.3.1</text>
<text top="578" left="234" width="542" height="16" font="0">Generating Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="578" left="792" width="18" height="16" font="0">50</text>
<text top="614" left="176" width="36" height="16" font="0">4.3.2</text>
<text top="614" left="234" width="542" height="16" font="0">Generating Pipelines and Split-Joins . . . . . . . . . . . . . . . . . . . . .</text>
<text top="614" left="792" width="18" height="16" font="0">54</text>
<text top="650" left="176" width="36" height="16" font="0">4.3.3</text>
<text top="650" left="234" width="542" height="16" font="0">Other Language Features . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="650" left="792" width="18" height="16" font="0">58</text>
<text top="686" left="135" width="22" height="16" font="0">4.4</text>
<text top="686" left="176" width="600" height="16" font="0">Embedded DSL: JavaScript . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="686" left="792" width="18" height="16" font="0">60</text>
<text top="722" left="176" width="36" height="16" font="0">4.4.1</text>
<text top="722" left="234" width="542" height="16" font="0">Sluice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="722" left="792" width="18" height="16" font="0">62</text>
<text top="758" left="176" width="36" height="16" font="0">4.4.2</text>
<text top="758" left="234" width="542" height="16" font="0">Dynamic Recompilation for SKIR . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="758" left="792" width="18" height="16" font="0">64</text>
<text top="794" left="176" width="36" height="16" font="0">4.4.3</text>
<text top="794" left="234" width="542" height="16" font="0">Ofﬂoading Kernel Execution . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="794" left="792" width="18" height="16" font="0">66</text>
<text top="830" left="176" width="36" height="16" font="0">4.4.4</text>
<text top="830" left="234" width="542" height="16" font="0">Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="830" left="792" width="18" height="16" font="0">68</text>
<text top="866" left="135" width="22" height="16" font="0">4.5</text>
<text top="866" left="176" width="600" height="16" font="0">Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="866" left="792" width="18" height="16" font="0">69</text>
<text top="919" left="108" width="9" height="16" font="0">5</text>
<text top="919" left="135" width="196" height="16" font="0">SKIR Dynamic Scheduling</text>
<text top="919" left="792" width="18" height="16" font="0">70</text>
<text top="955" left="135" width="22" height="16" font="0">5.1</text>
<text top="955" left="176" width="600" height="16" font="0">Stream Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="955" left="792" width="18" height="16" font="0">71</text>
<text top="991" left="135" width="22" height="16" font="0">5.2</text>
<text top="991" left="176" width="600" height="16" font="0">Single Threaded Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="991" left="792" width="18" height="16" font="0">73</text>
<text top="1027" left="135" width="22" height="16" font="0">5.3</text>
<text top="1027" left="176" width="600" height="16" font="0">Multithreaded Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="1027" left="792" width="18" height="16" font="0">80</text>
<text top="1063" left="135" width="22" height="16" font="0">5.4</text>
<text top="1063" left="176" width="600" height="16" font="0">Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="1063" left="792" width="18" height="16" font="0">83</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="791" width="19" height="16" font="0">vii</text>
<text top="128" left="108" width="9" height="16" font="0">6</text>
<text top="128" left="135" width="135" height="16" font="0">SKIR Compilation</text>
<text top="128" left="792" width="18" height="16" font="0">87</text>
<text top="164" left="135" width="22" height="16" font="0">6.1</text>
<text top="164" left="176" width="600" height="16" font="0">Static vs. Dynamic SKIR Compilation . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="164" left="792" width="18" height="16" font="0">87</text>
<text top="200" left="135" width="22" height="16" font="0">6.2</text>
<text top="200" left="176" width="600" height="16" font="0">Kernel Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="200" left="792" width="18" height="16" font="0">90</text>
<text top="236" left="176" width="36" height="16" font="0">6.2.1</text>
<text top="236" left="234" width="542" height="16" font="0">Detecting Hierarchical Kernels . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="236" left="792" width="18" height="16" font="0">90</text>
<text top="272" left="176" width="36" height="16" font="0">6.2.2</text>
<text top="272" left="234" width="542" height="16" font="0">Detecting Data Parallelism . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="272" left="792" width="18" height="16" font="0">91</text>
<text top="308" left="176" width="36" height="16" font="0">6.2.3</text>
<text top="308" left="234" width="542" height="16" font="0">Determining Rates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="308" left="792" width="18" height="16" font="0">91</text>
<text top="344" left="135" width="22" height="16" font="0">6.3</text>
<text top="344" left="176" width="600" height="16" font="0">Kernel Specialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="344" left="792" width="18" height="16" font="0">94</text>
<text top="380" left="176" width="36" height="16" font="0">6.3.1</text>
<text top="380" left="234" width="118" height="16" font="0">Kernel Batching</text>
<text top="380" left="368" width="408" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="380" left="792" width="18" height="16" font="0">95</text>
<text top="416" left="176" width="36" height="16" font="0">6.3.2</text>
<text top="416" left="234" width="542" height="16" font="0">Generating Kernels as Coroutines . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="416" left="792" width="18" height="16" font="0">96</text>
<text top="452" left="176" width="36" height="16" font="0">6.3.3</text>
<text top="452" left="234" width="576" height="16" font="0">Coroutine Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101</text>
<text top="488" left="176" width="36" height="16" font="0">6.3.4</text>
<text top="488" left="234" width="576" height="16" font="0">Specialization Templates . . . . . . . . . . . . . . . . . . . . . . . . . . . 103</text>
<text top="524" left="176" width="36" height="16" font="0">6.3.5</text>
<text top="524" left="234" width="576" height="16" font="0">Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106</text>
<text top="560" left="135" width="22" height="16" font="0">6.4</text>
<text top="560" left="176" width="122" height="16" font="0">Code Generation</text>
<text top="560" left="314" width="496" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108</text>
<text top="596" left="135" width="22" height="16" font="0">6.5</text>
<text top="596" left="176" width="634" height="16" font="0">Compiling for GPUs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108</text>
<text top="632" left="135" width="22" height="16" font="0">6.6</text>
<text top="632" left="176" width="634" height="16" font="0">Stream Graph Level Transformations . . . . . . . . . . . . . . . . . . . . . . . . . 112</text>
<text top="668" left="176" width="36" height="16" font="0">6.6.1</text>
<text top="668" left="234" width="576" height="16" font="0">Fusion: Reducing Parallelism . . . . . . . . . . . . . . . . . . . . . . . . 113</text>
<text top="704" left="176" width="36" height="16" font="0">6.6.2</text>
<text top="704" left="234" width="576" height="16" font="0">Fission: Increasing Parallelism . . . . . . . . . . . . . . . . . . . . . . . . 115</text>
<text top="757" left="108" width="9" height="16" font="0">7</text>
<text top="758" left="135" width="173" height="16" font="0">Performance Evaluation</text>
<text top="758" left="783" width="27" height="16" font="0">118</text>
<text top="794" left="135" width="22" height="16" font="0">7.1</text>
<text top="794" left="176" width="634" height="16" font="0">Benchmarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118</text>
<text top="830" left="135" width="22" height="16" font="0">7.2</text>
<text top="830" left="176" width="634" height="16" font="0">Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121</text>
<text top="866" left="135" width="22" height="16" font="0">7.3</text>
<text top="866" left="176" width="634" height="16" font="0">Sluice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134</text>
<text top="902" left="176" width="36" height="16" font="0">7.3.1</text>
<text top="902" left="234" width="576" height="16" font="0">Single Threaded Ofﬂoad . . . . . . . . . . . . . . . . . . . . . . . . . . . 136</text>
<text top="938" left="176" width="36" height="16" font="0">7.3.2</text>
<text top="938" left="234" width="576" height="16" font="0">Task Parallel Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138</text>
<text top="973" left="176" width="36" height="16" font="0">7.3.3</text>
<text top="973" left="234" width="576" height="16" font="0">Data Parallel Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139</text>
<text top="1027" left="108" width="9" height="16" font="0">8</text>
<text top="1027" left="135" width="99" height="16" font="0">Related Work</text>
<text top="1027" left="783" width="27" height="16" font="0">141</text>
<text top="1063" left="135" width="22" height="16" font="0">8.1</text>
<text top="1063" left="176" width="634" height="16" font="0">Compiler Representations for Stream Parallelism . . . . . . . . . . . . . . . . . . 141</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="786" width="24" height="16" font="0">viii</text>
<text top="128" left="135" width="22" height="16" font="0">8.2</text>
<text top="128" left="176" width="634" height="16" font="0">Dynamic Scheduling of Stream Parallelism . . . . . . . . . . . . . . . . . . . . . 143</text>
<text top="164" left="135" width="22" height="16" font="0">8.3</text>
<text top="164" left="176" width="634" height="16" font="0">Stream Parallelism for Heterogeneous Hardware . . . . . . . . . . . . . . . . . . . 145</text>
<text top="218" left="108" width="9" height="16" font="0">9</text>
<text top="218" left="135" width="82" height="16" font="0">Conclusion</text>
<text top="218" left="783" width="27" height="16" font="0">146</text>
<text top="294" left="113" width="100" height="16" font="0">Bibliography</text>
<text top="294" left="783" width="27" height="16" font="0">148</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="796" width="14" height="16" font="0">ix</text>
<text top="252" left="434" width="49" height="16" font="0">Tables</text>
<text top="367" left="108" width="42" height="16" font="0">Table</text>
<text top="418" left="135" width="22" height="16" font="0">3.1</text>
<text top="418" left="176" width="634" height="16" font="0">Overview of the Stream and Kernel Intermediate Representation (SKIR) operations. 26</text>
<text top="469" left="135" width="22" height="16" font="0">7.1</text>
<text top="469" left="176" width="588" height="16" font="0">The number and size of kernels for each benchmark. We bin the kernels in each</text>
<text top="505" left="176" width="588" height="16" font="0">benchmark according to their execution time in cycles. The table shows the number</text>
<text top="541" left="176" width="634" height="16" font="0">of kernels in each bin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">x</text>
<text top="252" left="430" width="57" height="16" font="0">Figures</text>
<text top="367" left="108" width="50" height="16" font="0">Figure</text>
<text top="418" left="135" width="22" height="16" font="0">1.1</text>
<text top="418" left="176" width="600" height="16" font="0">Pipeline found in the dedup benchmark. . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="418" left="801" width="9" height="16" font="0">7</text>
<text top="454" left="135" width="22" height="16" font="0">1.2</text>
<text top="454" left="176" width="600" height="16" font="0">Prime sieve implemented in the Go language. . . . . . . . . . . . . . . . . . . . .</text>
<text top="454" left="801" width="9" height="16" font="0">9</text>
<text top="505" left="135" width="22" height="16" font="0">2.1</text>
<text top="505" left="176" width="600" height="16" font="0">A data parallel addition written AMD’s Brook+ language . . . . . . . . . . . . . .</text>
<text top="505" left="792" width="18" height="16" font="0">16</text>
<text top="541" left="135" width="22" height="16" font="0">2.2</text>
<text top="541" left="176" width="600" height="16" font="0">A four stage pipeline in the language proposed by Kahn and MacQueen [40]. . . .</text>
<text top="541" left="792" width="18" height="16" font="0">17</text>
<text top="577" left="135" width="22" height="16" font="0">2.3</text>
<text top="577" left="176" width="391" height="16" font="0">A four stage pipeline written in the StreamIt language.</text>
<text top="577" left="583" width="193" height="16" font="0">. . . . . . . . . . . . . . .</text>
<text top="577" left="792" width="18" height="16" font="0">18</text>
<text top="613" left="135" width="22" height="16" font="0">2.4</text>
<text top="613" left="176" width="600" height="16" font="0">A kernel object in the GNU Radio stream processing system. . . . . . . . . . . . .</text>
<text top="613" left="792" width="18" height="16" font="0">19</text>
<text top="649" left="135" width="22" height="16" font="0">2.5</text>
<text top="649" left="176" width="588" height="16" font="0">An FM receiver application created for the GNU Radio stream processing frame-</text>
<text top="685" left="176" width="270" height="16" font="0">work using a graphical user interface.</text>
<text top="685" left="462" width="314" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="685" left="792" width="18" height="16" font="0">23</text>
<text top="721" left="135" width="22" height="16" font="0">2.6</text>
<text top="721" left="176" width="600" height="16" font="0">Constructing a stream graph for an equalizer in StreamIt. . . . . . . . . . . . . . .</text>
<text top="721" left="792" width="18" height="16" font="0">24</text>
<text top="772" left="135" width="22" height="16" font="0">3.1</text>
<text top="772" left="176" width="600" height="16" font="0">SKIR kernel state transitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="772" left="792" width="18" height="16" font="0">30</text>
<text top="808" left="135" width="22" height="16" font="0">3.2</text>
<text top="808" left="176" width="588" height="16" font="0">An example of a static SKIR program graph. The main procedure deﬁnes and</text>
<text top="844" left="176" width="588" height="16" font="0">executes a four stage pipeline similar to the one in Figure 2.2. The program is</text>
<text top="880" left="176" width="600" height="16" font="0">written in SKIR pseudo-code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="880" left="792" width="18" height="16" font="0">37</text>
<text top="916" left="135" width="22" height="16" font="0">3.3</text>
<text top="916" left="176" width="588" height="16" font="0">An example of a dynamic SKIR program graph. This ﬁgure shows the prime sieve</text>
<text top="952" left="176" width="588" height="16" font="0">program written as SKIR pseudo-code. It is similar to the Go program shown in</text>
<text top="988" left="176" width="600" height="16" font="0">Figure 1.2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="988" left="792" width="18" height="16" font="0">38</text>
<text top="1039" left="135" width="22" height="16" font="0">4.1</text>
<text top="1039" left="176" width="600" height="16" font="0">SKIR C Intrinsics. Each C intrinsic maps to one SKIR intrinsic . . . . . . . . . . .</text>
<text top="1039" left="792" width="18" height="16" font="0">42</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="796" width="14" height="16" font="0">xi</text>
<text top="128" left="135" width="22" height="16" font="0">4.2</text>
<text top="128" left="176" width="588" height="16" font="0">A simple SKIR program constructed using C compiler intrinsics. This program</text>
<text top="164" left="176" width="600" height="16" font="0">creates two streams of integers, adds them together, then prints the result. . . . . .</text>
<text top="164" left="792" width="18" height="16" font="0">43</text>
<text top="200" left="135" width="22" height="16" font="0">4.3</text>
<text top="200" left="176" width="181" height="16" font="0">An example of a SKIR C</text>
<text top="200" left="355" width="17" height="13" font="1">++</text>
<text top="200" left="376" width="147" height="16" font="0">program using the C</text>
<text top="200" left="522" width="17" height="13" font="1">++</text>
<text top="200" left="543" width="233" height="16" font="0">user library from Figure 4.4. . .</text>
<text top="200" left="792" width="18" height="16" font="0">46</text>
<text top="236" left="135" width="22" height="16" font="0">4.4</text>
<text top="236" left="176" width="135" height="16" font="0">An example of a C</text>
<text top="236" left="310" width="17" height="13" font="1">++</text>
<text top="236" left="331" width="433" height="16" font="0">library providing an object oriented interface for stream par-</text>
<text top="272" left="176" width="600" height="16" font="0">allelism using the SKIR C intrinsics. . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="272" left="792" width="18" height="16" font="0">48</text>
<text top="308" left="135" width="22" height="16" font="0">4.5</text>
<text top="308" left="176" width="349" height="16" font="0">A simple three stage pipeline written in StreamIt</text>
<text top="308" left="543" width="233" height="16" font="0">. . . . . . . . . . . . . . . . . .</text>
<text top="308" left="792" width="18" height="16" font="0">51</text>
<text top="344" left="135" width="22" height="16" font="0">4.6</text>
<text top="344" left="176" width="588" height="16" font="0">The result of compiling the IntSource ﬁlter from Figure 4.5 with the StreamIt</text>
<text top="380" left="176" width="600" height="16" font="0">to SKIR compiler. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="380" left="792" width="18" height="16" font="0">52</text>
<text top="416" left="135" width="22" height="16" font="0">4.7</text>
<text top="416" left="176" width="588" height="16" font="0">The result of compiling the Adder ﬁlter from Figure 4.5 with the StreamIt to</text>
<text top="452" left="176" width="600" height="16" font="0">SKIR compiler. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="452" left="792" width="18" height="16" font="0">53</text>
<text top="488" left="135" width="22" height="16" font="0">4.8</text>
<text top="488" left="176" width="588" height="16" font="0">The result of compiling the Main ﬁlter from Figure 4.5 with the StreamIt to SKIR</text>
<text top="524" left="176" width="67" height="16" font="0">compiler.</text>
<text top="524" left="260" width="516" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="524" left="792" width="18" height="16" font="0">55</text>
<text top="560" left="135" width="22" height="16" font="0">4.9</text>
<text top="560" left="176" width="600" height="16" font="0">The pipeline ﬁlter from the StreamIt to SKIR compiler runtime library. . . . . . . .</text>
<text top="560" left="792" width="18" height="16" font="0">56</text>
<text top="596" left="135" width="641" height="16" font="0">4.10 A generic duplicating splitter from the StreamIt to SKIR compiler runtime library. .</text>
<text top="596" left="792" width="18" height="16" font="0">57</text>
<text top="632" left="135" width="641" height="16" font="0">4.11 An example of a StreamIt prework function. . . . . . . . . . . . . . . . . . . . . .</text>
<text top="632" left="792" width="18" height="16" font="0">58</text>
<text top="668" left="135" width="336" height="16" font="0">4.12 An example of a StreamIt feedback loop.</text>
<text top="668" left="489" width="287" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . .</text>
<text top="668" left="792" width="18" height="16" font="0">58</text>
<text top="704" left="135" width="641" height="16" font="0">4.13 Array based vs. stream based addition in JavaScript . . . . . . . . . . . . . . . . .</text>
<text top="704" left="792" width="18" height="16" font="0">61</text>
<text top="740" left="135" width="629" height="16" font="0">4.14 Two simple Sluice kernels. The kernel on the left implements a simple counter.</text>
<text top="776" left="176" width="588" height="16" font="0">The kernel on the right adds the same value to each item popped the input stream</text>
<text top="812" left="176" width="297" height="16" font="0">and pushes the result to its output stream.</text>
<text top="812" left="489" width="287" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . .</text>
<text top="812" left="792" width="18" height="16" font="0">63</text>
<text top="848" left="135" width="311" height="16" font="0">4.15 An overview of Sluice kernel ofﬂoad.</text>
<text top="848" left="462" width="314" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="848" left="792" width="18" height="16" font="0">67</text>
<text top="899" left="135" width="22" height="16" font="0">5.1</text>
<text top="899" left="176" width="600" height="16" font="0">Basic lock free queue operations . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="899" left="792" width="18" height="16" font="0">72</text>
<text top="935" left="135" width="22" height="16" font="0">5.2</text>
<text top="935" left="176" width="600" height="16" font="0">Simpliﬁed version of the SKIR stream buffer data structure . . . . . . . . . . . . .</text>
<text top="935" left="792" width="18" height="16" font="0">73</text>
<text top="970" left="135" width="22" height="16" font="0">5.3</text>
<text top="970" left="176" width="600" height="16" font="0">An example of producer-consumer coroutines . . . . . . . . . . . . . . . . . . . .</text>
<text top="970" left="792" width="18" height="16" font="0">75</text>
<text top="1006" left="135" width="22" height="16" font="0">5.4</text>
<text top="1006" left="176" width="256" height="16" font="0">Yielding lock free queue operations</text>
<text top="1006" left="449" width="327" height="16" font="0">. . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="1006" left="792" width="18" height="16" font="0">76</text>
<text top="1042" left="135" width="22" height="16" font="0">5.5</text>
<text top="1042" left="176" width="600" height="16" font="0">An example of transforming a SKIR kernel to use coroutine scheduling. . . . . . .</text>
<text top="1042" left="792" width="18" height="16" font="0">77</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="791" width="19" height="16" font="0">xii</text>
<text top="128" left="135" width="22" height="16" font="0">5.6</text>
<text top="128" left="176" width="600" height="16" font="0">A single threaded scheduling algorithm for coroutine style kernel work functions. .</text>
<text top="128" left="792" width="18" height="16" font="0">77</text>
<text top="164" left="135" width="22" height="16" font="0">5.7</text>
<text top="164" left="176" width="588" height="16" font="0">An example of single threaded execution of a three stage pipeline. The large down-</text>
<text top="200" left="176" width="588" height="16" font="0">ward arrows represent work being done by a kernel, the dotted lines represent work</text>
<text top="236" left="176" width="600" height="16" font="0">stealing, and the horizontal arrows represent scheduling events. Time ﬂows down. .</text>
<text top="236" left="792" width="18" height="16" font="0">79</text>
<text top="272" left="135" width="22" height="16" font="0">5.8</text>
<text top="272" left="176" width="47" height="16" font="0">The K</text>
<text top="275" left="224" width="50" height="13" font="1">ERNEL</text>
<text top="272" left="273" width="11" height="16" font="0">T</text>
<text top="275" left="284" width="30" height="13" font="1">ASK</text>
<text top="272" left="315" width="23" height="16" font="0">::E</text>
<text top="275" left="338" width="61" height="13" font="1">XECUTE</text>
<text top="272" left="406" width="359" height="16" font="0">method runs the kernel work function and makes</text>
<text top="308" left="176" width="588" height="16" font="0">scheduling decisions in conjunction with a work stealing algorithm. The next task</text>
<text top="344" left="176" width="600" height="16" font="0">to run is returned. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</text>
<text top="344" left="792" width="18" height="16" font="0">81</text>
<text top="380" left="135" width="22" height="16" font="0">5.9</text>
<text top="380" left="176" width="588" height="16" font="0">An example of two processors executing a three stage pipeline. The large down-</text>
<text top="416" left="176" width="588" height="16" font="0">ward arrows represent work being done by a kernel, the dotted lines represent work</text>
<text top="452" left="176" width="600" height="16" font="0">stealing, and the horizontal arrows represent scheduling events. Time ﬂows down. .</text>
<text top="452" left="792" width="18" height="16" font="0">82</text>
<text top="503" left="135" width="22" height="16" font="0">6.1</text>
<text top="503" left="176" width="600" height="16" font="0">An example of a SKIR C program with a statically analyzable stream graph. . . . .</text>
<text top="503" left="792" width="18" height="16" font="0">89</text>
<text top="539" left="135" width="22" height="16" font="0">6.2</text>
<text top="539" left="176" width="539" height="16" font="0">Applying batching to SKIR CONSUMER produces BATCHED CONSUMER.</text>
<text top="539" left="731" width="45" height="16" font="0">. . . .</text>
<text top="539" left="792" width="18" height="16" font="0">95</text>
<text top="575" left="135" width="22" height="16" font="0">6.3</text>
<text top="575" left="176" width="600" height="16" font="0">Kernel work function template implementing batching. . . . . . . . . . . . . . . .</text>
<text top="575" left="792" width="18" height="16" font="0">96</text>
<text top="611" left="135" width="22" height="16" font="0">6.4</text>
<text top="611" left="176" width="600" height="16" font="0">An implementation of the skir.pop operation. . . . . . . . . . . . . . . . . . .</text>
<text top="611" left="792" width="18" height="16" font="0">97</text>
<text top="647" left="135" width="22" height="16" font="0">6.5</text>
<text top="647" left="176" width="600" height="16" font="0">SKIR coroutine helper function for x86-64. . . . . . . . . . . . . . . . . . . . . .</text>
<text top="647" left="792" width="18" height="16" font="0">98</text>
<text top="683" left="135" width="22" height="16" font="0">6.6</text>
<text top="683" left="176" width="600" height="16" font="0">Implementation of skir.yield for x86-64. . . . . . . . . . . . . . . . . . . . .</text>
<text top="683" left="792" width="18" height="16" font="0">99</text>
<text top="719" left="135" width="22" height="16" font="0">6.7</text>
<text top="719" left="176" width="634" height="16" font="0">Implementation of skir.return for x86-64. . . . . . . . . . . . . . . . . . . . 100</text>
<text top="755" left="135" width="22" height="16" font="0">6.8</text>
<text top="755" left="176" width="634" height="16" font="0">A coroutine elimination work function template. . . . . . . . . . . . . . . . . . . . 102</text>
<text top="791" left="135" width="22" height="16" font="0">6.9</text>
<text top="791" left="176" width="634" height="16" font="0">An implementation of skir.pop for use with coroutine elimination. . . . . . . . 103</text>
<text top="827" left="135" width="553" height="16" font="0">6.10 Generating specialized skir.pop templates with meta-programming.</text>
<text top="827" left="704" width="106" height="16" font="0">. . . . . . 105</text>
<text top="863" left="135" width="675" height="16" font="0">6.11 Execution order of SKIR kernel specialization passes. . . . . . . . . . . . . . . . . 106</text>
<text top="899" left="135" width="629" height="16" font="0">6.12 An example of the one work function instance per iteration execution strategy used</text>
<text top="935" left="176" width="588" height="16" font="0">by the OpenCL backend. In this example the kernel has an input rate of 2 and an</text>
<text top="970" left="176" width="634" height="16" font="0">output rate of 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110</text>
<text top="1006" left="135" width="675" height="16" font="0">6.13 The structure of OpenCL ofﬂoad within the SKIR runtime. . . . . . . . . . . . . . 111</text>
<text top="1042" left="135" width="675" height="16" font="0">6.14 SKIR kernel fusion algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="786" width="24" height="16" font="0">xiii</text>
<text top="128" left="135" width="675" height="16" font="0">6.15 SKIR kernel fusion algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114</text>
<text top="164" left="135" width="675" height="16" font="0">6.16 SKIR kernel ﬁssion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116</text>
<text top="215" left="135" width="22" height="16" font="0">7.1</text>
<text top="215" left="176" width="588" height="16" font="0">A SKIR version of the CalculateForces kernel from the nbody benchmark. The</text>
<text top="251" left="176" width="634" height="16" font="0">code is written in C++ using a class library interface to the SKIR intrinsics. . . . . 122</text>
<text top="287" left="135" width="22" height="16" font="0">7.2</text>
<text top="287" left="176" width="588" height="16" font="0">Throughput obtained by the SKIR compiler and scheduler for the StreamIt bench-</text>
<text top="323" left="176" width="634" height="16" font="0">marks using a varying number of threads. Error bars indicate one standard deviation.124</text>
<text top="359" left="135" width="22" height="16" font="0">7.3</text>
<text top="359" left="176" width="588" height="16" font="0">The results of performing coroutine elimination on the StreamIt benchmarks using</text>
<text top="395" left="176" width="634" height="16" font="0">the SKIR just-in-time compiler. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125</text>
<text top="431" left="135" width="22" height="16" font="0">7.4</text>
<text top="431" left="176" width="588" height="16" font="0">The results of performing dynamic fusion on the StreamIt benchmarks using the</text>
<text top="467" left="176" width="634" height="16" font="0">SKIR just-in-time compiler. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126</text>
<text top="503" left="135" width="22" height="16" font="0">7.5</text>
<text top="503" left="176" width="588" height="16" font="0">Throughput obtained by the SKIR dynamic scheduler, the StreamIt static sched-</text>
<text top="539" left="176" width="588" height="16" font="0">uler, and the GNU Radio dynamic scheduler for the StreamIt benchmarks using a</text>
<text top="575" left="176" width="634" height="16" font="0">varying number of threads. Error bars indicate one standard deviation. . . . . . . . 128</text>
<text top="611" left="135" width="22" height="16" font="0">7.6</text>
<text top="611" left="176" width="588" height="16" font="0">Throughput obtained by the SKIR dynamic scheduler, the StreamIt compiler tar-</text>
<text top="647" left="176" width="588" height="16" font="0">geting 8 threads, and the StreamIt compiler targeting the actual number of threads.</text>
<text top="683" left="176" width="634" height="16" font="0">Error bars indicate one standard deviation. . . . . . . . . . . . . . . . . . . . . . . 130</text>
<text top="719" left="135" width="22" height="16" font="0">7.7</text>
<text top="719" left="176" width="588" height="16" font="0">A comparison of SKIR performance to the performance of coarse-grained pipeline</text>
<text top="755" left="176" width="588" height="16" font="0">parallel applications parallelized using Pthreads, TBB, and FastFlow. Performance</text>
<text top="791" left="176" width="634" height="16" font="0">is measured as execution time. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132</text>
<text top="827" left="135" width="22" height="16" font="0">7.8</text>
<text top="827" left="176" width="588" height="16" font="0">Performance of the nbody benchmark running on SKIR using kernel ﬁssion on the</text>
<text top="863" left="176" width="634" height="16" font="0">CPU and OpenCL on the GPU. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134</text>
<text top="899" left="135" width="22" height="16" font="0">7.9</text>
<text top="899" left="176" width="588" height="16" font="0">Comparison of Pixastic code (left) with the same code ported to Sluice (right). The</text>
<text top="935" left="176" width="634" height="16" font="0">code that is shown inverts all the pixels in an image. . . . . . . . . . . . . . . . . . 135</text>
<text top="970" left="135" width="629" height="16" font="0">7.10 The CalculateForces kernel found in the nbody benchmark. Ported from the SKIR</text>
<text top="1006" left="176" width="634" height="16" font="0">C++ version of the benchmark shown in Figure 7.1. . . . . . . . . . . . . . . . . . 136</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="788" width="22" height="16" font="0">xiv</text>
<text top="128" left="135" width="629" height="16" font="0">7.11 Performance of Pixastic image processing routines coded as ordinary JavaScript</text>
<text top="164" left="176" width="588" height="16" font="0">compared to the performance of the same routines running as Sluice kernels using</text>
<text top="200" left="176" width="634" height="16" font="0">the SKIR runtime. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137</text>
<text top="236" left="135" width="629" height="16" font="0">7.12 Performance of the nbody benchmark implemented as procedural JavaScript, as</text>
<text top="272" left="176" width="588" height="16" font="0">Sluice code, and as Sluice code with CalculateForces kernel running on SKIR</text>
<text top="308" left="176" width="634" height="16" font="0">runtime. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138</text>
<text top="344" left="135" width="629" height="16" font="0">7.13 Per image processing time for the Pixastic benchmarks implemented when a vary-</text>
<text top="380" left="176" width="634" height="16" font="0">ing number of images are processed using Sluice task parallelism. . . . . . . . . . 139</text>
<text top="416" left="135" width="629" height="16" font="0">7.14 Speedup of the nbody benchmark due to data parallelism when the CalculateForces</text>
<text top="452" left="176" width="588" height="16" font="0">kernel is run on a multi-threaded SKIR runtime compared to the same benchmark</text>
<text top="488" left="176" width="634" height="16" font="0">using a single-threaded SKIR runtime. . . . . . . . . . . . . . . . . . . . . . . . . 140</text>
<text top="539" left="135" width="22" height="16" font="0">8.1</text>
<text top="539" left="176" width="634" height="16" font="0">An example of SVM-C pseudo code. . . . . . . . . . . . . . . . . . . . . . . . . . 142</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 1</text>
<text top="292" left="410" width="97" height="16" font="0">Introduction</text>
<text top="408" left="151" width="659" height="16" font="0">It has long been clear that the era of rapidly improving single processor performance is over.</text>
<text top="444" left="108" width="702" height="16" font="0">A decade ago, technological and economic realities forced the semiconductor industry to stop pur-</text>
<text top="479" left="108" width="702" height="16" font="0">suing increased clock speed as the primary means of improving performance. At the same time,</text>
<text top="515" left="108" width="702" height="16" font="0">computer architects had already extracted much of the performance to be gained from the exploita-</text>
<text top="551" left="108" width="702" height="16" font="0">tion of instruction level parallelism and prediction. Nevertheless, Moore’s Law has continued to</text>
<text top="587" left="108" width="702" height="16" font="0">hold and the number of transistors available to hardware architects has continued to increase. As</text>
<text top="623" left="108" width="702" height="16" font="0">a result, the semiconductor industry has been forced to provide performance improvements by</text>
<text top="659" left="108" width="702" height="16" font="0">adding more processing elements per chip with every new silicon generation. Chips with 10’s to</text>
<text top="695" left="108" width="702" height="16" font="0">100’s of processing cores are already a reality and will soon become the norm. Even mainstream</text>
<text top="731" left="108" width="702" height="16" font="0">mobile phones contain multiple processors, vector instruction set extensions, and programmable</text>
<text top="767" left="108" width="136" height="16" font="0">graphics hardware.</text>
<text top="803" left="151" width="659" height="16" font="0">Chip manufacturers are also attempting to differentiate their products and tailor their designs</text>
<text top="839" left="108" width="702" height="16" font="0">to different markets. The result is increased heterogeneity among the individual cores in single sys-</text>
<text top="875" left="108" width="702" height="16" font="0">tems and among different versions of the same architecture. Processing cores in the same product</text>
<text top="911" left="108" width="702" height="16" font="0">family can vary greatly in functionality, performance and energy efﬁciency. Compute accelerators</text>
<text top="947" left="108" width="702" height="16" font="0">that were previously ﬁxed function and single purpose are becoming more programable and more</text>
<text top="983" left="108" width="702" height="16" font="0">general purpose. Looking forward, there is a continued desire to investigate and invest in hetero-</text>
<text top="1019" left="108" width="683" height="16" font="0">geneous processor designs, many-core architectures, and processors using reconﬁgurable logic.</text>
<text top="1055" left="151" width="659" height="16" font="0">In the recent past, a programmer wanting to improve the performance of a piece of code</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">2</text>
<text top="128" left="108" width="702" height="16" font="0">could simply wait for the next processor generation and see their program run much faster on the</text>
<text top="164" left="108" width="702" height="16" font="0">new chip. Faster hardware designs, not better programs, provided most of the performance gains.</text>
<text top="200" left="108" width="702" height="16" font="0">While this is still true to some extent, the trends in mainstream processor design listed above are</text>
<text top="236" left="108" width="702" height="16" font="0">causing a shift in who is responsible for the performance of computer software. The burden of</text>
<text top="272" left="108" width="702" height="16" font="0">taking advantage of new hardware capabilities is shifting from away from processor architects and</text>
<text top="308" left="108" width="491" height="16" font="0">onto the backs of programmers, languages designers, and compilers.</text>
<text top="344" left="151" width="659" height="16" font="0">Unfortunately, writing algorithms and compilers that can take advantage of parallel proces-</text>
<text top="380" left="108" width="702" height="16" font="0">sor designs is challenging. Creating parallel code that is efﬁcient, correct, and portable is difﬁcult</text>
<text top="416" left="108" width="702" height="16" font="0">even for the most skilled programmers. Mainstream languages are highly sequential and contain</text>
<text top="452" left="108" width="702" height="16" font="0">only primitive support for parallel constructs. Common parallel programming constructs such as</text>
<text top="488" left="108" width="702" height="16" font="0">threads, locks, and SIMD intrinsics are to parallel programing as assembly language is to sequential</text>
<text top="524" left="108" width="702" height="16" font="0">programming, and are notoriously difﬁcult to use correctly. Decades of research on parallelizing</text>
<text top="560" left="108" width="702" height="16" font="0">sequential languages has failed to produce compiler technology that can automatically extract par-</text>
<text top="596" left="108" width="702" height="16" font="0">allelism from much more than simple loop nests. Adding heterogeneity into the mix only makes</text>
<text top="632" left="108" width="702" height="16" font="0">the problem of parallelizing applications more difﬁcult. To sustain the historical performance gains</text>
<text top="668" left="108" width="702" height="16" font="0">of the computer industry, new programming techniques must be developed for the new hardware</text>
<text top="704" left="108" width="331" height="16" font="0">architectures reaching the mainstream market.</text>
<text top="740" left="151" width="114" height="15" font="0">Stream parallel</text>
<text top="740" left="272" width="538" height="16" font="0">programming is one technique that has been used for exploiting parallel</text>
<text top="776" left="108" width="702" height="16" font="0">hardware, such as multi-core processors and vector acceleration units, as well as non-traditional</text>
<text top="812" left="108" width="702" height="16" font="0">programmable hardware such as graphics processors (GPU) and ﬁeld programmable gate arrays</text>
<text top="848" left="108" width="702" height="16" font="0">(FPGA). In the stream parallel model, a program is made up of a number of computational kernels</text>
<text top="884" left="108" width="702" height="16" font="0">that produce and consume streams of data. The kernels are linked together via their input and</text>
<text top="920" left="108" width="702" height="16" font="0">output streams to form a stream graph representing an algorithm. This abstraction is a natural ﬁt</text>
<text top="956" left="108" width="702" height="16" font="0">for many application domains. Any data driven application that must process large ﬂows of data</text>
<text top="992" left="108" width="702" height="16" font="0">with fairly regular computation is a good candidate for the stream parallel model. This includes</text>
<text top="1027" left="108" width="702" height="16" font="0">many algorithms that exhibit data or pipeline parallelism such as those found in graphics, all kinds</text>
<text top="1063" left="108" width="702" height="16" font="0">of signal processing (e.g. audio, video, radio), scientiﬁc codes, ﬁnancial applications, network</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">3</text>
<text top="128" left="108" width="658" height="16" font="0">processing, and most recently, distributed real-time processing of social network feeds [13].</text>
<text top="164" left="151" width="659" height="16" font="0">The kernel and stream based construction of stream programs has two beneﬁts. It makes</text>
<text top="200" left="108" width="702" height="16" font="0">parallelism and inter-task communication easy to express by programmers and it makes paral-</text>
<text top="236" left="108" width="702" height="16" font="0">lelism and inter-task communication easy to extract by compilers. There are three general types</text>
<text top="272" left="108" width="702" height="16" font="0">of parallelism that can be expressed by programmers and extracted by compilers in stream paral-</text>
<text top="308" left="108" width="702" height="16" font="0">lel programs. Because individual kernels are conceptually concurrent, with independent threads</text>
<text top="344" left="108" width="702" height="16" font="0">of control, kernels operating concurrently in different regions of a stream graph naturally exhibit</text>
<text top="380" left="108" width="702" height="16" font="0">task parallelism. Other kernels might be directly connected to one another in a producer consumer</text>
<text top="416" left="108" width="702" height="16" font="0">relationship. These kernels exhibit pipeline parallelism and can be scheduled to run on differ-</text>
<text top="452" left="108" width="702" height="16" font="0">ent processors with communication channels allocated between them. Finally, some kernels are</text>
<text top="488" left="108" width="702" height="16" font="0">stateless, and as a result do not carry dependencies from one execution to the next. These kernels</text>
<text top="524" left="108" width="702" height="16" font="0">exhibit data parallelism and many instances of the same kernel can be working on different parts</text>
<text top="560" left="108" width="280" height="16" font="0">of the input stream(s) at the same time.</text>
<text top="617" left="112" width="22" height="16" font="0">1.1</text>
<text top="617" left="170" width="140" height="16" font="0">Streaming Models</text>
<text top="672" left="151" width="659" height="16" font="0">There are two formal models of computation that are generally usually used to describe</text>
<text top="708" left="108" width="702" height="16" font="0">stream parallel computation. They are Kahn Process Networks and Synchronous Dataﬂow Net-</text>
<text top="744" left="108" width="702" height="16" font="0">works. A related model of computation that is also popular is Communicating Sequential Pro-</text>
<text top="780" left="108" width="49" height="16" font="0">cesses.</text>
<text top="816" left="151" width="659" height="16" font="0">A Kahn Process Network (KPN) consists of a network of deterministic processes (kernels)</text>
<text top="852" left="108" width="702" height="16" font="0">communicating using unbounded ﬁrst-in ﬁrst-out data channels (streams) [39]. These channels are</text>
<text top="888" left="108" width="702" height="16" font="0">the only means with which processes can communication with one another. In the KPN model,</text>
<text top="924" left="108" width="702" height="16" font="0">processes can always enqueue data to their output stream, will always block on a read of an empty</text>
<text top="960" left="108" width="702" height="16" font="0">input stream, and are not allowed to test for the presence or absence of data in the channels.</text>
<text top="996" left="108" width="702" height="16" font="0">Because of these properties, Kahn process networks are deterministic. That is, the same input on a</text>
<text top="1032" left="108" width="702" height="16" font="0">set of channels will always produce the same output, independent of processes execution order. A</text>
<text top="1068" left="108" width="702" height="16" font="0">KPN is called bounded if it is possible to run the network to completion using a bounded amount of</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">4</text>
<text top="128" left="108" width="702" height="16" font="0">buffer space between the processes. It is undecidable to statically determine the amount of buffer</text>
<text top="164" left="108" width="702" height="16" font="0">space required between processes. However, it is possible to dynamically adjust the amount of</text>
<text top="200" left="108" width="581" height="16" font="0">buffer space such that bounded networks require only bounded buffer space [48].</text>
<text top="236" left="151" width="659" height="16" font="0">A restricted form of the KPN model is the Synchronous Dataﬂow Network (SDF) [43].</text>
<text top="272" left="108" width="702" height="16" font="0">Under SDF, the processes in the network execute atomically, reading all their inputs and writing</text>
<text top="308" left="108" width="702" height="16" font="0">all their outputs in a single execution. If an execution of a kernel cannot run to completion because</text>
<text top="344" left="108" width="702" height="16" font="0">it lacks input data or lacks output buffer space, then it will not run at all. In a SDF computation,</text>
<text top="380" left="108" width="702" height="16" font="0">the number of inputs read and written to and from each data channel is ﬁxed and known to the</text>
<text top="416" left="108" width="702" height="16" font="0">system at compile time. This means that for a given network, the compiler can prove the absence</text>
<text top="452" left="108" width="702" height="16" font="0">of deadlock, can compute a static execution schedule, and can determine static buffer sizes for that</text>
<text top="488" left="108" width="702" height="16" font="0">schedule. Because they can be statically analyzed and scheduled, SDF networks generally exhibit</text>
<text top="524" left="108" width="312" height="16" font="0">more potential for optimization than KPNs.</text>
<text top="560" left="151" width="659" height="16" font="0">The Communicating Sequential Process (CSP) model of computation is a formal model</text>
<text top="596" left="108" width="702" height="16" font="0">closely related to Kahn process networks. A primary difference between KPN and CSP is that CSP</text>
<text top="632" left="108" width="702" height="16" font="0">communication channels involve synchronous unbuffered rendezvous between the sender and the</text>
<text top="668" left="108" width="702" height="16" font="0">receiver. That is, a sender cannot transmit a message until a receiver is ready to receive it. Another</text>
<text top="704" left="108" width="702" height="16" font="0">signiﬁcant difference is that CSP processes are allowed to non-deterministically read a message</text>
<text top="740" left="108" width="686" height="16" font="0">from one of a set of input channels. As in KPNs, determining deadlock freedom is undecidable.</text>
<text top="776" left="151" width="659" height="16" font="0">The motivation for this thesis is to enable ﬂexible use of stream parallelism in general pur-</text>
<text top="812" left="108" width="702" height="16" font="0">pose languages and for a variety of application domains. Stream parallelism is therefore viewed as</text>
<text top="848" left="108" width="702" height="16" font="0">a slight generalization of the KPN model. We want to allow for programs with dynamic behaviors</text>
<text top="884" left="108" width="702" height="16" font="0">not supported under the SDF model (including dynamic input and output rates) or the KPN model</text>
<text top="920" left="108" width="702" height="16" font="0">(e.g. dynamic stream graphs, non-deterministic kernels). As with any programming construct,</text>
<text top="956" left="108" width="702" height="16" font="0">it is beneﬁcial to write stream parallel programs in a certain way to promote compiler optimiza-</text>
<text top="992" left="108" width="702" height="16" font="0">tion. For stream parallel programs, this simply means writing code in a style close to the SDF</text>
<text top="1027" left="108" width="557" height="16" font="0">model when compiler optimization is most important. An analogy is that C/C</text>
<text top="1027" left="663" width="17" height="13" font="1">++</text>
<text top="1027" left="685" width="125" height="16" font="0">programmers can</text>
<text top="1063" left="108" width="702" height="16" font="0">write loops following certain restrictions when auto-vectorization, loop unrolling, or other loop</text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">5</text>
<text top="128" left="108" width="587" height="16" font="0">transformations are important, and allow themselves more freedom when it is not.</text>
<text top="186" left="112" width="22" height="16" font="0">1.2</text>
<text top="186" left="170" width="358" height="16" font="0">Limitations of Existing Programming Methods</text>
<text top="241" left="151" width="659" height="16" font="0">The authors of the StreamIt project correctly observed that languages prior to their own</text>
<text top="276" left="108" width="702" height="16" font="0">have either elegant and general ways for expressing streams, but are too general for aggressive</text>
<text top="312" left="108" width="702" height="16" font="0">optimization (e.g. functional languages), or provide good analysis and optimization of stream</text>
<text top="348" left="108" width="702" height="16" font="0">graphs, but are narrowly focused and exist largely outside of programming languages, applying</text>
<text top="384" left="108" width="702" height="16" font="0">mainly to speciﬁc domains (e.g. modeling systems for DSP) [52][32]. As a result, they propose</text>
<text top="420" left="108" width="702" height="16" font="0">a language, StreamIt, that is very close to the synchronous dataﬂow model, allowing for high</text>
<text top="456" left="108" width="702" height="16" font="0">performance implementation, but which also has a programmer friendly syntax [34]. Although</text>
<text top="492" left="108" width="702" height="16" font="0">they succeeded in their goals, the programming model is still very close to SDF and the language</text>
<text top="528" left="108" width="221" height="16" font="0">is not practical for general use.</text>
<text top="564" left="151" width="659" height="16" font="0">In this dissertation we reject the notion that support for aggressive optimization and support</text>
<text top="600" left="108" width="702" height="16" font="0">for more general forms of stream parallelism are mutually exclusive. We argue for a middle way;</text>
<text top="636" left="108" width="702" height="16" font="0">that is, allow for a general form of process networks and apply aggressive SDF style optimization</text>
<text top="672" left="108" width="702" height="16" font="0">where possible. We can identify two major shortcomings with respect to existing methods of pro-</text>
<text top="708" left="108" width="702" height="16" font="0">gramming using the stream parallel model that prevent this from happening. These shortcomings</text>
<text top="744" left="108" width="702" height="16" font="0">are the result of the artiﬁcial division between support for optimizable stream graphs and support</text>
<text top="780" left="108" width="100" height="16" font="0">for generality.</text>
<text top="816" left="151" width="659" height="16" font="0">The ﬁrst shortcoming is the lack of stream parallelism in general purpose languages.</text>
<text top="852" left="108" width="702" height="16" font="0">As alluded to in the motivations for StreamIt cited above, there is little support for writing opti-</text>
<text top="888" left="108" width="702" height="16" font="0">mizable stream parallel algorithms in mainstream general purpose languages. If there is support</text>
<text top="924" left="108" width="702" height="16" font="0">available, it is in the form of a user library or framework which can provide stream parallel ab-</text>
<text top="960" left="108" width="702" height="16" font="0">stractions, but which cannot provide stream graph optimization. Recent examples of this approach</text>
<text top="996" left="108" width="66" height="16" font="0">for the C</text>
<text top="995" left="173" width="17" height="13" font="1">++</text>
<text top="996" left="195" width="615" height="16" font="0">language are GNU Radio, Feedback-Directed Pipeline Parallelism, DoPE, and Fast-</text>
<text top="1032" left="108" width="702" height="16" font="0">Flow [4][51][49][19]. While these frameworks employ efﬁcient dynamic scheduling mechanisms,</text>
<text top="1068" left="108" width="702" height="16" font="0">they cannot employ the optimization, parallel scheduling, or code generation techniques that make</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">6</text>
<text top="128" left="108" width="702" height="16" font="0">a specialized stream parallel language attractive. A good example of this is seen in DoPE [49],</text>
<text top="164" left="108" width="702" height="16" font="0">where the best result required manual kernel fusion. This basic stream graph transformation is</text>
<text top="200" left="108" width="632" height="16" font="0">easily performed by stream parallel compilers but very difﬁcult to achieve using only a C</text>
<text top="200" left="738" width="17" height="13" font="1">++</text>
<text top="200" left="759" width="51" height="16" font="0">library.</text>
<text top="236" left="151" width="659" height="16" font="0">The second shortcoming is the lack of generality in stream parallel languages. While</text>
<text top="272" left="108" width="702" height="16" font="0">a language like StreamIt is an excellent platform for research into static stream graph transfor-</text>
<text top="308" left="108" width="702" height="16" font="0">mations, it does nothing to help programmers use stream parallelism in existing general purpose</text>
<text top="344" left="108" width="702" height="16" font="0">languages. It still requires that programmers use a specialized language of limited scope. In par-</text>
<text top="380" left="108" width="702" height="16" font="0">ticular, the set of real applications that use only SDF or KPN style computation without requiring</text>
<text top="416" left="108" width="702" height="16" font="0">other abstractions or third party libraries is very small. Languages speciﬁc to stream parallelism</text>
<text top="452" left="108" width="702" height="16" font="0">feature powerful graph transformation, scheduling, and code generation techniques, but lack the</text>
<text top="488" left="108" width="542" height="16" font="0">ability to express or execute computation outside of stream parallel models.</text>
<text top="524" left="151" width="659" height="16" font="0">Within the category of generality are two very useful features missing from high performance</text>
<text top="560" left="108" width="702" height="16" font="0">static compilers for stream parallelism. These are support for dynamic applications and support</text>
<text top="596" left="108" width="642" height="16" font="0">for portability and forward-scaling. It is useful to examine both of these in more detail.</text>
<text top="658" left="112" width="36" height="16" font="0">1.2.1</text>
<text top="658" left="182" width="169" height="16" font="0">Dynamic Applications</text>
<text top="706" left="151" width="659" height="16" font="0">Our ﬁrst missing feature with respect to generality in stream parallel languages – support for</text>
<text top="742" left="108" width="686" height="16" font="0">dynamic applications – can be viewed from multiple perspectives. We expand on three of them:</text>
<text top="793" left="141" width="613" height="16" font="0">(1) Applications where individual kernels have dynamic performance characteristics.</text>
<text top="844" left="141" width="665" height="16" font="0">(2) Applications where an actor outside of the stream graph wishes to reconﬁgure the graph.</text>
<text top="895" left="141" width="625" height="16" font="0">(3) Applications where a kernel inside of the stream graph wishes to reconﬁgure itself.</text>
<text top="946" left="151" width="659" height="16" font="0">As a simple example of the ﬁrst case, we can consider the dedup program from the Parsec</text>
<text top="982" left="108" width="702" height="16" font="0">benchmark suite [21]. This application is a data compression/decompression benchmark. The</text>
<text top="1018" left="108" width="702" height="16" font="0">compression algorithm is used by Parsec for actual benchmarking. It is written in a stream parallel</text>
<text top="1054" left="108" width="702" height="16" font="0">style as a ﬁve stage dataﬂow pipeline, pictured in Figure 1.1. The developer of this program</text>
</page>
<page number="21" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="2" size="11" family="Times" color="#1a1a1a"/>
<text top="85" left="801" width="9" height="16" font="0">7</text>
<text top="128" left="108" width="702" height="16" font="0">implemented parallel execution with Pthreads and wrote a custom queuing mechanism to deal with</text>
<text top="164" left="108" width="702" height="16" font="0">stream communication. It would have been much easier to write the program in an environment</text>
<text top="200" left="108" width="257" height="16" font="0">with support for stream parallelism.</text>
<text top="246" left="258" width="75" height="15" font="2">DataProcess</text>
<text top="246" left="364" width="82" height="15" font="2">FindAllAnchor</text>
<text top="246" left="471" width="85" height="15" font="2">ChunkProcess</text>
<text top="246" left="592" width="63" height="15" font="2">SendBlock</text>
<text top="301" left="593" width="60" height="15" font="2">Compress</text>
<text top="352" left="273" width="371" height="16" font="0">Figure 1.1: Pipeline found in the dedup benchmark.</text>
<text top="420" left="151" width="659" height="16" font="0">The stages of the dedup compression algorithm are unchanging and can be viewed as kernels</text>
<text top="456" left="108" width="702" height="16" font="0">in a static program graph. Despite this, we cannot use SDF style scheduling or code transformation</text>
<text top="492" left="108" width="702" height="16" font="0">on the full graph. This is because two of the program stages, ChunkProcess and SendBlock, do</text>
<text top="528" left="108" width="702" height="16" font="0">not have ﬁxed input and output rates. ChunkProcess conditionally sends its output to one of two</text>
<text top="564" left="108" width="702" height="16" font="0">destinations depending on whether or not the data being processed hits in a compression cache. If</text>
<text top="600" left="108" width="702" height="16" font="0">the data is not present in the cache, then the data must be sent to the Compression stage. Otherwise,</text>
<text top="636" left="108" width="702" height="16" font="0">it can be sent directly to the SendBlock stage. The result is that static compiler and scheduler</text>
<text top="672" left="108" width="702" height="16" font="0">cannot predict the output rates of ChunkProcess or the input rates of SendBlock. One could make</text>
<text top="708" left="108" width="702" height="16" font="0">the graph synchronous by tagging data as cached in the ChunkProcess stage, sending all data to</text>
<text top="744" left="108" width="702" height="16" font="0">the Compress stage, then using the identity operation in Compress for tagged data chunks. But</text>
<text top="780" left="108" width="702" height="16" font="0">doing this makes the runtime of Compress highly variable and dependent on the particular input</text>
<text top="816" left="108" width="702" height="16" font="0">data being compressed. While general purpose frameworks with dynamic scheduling can handle</text>
<text top="852" left="108" width="522" height="16" font="0">this gracefully, stream parallel languages using static scheduling can not.</text>
<text top="888" left="151" width="659" height="16" font="0">The second case above – applications where an actor outside of a stream graph wishes to</text>
<text top="924" left="108" width="702" height="16" font="0">reconﬁgure the graph – is easily illustrated using an example from software deﬁned radio. In</text>
<text top="960" left="108" width="702" height="16" font="0">many radio applications the signal processing and modulation schemes for a particular protocol</text>
<text top="996" left="108" width="702" height="16" font="0">can change over time depending on the radio environment and user requirements. As an example</text>
<text top="1032" left="108" width="702" height="16" font="0">we describe at a high level the structure of a software receiver for orthogonal frequency division</text>
<text top="1068" left="108" width="639" height="16" font="0">multiple access (OFDMA). One place this technology is used is in the WiMAX standard.</text>
</page>
<page number="22" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="801" width="9" height="16" font="0">8</text>
<text top="128" left="151" width="659" height="16" font="0">In a software implementation of a receiver for OFDMA, we begin with time domain samples</text>
<text top="164" left="108" width="702" height="16" font="0">converted from the analog domain to the digital domain by an analog-to-digital converter (A/D).</text>
<text top="200" left="108" width="702" height="16" font="0">The samples obtained from the A/D must be preprocessed before we can apply OFMDA demod-</text>
<text top="236" left="108" width="702" height="16" font="0">ulation and obtain the encoded digital information. This preprocessing step includes things like</text>
<text top="272" left="108" width="702" height="16" font="0">automatic gain control and ﬁltering. Here we encounter the ﬁrst place where the stream graph</text>
<text top="308" left="108" width="702" height="16" font="0">might be signiﬁcantly reconﬁgured while running. Filter operations are used to smooth data or to</text>
<text top="344" left="108" width="702" height="16" font="0">eliminate interference from frequencies the receiver is not interested in. The effectiveness of any</text>
<text top="380" left="108" width="702" height="16" font="0">particular ﬁlter is largely determined by the number of taps that are used. Each tap serves as a co-</text>
<text top="416" left="108" width="702" height="16" font="0">efﬁcient in a dot product operation. This dot product operation is performed to produce one output</text>
<text top="452" left="108" width="702" height="16" font="0">sample for every input sample using a sliding window of data in the input stream. By increasing</text>
<text top="488" left="108" width="702" height="16" font="0">the number of taps, we generally increase the effectiveness of the ﬁlter but we also increase the</text>
<text top="524" left="108" width="702" height="16" font="0">computation requirements of the ﬁlter. One of the beneﬁts of software deﬁned radio is that an</text>
<text top="560" left="108" width="702" height="16" font="0">algorithm can make this trade-off dynamically. Unfortunately, for a SDF style stream parallel pro-</text>
<text top="596" left="108" width="702" height="16" font="0">gram this means the weighting of the ﬁlter kernel might change signiﬁcantly in the static execution</text>
<text top="632" left="108" width="702" height="16" font="0">schedule or that buffer sizes related to the windowing operation (i.e. the input rate) must change.</text>
<text top="668" left="108" width="551" height="16" font="0">Either of these events could require recompilation of the entire stream graph.</text>
<text top="704" left="151" width="659" height="16" font="0">After preprocessing, our software OFDMA receiver will perform a Fast Fourier Transform</text>
<text top="740" left="108" width="702" height="16" font="0">(FFT) operation to transform the signal from the time domain to the frequency domain. Depend-</text>
<text top="776" left="108" width="702" height="16" font="0">ing on the OFDMA protocol being used, the width of the FFT may, like the number of ﬁlter taps,</text>
<text top="812" left="108" width="702" height="16" font="0">require dynamic modiﬁcation. The implications of this change with regard to the stream graph are</text>
<text top="848" left="108" width="702" height="16" font="0">similar to the number taps used by ﬁlters. That is, the computation and communication require-</text>
<text top="884" left="108" width="702" height="16" font="0">ments of the FFT can change signiﬁcantly. After the FFT operation, our partially demodulated</text>
<text top="920" left="108" width="702" height="16" font="0">OFDMA signal consists of some number of small frequency bands called sub-carriers. Each of</text>
<text top="956" left="108" width="702" height="16" font="0">the sub-carriers is demodulated using a scheme dictated by the radio environment and user require-</text>
<text top="992" left="108" width="702" height="16" font="0">ments. As with the ﬁlter and FFT, dynamic modiﬁcation of the sub-carrier modulation schemes</text>
<text top="1027" left="108" width="702" height="16" font="0">is desirable, and can have signiﬁcant implications on the stream graph. After demodulating our</text>
<text top="1063" left="108" width="702" height="16" font="0">individual sub-carriers, we ﬁnally have bits. It is common for these bits to be coded using an error</text>
</page>
<page number="23" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="3" size="9" family="Times" color="#000000"/>
<text top="85" left="801" width="9" height="16" font="0">9</text>
<text top="128" left="108" width="702" height="16" font="0">coding scheme such as Viterbi or Reed-Solomon encoding. One of the advantages of software de-</text>
<text top="164" left="108" width="702" height="16" font="0">ﬁned radio is that these too can be dynamically changed. Again, this can have a signiﬁcant impact</text>
<text top="200" left="108" width="702" height="16" font="0">on the structure of the stream graph with respect to computation requirements and stream commu-</text>
<text top="236" left="108" width="702" height="16" font="0">nication rates. It is desirable to have a system that easily accommodates these kinds of dynamic</text>
<text top="272" left="108" width="191" height="16" font="0">changes to a stream graph.</text>
<text top="308" left="151" width="659" height="16" font="0">The third case listed above – a kernel inside of the stream graph that wishes to reconﬁgure</text>
<text top="344" left="108" width="702" height="16" font="0">itself – can be illustrated using an amusing example credited to Doug McIlroy but made popular</text>
<text top="380" left="108" width="702" height="16" font="0">by Rob Pike. The example is the implementation of the prime sieve of Eratosthenes written as a</text>
<text top="416" left="108" width="702" height="16" font="0">self modifying pipeline of kernels. A version of the algorithm implemented in the CSP language</text>
<text top="452" left="108" width="216" height="16" font="0">Go is shown in Figure 1.2 [5].</text>
<text top="485" left="215" width="86" height="9" font="3">package main</text>
<text top="499" left="215" width="86" height="9" font="3">import &#34;fmt&#34;</text>
<text top="528" left="215" width="359" height="9" font="3">// Send the sequence 2, 3, 4, ... to channel ’ch’.</text>
<text top="542" left="215" width="201" height="9" font="3">func generate(ch chan int) {</text>
<text top="556" left="272" width="136" height="9" font="3">for i := 2; ; i++ {</text>
<text top="570" left="329" width="258" height="9" font="3">ch &lt;- i // Send ’i’ to channel ’ch’.</text>
<text top="584" left="272" width="7" height="9" font="3">}</text>
<text top="598" left="215" width="7" height="9" font="3">}</text>
<text top="627" left="215" width="387" height="9" font="3">// Copy the values from channel ’in’ to channel ’out’,</text>
<text top="641" left="215" width="280" height="9" font="3">// removing those divisible by ’prime’.</text>
<text top="655" left="215" width="301" height="9" font="3">func filter(in, out chan int, prime int) {</text>
<text top="669" left="272" width="36" height="9" font="3">for {</text>
<text top="684" left="329" width="409" height="9" font="3">i := &lt;-in // Receive value of new variable ’i’ from ’in’.</text>
<text top="698" left="329" width="122" height="9" font="3">if i%prime != 0 {</text>
<text top="712" left="387" width="273" height="9" font="3">out &lt;- i // Send ’i’ to channel ’out’.</text>
<text top="726" left="329" width="7" height="9" font="3">}</text>
<text top="740" left="272" width="7" height="9" font="3">}</text>
<text top="755" left="215" width="7" height="9" font="3">}</text>
<text top="783" left="215" width="416" height="9" font="3">// The prime sieve: Daisy-chain filter processes together.</text>
<text top="797" left="215" width="93" height="9" font="3">func main() {</text>
<text top="811" left="272" width="143" height="9" font="3">ch := make(chan int)</text>
<text top="811" left="466" width="172" height="9" font="3">// Create a new channel.</text>
<text top="826" left="272" width="108" height="9" font="3">go generate(ch)</text>
<text top="826" left="466" width="251" height="9" font="3">// Start generate() as a goroutine.</text>
<text top="840" left="272" width="438" height="9" font="3">for i := 0; i &lt; 100; i++ { // Print the first hundred primes.</text>
<text top="854" left="329" width="93" height="9" font="3">prime := &lt;-ch</text>
<text top="868" left="329" width="129" height="9" font="3">fmt.Println(prime)</text>
<text top="882" left="329" width="151" height="9" font="3">ch1 := make(chan int)</text>
<text top="897" left="329" width="179" height="9" font="3">go filter(ch, ch1, prime)</text>
<text top="911" left="329" width="57" height="9" font="3">ch = ch1</text>
<text top="925" left="272" width="7" height="9" font="3">}</text>
<text top="939" left="215" width="7" height="9" font="3">}</text>
<text top="965" left="254" width="411" height="16" font="0">Figure 1.2: Prime sieve implemented in the Go language.</text>
<text top="1032" left="151" width="659" height="16" font="0">The sieve program begins by connecting a goroutine computing a sequence of integers to a</text>
<text top="1068" left="108" width="702" height="16" font="0">printer goroutine that prints its input. The sequence of integers starts with the prime number 2.</text>
</page>
<page number="24" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">10</text>
<text top="128" left="108" width="702" height="16" font="0">Each time the printer goroutine receives an input it constructs new a goroutine which ﬁlters out</text>
<text top="164" left="108" width="702" height="16" font="0">all multiples of that number. It then inserts the new goroutine into the pipeline between itself and</text>
<text top="200" left="108" width="702" height="16" font="0">and its source. By induction, all the numbers received by the printing ﬁlter are prime. The result</text>
<text top="236" left="108" width="702" height="16" font="0">is a pipeline which grows by one each time a new prime is discovered. Although this program</text>
<text top="272" left="108" width="702" height="16" font="0">is typically given as an example in a CSP language like Go, it is more of a stream parallel style</text>
<text top="308" left="108" width="702" height="16" font="0">dataﬂow algorithm than a CSP style rendezvous algorithm. Furthermore, each conﬁguration of</text>
<text top="344" left="108" width="702" height="16" font="0">the pipeline can be expressed as a KPN computation. More complex examples of this type of</text>
<text top="380" left="108" width="698" height="16" font="0">recursively deﬁned stream graphs can be found in McIlroy’s paper on computing power sets [46].</text>
<text top="416" left="151" width="659" height="16" font="0">A more practical example of this kind of dynamic graph reconﬁguration is found in programs</text>
<text top="452" left="108" width="702" height="16" font="0">where a kernel must perform some initialization work before the stream graph enters a steady state.</text>
<text top="488" left="108" width="702" height="16" font="0">In stream graphs with feedback loops it might be necessary to initialize the back edge stream in the</text>
<text top="524" left="108" width="702" height="16" font="0">graph with data before starting the computation. In DSP applications it might be necessary to write</text>
<text top="560" left="108" width="702" height="16" font="0">some amount of data to an output stream to implement a delay. Both cases are easily implemented</text>
<text top="596" left="108" width="702" height="16" font="0">by a kernel that pushes some data to an output stream, then replaces itself with another kernel</text>
<text top="632" left="108" width="323" height="16" font="0">which provides the steady state functionality.</text>
<text top="694" left="112" width="36" height="16" font="0">1.2.2</text>
<text top="694" left="182" width="82" height="16" font="0">Portability</text>
<text top="742" left="151" width="659" height="16" font="0">Another desirable feature with respect to generality in stream parallel languages - support for</text>
<text top="778" left="108" width="702" height="16" font="0">portability and forward-scaling – is based on the observation that computing platforms and proces-</text>
<text top="814" left="108" width="702" height="16" font="0">sor designs, even within a single product line of a single architecture, are increasingly diverse and</text>
<text top="850" left="108" width="702" height="16" font="0">heterogeneous. These trends require that parallel codes written for high performance, like stream</text>
<text top="886" left="108" width="702" height="16" font="0">parallel algorithms, be written with a certain amount of robustness to architectural variation. Un-</text>
<text top="922" left="108" width="702" height="16" font="0">fortunately, static scheduling and compilation methods fail in this regard, and not just for stream</text>
<text top="958" left="108" width="702" height="16" font="0">parallel applications. For example, if a program using vector ISA extensions must be compiled</text>
<text top="994" left="108" width="702" height="16" font="0">to run on a wide variety of end user machines then the developer has two choices. Use the low-</text>
<text top="1030" left="108" width="702" height="16" font="0">est common denominator, and compile for the most widely available (i.e. oldest) ISA extensions,</text>
<text top="1066" left="108" width="702" height="16" font="0">giving up performance on newer processors. Or, somehow ship a “fat binary” which can select</text>
</page>
<page number="25" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">11</text>
<text top="128" left="108" width="702" height="16" font="0">at runtime the appropriate version of code to run. One way to get this for free is to compile to a</text>
<text top="164" left="108" width="605" height="16" font="0">common intermediate form, such as a virtual machine, and use runtime compilation.</text>
<text top="200" left="151" width="121" height="15" font="0">Forward Scaling</text>
<text top="200" left="278" width="532" height="16" font="0">is a term used by Intel to describe the increasing need for dynamic com-</text>
<text top="236" left="108" width="702" height="16" font="0">pilation on Intel platforms to provide portability with respect to future (and past) products. They</text>
<text top="272" left="108" width="702" height="16" font="0">say it is required because “the performance of parallel applications is very sensitive to core count,</text>
<text top="308" left="108" width="702" height="15" font="0">vector ISA width (e.g., SSE), core-to-core latencies, memory hierarchy design, and synchroniza-</text>
<text top="344" left="108" width="68" height="15" font="0">tion costs</text>
<text top="344" left="176" width="634" height="16" font="0">,” and because all of these factors are changing rapidly in the x86 architecture [29]. They</text>
<text top="380" left="108" width="702" height="16" font="0">propose that one solution is to write code using a well deﬁned programming model (in their case</text>
<text top="416" left="108" width="702" height="16" font="0">parallel arrays) in a way that allows an algorithm to be analyzed at runtime, then re-optimize the</text>
<text top="452" left="108" width="702" height="16" font="0">program dynamically as appropriate for the algorithm being executed and the hardware that it is</text>
<text top="488" left="108" width="666" height="16" font="0">executing on. This thesis advocates a similar approach, only for stream parallel computation.</text>
<text top="524" left="151" width="659" height="16" font="0">Synchronous dataﬂow style stream parallelism has been shown to be a good programming</text>
<text top="560" left="108" width="702" height="16" font="0">model for targeting non-traditional processors such as GPUs [23][38][54], and FPGAs [24][25]</text>
<text top="596" left="108" width="702" height="16" font="0">[31][36]. However, the portability problems above are made worse when heterogeneous computa-</text>
<text top="632" left="108" width="702" height="16" font="0">tion is added to the mix. As an example, consider a program where some piece of the code is well</text>
<text top="668" left="108" width="702" height="16" font="0">suited for execution on a GPU. It may be the case that doing so on one system hurts performance</text>
<text top="704" left="108" width="702" height="16" font="0">because the cost of communicating data between the CPU and a discrete GPU overwhelms the</text>
<text top="740" left="108" width="702" height="16" font="0">performance gains. On another system, the same program might have access to low latency shared</text>
<text top="776" left="108" width="702" height="16" font="0">memory between the CPU and an integrated GPU resulting in increased performance. Achieving</text>
<text top="812" left="108" width="702" height="16" font="0">the best performance for this kind of a program requires a sophisticated awareness of the execu-</text>
<text top="848" left="108" width="702" height="16" font="0">tion environment. In the case of stream parallelism, the static optimization techniques of existing</text>
<text top="884" left="108" width="702" height="16" font="0">stream parallel languages should be coupled with dynamic compilation and execution mechanisms</text>
<text top="920" left="108" width="510" height="16" font="0">in order to gain the desired runtime platform awareness and portability.</text>
<text top="977" left="112" width="22" height="16" font="0">1.3</text>
<text top="977" left="170" width="107" height="16" font="0">Contributions</text>
<text top="1032" left="151" width="659" height="16" font="0">In this dissertation we present a compiler level representation for stream parallel compu-</text>
<text top="1068" left="108" width="702" height="16" font="0">tation which addresses the limitations discussed in the previous section. We describe a general</text>
</page>
<page number="26" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">12</text>
<text top="128" left="108" width="702" height="16" font="0">purpose solution which can be implemented in a fully dynamic and high performance manner. It</text>
<text top="164" left="108" width="702" height="16" font="0">is general purpose because it is source language and target architecture independent. It is dynamic</text>
<text top="200" left="108" width="702" height="16" font="0">because it supports dynamic programs, dynamic compilation, and dynamic scheduling. Because it</text>
<text top="236" left="108" width="689" height="16" font="0">is a compiler level representation, execution can be implemented in a high performance manner.</text>
<text top="308" left="108" width="596" height="16" font="0">The underlying thesis for this work can be summarized by the following statement:</text>
<text top="380" left="108" width="702" height="16" font="0">Thesis Statement: By preserving high level stream graph information, a low level representation</text>
<text top="416" left="108" width="702" height="16" font="0">can provide portability and generality in the context of stream processing on parallel and heteroge-</text>
<text top="452" left="108" width="702" height="16" font="0">neous hardware. Furthermore, such a representation can be parallelized and executed efﬁciently on</text>
<text top="488" left="108" width="691" height="16" font="0">such hardware using generic parallelization mechanisms, without limiting ease of programming.</text>
<text top="560" left="108" width="489" height="16" font="0">The contributions of this dissertation can be summarized as follows:</text>
<text top="611" left="141" width="669" height="16" font="0">(1) A low level representation for stream parallel computation, SKIR (Chapter 3). The</text>
<text top="647" left="171" width="642" height="16" font="0">Stream and Kernel Intermediate Representation (SKIR) allows for the expression of stream</text>
<text top="683" left="171" width="639" height="16" font="0">parallel computation at the level of a compiler intermediate representation or virtual ma-</text>
<text top="719" left="171" width="639" height="16" font="0">chine instruction set. It can be used by both stream speciﬁc and general purpose program-</text>
<text top="755" left="171" width="639" height="16" font="0">ming languages. It allows static and dynamic compilation and execution strategies as well</text>
<text top="791" left="171" width="263" height="16" font="0">as static and dynamic stream graphs.</text>
<text top="842" left="141" width="669" height="16" font="0">(2) A set of case studies showing that SKIR can be used effectively as a compilation</text>
<text top="877" left="171" width="639" height="16" font="0">target for stream parallel computation written in high level languages (Chapter 4).</text>
<text top="914" left="171" width="639" height="16" font="0">We present four very different high level language interfaces to SKIR: a set of C language</text>
<text top="949" left="171" width="639" height="16" font="0">compiler intrinsics, giving almost direct access to the SKIR primitives; an object oriented</text>
<text top="985" left="171" width="12" height="16" font="0">C</text>
<text top="985" left="181" width="17" height="13" font="1">++</text>
<text top="985" left="202" width="270" height="16" font="0">user library, similar in style to other C</text>
<text top="985" left="470" width="17" height="13" font="1">++</text>
<text top="985" left="491" width="319" height="16" font="0">frameworks for parallelism; a language front</text>
<text top="1021" left="171" width="639" height="16" font="0">end for StreamIt, currently the standard language for experimentation with static stream</text>
<text top="1057" left="171" width="639" height="16" font="0">program transformations; and a JavaScript to SKIR compiler, showing how even very</text>
</page>
<page number="27" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">13</text>
<text top="128" left="171" width="639" height="16" font="0">high level dynamic languages can beneﬁt from the stream parallel model using a dynamic</text>
<text top="164" left="171" width="162" height="16" font="0">SKIR implementation.</text>
<text top="214" left="141" width="669" height="16" font="0">(3) A scheme for the dynamic scheduling of stream parallel computation combining co-</text>
<text top="249" left="171" width="639" height="16" font="0">operative multitasking with randomized task stealing (Chapter 5). With the advent</text>
<text top="286" left="171" width="639" height="16" font="0">of parallel programming environments like Cilk and Thread Building Blocks, randomized</text>
<text top="322" left="171" width="639" height="16" font="0">task stealing has become a popular mechanism for expressing concurrency and obtaining</text>
<text top="358" left="171" width="639" height="16" font="0">parallel execution. The reasons for this are that task stealing naturally provides good load</text>
<text top="393" left="171" width="639" height="16" font="0">balancing and low overhead task switching. We show how to combine this technique with</text>
<text top="429" left="171" width="639" height="16" font="0">one of the oldest mechanisms for cooperative multitasking in stream parallel programs to</text>
<text top="465" left="171" width="244" height="16" font="0">obtain efﬁcient parallel execution.</text>
<text top="515" left="141" width="669" height="16" font="0">(4) An optimizing just-in-time compiler for stream parallel programs (Chapter 6) To</text>
<text top="551" left="171" width="639" height="16" font="0">enable dynamic compilation and optimization of stream parallel programs, we have built</text>
<text top="587" left="171" width="639" height="16" font="0">a just-in-time (JIT) compiler for SKIR programs. The JIT compiler transforms SKIR</text>
<text top="623" left="171" width="639" height="16" font="0">kernels into a form that can execute concurrently and provides the implementation of the</text>
<text top="659" left="171" width="639" height="16" font="0">data stream abstraction. The compiler can also apply static analysis to determine which</text>
<text top="695" left="171" width="639" height="16" font="0">parts of a stream graph conform to the synchronous data ﬂow model and apply additional</text>
<text top="731" left="171" width="601" height="16" font="0">kernel optimization and stream graph transformations those kernels and sub-graphs.</text>
<text top="780" left="141" width="669" height="16" font="0">(5) A performance evaluation of the SKIR runtime, JIT compiler, and dynamic sched-</text>
<text top="816" left="171" width="639" height="16" font="0">uler on a diverse set of benchmarks (Chapter 7). The dynamic SKIR environment is</text>
<text top="852" left="171" width="639" height="16" font="0">evaluated on two sets of benchmarks. The ﬁrst is a set of StreamIt benchmarks where</text>
<text top="888" left="171" width="639" height="16" font="0">SDF semantics are present, low overhead execution is important because kernels are ﬁne</text>
<text top="924" left="171" width="639" height="16" font="0">grained, and high performance is the primary goal. The performance is compared to a</text>
<text top="960" left="171" width="639" height="16" font="0">fully dynamic system and a fully static system. The second set of benchmarks is taken</text>
<text top="996" left="171" width="639" height="16" font="0">from a variety of application domains and includes data parallel and pipeline parallel</text>
<text top="1032" left="171" width="639" height="16" font="0">stream graph topologies. These benchmarks use a variety of implementation technologies</text>
<text top="1068" left="171" width="639" height="16" font="0">and contain one or two compute intense kernels and one or more lightweight kernels. Per-</text>
</page>
<page number="28" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">14</text>
<text top="128" left="171" width="639" height="16" font="0">formance is again the primary goal and SKIR performance is compared with the original</text>
<text top="164" left="171" width="258" height="16" font="0">implementation of each benchmark.</text>
<text top="215" left="108" width="702" height="16" font="0">Additionally, an overview of the stream parallel programming model is given in Chapter 2 and</text>
<text top="251" left="108" width="424" height="16" font="0">Chapter 8 reviews related work. We conclude in Chapter 9.</text>
</page>
<page number="29" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 2</text>
<text top="292" left="249" width="421" height="16" font="0">Language Constructs for Stream Parallel Computation</text>
<text top="408" left="151" width="659" height="16" font="0">The stream parallel model is widely used for data-centric computations that have high com-</text>
<text top="444" left="108" width="702" height="16" font="0">putational intensity, that can be decomposed into independent components, and that use their inputs</text>
<text top="479" left="108" width="702" height="16" font="0">very few times before throwing them away. This is traditionally true of application domains such</text>
<text top="515" left="108" width="682" height="16" font="0">as graphics and signal processing but increasingly applies to other application domains as well.</text>
<text top="551" left="151" width="659" height="16" font="0">This chapter presents features common to different stream parallel programming languages,</text>
<text top="587" left="108" width="702" height="16" font="0">differentiating characteristics of different stream parallel programming languages, and deﬁnes ter-</text>
<text top="623" left="108" width="702" height="16" font="0">minology used in the rest of this dissertation. This is done in the context of four example stream</text>
<text top="659" left="108" width="702" height="16" font="0">processing systems. It is important that any low level abstraction for stream parallelism – like</text>
<text top="695" left="108" width="618" height="16" font="0">SKIR – is able to express common high level stream parallel programming constructs.</text>
<text top="731" left="151" width="659" height="16" font="0">Stream parallel computation is based on two main concepts: streams and kernels. A stream</text>
<text top="767" left="108" width="702" height="16" font="0">is typically an unbounded collection of data elements. It is much like a common queue abstraction</text>
<text top="803" left="108" width="702" height="16" font="0">except that it is allowed to be conceptually inﬁnite in size. It has push and pop operations like a</text>
<text top="839" left="108" width="702" height="16" font="0">ﬁrst-in ﬁrst-out queue where elements are written by pushing data to one end of the stream and</text>
<text top="875" left="108" width="357" height="16" font="0">read by popping from the other end of the stream.</text>
<text top="911" left="151" width="659" height="16" font="0">A kernel is simply a procedure that is speciﬁcally designed to execute using streams as its</text>
<text top="947" left="108" width="702" height="16" font="0">primary inputs and outputs. It may contain state but does not share data with other parts of the</text>
<text top="983" left="108" width="702" height="16" font="0">program except using streams. To create a stream parallel computation, streams and kernels are</text>
<text top="1019" left="108" width="702" height="16" font="0">connected together to form a stream graph. The stream graph is a directed graph with kernels as</text>
<text top="1055" left="108" width="702" height="16" font="0">the nodes and streams as the edges. Stream data ﬂows along the edges in the graph and is processed</text>
</page>
<page number="30" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">16</text>
<text top="128" left="108" width="702" height="16" font="0">by the kernels at the nodes in the graph. Cycles are allowed in the graph but the stream parallel</text>
<text top="164" left="108" width="532" height="16" font="0">model does not prevent programs containing deadlock from being written.</text>
<text top="222" left="112" width="22" height="16" font="0">2.1</text>
<text top="222" left="170" width="59" height="16" font="0">Kernels</text>
<text top="277" left="151" width="659" height="16" font="0">There are two basic conceptual representations of kernels used in stream programming lan-</text>
<text top="313" left="108" width="612" height="16" font="0">guages. They are either viewed as special kernel function or as special kernel objects.</text>
<text top="349" left="151" width="659" height="16" font="0">Using the function representation, kernels are deﬁned and executed similar to an ordinary</text>
<text top="385" left="108" width="702" height="16" font="0">procedure call. This is the case in the StreamC/KernelC [41] and Brook family of languages</text>
<text top="421" left="108" width="702" height="16" font="0">[22][23][44]. An example of a Brook program is shown in Figure 2.1. Using this approach,</text>
<text top="464" left="296" width="373" height="9" font="3">kernel void sum(float a&lt;&gt;, float b&lt;&gt;, out float c&lt;&gt;)</text>
<text top="479" left="296" width="7" height="9" font="3">{</text>
<text top="493" left="324" width="72" height="9" font="3">c = a + b;</text>
<text top="507" left="296" width="7" height="9" font="3">}</text>
<text top="535" left="296" width="222" height="11" font="3">int main(int argc, char** argv)</text>
<text top="550" left="296" width="7" height="9" font="3">{</text>
<text top="564" left="324" width="65" height="9" font="3">int i, j;</text>
<text top="578" left="324" width="115" height="9" font="3">float a&lt;10, 10&gt;;</text>
<text top="592" left="324" width="115" height="9" font="3">float b&lt;10, 10&gt;;</text>
<text top="606" left="324" width="115" height="9" font="3">float c&lt;10, 10&gt;;</text>
<text top="620" left="324" width="158" height="9" font="3">float input_a[10][10];</text>
<text top="635" left="324" width="158" height="9" font="3">float input_b[10][10];</text>
<text top="649" left="324" width="158" height="9" font="3">float input_c[10][10];</text>
<text top="677" left="324" width="151" height="9" font="3">for(i=0; i&lt;10; i++) {</text>
<text top="691" left="353" width="151" height="9" font="3">for(j=0; j&lt;10; j++) {</text>
<text top="706" left="382" width="187" height="9" font="3">input_a[i][j] = (float) i;</text>
<text top="720" left="382" width="187" height="9" font="3">input_b[i][j] = (float) j;</text>
<text top="734" left="353" width="7" height="9" font="3">}</text>
<text top="748" left="324" width="7" height="9" font="3">}</text>
<text top="762" left="324" width="165" height="9" font="3">streamRead(a, input_a);</text>
<text top="777" left="324" width="165" height="9" font="3">streamRead(b, input_b);</text>
<text top="791" left="324" width="93" height="9" font="3">sum(a, b, c);</text>
<text top="805" left="324" width="172" height="9" font="3">streamWrite(c, input_c);</text>
<text top="819" left="296" width="7" height="9" font="3">}</text>
<text top="845" left="211" width="495" height="16" font="0">Figure 2.1: A data parallel addition written AMD’s Brook+ language</text>
<text top="916" left="108" width="702" height="16" font="0">the main distinction between kernel and non-kernel functions is that kernel functions can operate</text>
<text top="952" left="108" width="702" height="16" font="0">directly on streams (declared using angle brackets in Brook) while non-kernel functions must use</text>
<text top="988" left="108" width="702" height="16" font="0">an API to manipulate streams. The Brook language also requires that kernels be side-effect free,</text>
<text top="1024" left="108" width="702" height="16" font="0">implying that they are data parallel. This is because this particular language speciﬁcally targets</text>
<text top="1060" left="108" width="702" height="16" font="0">data parallel hardware such as GPUs. Also, unlike some of the other stream parallel languages</text>
</page>
<page number="31" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">17</text>
<text top="128" left="108" width="702" height="16" font="0">described in this dissertation, Brook operates on ﬁnite size streams. Other programming languages</text>
<text top="164" left="108" width="702" height="16" font="0">targeting graphics processors, such as CUDA and OpenCL, inherit many characteristics from the</text>
<text top="200" left="108" width="119" height="16" font="0">Brook language.</text>
<text top="236" left="151" width="659" height="16" font="0">A similar kernel model is found in one of the earliest stream processing languages, proposed</text>
<text top="272" left="108" width="702" height="16" font="0">by Kahn and MacQueen [40], and shown in Figure 2.2. The code in the ﬁgure describes and</text>
<text top="314" left="323" width="172" height="9" font="3">Process PRODUCER out QO;</text>
<text top="328" left="351" width="50" height="9" font="3">vars N;</text>
<text top="328" left="416" width="50" height="9" font="3">0 -&gt; N;</text>
<text top="342" left="351" width="136" height="9" font="3">repeat INCREMENT N;</text>
<text top="342" left="502" width="122" height="9" font="3">PUT(N,Q0) forever</text>
<text top="356" left="323" width="79" height="9" font="3">Endprocess;</text>
<text top="371" left="323" width="244" height="9" font="3">Process TRANSDUCER A in QI out QO;</text>
<text top="385" left="351" width="251" height="9" font="3">repeat PUT(A + GET(QI), QO) forever</text>
<text top="399" left="323" width="79" height="9" font="3">Endprocess;</text>
<text top="413" left="323" width="165" height="9" font="3">Process CONSUMER in QI;</text>
<text top="427" left="351" width="258" height="9" font="3">repeat 20 times PRINT(GET(QI)) close</text>
<text top="442" left="323" width="79" height="9" font="3">Endprocess;</text>
<text top="456" left="323" width="79" height="9" font="3">Process GO;</text>
<text top="470" left="351" width="165" height="9" font="3">doco channels Q1 Q2 Q3;</text>
<text top="484" left="351" width="93" height="9" font="3">PRODUCER(Q1);</text>
<text top="484" left="466" width="143" height="9" font="3">TRANSDUCER(1,Q1,Q2);</text>
<text top="498" left="351" width="151" height="9" font="3">TRANSDUCER(-1,Q2,Q3);</text>
<text top="498" left="516" width="93" height="9" font="3">CONSUMER(Q3);</text>
<text top="513" left="351" width="50" height="9" font="3">closeco</text>
<text top="527" left="323" width="79" height="9" font="3">Endprocess;</text>
<text top="541" left="323" width="172" height="9" font="3">Start doco GO() closeco;</text>
<text top="566" left="140" width="638" height="16" font="0">Figure 2.2: A four stage pipeline in the language proposed by Kahn and MacQueen [40].</text>
<text top="636" left="108" width="702" height="16" font="0">executes a four stage pipeline. Like in Brook, kernels (Processes) in this language operate on</text>
<text top="672" left="108" width="702" height="16" font="0">streams (channels) and are invoked using an ordinary procedure call syntax. One difference</text>
<text top="708" left="108" width="702" height="16" font="0">is that this language allows writable state to be present in the kernels. This feature increases</text>
<text top="744" left="108" width="702" height="16" font="0">generality but makes it harder to detect data parallelism. The TRANSDUCER kernel exhibits data</text>
<text top="780" left="108" width="702" height="16" font="0">parallelism, but in order to take advantage of that parallelism, the compiler will have to determine</text>
<text top="816" left="108" width="569" height="16" font="0">that it exists. The example also shows pipeline parallelism between the kernels.</text>
<text top="852" left="151" width="659" height="16" font="0">The other common language construct for representing kernels is as a special object. Using</text>
<text top="888" left="108" width="702" height="16" font="0">this model, the kernel is an object or similar structure containing a kernel work function. The</text>
<text top="924" left="108" width="702" height="16" font="0">kernel work function is equivalent to a kernel represented as a special function as described above.</text>
<text top="960" left="108" width="702" height="16" font="0">In addition to the kernel work function, the object might contain additional metadata describing</text>
<text top="996" left="108" width="702" height="16" font="0">the operation of the kernel, encapsulated program state, and helper methods such as constructors</text>
<text top="1032" left="108" width="702" height="16" font="0">and destructors. One form of metadata sometimes associated with the kernel is the amount of data</text>
<text top="1068" left="108" width="702" height="16" font="0">read from each input stream and written to each output stream each time the kernel work function</text>
</page>
<page number="32" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">18</text>
<text top="128" left="108" width="702" height="16" font="0">is executed. This information, which we call the input rates and output rates of the kernel, gives</text>
<text top="164" left="108" width="702" height="16" font="0">the compiler insight into the behavior of the kernel and can be used to ﬁnd efﬁcient schedules for</text>
<text top="200" left="108" width="702" height="16" font="0">executing a stream graph or to enable stream graph transformations. An example of a programming</text>
<text top="236" left="108" width="702" height="16" font="0">language featuring object based kernels with rate metadata is the StreamIt programming language</text>
<text top="272" left="108" width="702" height="16" font="0">[34]. An example StreamIt program is shown in Figure 2.3. This is essentially the same program</text>
<text top="316" left="336" width="201" height="9" font="3">void-&gt;int filter IntSource {</text>
<text top="330" left="365" width="43" height="9" font="3">int x;</text>
<text top="344" left="365" width="108" height="9" font="3">init { x = 0; }</text>
<text top="358" left="365" width="93" height="9" font="3">work push 1 {</text>
<text top="373" left="393" width="57" height="9" font="3">push(x);</text>
<text top="387" left="393" width="72" height="9" font="3">x = x + 1;</text>
<text top="401" left="365" width="7" height="9" font="3">}</text>
<text top="415" left="336" width="7" height="9" font="3">}</text>
<text top="444" left="336" width="215" height="9" font="3">int-&gt;int filter Adder(int A) {</text>
<text top="458" left="365" width="258" height="9" font="3">work push 1 pop 1 { push(A+pop()); }</text>
<text top="472" left="336" width="7" height="9" font="3">}</text>
<text top="500" left="336" width="208" height="9" font="3">int-&gt;void filter IntPrinter {</text>
<text top="515" left="365" width="215" height="9" font="3">work pop 1 { println(pop()); }</text>
<text top="529" left="336" width="7" height="9" font="3">}</text>
<text top="557" left="336" width="187" height="9" font="3">void-&gt;void pipeline Main {</text>
<text top="571" left="365" width="100" height="9" font="3">add IntSource;</text>
<text top="586" left="365" width="93" height="9" font="3">add Adder(1);</text>
<text top="600" left="365" width="100" height="9" font="3">add Adder(-1);</text>
<text top="614" left="365" width="108" height="9" font="3">add IntPrinter;</text>
<text top="628" left="336" width="7" height="9" font="3">}</text>
<text top="653" left="221" width="475" height="16" font="0">Figure 2.3: A four stage pipeline written in the StreamIt language.</text>
<text top="725" left="108" width="702" height="16" font="0">as the one shown in Figure 2.2, a simple four stage pipeline. The three kernels in this program</text>
<text top="761" left="108" width="702" height="16" font="0">are the objects IntSource, Adder, and IntPrinter. In StreamIt, kernel work functions are</text>
<text top="797" left="108" width="702" height="16" font="0">named work and constructors are named init. Kernels can also contain other helper functions.</text>
<text top="833" left="108" width="702" height="16" font="0">In the example, the IntSouce kernel contains encapsulated state x and a constructor function.</text>
<text top="869" left="108" width="702" height="16" font="0">The Adder kernel also has read-only state in the form of the kernel parameter A. The kernels in</text>
<text top="905" left="108" width="702" height="16" font="0">the ﬁgure are also annotated with their input and output rates. These are the statements push 1</text>
<text top="941" left="108" width="89" height="16" font="0">and pop 1.</text>
<text top="977" left="151" width="659" height="16" font="0">When a kernel work function is annotated with its rate information or when the compiler can</text>
<text top="1013" left="108" width="702" height="16" font="0">determine this information through compiler analysis, we call the kernel a synchronous kernel with</text>
<text top="1049" left="108" width="78" height="15" font="0">static rates</text>
<text top="1049" left="186" width="624" height="16" font="0">. This terminology comes from the the synchronous dataﬂow model in which all kernels</text>
</page>
<page number="33" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">19</text>
<text top="128" left="108" width="702" height="16" font="0">must have static rates. Although kernels in the StreamIt language are not technically required to be</text>
<text top="164" left="108" width="702" height="16" font="0">synchronous, in practice they are because this information is provided as programmer annotations</text>
<text top="200" left="108" width="702" height="16" font="0">and because the original StreamIt compiler depends on synchronous kernels for scheduling. For</text>
<text top="236" left="108" width="512" height="16" font="0">more general models such as KPN, static or dynamic rates are possible.</text>
<text top="272" left="151" width="659" height="16" font="0">Another object oriented stream parallel programing environment is GNU Radio [4]. GNU</text>
<text top="308" left="108" width="86" height="16" font="0">Radio is a C</text>
<text top="308" left="193" width="17" height="13" font="1">++</text>
<text top="308" left="213" width="597" height="16" font="0">programming framework and runtime system designed for digital signal processing.</text>
<text top="344" left="108" width="702" height="16" font="0">It is an example of a framework for expressing stream parallelism layered on top of an existing</text>
<text top="380" left="108" width="472" height="16" font="0">general purpose language. In it, hand tuned kernels written in C</text>
<text top="379" left="578" width="17" height="13" font="1">++</text>
<text top="380" left="601" width="209" height="16" font="0">are connected together using</text>
<text top="416" left="108" width="702" height="16" font="0">a Python API. An example of a constructor and work function for a kernel object from the GNU</text>
<text top="452" left="108" width="702" height="16" font="0">Radio tutorial are shown in Figure 2.4. In GNU Radio, kernels are called Blocks. The block in</text>
<text top="495" left="242" width="251" height="9" font="3">howto_square_ff::howto_square_ff ()</text>
<text top="509" left="256" width="172" height="9" font="3">: gr_block (&#34;square_ff&#34;,</text>
<text top="523" left="285" width="387" height="9" font="3">gr_make_io_signature (MIN_IN, MAX_IN, sizeof (float)),</text>
<text top="537" left="285" width="402" height="9" font="3">gr_make_io_signature (MIN_OUT, MAX_OUT, sizeof (float)))</text>
<text top="551" left="242" width="7" height="9" font="3">{</text>
<text top="566" left="242" width="7" height="9" font="3">}</text>
<text top="594" left="242" width="22" height="9" font="3">int</text>
<text top="608" left="242" width="351" height="9" font="3">howto_square_ff::general_work (int noutput_items,</text>
<text top="622" left="292" width="201" height="9" font="3">gr_vector_int &amp;ninput_items,</text>
<text top="637" left="292" width="280" height="9" font="3">gr_vector_const_void_star &amp;input_items,</text>
<text top="651" left="292" width="244" height="9" font="3">gr_vector_void_star &amp;output_items)</text>
<text top="665" left="242" width="7" height="9" font="3">{</text>
<text top="679" left="256" width="351" height="11" font="3">const float *in = (const float *) input_items[0];</text>
<text top="693" left="256" width="280" height="11" font="3">float *out = (float *) output_items[0];</text>
<text top="722" left="256" width="287" height="9" font="3">for (int i = 0; i &lt; noutput_items; i++){</text>
<text top="736" left="270" width="165" height="11" font="3">out[i] = in[i] * in[i];</text>
<text top="750" left="256" width="7" height="9" font="3">}</text>
<text top="779" left="256" width="416" height="9" font="3">// Tell runtime system how many input items we consumed on</text>
<text top="793" left="256" width="151" height="9" font="3">// each input stream.</text>
<text top="807" left="256" width="208" height="9" font="3">consume_each (noutput_items);</text>
<text top="835" left="256" width="409" height="9" font="3">// Tell runtime system how many output items we produced.</text>
<text top="850" left="256" width="151" height="9" font="3">return noutput_items;</text>
<text top="864" left="242" width="7" height="9" font="3">}</text>
<text top="889" left="198" width="522" height="16" font="0">Figure 2.4: A kernel object in the GNU Radio stream processing system.</text>
<text top="960" left="108" width="702" height="16" font="0">the ﬁgure computes the square of its input stream and writes the result to its output stream. In the</text>
<text top="996" left="108" width="702" height="16" font="0">ﬁgure we can see that the block constructor declares the number of input and output streams the</text>
<text top="1032" left="108" width="702" height="16" font="0">block can handle, as well as the size of data items in the input and output streams. The kernel</text>
<text top="1068" left="108" width="702" height="16" font="0">work function is the method named general work. This function extracts data from its input</text>
</page>
<page number="34" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">20</text>
<text top="128" left="108" width="702" height="16" font="0">buffers, performs the required computation and writes the result to its output buffers. It then tells</text>
<text top="164" left="108" width="581" height="16" font="0">the runtime how much data was read/written and returns control to the scheduler.</text>
<text top="200" left="151" width="659" height="16" font="0">In both the function and object forms of kernels, we end up with a kernel work function</text>
<text top="236" left="108" width="702" height="16" font="0">describing the computation performed by the kernel. There are two ways that kernel work functions</text>
<text top="272" left="108" width="702" height="16" font="0">are written in stream parallel languages. For convenience, we call them implicitly looped and</text>
<text top="308" left="108" width="119" height="15" font="0">explicitly looped</text>
<text top="308" left="227" width="4" height="16" font="0">.</text>
<text top="344" left="151" width="659" height="16" font="0">The kernels in the Brook (Figure 2.1) and StreamIt (Figure 2.3) examples above are im-</text>
<text top="380" left="108" width="702" height="16" font="0">plicitly looped. In systems with implicitly looped kernels, kernel work functions are written to</text>
<text top="416" left="108" width="702" height="16" font="0">consume the least amount of input necessary to produce output. The functions are assumed to be</text>
<text top="452" left="108" width="702" height="16" font="0">wrapped in an implicit loop which will repeatedly call the function until all input data is consumed</text>
<text top="488" left="108" width="702" height="16" font="0">or until the program terminates. Another way to think of this is that implicitly looped kernel work</text>
<text top="524" left="108" width="702" height="16" font="0">functions implement one iteration of some loop. Within implicitly looped kernel work functions,</text>
<text top="560" left="108" width="702" height="16" font="0">the programmer does not have to manage blocking or buffering of stream communication or other-</text>
<text top="596" left="108" width="702" height="16" font="0">wise be aware of stream communication implementation details. Similarly, the programmer does</text>
<text top="632" left="108" width="702" height="16" font="0">not have to be aware of runtime scheduling mechanisms. Instead, it is assumed that when an im-</text>
<text top="668" left="108" width="702" height="16" font="0">plicitly looped kernel work function is called the kernel can execute without blocking to wait for</text>
<text top="704" left="108" width="463" height="16" font="0">input data in an input stream or buffer space in an output stream.</text>
<text top="740" left="151" width="659" height="16" font="0">In contrast, the kernels in the language of Kahn and MacQueen (Figure 2.2) and in the GNU</text>
<text top="776" left="108" width="702" height="16" font="0">Radio framework (Figure 2.4) are explicitly looped. In systems with explicitly looped kernels,</text>
<text top="812" left="108" width="702" height="16" font="0">kernel work functions do not have an implicit loop around them. Instead, the programmer is</text>
<text top="848" left="108" width="702" height="16" font="0">responsible for constructing any loops needed to consume input during the execution of the stream</text>
<text top="884" left="108" width="702" height="16" font="0">graph. Depending on the system, the programmer may need to be aware of stream communication</text>
<text top="920" left="108" width="702" height="16" font="0">implementation details and/or interact with the scheduler in order to block or yield for buffer space</text>
<text top="956" left="108" width="702" height="16" font="0">correctly. In Figure 2.2, the programmer constructs while loops inside of the kernel work functions</text>
<text top="992" left="108" width="702" height="16" font="0">to consume the appropriate amount of input. The PRODUCER and TRANSDUCER kernels will run</text>
<text top="1027" left="108" width="702" height="16" font="0">as long as the stream graph is active, and the CONSUMER kernel runs for 20 iterations. When</text>
<text top="1064" left="108" width="86" height="14" font="0">CONSUMER</text>
<text top="1063" left="199" width="611" height="16" font="0">ﬁnishes, the others will as well. We see more extensive programmer involvement in</text>
</page>
<page number="35" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">21</text>
<text top="128" left="108" width="702" height="16" font="0">the GNU Radio example. Here the kernel work function is passed an input buffer and an output</text>
<text top="164" left="108" width="702" height="16" font="0">buffer. The programmer must manually extract the inputs and write the outputs in an explicit loop.</text>
<text top="200" left="108" width="702" height="16" font="0">After completing the available work, the kernel tells the scheduler how much data it has consumed</text>
<text top="236" left="108" width="702" height="16" font="0">and how much data it has produced. By returning, the kernel effectively blocks until more input is</text>
<text top="272" left="108" width="68" height="16" font="0">available.</text>
<text top="308" left="151" width="659" height="16" font="0">The advantage of implicit looping is that the compiler has more freedom in how it schedules</text>
<text top="344" left="108" width="702" height="16" font="0">and executes the kernel. In particular, it allows easy decomposition of data parallel kernels and</text>
<text top="380" left="108" width="702" height="16" font="0">merging of ﬁne grained kernels. In contrast, the explicit looping style often gives the programmer</text>
<text top="416" left="108" width="702" height="16" font="0">more control over the execution of the kernel. This means the programmer can potentially hand</text>
<text top="452" left="108" width="702" height="16" font="0">tune the kernel for performance, but the compiler has less freedom to perform code transformations</text>
<text top="488" left="108" width="250" height="16" font="0">or to alter scheduling mechanisms.</text>
<text top="545" left="112" width="22" height="16" font="0">2.2</text>
<text top="545" left="170" width="62" height="16" font="0">Streams</text>
<text top="600" left="151" width="659" height="16" font="0">The way that streams work is fairly uniform across stream parallel languages, but there are</text>
<text top="636" left="108" width="702" height="16" font="0">a few variations. Streams are typically unbounded, as in the Kahn/MacQueen, StreamIt, and GNU</text>
<text top="672" left="108" width="702" height="16" font="0">Radio examples above, although in some systems they are declared with a ﬁnite size similar to an</text>
<text top="708" left="108" width="702" height="16" font="0">ordinary array, as in Brook. They have ﬁrst-in ﬁrst-out semantics with some form of push and pop</text>
<text top="744" left="108" width="702" height="16" font="0">operators to add and remove elements from the stream. In the Brook and GNU Radio examples</text>
<text top="780" left="108" width="702" height="16" font="0">these are expressed as ordinary memory reads and writes while in Kahn/MacQueen and StreamIt,</text>
<text top="816" left="108" width="311" height="16" font="0">these are named constructs in the language.</text>
<text top="852" left="151" width="659" height="16" font="0">Some languages add a peek operator that can read a data item from a stream without remov-</text>
<text top="888" left="108" width="702" height="16" font="0">ing it from the stream. This can be useful for kernels such as ﬁlters which read a sliding window of</text>
<text top="924" left="108" width="702" height="16" font="0">stream data for each output produced. Without the peek operator these types of kernels would need</text>
<text top="960" left="108" width="702" height="16" font="0">to maintain state between iterations. With a peek operator they can be state free and potentially</text>
<text top="996" left="108" width="702" height="16" font="0">data parallel. In the example languages, peek is explicit in StreamIt and available in GNU Radio</text>
<text top="1032" left="108" width="201" height="16" font="0">as raw stream buffer access.</text>
<text top="1068" left="151" width="659" height="16" font="0">The push, pop and peek operations are almost always viewed as synchronous and blocking</text>
</page>
<page number="36" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="4" size="14" family="Times" color="#000000"/>
<text top="85" left="792" width="18" height="16" font="0">22</text>
<text top="128" left="108" width="702" height="16" font="0">operators. That is, it is never necessary for the programmer to test a input stream for data or an</text>
<text top="164" left="108" width="702" height="16" font="0">output stream for buffer space. They only return after completing their operation. Testing for</text>
<text top="200" left="108" width="679" height="16" font="0">presence or absence of data is not allowed under either the SDF or KPN programming models.</text>
<text top="258" left="112" width="22" height="16" font="0">2.3</text>
<text top="258" left="170" width="216" height="16" font="0">Stream Graph Construction</text>
<text top="313" left="151" width="659" height="16" font="0">It is convenient and correct to think of kernels and streams as nodes and edges in a stream</text>
<text top="349" left="108" width="702" height="16" font="0">graph. There are several different ways that the structure of stream graphs can be expressed in</text>
<text top="385" left="108" width="289" height="16" font="0">stream parallel programming languages.</text>
<text top="421" left="151" width="659" height="16" font="0">One method is to simply invoke kernels with the syntax of an ordinary procedure call. Ex-</text>
<text top="457" left="108" width="702" height="16" font="0">amples of this approach are found in the GO process in the Kahn/MacQueen example in Figure</text>
<text top="493" left="108" width="702" height="16" font="0">2.2 and in the main function shown in the Brook example in Figure 2.1. Using this approach, the</text>
<text top="529" left="108" width="702" height="16" font="0">compiler must either run the kernels one at a time, or it must extract the edges of the stream graph</text>
<text top="565" left="108" width="451" height="16" font="0">by examining the uses of streams by the kernel call statements.</text>
<text top="600" left="151" width="659" height="16" font="0">A second approach is to programmatically construct the stream graph. This is the approach</text>
<text top="636" left="108" width="702" height="16" font="0">taken in the GNU Radio framework. In that system, kernels are compiled into a library of pro-</text>
<text top="672" left="108" width="702" height="16" font="0">cessing blocks. At runtime, a Python program allocates instance of blocks, connects them together</text>
<text top="708" left="108" width="702" height="16" font="0">into a stream graph, and triggers execution. For example, to connect two signal source kernels to</text>
<text top="744" left="108" width="702" height="16" font="0">a single audio sink kernel (i.e. a speaker) in GNU Radio, we can use the following Python code</text>
<text top="780" left="108" width="229" height="16" font="0">which produces a U.S. dialtone:</text>
<text top="808" left="151" width="609" height="13" font="4">src0 = gr.sig_source_f(sample_rate, gr.GR_SIN_WAVE, 350, ampl)</text>
<text top="828" left="151" width="609" height="13" font="4">src1 = gr.sig_source_f(sample_rate, gr.GR_SIN_WAVE, 440, ampl)</text>
<text top="849" left="151" width="324" height="13" font="4">dst = audio.sink(sample_rate, &#34;&#34;)</text>
<text top="869" left="151" width="275" height="13" font="4">self.connect(src0, (dst, 0))</text>
<text top="889" left="151" width="275" height="13" font="4">self.connect(src1, (dst, 1))</text>
<text top="910" left="190" width="29" height="13" font="4">...</text>
<text top="930" left="151" width="108" height="13" font="4">graph.run()</text>
<text top="968" left="151" width="659" height="16" font="0">A third approach is to specify the structure of the stream graph directly in a text based</text>
<text top="1004" left="108" width="702" height="16" font="0">language or using a graphical interface. In GNU Radio, for example, it is possible to create stream</text>
<text top="1040" left="108" width="702" height="16" font="0">graphs using a graphical interface called GRC, instead of using Python directly. Figure 2.5 shows</text>
</page>
<page number="37" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">23</text>
<text top="516" left="108" width="702" height="16" font="0">Figure 2.5: An FM receiver application created for the GNU Radio stream processing framework</text>
<text top="538" left="108" width="228" height="16" font="0">using a graphical user interface.</text>
<text top="630" left="108" width="702" height="16" font="0">a graphical example of a signal processing application created using this software. It is easy to</text>
<text top="666" left="108" width="702" height="16" font="0">imagine how the GRC software can translate this graphical representation into the appropriate</text>
<text top="702" left="108" width="379" height="16" font="0">sequence of stream graph operations in Python code.</text>
<text top="738" left="151" width="659" height="16" font="0">A hierarchical stream graph construction method is built into the StreamIt language. Kernel</text>
<text top="774" left="108" width="702" height="16" font="0">work functions can perform work on their input streams or they can declare a set of children</text>
<text top="810" left="108" width="702" height="16" font="0">kernels to do the work for them. These children kernels are connected to one another using several</text>
<text top="846" left="108" width="702" height="16" font="0">patterns built into the language. They can be connected as pipelines or in various split-join patterns.</text>
<text top="881" left="108" width="702" height="16" font="0">A split-join is a pattern where a parent kernel’s input stream is split or duplicated among the inputs</text>
<text top="917" left="108" width="702" height="16" font="0">of its children kernels, then the outputs of those children are recombined into a single stream</text>
<text top="953" left="108" width="702" height="16" font="0">which serves as the output of the parent kernel. The pipeline pattern can be seen in the Main</text>
<text top="989" left="108" width="702" height="16" font="0">kernel in Figure 2.3. Another StreamIt example is shown in Figure 2.6. This example is from the</text>
<text top="1025" left="108" width="702" height="16" font="0">StreamIt Cookbook [16]. In the program fragment shown in the ﬁgure, the pipeline pattern is used</text>
<text top="1061" left="108" width="702" height="16" font="0">in the BandPassFilter kernel and the split-join pattern is used in the BPFCore kernel. The</text>
</page>
<page number="38" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">24</text>
<text top="98" left="117" width="423" height="9" font="3">float-&gt;float pipeline BandPassFilter(float rate, float low,</text>
<text top="112" left="382" width="151" height="9" font="3">float high, int taps)</text>
<text top="126" left="117" width="7" height="9" font="3">{</text>
<text top="140" left="131" width="251" height="9" font="3">add BPFCore(rate, low, high, taps);</text>
<text top="154" left="131" width="122" height="9" font="3">add Subtracter();</text>
<text top="169" left="117" width="7" height="9" font="3">}</text>
<text top="197" left="117" width="387" height="9" font="3">float-&gt;float splitjoin BPFCore (float rate, float low,</text>
<text top="211" left="347" width="151" height="9" font="3">float high, int taps)</text>
<text top="225" left="117" width="7" height="9" font="3">{</text>
<text top="240" left="131" width="115" height="9" font="3">split duplicate;</text>
<text top="254" left="131" width="273" height="9" font="3">add LowPassFilter(rate, low, taps, 0);</text>
<text top="268" left="131" width="280" height="9" font="3">add LowPassFilter(rate, high, taps, 0);</text>
<text top="282" left="131" width="115" height="9" font="3">join roundrobin;</text>
<text top="296" left="117" width="7" height="9" font="3">}</text>
<text top="325" left="117" width="215" height="9" font="3">float-&gt;float filter Subtracter</text>
<text top="339" left="117" width="7" height="9" font="3">{</text>
<text top="353" left="131" width="136" height="9" font="3">work pop 2 push 1 {</text>
<text top="367" left="146" width="172" height="9" font="3">push(peek(1) - peek(0));</text>
<text top="382" left="146" width="93" height="9" font="3">pop(); pop();</text>
<text top="396" left="131" width="7" height="9" font="3">}</text>
<text top="410" left="117" width="7" height="9" font="3">}</text>
<text top="435" left="212" width="493" height="16" font="0">Figure 2.6: Constructing a stream graph for an equalizer in StreamIt.</text>
<text top="527" left="108" width="702" height="16" font="0">hierarchically deﬁned structure of the computation is shown graphically alongside the program</text>
<text top="563" left="108" width="31" height="16" font="0">text.</text>
<text top="621" left="112" width="22" height="16" font="0">2.4</text>
<text top="621" left="170" width="85" height="16" font="0">Scheduling</text>
<text top="676" left="151" width="659" height="16" font="0">The individual kernels in stream programs can be statically scheduled prior to execution or</text>
<text top="712" left="108" width="702" height="16" font="0">dynamically scheduled at runtime. This is not really a feature of the language as much as a feature</text>
<text top="748" left="108" width="702" height="16" font="0">of the implementation of the compiler or runtime. Nevertheless, the design of the language can</text>
<text top="784" left="108" width="702" height="16" font="0">impact the ability to use one or the other form of scheduling. For example, in a language like</text>
<text top="820" left="108" width="702" height="16" font="0">StreamIt, where the structure of the stream graph is explicit, it is much easier to come up with a</text>
<text top="856" left="108" width="702" height="16" font="0">static schedule than in other languages where the structure of the stream graph is not obvious. In a</text>
<text top="892" left="108" width="702" height="16" font="0">system like GNU Radio, the opposite is true. Because the stream graph is constructed at runtime</text>
<text top="927" left="108" width="507" height="16" font="0">using pre-compiled components, effective static scheduling is difﬁcult.</text>
</page>
<page number="39" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 3</text>
<text top="292" left="227" width="465" height="16" font="0">The Stream and Kernel Intermediate Representation (SKIR)</text>
<text top="398" left="112" width="22" height="16" font="0">3.1</text>
<text top="398" left="170" width="97" height="16" font="0">Introduction</text>
<text top="453" left="151" width="659" height="16" font="0">The Stream and Kernel Intermediate Representation (SKIR) provides the two basic con-</text>
<text top="489" left="108" width="702" height="16" font="0">structs, streams and kernels, required by stream parallel programs. It also includes operations to</text>
<text top="525" left="108" width="702" height="16" font="0">create streams, to identify and execute kernels, and to construct and modify stream graphs. It</text>
<text top="561" left="108" width="702" height="16" font="0">can be used as an extension to low level program representations targeted by front-end compilers</text>
<text top="597" left="108" width="702" height="16" font="0">– such as JVM, LLVM, or CIL – or as a set low level primitives exposed as compiler intrinsics</text>
<text top="633" left="108" width="702" height="16" font="0">to domain speciﬁc libraries and frameworks. The stream and kernel abstractions are provided by</text>
<text top="669" left="108" width="702" height="16" font="0">SKIR as a set of low-level instruction-like operations. Applications create and execute streaming</text>
<text top="704" left="108" width="702" height="16" font="0">computation by sequentially executing procedural SKIR operations at runtime. A complete list of</text>
<text top="740" left="108" width="281" height="16" font="0">SKIR operations is shown in Table 3.1.</text>
<text top="784" left="108" width="621" height="16" font="0">The design goals for SKIR are to address the limitations detailed in Chapter 1. That is,</text>
<text top="818" left="141" width="564" height="16" font="0">(1) Support a variety of stream parallel and general purpose source languages.</text>
<text top="854" left="141" width="432" height="16" font="0">(2) Support a variety of stream parallel programing models.</text>
<text top="890" left="141" width="466" height="16" font="0">(3) Support static and/or dynamic compilation and optimization.</text>
<text top="926" left="141" width="262" height="16" font="0">(4) Support dynamic stream graphs.</text>
<text top="960" left="108" width="189" height="16" font="0">In addition, SKIR aims to,</text>
<text top="994" left="141" width="669" height="16" font="0">(5) Provide an abstraction layer to hide the implementation details of parallel execution and</text>
<text top="1016" left="171" width="168" height="16" font="0">stream communication.</text>
<text top="1051" left="141" width="492" height="16" font="0">(6) Allow for performance greater than or equal to existing systems.</text>
</page>
<page number="40" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">26</text>
<text top="102" left="134" width="79" height="16" font="0">Operation</text>
<text top="102" left="363" width="89" height="16" font="0">Description</text>
<text top="125" left="371" width="177" height="16" font="0">SKIR Kernel Operations</text>
<text top="147" left="134" width="8" height="15" font="0">k</text>
<text top="147" left="147" width="163" height="16" font="0">= skir.kernel work, arg</text>
<text top="147" left="363" width="421" height="16" font="0">Create a new runtime kernel object with the work function</text>
<text top="169" left="363" width="36" height="15" font="0">work</text>
<text top="169" left="404" width="380" height="16" font="0">and kernel state arg. Store a handle to the resulting</text>
<text top="190" left="363" width="128" height="16" font="0">kernel object in k.</text>
<text top="212" left="134" width="137" height="16" font="0">skir.call k, ins, outs</text>
<text top="212" left="363" width="421" height="16" font="0">Execute kernel k with the input streams ins and the output</text>
<text top="234" left="363" width="391" height="16" font="0">streams outs. ins and outs are arrays of stream objects.</text>
<text top="256" left="134" width="87" height="16" font="0">skir.uncall k</text>
<text top="256" left="363" width="409" height="16" font="0">Stop execution of k and remove it from the stream graph.</text>
<text top="279" left="134" width="74" height="16" font="0">skir.wait k</text>
<text top="279" left="363" width="279" height="16" font="0">Block until kernel k ﬁnishes execution.</text>
<text top="301" left="134" width="99" height="16" font="0">skir.become k</text>
<text top="301" left="363" width="421" height="16" font="0">Replace the currently executing kernel with k. Must be</text>
<text top="323" left="363" width="299" height="16" font="0">called from within a kernel work function</text>
<text top="345" left="369" width="179" height="16" font="0">SKIR Stream Operations</text>
<text top="367" left="134" width="7" height="15" font="0">s</text>
<text top="367" left="146" width="124" height="16" font="0">= skir.stream size</text>
<text top="367" left="363" width="421" height="16" font="0">Create new a runtime stream object and store a handle to</text>
<text top="389" left="363" width="421" height="16" font="0">the resulting object in s. size is the size in bytes of the</text>
<text top="410" left="363" width="165" height="16" font="0">elements in the stream.</text>
<text top="433" left="134" width="132" height="16" font="0">skir.push idx, data</text>
<text top="433" left="363" width="241" height="16" font="0">Push data onto output stream idx.</text>
<text top="455" left="134" width="125" height="16" font="0">skir.pop idx, data</text>
<text top="455" left="363" width="421" height="16" font="0">Pop an element from input stream idx and store the result</text>
<text top="477" left="363" width="69" height="16" font="0">into data.</text>
<text top="499" left="134" width="159" height="16" font="0">skir.peek idx, data, off</text>
<text top="499" left="363" width="421" height="16" font="0">Read the stream element from input stream idx at offset off</text>
<text top="521" left="363" width="209" height="16" font="0">and store the result into data.</text>
<text top="566" left="119" width="679" height="16" font="0">Table 3.1: Overview of the Stream and Kernel Intermediate Representation (SKIR) operations.</text>
<text top="657" left="112" width="22" height="16" font="0">3.2</text>
<text top="657" left="170" width="107" height="16" font="0">SKIR Kernels</text>
<text top="712" left="151" width="659" height="16" font="0">SKIR kernels are kernel objects managed by the SKIR compiler and runtime which encap-</text>
<text top="748" left="108" width="702" height="16" font="0">sulate a single kernel work function and any associated kernel state. They are created with the</text>
<text top="785" left="108" width="118" height="14" font="0">skir.kernel</text>
<text top="784" left="231" width="72" height="16" font="0">operation,</text>
<text top="826" left="236" width="304" height="13" font="4">kernel = skir.kernel(work, arg)</text>
<text top="879" left="108" width="702" height="16" font="0">This operation takes two parameters, work and arg. The work parameter is a pointer to a kernel</text>
<text top="915" left="108" width="702" height="16" font="0">work function. This is the function to be called when a kernel is scheduled for execution. The</text>
<text top="951" left="108" width="702" height="16" font="0">required form of this function is discussed below. The arg parameter is a pointer that will be</text>
<text top="987" left="108" width="702" height="16" font="0">passed to the kernel work function when it is called by the SKIR runtime. This parameter is useful</text>
<text top="1023" left="108" width="702" height="16" font="0">for passing kernel state or arguments to the work function. The stream parallel programming model</text>
<text top="1059" left="108" width="702" height="16" font="0">used by SKIR assumes that program state, including state accessed through the arg parameter, is</text>
</page>
<page number="41" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">27</text>
<text top="128" left="108" width="702" height="16" font="0">for the most part not shared between kernels. This is discussed in more detail in Section 3.4.</text>
<text top="164" left="108" width="702" height="16" font="0">However, a SKIR implementation cannot assume that a kernel is side-effect free. That is, a SKIR</text>
<text top="200" left="108" width="702" height="16" font="0">implementation must determine using static analysis or other methods that a kernel is data parallel.</text>
<text top="236" left="108" width="702" height="18" font="0">As a practical matter, we note that if the arg parameter is a typed pointer (e.g. not void* in C),</text>
<text top="272" left="108" width="702" height="16" font="0">then an implementation can likely perform better analysis with respect to data parallel execution</text>
<text top="308" left="108" width="702" height="16" font="0">and execution on non-CPU devices. However, the use of a typed pointer is not a requirement of</text>
<text top="344" left="108" width="45" height="16" font="0">SKIR.</text>
<text top="380" left="151" width="659" height="16" font="0">The result of the skir.kernel operation is an opaque reference to an implementation de-</text>
<text top="416" left="108" width="713" height="16" font="0">ﬁned SKIR kernel object. These objects are used as an arguments to the skir.call, skir.wait,</text>
<text top="453" left="108" width="118" height="14" font="0">skir.become</text>
<text top="452" left="226" width="584" height="16" font="0">, and skir.uncall operations. The behavior of any other operation performed</text>
<text top="488" left="108" width="702" height="16" font="0">on kernel objects is undeﬁned. A kernel object can be in one of four states: allocated, active,</text>
<text top="524" left="108" width="56" height="15" font="0">ﬁnished</text>
<text top="524" left="164" width="646" height="16" font="0">, or deallocated. These states are used by SKIR implementations and are not made visible</text>
<text top="560" left="108" width="702" height="16" font="0">to the program. The skir.kernel operation returns a kernel in the allocated state. A SKIR</text>
<text top="596" left="108" width="702" height="16" font="0">implementation may start analyzing the kernel work function associated with the kernel object any</text>
<text top="632" left="108" width="702" height="16" font="0">time after the skir.kernel operation but the implementation cannot start executing the kernel.</text>
<text top="668" left="151" width="495" height="16" font="0">Kernels are spawned for execution using the skir.call operation,</text>
<text top="709" left="226" width="137" height="13" font="4">stream ins[] =</text>
<text top="709" left="383" width="108" height="13" font="4">{..., null}</text>
<text top="730" left="226" width="265" height="13" font="4">stream outs[] = (..., null}</text>
<text top="750" left="226" width="275" height="13" font="4">skir.call(kernel, ins, outs)</text>
<text top="804" left="108" width="702" height="16" font="0">The parameters to skir.call are the kernel to execute followed by null-terminated arrays of</text>
<text top="840" left="108" width="702" height="16" font="0">input and output streams. The input and output streams in the arrays must be stream objects</text>
<text top="876" left="108" width="702" height="16" font="0">returned by skir.stream operations. Stream objects can be present in at most one input stream</text>
<text top="911" left="108" width="702" height="16" font="0">array and at most one output stream array. The effect of a skir.call operation is to connect the</text>
<text top="947" left="108" width="702" height="16" font="0">given input and output streams to the given kernel object then transition an allocated or ﬁnished</text>
<text top="983" left="108" width="702" height="16" font="0">kernel object to the active state. Any stream already connected to the kernel different from the</text>
<text top="1019" left="108" width="702" height="16" font="0">streams given to skir.call is disconnected. A SKIR implementation may execute a kernel</text>
<text top="1055" left="108" width="702" height="16" font="0">if and only if the kernel object is in the active state. The behavior of skir.call for active,</text>
</page>
<page number="42" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">28</text>
<text top="128" left="108" width="84" height="15" font="0">deallocated</text>
<text top="128" left="192" width="618" height="16" font="0">, or invalid kernel objects is undeﬁned. The SKIR implementation is not required to</text>
<text top="164" left="108" width="702" height="16" font="0">check that the number of input and output streams passed to a skir.call operation or the size of</text>
<text top="200" left="108" width="702" height="16" font="0">data the streams contain is compatible with the given kernel’s work function. If it is not compatible,</text>
<text top="236" left="108" width="245" height="16" font="0">the runtime behavior is undeﬁned.</text>
<text top="272" left="151" width="659" height="16" font="0">The skir.wait operation provides synchronization between kernels and the threads that</text>
<text top="308" left="108" width="107" height="16" font="0">spawned them,</text>
<text top="348" left="226" width="167" height="13" font="4">skir.wait(kernel)</text>
<text top="400" left="108" width="702" height="16" font="0">The skir.wait operation takes a kernel object as its single parameter. When executed it will</text>
<text top="436" left="108" width="702" height="16" font="0">block if kernel is in the allocated or active states. The skir.wait operation returns immedi-</text>
<text top="472" left="108" width="702" height="16" font="0">ately when the kernel is in, or transitions to, the ﬁnished or deallocated states. The skir.wait</text>
<text top="508" left="108" width="527" height="16" font="0">operation also returns immediately if kernel is an invalid kernel object.</text>
<text top="544" left="151" width="659" height="16" font="0">To forcibly stop a kernel from executing and/or deallocate a kernel object, a program can</text>
<text top="580" left="108" width="266" height="16" font="0">execute a skir.uncall operation,</text>
<text top="620" left="226" width="187" height="13" font="4">skir.uncall(kernel)</text>
<text top="672" left="108" width="702" height="16" font="0">The skir.uncall operation stops the execution of kernel, disconnects any input or output</text>
<text top="708" left="108" width="702" height="16" font="0">streams connected to the kernel object, transitions the kernel object to the deallocated state, then</text>
<text top="744" left="108" width="702" height="16" font="0">returns once the SKIR implementation can guarantee that the kernel will no longer execute. An</text>
<text top="780" left="108" width="702" height="16" font="0">implementation must also guarantee that execution stops normally, with the kernel work function</text>
<text top="816" left="108" width="702" height="16" font="0">retuning a boolean value. That is, it will not preemptively suspend a kernel. Upon returning from</text>
<text top="853" left="108" width="118" height="14" font="0">skir.uncall</text>
<text top="852" left="226" width="584" height="16" font="0">, the value of kernel is undeﬁned with respect to the SKIR program. Internally,</text>
<text top="888" left="108" width="702" height="16" font="0">a SKIR implementation may free any resources associated with any kernel object in the dealloated</text>
<text top="924" left="108" width="37" height="16" font="0">state.</text>
<text top="960" left="151" width="659" height="16" font="0">Kernel work functions in SKIR are ordinary procedures with a certain form. They are implic-</text>
<text top="996" left="108" width="702" height="16" font="0">itly looped and always have three pointers as their only parameters. The ﬁrst parameter receives</text>
<text top="1032" left="108" width="702" height="16" font="0">the arg pointer that was given as an argument to the skir.kernel operation. The second and</text>
<text top="1068" left="108" width="702" height="16" font="0">third parameters receive the arrays of input and output streams that were passed as arguments to</text>
</page>
<page number="43" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">29</text>
<text top="128" left="108" width="702" height="16" font="0">the skir.call operation. These arrays are primarily for building hierarchical kernels (described</text>
<text top="164" left="108" width="702" height="16" font="0">below) and for internal use by a SKIR implementation. We could have made the second and third</text>
<text top="200" left="108" width="702" height="16" font="0">parameters optional, but we favored a uniform kernel work function prototype instead. The result</text>
<text top="236" left="108" width="702" height="16" font="0">of directly accessing or manipulating the arrays of input and output streams or the stream objects</text>
<text top="272" left="108" width="702" height="16" font="0">they contain is undeﬁned for non-hierarchical work functions. Stream data is accessed from within</text>
<text top="308" left="108" width="702" height="16" font="0">kernel work functions using the skir.push, skir.pop, and skir.peek operations. The</text>
<text top="344" left="108" width="702" height="16" font="0">behavior of these operations is undeﬁned outside of the work functions of active kernels. Kernel</text>
<text top="380" left="108" width="702" height="16" font="0">work functions always return a boolean value. A return value of true indicates that the kernel has</text>
<text top="416" left="108" width="702" height="16" font="0">ﬁnished executing and should be transitioned to the ﬁnished state by the SKIR implementation. A</text>
<text top="452" left="108" width="702" height="16" font="0">return value of false indicates that the kernel can process more data and should remain in the</text>
<text top="488" left="108" width="43" height="15" font="0">active</text>
<text top="488" left="155" width="37" height="16" font="0">state.</text>
<text top="524" left="151" width="659" height="16" font="0">Non-hierarchical kernels can replace their functionality in an active program by executing a</text>
<text top="561" left="108" width="118" height="14" font="0">skir.become</text>
<text top="560" left="231" width="72" height="16" font="0">operation,</text>
<text top="592" left="226" width="187" height="13" font="4">skir.become(kernel)</text>
<text top="636" left="108" width="702" height="16" font="0">The skir.become operation takes a single parameter, the new kernel to be used in place</text>
<text top="672" left="108" width="702" height="16" font="0">of the currently executing kernel. The kernel parameter must be the result of a skir.call</text>
<text top="708" left="108" width="702" height="16" font="0">operation invoked from within the kernel work function executing the skir.become operation.</text>
<text top="744" left="108" width="702" height="16" font="0">The effect of the skir.become operation is to immediately and atomically replace the kernel</text>
<text top="780" left="108" width="702" height="16" font="0">work function and the kernel state of the running kernel object with that of kernel. The kernel</text>
<text top="816" left="108" width="702" height="16" font="0">remains in the active state and the streams connected to the kernel object remain the same. This</text>
<text top="852" left="108" width="702" height="16" font="0">implies that the new kernel work function must be compatible with the number of connected input</text>
<text top="888" left="108" width="702" height="16" font="0">and output streams and the size of data they contain. If it is not compatible, the behavior of the</text>
<text top="924" left="108" width="702" height="16" font="0">kernel object is now undeﬁned. When the kernel object transitions to the ﬁnished or deallocated</text>
<text top="960" left="108" width="702" height="16" font="0">state, the SKIR implementation must reset the kernel object’s kernel work function and kernel state</text>
<text top="996" left="108" width="702" height="16" font="0">to the values passed as arguments to the original skir.kernel operation for the kernel object.</text>
<text top="1032" left="108" width="702" height="16" font="0">The implementation can then deallocate any resources associated with the internal kernel object</text>
<text top="1068" left="108" width="320" height="16" font="0">which was the argument to skir.become.</text>
</page>
<page number="44" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="5" size="16" family="Times" color="#1a1a1a"/>
	<fontspec id="6" size="9" family="Times" color="#1a1a1a"/>
	<fontspec id="7" size="13" family="Times" color="#1a1a1a"/>
	<fontspec id="8" size="12" family="Times" color="#1a1a1a"/>
<text top="85" left="792" width="18" height="16" font="0">30</text>
<text top="128" left="151" width="659" height="16" font="0">The skir.become operation is useful in cases where a kernel has to perform some ini-</text>
<text top="164" left="108" width="702" height="16" font="0">tialization work before the stream graph enters a steady state. For example in stream graphs with</text>
<text top="200" left="108" width="702" height="16" font="0">feedback loops it might be necessary to initialize the back edge stream in the graph with some data.</text>
<text top="236" left="108" width="702" height="16" font="0">Another simple example is a kernel implementing a delay in a DSP application. In this case, the</text>
<text top="272" left="108" width="702" height="16" font="0">kernel might push some number of zeros to an output stream, then replace itself with an identity</text>
<text top="308" left="108" width="702" height="16" font="0">function. By using the skir.become operation, the kernel can avoid internal branches and have</text>
<text top="344" left="108" width="141" height="16" font="0">ﬁxed output rate(s).</text>
<text top="457" left="383" width="75" height="21" font="5">allocated</text>
<text top="588" left="396" width="49" height="21" font="5">active</text>
<text top="720" left="388" width="65" height="21" font="5">finished</text>
<text top="588" left="598" width="96" height="21" font="5">deallocated</text>
<text top="645" left="298" width="57" height="13" font="6">return true,</text>
<text top="657" left="221" width="133" height="13" font="6">blocked on finished kernel</text>
<text top="538" left="258" width="61" height="13" font="6">return false,</text>
<text top="551" left="254" width="65" height="13" font="6">skir.become,</text>
<text top="563" left="196" width="124" height="13" font="6">blocked on active kernel</text>
<text top="395" left="436" width="71" height="17" font="7">skir.kernel</text>
<text top="579" left="500" width="65" height="16" font="8">skir.uncall</text>
<text top="466" left="597" width="65" height="16" font="8">skir.uncall</text>
<text top="715" left="594" width="65" height="16" font="8">skir.uncall</text>
<text top="521" left="428" width="52" height="17" font="7">skir.call</text>
<text top="659" left="484" width="52" height="17" font="7">skir.call</text>
<text top="793" left="314" width="291" height="16" font="0">Figure 3.1: SKIR kernel state transitions</text>
<text top="865" left="151" width="659" height="16" font="0">The state transitions of kernel objects are summarized in Figure 3.1. Kernel objects are</text>
<text top="901" left="108" width="702" height="16" font="0">created in the allocated state. Once a kernel has been spawned for execution using skir.call,</text>
<text top="937" left="108" width="702" height="16" font="0">it is in the active state and the kernel work function will be executed repeatedly by the SKIR</text>
<text top="973" left="108" width="702" height="16" font="0">runtime until it leaves that state. An active kernel transitions to ﬁnished if it returns true or if it</text>
<text top="1009" left="108" width="702" height="16" font="0">becomes blocked on a stream operation where the kernel connected to the other end of the stream</text>
<text top="1045" left="108" width="702" height="16" font="0">is in the ﬁnished state. For example, if a kernel A tries to execute a skir.pop instruction on</text>
</page>
<page number="45" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">31</text>
<text top="128" left="108" width="702" height="16" font="0">an empty stream, and the kernel B that was writing to the stream returned true the last time it</text>
<text top="164" left="108" width="702" height="16" font="0">ran, then kernel A is also marked as ﬁnished as if it had returned true. A kernel is transitioned</text>
<text top="200" left="108" width="702" height="16" font="0">to deallocated if a skir.uncall operation is called on it. Kernels in the allocated or ﬁnished</text>
<text top="236" left="108" width="459" height="16" font="0">states are ready to be spawned for execution with skir.call.</text>
<text top="272" left="151" width="659" height="16" font="0">Using the SKIR operations, the pieces of a stream graph are constructed sequentially but</text>
<text top="308" left="108" width="702" height="16" font="0">potentially execute in parallel. This implies that there are times when the graph contains active</text>
<text top="344" left="108" width="702" height="16" font="0">kernels but is also being constructed, modiﬁed, or deconstructed. During these transition periods,</text>
<text top="380" left="108" width="702" height="16" font="0">the stream graph may contain active kernels whose input and output streams are not yet connected.</text>
<text top="416" left="108" width="702" height="16" font="0">Whether or not these kernels will run while their neighbors are unconnected is implementation</text>
<text top="452" left="108" width="702" height="16" font="0">deﬁned. In the implementation of SKIR described in this dissertation, for example, a kernel can</text>
<text top="488" left="108" width="702" height="16" font="0">always safely execute and write data to an output stream until the data buffer associated with</text>
<text top="524" left="108" width="702" height="16" font="0">that stream is full. After blocking on the full buffer, the kernel will only run again if a kernel is</text>
<text top="560" left="108" width="702" height="16" font="0">connected to the other end of the stream and executes long enough to start draining the buffer. An-</text>
<text top="596" left="108" width="702" height="16" font="0">other SKIR implementation might show different behavior because of a different implementation</text>
<text top="632" left="108" width="702" height="16" font="0">of stream communication, but the output of the program will be the same. The same applies when</text>
<text top="668" left="108" width="702" height="16" font="0">streams are disconnected as the result of an skir.uncall operation. Whether or not the SKIR</text>
<text top="704" left="108" width="702" height="16" font="0">implementation executes active kernels attached to the other end of the uncalled kernel’s former</text>
<text top="740" left="108" width="702" height="16" font="0">stream objects is implementation dependent. The only thing SKIR guarantees is that the stream</text>
<text top="776" left="108" width="702" height="16" font="0">objects are left in a state that allows them to be connected to a new kernel with a skir.call</text>
<text top="812" left="108" width="72" height="16" font="0">operation.</text>
<text top="848" left="151" width="659" height="16" font="0">Once stream objects have been connected to kernel objects, they can be deallocated by a</text>
<text top="884" left="108" width="702" height="16" font="0">SKIR implementation if and only if both ends of the stream have been disconnected from kernels</text>
<text top="920" left="108" width="702" height="16" font="0">transitioning to the deallocated state without any skir.call operations referencing the stream</text>
<text top="956" left="108" width="702" height="16" font="0">object between these two events. This means that both kernel objects and stream objects allocated</text>
<text top="992" left="108" width="702" height="16" font="0">using skir.kernel or skir.stream will only be deallocated as the result of deliberate pro-</text>
<text top="1027" left="108" width="702" height="16" font="0">gram actions and not as the result of simple program execution or modiﬁcation. For stream objects,</text>
<text top="1063" left="108" width="702" height="16" font="0">this also means that a program must be careful to always leave one end of a stream connected to an</text>
</page>
<page number="46" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">32</text>
<text top="128" left="108" width="43" height="15" font="0">active</text>
<text top="128" left="151" width="659" height="16" font="0">, allocated or ﬁnished kernel if the stream object is to be reused. These properties also imply</text>
<text top="164" left="108" width="702" height="16" font="0">that a steam object can never be deallocated if one or both of its ends are never connected to kernel</text>
<text top="200" left="108" width="702" height="16" font="0">objects. However, based on the discussion in the previous paragraph, the execution behavior of</text>
<text top="236" left="108" width="292" height="16" font="0">such a program may not be well deﬁned.</text>
<text top="298" left="112" width="36" height="16" font="0">3.2.1</text>
<text top="298" left="182" width="160" height="16" font="0">Hierarchical Kernels</text>
<text top="346" left="151" width="659" height="16" font="0">There is a special type of kernel object deﬁned by SKIR called a hierarchical kernel. Hier-</text>
<text top="382" left="108" width="702" height="16" font="0">archical kernels are deﬁned as kernels whose work functions do not contain any skir.push,</text>
<text top="419" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="418" left="194" width="616" height="16" font="0">, skir.peek, or skir.become operations. Instead, the kernel work function</text>
<text top="454" left="108" width="702" height="16" font="0">may contain skir.kernel, skir.stream, and skir.call operations necessary to instan-</text>
<text top="490" left="108" width="702" height="16" font="0">tiate, connect, and spawn child kernels. These child kernels are allocated and executed using</text>
<text top="527" left="108" width="118" height="14" font="0">skir.kernel</text>
<text top="526" left="232" width="578" height="16" font="0">and skir.call operations with the usual semantics. It is legal and desirable</text>
<text top="562" left="108" width="702" height="16" font="0">for the kernel work function of hierarchical kernels to access the input and output stream arrays</text>
<text top="598" left="108" width="702" height="16" font="0">of the kernel work function and pass the streams found therein to skir.call operations. Such</text>
<text top="634" left="108" width="702" height="16" font="0">streams are then considered to be connected to the corresponding child kernel and associated with</text>
<text top="670" left="108" width="702" height="16" font="0">that kernel’s arrays of input and/or output streams. Hierarchical kernels allow the recursive def-</text>
<text top="706" left="108" width="702" height="16" font="0">inition of stream graphs using ordinary skir.kernel and skir.call operations, increasing</text>
<text top="742" left="108" width="702" height="16" font="0">code modularity. For example, a program could use a kernel from a separate code library without</text>
<text top="778" left="108" width="702" height="16" font="0">knowing that the kernel is a hierarchical kernel expanding into many smaller kernels implementing</text>
<text top="814" left="108" width="702" height="16" font="0">the desired functionality. Hierarchical kernels also simplify the implementation of stream parallel</text>
<text top="850" left="108" width="632" height="16" font="0">programming languages such as StreamIt where programs are composed in this manner.</text>
<text top="886" left="151" width="659" height="16" font="0">Unlike ordinary kernel objects which potentially execute their kernel work function many</text>
<text top="922" left="108" width="702" height="16" font="0">times, the kernel work function of hierarchical kernels must be executed by the SKIR implemen-</text>
<text top="958" left="108" width="702" height="16" font="0">tation exactly once. A hierarchical kernel remains in the active state until all children allocated</text>
<text top="994" left="108" width="702" height="16" font="0">and called from within the hierarchical kernel’s work function reach the ﬁnished or deallocated</text>
<text top="1030" left="108" width="702" height="16" font="0">state. If all child kernels reach the ﬁnished state, then the hierarchical parent kernel is transitioned</text>
<text top="1066" left="108" width="702" height="16" font="0">to ﬁnished. If all child kernels reach the deallocated state, then the hierarchical parent kernel is</text>
</page>
<page number="47" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">33</text>
<text top="128" left="108" width="702" height="16" font="0">transitioned to deallocated. When a skir.uncall operation is invoked on an active or ﬁnished</text>
<text top="164" left="108" width="702" height="16" font="0">hierarchical kernel, the SKIR implementation must invoke skir.uncall on each child kernel.</text>
<text top="200" left="108" width="702" height="16" font="0">When a skir.uncall operation is invoked on an allocated hierarchical kernel, no children will</text>
<text top="236" left="108" width="702" height="16" font="0">be present and the hierarchical kernel is immediately transitioned to the deallocated state. Refer-</text>
<text top="272" left="108" width="702" height="16" font="0">ences to child kernels are considered part of the state of the kernel. Therefore it can be assumed by</text>
<text top="308" left="108" width="702" height="16" font="0">a SKIR implementation that references to these kernel objects are not accessable outside of the hi-</text>
<text top="344" left="108" width="702" height="16" font="0">erarchical kernel’s work function. This implies that the only way to execute skir.uncall on a</text>
<text top="380" left="108" width="702" height="16" font="0">child kernel is to execute skir.uncall on the hierarchical parent kernel. This also implies that</text>
<text top="416" left="108" width="702" height="16" font="0">children of a hierarchical kernel cannot be in a mixture of ﬁnished and deallocated states except</text>
<text top="452" left="108" width="702" height="16" font="0">during the execution of a skir.uncall operation on the hierarchical parent kernel. All of these</text>
<text top="488" left="108" width="545" height="16" font="0">properties ensure correct operation of skir.wait for hierarchical kernels.</text>
<text top="546" left="112" width="22" height="16" font="0">3.3</text>
<text top="546" left="170" width="111" height="16" font="0">SKIR Streams</text>
<text top="600" left="151" width="659" height="16" font="0">SKIR streams use the usual stream abstraction of an unbounded ﬁrst-in ﬁrst-out queue of data</text>
<text top="636" left="108" width="702" height="16" font="0">to communicate between a single source kernel and a single destination kernel. Data written to a</text>
<text top="672" left="108" width="702" height="16" font="0">stream by the source kernel can be later read by the destination kernel in the order it was written.</text>
<text top="708" left="108" width="702" height="16" font="0">Streams are allocated using the skir.stream operation which takes as a single parameter the</text>
<text top="744" left="108" width="702" height="16" font="0">desired size, in bytes, of data elements stored in the stream. The result is an opaque reference to a</text>
<text top="781" left="108" width="96" height="15" font="0">stream object</text>
<text top="780" left="209" width="451" height="16" font="0">that can be used as an argument to the skir.call operation.</text>
<text top="816" left="151" width="659" height="16" font="0">The operations deﬁned on stream objects are the three stream operations: skir.push,</text>
<text top="853" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="852" left="194" width="141" height="16" font="0">, and skir.peek,</text>
<text top="894" left="226" width="187" height="13" font="4">skir.push(idx, ptr)</text>
<text top="914" left="226" width="177" height="13" font="4">skir.pop(idx, ptr)</text>
<text top="935" left="226" width="265" height="13" font="4">skir.peek(idx, ptr, offset)</text>
<text top="988" left="108" width="702" height="16" font="0">The parameters to skir.push, skir.pop, and skir.peek are an index indicating the stream</text>
<text top="1024" left="108" width="702" height="16" font="0">to operate on along with a pointer to the source data (for skir.push) or destination location (for</text>
<text top="1061" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="1060" left="199" width="611" height="16" font="0">and skir.peek). Streams are indexed starting with zero for both input and output</text>
</page>
<page number="48" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">34</text>
<text top="128" left="108" width="702" height="16" font="0">streams. For example, a skir.push operation with an index argument of one indicates that</text>
<text top="164" left="108" width="702" height="16" font="0">data should be written to the second output stream that was passed to the skir.call operation.</text>
<text top="200" left="108" width="702" height="16" font="0">As one would expect, skir.push writes data to an output stream and skir.pop reads (and</text>
<text top="236" left="108" width="702" height="16" font="0">removes) data from an input stream. The skir.peek operation reads data from an input stream</text>
<text top="272" left="108" width="702" height="16" font="0">but does not remove it and takes an additional unsigned offset parameter. When a non-zero offset</text>
<text top="308" left="108" width="527" height="16" font="0">is speciﬁed, skir.peek reads ahead in the stream by the given amount.</text>
<text top="344" left="151" width="659" height="16" font="0">Streams are allocated using the skir.stream operation which takes as its sole parameter</text>
<text top="380" left="108" width="452" height="16" font="0">the desired size, in bytes, of data elements stored in the stream,</text>
<text top="422" left="226" width="275" height="13" font="4">stream = skir.stream(nbytes)</text>
<text top="475" left="108" width="702" height="16" font="0">The resulting stream can be used as an argument to the skir.call operation by including it in</text>
<text top="511" left="108" width="702" height="16" font="0">one of the null terminated arrays passed to that operation. SKIR kernels are the only code in the</text>
<text top="547" left="108" width="618" height="16" font="0">program that can operate on streams, and they must do so using the stream operations.</text>
<text top="605" left="112" width="22" height="16" font="0">3.4</text>
<text top="605" left="170" width="167" height="16" font="0">SKIR Memory Model</text>
<text top="660" left="151" width="659" height="16" font="0">The stream parallel model makes an important assumption about memory accesses which is</text>
<text top="696" left="108" width="702" height="16" font="0">necessary for parallel execution. As stated in section 3.2, the stream parallel programming model</text>
<text top="732" left="108" width="702" height="16" font="0">assumes that program state is not shared between kernels. The result of this assumption is that</text>
<text top="768" left="108" width="702" height="16" font="0">execution of kernels can be freely interleaved by a compiler or scheduler without introducing data</text>
<text top="804" left="108" width="702" height="16" font="0">races or other synchronization errors. This is also an important property of both Kahn Process</text>
<text top="840" left="108" width="346" height="16" font="0">Networks and Synchronous Dataﬂow Networks.</text>
<text top="875" left="151" width="659" height="16" font="0">It is helpful to examine this assumption with respect to SKIR. There are two types of program</text>
<text top="911" left="108" width="702" height="16" font="0">state that are purposely passed to SKIR kernels. These are the private kernel state passed to a</text>
<text top="947" left="108" width="702" height="16" font="0">program kernel as the arg parameter of a skir.call operation and stream data passed between</text>
<text top="983" left="108" width="151" height="16" font="0">kernels over streams.</text>
<text top="1019" left="151" width="659" height="16" font="0">Kernel state is deﬁned to be any memory location read or written by the kernel work func-</text>
<text top="1055" left="108" width="702" height="16" font="0">tion whose address was obtained though arithmetic involving arg. A SKIR implementation can</text>
</page>
<page number="49" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">35</text>
<text top="128" left="108" width="702" height="16" font="0">assume that memory operations on kernel state do not conﬂict with memory operations performed</text>
<text top="164" left="108" width="702" height="16" font="0">by any other kernel work function. Two memory operations conﬂict if they access the same mem-</text>
<text top="200" left="108" width="702" height="16" font="0">ory location and at least one of them is a store operation. Furthermore, it is assumed that memory</text>
<text top="236" left="108" width="702" height="16" font="0">operations on kernel state do not conﬂict with other parts of the program (outside of kernel work</text>
<text top="272" left="108" width="702" height="16" font="0">functions) while the kernel is active. A SKIR implementation must only ensure that memory oper-</text>
<text top="308" left="108" width="702" height="16" font="0">ations on kernel state are sequentially consistent between invocations of the kernel work function.</text>
<text top="344" left="108" width="702" height="16" font="0">For example, if a SKIR implementation runs a kernel K on processor A, then on processor B, then</text>
<text top="380" left="108" width="701" height="16" font="0">on processor C, then any modiﬁcation to K’s kernel state by A and B must appear to C as if K</text>
<text top="416" left="108" width="105" height="16" font="0">ran only on C.</text>
<text top="452" left="151" width="659" height="16" font="0">Stream data is deﬁned as any data read directly from an input stream as well as any memory</text>
<text top="488" left="108" width="702" height="16" font="0">location read or written by a kernel work function whose addresses was obtained through arithmetic</text>
<text top="524" left="108" width="702" height="16" font="0">involving memory addresses read directly from an input stream. For the latter, a SKIR implemen-</text>
<text top="560" left="108" width="702" height="16" font="0">tation must provide sequential consistency between such memory operations and skir.push,</text>
<text top="597" left="108" width="97" height="14" font="0">skir.peek</text>
<text top="596" left="205" width="605" height="16" font="0">, or skir.pop operations. In practice this means that for kernels operating on</text>
<text top="632" left="108" width="702" height="16" font="0">streams of pointers, a memory fence might be inserted for every skir.push, skir.peek, or</text>
<text top="669" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="668" left="198" width="612" height="16" font="0">operation unless the compiler can prove it is not needed based on behaviors such as the</text>
<text top="704" left="108" width="702" height="16" font="0">target hardware’s consistency model, the control ﬂow of the kernel work function, or the behavior</text>
<text top="740" left="108" width="702" height="16" font="0">of the underlying kernel scheduler (e.g. single threaded or multi-threaded). A SKIR implementa-</text>
<text top="776" left="108" width="702" height="16" font="0">tion can assume that a kernel obtains exclusive ownership of stream data when it is read from an</text>
<text top="812" left="108" width="702" height="16" font="0">input stream. Ownership is released by writing the stream data (or the pointer used to reference the</text>
<text top="848" left="108" width="702" height="16" font="0">stream data) to an output stream or by returning control to the scheduler. While a kernel has own-</text>
<text top="884" left="108" width="702" height="16" font="0">ership of stream data, a SKIR implementation can assume that memory operations on stream data</text>
<text top="920" left="108" width="702" height="16" font="0">do not conﬂict with memory operations in other parts of the program. The behavior of a program</text>
<text top="956" left="108" width="318" height="16" font="0">that violates these assumptions is undeﬁned.</text>
<text top="992" left="151" width="659" height="16" font="0">For all other types of memory operations not mentioned above, such as loads and stores to</text>
<text top="1027" left="108" width="702" height="16" font="0">global variables or procedure calls with side effects, a SKIR compiler is not required to provide</text>
<text top="1063" left="108" width="702" height="16" font="0">any consistency or synchronization guarantees beyond those provided to these operations by the</text>
</page>
<page number="50" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">36</text>
<text top="128" left="108" width="702" height="16" font="0">underlying implementation IR. In the presence of such operations, the SKIR implementation may</text>
<text top="164" left="108" width="702" height="16" font="0">still assume that the execution of kernels can be freely interleaved without introducing data races</text>
<text top="200" left="108" width="226" height="16" font="0">or other synchronization errors.</text>
<text top="258" left="112" width="22" height="16" font="0">3.5</text>
<text top="258" left="170" width="222" height="16" font="0">SKIR Program Construction</text>
<text top="313" left="151" width="659" height="16" font="0">The previous sections described the individual SKIR operations and execution model in de-</text>
<text top="349" left="108" width="702" height="16" font="0">tail. This section shows two examples of how these operations can be used to build and execute</text>
<text top="385" left="108" width="702" height="16" font="0">stream parallel computation. The ﬁrst example is a static stream graph that could be analyzed</text>
<text top="421" left="108" width="702" height="16" font="0">and compiled statically using a SDF compiler. The second example is a stream graph which uses</text>
<text top="457" left="108" width="574" height="16" font="0">hierarchical kernels and reconﬁgures itself using the skir.become operation.</text>
<text top="519" left="112" width="36" height="16" font="0">3.5.1</text>
<text top="519" left="182" width="252" height="16" font="0">Example 1: Static Stream Graph</text>
<text top="567" left="151" width="659" height="16" font="0">An example of how the SKIR operations can be combined to create and execute a stream</text>
<text top="603" left="108" width="702" height="16" font="0">parallel computation is shown in Figure 3.2 using SKIR pseudo-code. The C like pseudo-code</text>
<text top="639" left="108" width="702" height="16" font="0">syntax used in the ﬁgure contains SKIR operations similar to the SKIR compiler intrinsics that</text>
<text top="675" left="108" width="702" height="16" font="0">have been implemented for the C language. The program in the ﬁgure has the same structure as the</text>
<text top="711" left="108" width="702" height="16" font="0">program by Kahn and McQueen in Figure 2.2. The main procedure creates four kernels, allocates</text>
<text top="747" left="108" width="702" height="16" font="0">three streams to connect them, then calls each kernel to begin execution. A skir.wait operation</text>
<text top="783" left="108" width="597" height="16" font="0">on the last kernel prevents main from returning until the computation has ﬁnished.</text>
<text top="845" left="112" width="36" height="16" font="0">3.5.2</text>
<text top="845" left="182" width="277" height="16" font="0">Example 2: Dynamic Stream Graph</text>
<text top="893" left="151" width="659" height="16" font="0">Section 1.2.1 stated that two desirable features for stream parallel computation are to al-</text>
<text top="929" left="108" width="702" height="16" font="0">low dynamically constructed stream graphs and to allow dynamically modiﬁable stream graphs.</text>
<text top="965" left="108" width="702" height="16" font="0">The ﬁrst feature, dynamically constructed graphs, is trivially provided by the SKIR operations</text>
<text top="1002" left="108" width="118" height="14" font="0">skir.stream</text>
<text top="1001" left="226" width="584" height="16" font="0">, skir.kernel, and skir.call; graphs are constructed dynamically by de-</text>
<text top="1037" left="108" width="702" height="16" font="0">fault. The second feature, dynamically modiﬁable graphs, is provided by the two SKIR operations</text>
</page>
<page number="51" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">37</text>
<text top="98" left="214" width="538" height="14" font="1">bool SKIR_PRODUCER (int *state, void *ins[], void *outs[]) {</text>
<text top="118" left="250" width="170" height="12" font="1">*state = *state + 1</text>
<text top="134" left="250" width="170" height="12" font="1">skir.push(0, state)</text>
<text top="152" left="214" width="9" height="12" font="1">}</text>
<text top="187" left="214" width="556" height="14" font="1">bool SKIR_TRANSDUCER (int *state, void *ins[], void *outs[]) {</text>
<text top="205" left="250" width="72" height="12" font="1">int data</text>
<text top="223" left="250" width="161" height="12" font="1">skir.pop(0, &amp;data)</text>
<text top="241" left="250" width="126" height="14" font="1">data += *state</text>
<text top="259" left="250" width="170" height="12" font="1">skir.push(0, &amp;data)</text>
<text top="277" left="250" width="108" height="12" font="1">return false</text>
<text top="295" left="214" width="9" height="12" font="1">}</text>
<text top="331" left="214" width="538" height="14" font="1">bool SKIR_CONSUMER (int *state, void *ins[], void *outs[]) {</text>
<text top="349" left="250" width="72" height="12" font="1">int data</text>
<text top="367" left="250" width="251" height="14" font="1">if (*state == 0) return true</text>
<text top="385" left="250" width="161" height="12" font="1">skir.pop(0, &amp;data)</text>
<text top="403" left="250" width="99" height="12" font="1">print(data)</text>
<text top="423" left="250" width="170" height="12" font="1">*state = *state - 1</text>
<text top="438" left="250" width="108" height="12" font="1">return false</text>
<text top="456" left="214" width="9" height="12" font="1">}</text>
<text top="492" left="214" width="54" height="12" font="1">main()</text>
<text top="510" left="214" width="9" height="12" font="1">{</text>
<text top="528" left="250" width="134" height="12" font="1">int counter = 0</text>
<text top="546" left="250" width="126" height="12" font="1">int limit = 20</text>
<text top="564" left="250" width="99" height="12" font="1">int one = 1</text>
<text top="582" left="250" width="108" height="12" font="1">int neg = -1</text>
<text top="618" left="250" width="233" height="12" font="1">stream Q1[2], Q2[2], Q3[2]</text>
<text top="636" left="250" width="188" height="12" font="1">kernel K1, K2, K3, K4</text>
<text top="672" left="250" width="386" height="12" font="1">Q1[0] = skir.stream(sizeof(int)); Q1[1] = 0</text>
<text top="690" left="250" width="386" height="12" font="1">Q2[0] = skir.stream(sizeof(int)); Q2[1] = 0</text>
<text top="707" left="250" width="386" height="12" font="1">Q3[0] = skir.stream(sizeof(int)); Q3[1] = 0</text>
<text top="743" left="250" width="368" height="12" font="1">K1 = skir.kernel(SKIR_PRODUCER, &amp;counter)</text>
<text top="761" left="250" width="350" height="12" font="1">K2 = skir.kernel(SKIR_TRANSDUCER, &amp;one)</text>
<text top="779" left="250" width="350" height="12" font="1">K3 = skir.kernel(SKIR_TRANSDUCER, &amp;neg)</text>
<text top="797" left="250" width="350" height="12" font="1">K4 = skir.kernel(SKIR_CONSUMER, &amp;limit)</text>
<text top="833" left="250" width="206" height="12" font="1">skir.call(K1, NULL, Q1)</text>
<text top="851" left="250" width="188" height="12" font="1">skir.call(K1, Q1, Q2)</text>
<text top="869" left="250" width="188" height="12" font="1">skir.call(K2, Q2, Q3)</text>
<text top="887" left="250" width="206" height="12" font="1">skir.call(K3, Q3, NULL)</text>
<text top="905" left="250" width="117" height="12" font="1">skir.wait(K3)</text>
<text top="923" left="214" width="9" height="12" font="1">}</text>
<text top="950" left="108" width="702" height="16" font="0">Figure 3.2: An example of a static SKIR program graph. The main procedure deﬁnes and executes</text>
<text top="972" left="108" width="702" height="16" font="0">a four stage pipeline similar to the one in Figure 2.2. The program is written in SKIR pseudo-code.</text>
</page>
<page number="52" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">38</text>
<text top="98" left="215" width="172" height="9" font="3">struct printer_state_t {</text>
<text top="112" left="243" width="244" height="9" font="3">int limit; int cnt; int last_prime</text>
<text top="126" left="215" width="7" height="9" font="3">}</text>
<text top="140" left="215" width="380" height="11" font="3">bool generate (int *cnt, void *ins[], void *outs[]) {</text>
<text top="157" left="243" width="108" height="9" font="3">*cnt = *cnt + 1</text>
<text top="169" left="243" width="122" height="9" font="3">skir.push(0, cnt)</text>
<text top="183" left="243" width="86" height="9" font="3">return false</text>
<text top="197" left="215" width="7" height="9" font="3">}</text>
<text top="211" left="215" width="380" height="11" font="3">bool filter (int *prime, void *ins[], void *outs[]) {</text>
<text top="225" left="243" width="36" height="9" font="3">int e</text>
<text top="240" left="243" width="108" height="9" font="3">skir.pop(0, &amp;e)</text>
<text top="254" left="243" width="108" height="11" font="3">if (e % *prime)</text>
<text top="268" left="272" width="115" height="9" font="3">skir.push(0, &amp;e)</text>
<text top="282" left="243" width="86" height="9" font="3">return false</text>
<text top="296" left="215" width="7" height="9" font="3">}</text>
<text top="311" left="215" width="452" height="11" font="3">bool printer (printer_state_t *ps, void *ins[], void *outs[]) {</text>
<text top="339" left="243" width="201" height="9" font="3">skir.pop(0, &amp;ps-&gt;last_prime)</text>
<text top="353" left="243" width="359" height="9" font="3">print(&#34;prime %u: %u\n&#34;, ++ps-&gt;cnt, ps-&gt;last_prime)</text>
<text top="382" left="243" width="265" height="9" font="3">if (ps-&gt;cnt &gt;= ps-&gt;limit) return true</text>
<text top="410" left="243" width="323" height="9" font="3">kernel = skir.kernel(make_printer_filter, ps)</text>
<text top="424" left="243" width="100" height="9" font="3">skir.become(k)</text>
<text top="453" left="243" width="86" height="9" font="3">return false</text>
<text top="453" left="358" width="100" height="9" font="3">// unreachable</text>
<text top="467" left="215" width="7" height="9" font="3">}</text>
<text top="481" left="215" width="524" height="11" font="3">bool make_printer_filter (printer_state_t *ps, void *ins[], void *outs[])</text>
<text top="495" left="215" width="7" height="9" font="3">{</text>
<text top="509" left="243" width="201" height="11" font="3">int *p = malloc(sizeof(int))</text>
<text top="526" left="243" width="136" height="9" font="3">*p = ps-&gt;last_prime</text>
<text top="552" left="243" width="244" height="9" font="3">kernel k0 = skir.kernel(filter, p)</text>
<text top="566" left="243" width="258" height="9" font="3">kernel k1 = skir.kernel(printer, ps)</text>
<text top="595" left="243" width="344" height="9" font="3">stream strm[2] = { skir.stream(sizeof(int)), 0 }</text>
<text top="623" left="243" width="172" height="9" font="3">skir.call(k0, ins, strm)</text>
<text top="637" left="243" width="179" height="9" font="3">skir.call(k1, strm, outs)</text>
<text top="666" left="243" width="86" height="9" font="3">return false</text>
<text top="680" left="215" width="7" height="9" font="3">}</text>
<text top="708" left="215" width="208" height="9" font="3">void run_sieve (int nprime) {</text>
<text top="737" left="243" width="344" height="9" font="3">stream strm[2] = { skir.stream(sizeof(int)), 0 }</text>
<text top="751" left="243" width="136" height="9" font="3">stream nul[1] = {0}</text>
<text top="779" left="243" width="122" height="9" font="3">int gen_state = 1</text>
<text top="793" left="243" width="330" height="9" font="3">kernel src = skir.kernel(generate, &amp;gen_state)</text>
<text top="807" left="243" width="179" height="9" font="3">skir.call(src, nul, strm)</text>
<text top="836" left="243" width="208" height="9" font="3">printer_state_t printer_state</text>
<text top="850" left="243" width="201" height="9" font="3">printer_state.limit = nprime</text>
<text top="864" left="243" width="151" height="9" font="3">printer_state.cnt = 0</text>
<text top="893" left="243" width="359" height="9" font="3">kernel sink = skir.kernel(printer, &amp;printer_state)</text>
<text top="907" left="243" width="187" height="9" font="3">skir.call(sink, strm, nul)</text>
<text top="935" left="243" width="108" height="9" font="3">skir.wait(sink)</text>
<text top="949" left="243" width="108" height="9" font="3">print(&#34;done\n&#34;)</text>
<text top="964" left="215" width="7" height="9" font="3">}</text>
<text top="989" left="108" width="702" height="16" font="0">Figure 3.3: An example of a dynamic SKIR program graph. This ﬁgure shows the prime sieve</text>
<text top="1011" left="108" width="656" height="16" font="0">program written as SKIR pseudo-code. It is similar to the Go program shown in Figure 1.2.</text>
</page>
<page number="53" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">39</text>
<text top="129" left="108" width="118" height="14" font="0">skir.uncall</text>
<text top="128" left="231" width="579" height="16" font="0">and skir.become. The use of skir.uncall for this task is fairly obvious.</text>
<text top="164" left="108" width="702" height="16" font="0">It allows a kernel to be removed from an active stream graph and potentially replaced by one or</text>
<text top="200" left="108" width="702" height="16" font="0">more new kernels using the other SKIR operations. The skir.become operator allows the same</text>
<text top="236" left="108" width="483" height="16" font="0">thing to occur from within a non-hierarchical kernel work function.</text>
<text top="272" left="151" width="659" height="16" font="0">Figure 3.3 shows the prime sieve program from Figure 1.2 written as SKIR pseudo-code.</text>
<text top="308" left="108" width="702" height="16" font="0">The program begins by constructing and executing a two stage pipline consisting of a generate</text>
<text top="344" left="108" width="702" height="16" font="0">kernel and a printer kernel. Each time the printer kernel receives a new prime from its input</text>
<text top="380" left="108" width="702" height="16" font="0">stream it allocates a new hierarchical kernel, make printer filter, then replaces itself with</text>
<text top="416" left="108" width="702" height="16" font="0">that kernel using skir.become. The hierarchical kernel is itself a two stage pipeline containing</text>
<text top="452" left="108" width="626" height="16" font="0">a filter kernel, to ﬁlter out multiples of a single prime, and a new printer kernel.</text>
<text top="510" left="112" width="22" height="16" font="0">3.6</text>
<text top="510" left="170" width="123" height="16" font="0">Implementation</text>
<text top="564" left="151" width="659" height="16" font="0">In this dissertation, SKIR is implemented as an extension to the Low Level Virtual Machine</text>
<text top="600" left="108" width="702" height="16" font="0">(LLVM) code representation version 2.9. The LLVM representation is a “Static Single Assign-</text>
<text top="636" left="108" width="702" height="15" font="0">ment (SSA) based representation that provides type safety, low-level operations, ﬂexibility, and</text>
<text top="672" left="108" width="702" height="15" font="0">the capability of representing ’all’ high-level languages cleanly ... designed to be used in three</text>
<text top="708" left="108" width="702" height="15" font="0">different forms: as an in-memory compiler IR, as an on-disk bitcode representation ..., and as a</text>
<text top="744" left="108" width="258" height="15" font="0">human readable assembly language</text>
<text top="744" left="366" width="444" height="16" font="0">” [7]. The SKIR operations are implemented using the LLVM</text>
<text top="780" left="108" width="702" height="16" font="0">intrinsic facility. It is generally much easier to extend LLVM using intrinsics rather than adding a</text>
<text top="816" left="108" width="702" height="16" font="0">new instruction. This is because an intrinsic looks like an ordinary function call to compiler passes</text>
<text top="852" left="108" width="702" height="16" font="0">that do not have any knowledge of an intrinsic’s semantics while appearing as a LLVM instruc-</text>
<text top="888" left="108" width="702" height="16" font="0">tion to compiler passes that have been modiﬁed to recognize the intrinsic. Intrinsics also support</text>
<text top="924" left="108" width="702" height="16" font="0">custom code generation in the compiler backend like an ordinary LLVM instruction. Adding an</text>
<text top="960" left="108" width="702" height="16" font="0">instruction rather than an intrinsic also changes the LLVM bitcode format and therefore breaks</text>
<text top="996" left="108" width="702" height="16" font="0">compatibility with other LLVM versions. Other features of LLVM implemented as intrinsics in-</text>
<text top="1032" left="108" width="702" height="16" font="0">clude vararg support, basic support for garbage collection, atomic instructions, exception handling,</text>
<text top="1068" left="108" width="702" height="16" font="0">and some standard library operations such as memcopy and trigonometric functions. As in SKIR,</text>
</page>
<page number="54" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">40</text>
<text top="128" left="108" width="671" height="16" font="0">these intrinsics allow for easier code transformation and optimization by the LLVM compiler.</text>
</page>
<page number="55" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 4</text>
<text top="292" left="296" width="325" height="16" font="0">Compiling High-Level Languages to SKIR</text>
<text top="408" left="151" width="659" height="16" font="0">One of the design goals of SKIR is for it to be suitable as a compilation target for multiple</text>
<text top="444" left="108" width="702" height="16" font="0">languages. This chapter presents four case studies involving the compilation of high-level lan-</text>
<text top="479" left="108" width="702" height="16" font="0">guages to SKIR. In Section 4.1, C language compiler intrinsics providing direct access to SKIR</text>
<text top="515" left="108" width="702" height="16" font="0">operations are described. Section 4.2 shows how these intrinsics can be used to build a user li-</text>
<text top="551" left="108" width="100" height="16" font="0">brary in the C</text>
<text top="551" left="206" width="17" height="13" font="1">++</text>
<text top="551" left="227" width="583" height="16" font="0">language. The library provides a high level object oriented abstraction for stream</text>
<text top="587" left="108" width="702" height="16" font="0">processing. In Section 4.3, the StreamIt compiler frontend for SKIR is described. Finally, Section</text>
<text top="623" left="108" width="702" height="16" font="0">4.4 shows how we can use the SKIR compiler and runtime system to provide an out of process</text>
<text top="659" left="108" width="540" height="16" font="0">acceleration layer for an embedded domain speciﬁc language in JavaScript.</text>
<text top="717" left="112" width="22" height="16" font="0">4.1</text>
<text top="717" left="170" width="255" height="16" font="0">Compiler Intrinsics: C Language</text>
<text top="772" left="151" width="659" height="16" font="0">The SKIR operations can be exposed to programmers of low level languages like C as com-</text>
<text top="808" left="108" width="702" height="16" font="0">piler intrinsics. Using compiler intrinsics in this way is a common method of exposing low level</text>
<text top="844" left="108" width="702" height="16" font="0">functionality to a programmer. Compiler intrinsics take the form of special functions that are han-</text>
<text top="880" left="108" width="702" height="16" font="0">dled differently than other functions in the compiler. They are most often used to provide compiler</text>
<text top="916" left="108" width="702" height="16" font="0">optimized implementations of certain function (e.g. math libraries), to provide low level synchro-</text>
<text top="952" left="108" width="702" height="16" font="0">nization methods (e.g atomic operations), or to expose features of a speciﬁc processor (e.g. vector</text>
<text top="988" left="108" width="702" height="16" font="0">instructions). The SKIR intrinsic declarations for the C language are shown in Figure 4.1. Each of</text>
<text top="1024" left="108" width="609" height="16" font="0">the SKIR C intrinsics corresponds to one of the SKIR operations shown in Table 3.1.</text>
</page>
<page number="56" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">42</text>
<text top="108" left="110" width="91" height="11" font="3">t y p e d e f v o i d ∗</text>
<text top="108" left="261" width="125" height="11" font="3">s k i r s t r e a m p t r t ;</text>
<text top="122" left="110" width="140" height="11" font="3">t y p e d e f u n s i g n e d i n t</text>
<text top="122" left="261" width="125" height="11" font="3">s k i r s t r e a m i d x t ;</text>
<text top="136" left="110" width="91" height="11" font="3">t y p e d e f v o i d ∗</text>
<text top="136" left="261" width="154" height="11" font="3">s k i r s t r e a m e l e m e n t t ;</text>
<text top="150" left="110" width="91" height="11" font="3">t y p e d e f v o i d ∗</text>
<text top="151" left="261" width="125" height="11" font="3">s k i r k e r n e l p t r t ;</text>
<text top="179" left="110" width="40" height="11" font="3">e x t e r n</text>
<text top="179" left="161" width="126" height="11" font="3">s k i r k e r n e l p t r t ∗</text>
<text top="179" left="308" width="271" height="11" font="3">S K I R k e r n e l ( v o i d ∗ workfn , v o i d ∗ a r g s ) ;</text>
<text top="207" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="207" left="208" width="213" height="11" font="3">S K I R c a l l ( s k i r k e r n e l p t r t k ,</text>
<text top="207" left="433" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="207" left="562" width="39" height="11" font="3">i n s [ ] ,</text>
<text top="207" left="612" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="207" left="741" width="53" height="11" font="3">o u t s [ ] ) ;</text>
<text top="221" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="222" left="207" width="221" height="11" font="3">S K I R w a i t ( s k i r k e r n e l p t r t k ) ;</text>
<text top="236" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="236" left="206" width="237" height="11" font="3">S K I R b e c o m e ( s k i r k e r n e l p t r t k ) ;</text>
<text top="250" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="250" left="208" width="235" height="11" font="3">S K I R u n c a l l ( s k i r k e r n e l p t r t k ) ;</text>
<text top="278" left="110" width="40" height="11" font="3">e x t e r n</text>
<text top="278" left="161" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="278" left="300" width="171" height="11" font="3">S K I R s t r e a m ( u n s i g n e d i n t</text>
<text top="278" left="483" width="39" height="11" font="3">s i z e ) ;</text>
<text top="307" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="307" left="207" width="215" height="11" font="3">S K I R p u s h ( s k i r s t r e a m i d x t s ,</text>
<text top="307" left="433" width="175" height="11" font="3">s k i r s t r e a m e l e m e n t t e ) ;</text>
<text top="321" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="321" left="206" width="215" height="11" font="3">S K I R p o p ( s k i r s t r e a m i d x t s ,</text>
<text top="321" left="433" width="175" height="11" font="3">s k i r s t r e a m e l e m e n t t e ) ;</text>
<text top="335" left="110" width="76" height="11" font="3">e x t e r n v o i d</text>
<text top="335" left="207" width="215" height="11" font="3">S K I R p e e k ( s k i r s t r e a m i d x t s ,</text>
<text top="335" left="433" width="261" height="11" font="3">s k i r s t r e a m e l e m e n t t e , u n s i g n e d i n t</text>
<text top="335" left="706" width="53" height="11" font="3">o f f s e t ) ;</text>
<text top="377" left="190" width="538" height="16" font="0">Figure 4.1: SKIR C Intrinsics. Each C intrinsic maps to one SKIR intrinsic</text>
<text top="468" left="112" width="36" height="16" font="0">4.1.1</text>
<text top="468" left="182" width="68" height="16" font="0">Example</text>
<text top="517" left="151" width="659" height="16" font="0">An example program written using the SKIR C intrinsics is shown in Figure 4.2. This pro-</text>
<text top="553" left="108" width="702" height="16" font="0">gram reads an integer from the command line and uses it to initialize the state (cnt0 and cnt1)</text>
<text top="589" left="108" width="702" height="16" font="0">of two counter kernels. It then allocates 3 integer streams, in0, in1, and out. The streams in0</text>
<text top="625" left="108" width="702" height="16" font="0">and in1 are used as the outputs of two counter kernels src0 and src1, and as the two inputs</text>
<text top="661" left="108" width="702" height="16" font="0">of a single adder kernel, add. The adder kernel computes the sum of these inputs then pushes the</text>
<text top="697" left="108" width="702" height="16" font="0">result to the out stream. The stream out is the sole input of the kernel sink. This kernel simply</text>
<text top="732" left="108" width="115" height="16" font="0">prints its inputs.</text>
<text top="768" left="151" width="659" height="16" font="0">The work function for the counter kernels src0 and src1, named counter work, and</text>
<text top="804" left="108" width="702" height="16" font="0">the work function for the printer kernel sink, named int printer work, are not shown. In</text>
<text top="840" left="108" width="504" height="16" font="0">this example, they are found in the header ﬁle simple kernels.h.</text>
<text top="902" left="112" width="36" height="16" font="0">4.1.2</text>
<text top="902" left="182" width="123" height="16" font="0">Implementation</text>
<text top="951" left="151" width="659" height="16" font="0">Instead of implementing the C intrinsics as an extension to each front-end compiler we might</text>
<text top="987" left="108" width="702" height="16" font="0">want to use (e.g. llvm-gcc, llvm-g++, and clang), they are implemented as a LLVM com-</text>
<text top="1023" left="108" width="702" height="16" font="0">piler pass that can run from the command line. The pass recognizes the SKIR C intrinsics in</text>
<text top="1059" left="108" width="702" height="16" font="0">LLVM bitcode and translates them to the appropriate SKIR operations. Thus to compile a SKIR C</text>
</page>
<page number="57" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">43</text>
<text top="108" left="163" width="199" height="11" font="3"># i n c l u d e ” s k i r i n t r i n s i c s . h ”</text>
<text top="122" left="163" width="192" height="11" font="3"># i n c l u d e ” s i m p l e k e r n e l s . h ”</text>
<text top="150" left="164" width="147" height="11" font="3">i n t a d d w o r k ( v o i d ∗ s ,</text>
<text top="151" left="322" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="151" left="451" width="39" height="11" font="3">i n s [ ] ,</text>
<text top="151" left="502" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="151" left="630" width="46" height="11" font="3">o u t s [ ] )</text>
<text top="164" left="162" width="6" height="11" font="3">{</text>
<text top="179" left="193" width="68" height="11" font="3">i n t a , b , c ;</text>
<text top="193" left="203" width="114" height="11" font="3">S K I R p o p ( 0 , &amp;a ) ;</text>
<text top="207" left="203" width="114" height="11" font="3">S K I R p o p ( 1 , &amp;b ) ;</text>
<text top="222" left="192" width="69" height="11" font="3">c = a + b ;</text>
<text top="236" left="203" width="121" height="11" font="3">S K I R p u s h ( 0 , &amp;c ) ;</text>
<text top="250" left="192" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="263" left="162" width="6" height="11" font="3">}</text>
<text top="292" left="164" width="225" height="11" font="3">i n t main ( i n t a r g c , c h a r ∗ a r g v [ ] )</text>
<text top="306" left="162" width="6" height="11" font="3">{</text>
<text top="321" left="193" width="10" height="11" font="3">i f</text>
<text top="321" left="214" width="91" height="11" font="3">( a r g c ! = 2 ) {</text>
<text top="335" left="222" width="318" height="11" font="3">p r i n t f ( ” u s a g e : %s &lt;num s a m p l e s &gt;\n ” , a r g v [ 0 ] ) ;</text>
<text top="349" left="222" width="53" height="11" font="3">e x i t ( 0 ) ;</text>
<text top="363" left="191" width="6" height="11" font="3">}</text>
<text top="392" left="193" width="18" height="11" font="3">i n t</text>
<text top="392" left="221" width="139" height="11" font="3">c n t = a t o i ( a r g v [ 1 ] ) ;</text>
<text top="406" left="193" width="104" height="11" font="3">i n t c n t 0 = c n t ;</text>
<text top="420" left="193" width="104" height="11" font="3">i n t c n t 1 = c n t ;</text>
<text top="449" left="193" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="449" left="321" width="97" height="11" font="3">i n 0 , i n 1 , o u t ,</text>
<text top="449" left="429" width="46" height="11" font="3">i n s [ 3 ] ,</text>
<text top="449" left="487" width="53" height="11" font="3">o u t s [ 2 ] ;</text>
<text top="463" left="192" width="34" height="11" font="3">i n 0 =</text>
<text top="463" left="247" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="477" left="192" width="34" height="11" font="3">i n 1 =</text>
<text top="477" left="247" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="491" left="192" width="34" height="11" font="3">o u t =</text>
<text top="491" left="247" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="506" left="193" width="75" height="11" font="3">i n s [ 0 ] = 0 ;</text>
<text top="520" left="192" width="83" height="11" font="3">o u t s [ 1 ] = 0 ;</text>
<text top="548" left="193" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="548" left="322" width="41" height="11" font="3">s r c 0 =</text>
<text top="548" left="384" width="285" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) c o u n t e r w o r k , &amp;c n t 0 ) ;</text>
<text top="562" left="192" width="97" height="11" font="3">o u t s [ 0 ] = i n 0 ;</text>
<text top="576" left="205" width="106" height="11" font="3">S K I R c a l l ( s r c 0 ,</text>
<text top="576" left="321" width="25" height="11" font="3">i n s ,</text>
<text top="576" left="357" width="39" height="11" font="3">o u t s ) ;</text>
<text top="605" left="193" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="605" left="322" width="41" height="11" font="3">s r c 1 =</text>
<text top="605" left="384" width="285" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) c o u n t e r w o r k , &amp;c n t 1 ) ;</text>
<text top="619" left="192" width="97" height="11" font="3">o u t s [ 0 ] = i n 1 ;</text>
<text top="633" left="205" width="106" height="11" font="3">S K I R c a l l ( s r c 1 ,</text>
<text top="633" left="321" width="25" height="11" font="3">i n s ,</text>
<text top="633" left="357" width="39" height="11" font="3">o u t s ) ;</text>
<text top="662" left="193" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="662" left="321" width="35" height="11" font="3">add =</text>
<text top="662" left="376" width="200" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) a d d w o r k ,</text>
<text top="662" left="587" width="17" height="11" font="3">0 ) ;</text>
<text top="676" left="193" width="89" height="11" font="3">i n s [ 0 ] = i n 0 ;</text>
<text top="690" left="193" width="89" height="11" font="3">i n s [ 1 ] = i n 1 ;</text>
<text top="704" left="193" width="75" height="11" font="3">i n s [ 2 ] = 0 ;</text>
<text top="718" left="192" width="97" height="11" font="3">o u t s [ 0 ] = o u t ;</text>
<text top="733" left="205" width="99" height="11" font="3">S K I R c a l l ( add ,</text>
<text top="733" left="314" width="25" height="11" font="3">i n s ,</text>
<text top="733" left="350" width="39" height="11" font="3">o u t s ) ;</text>
<text top="761" left="193" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="761" left="322" width="41" height="11" font="3">s i n k =</text>
<text top="761" left="384" width="257" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) i n t p r i n t e r w o r k ,</text>
<text top="761" left="652" width="17" height="11" font="3">0 ) ;</text>
<text top="775" left="193" width="89" height="11" font="3">i n s [ 0 ] = o u t ;</text>
<text top="789" left="193" width="75" height="11" font="3">i n s [ 1 ] = 0 ;</text>
<text top="804" left="192" width="83" height="11" font="3">o u t s [ 0 ] = 0 ;</text>
<text top="818" left="205" width="106" height="11" font="3">S K I R c a l l ( s i n k ,</text>
<text top="818" left="321" width="25" height="11" font="3">i n s ,</text>
<text top="818" left="357" width="39" height="11" font="3">o u t s ) ;</text>
<text top="846" left="204" width="114" height="11" font="3">S K I R w a i t ( s i n k ) ;</text>
<text top="874" left="192" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="888" left="162" width="6" height="11" font="3">}</text>
<text top="930" left="108" width="702" height="16" font="0">Figure 4.2: A simple SKIR program constructed using C compiler intrinsics. This program creates</text>
<text top="952" left="108" width="472" height="16" font="0">two streams of integers, adds them together, then prints the result.</text>
<text top="1044" left="108" width="542" height="16" font="0">program to SKIR bitcode we can use the following sequence of commands:</text>
</page>
<page number="58" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">44</text>
<text top="130" left="187" width="471" height="13" font="4">$ llvm-gcc -O2 -emit-llvm -c -o input.bc input.c</text>
<text top="150" left="187" width="481" height="13" font="4">$ opt -skir-c-to-intr &lt; input.bc &gt; output-skir.bc</text>
<text top="199" left="151" width="659" height="16" font="0">The program llvm-gcc is the LLVM version of the GCC C front-end which knows how to</text>
<text top="235" left="108" width="702" height="16" font="0">emit LLVM bitcode. The program opt is the LLVM command line code optimizer. The command</text>
<text top="271" left="108" width="702" height="16" font="0">line option -skir-c-to-intr tells opt to run the C intrinsic to SKIR intrinsic transformation</text>
<text top="307" left="108" width="702" height="16" font="0">pass. This sequence of commands is easily wrapped in a shell script, resulting in SKIR compilers</text>
<text top="343" left="108" width="468" height="16" font="0">called skircc and skir++ for compiling SKIR C and SKIR C</text>
<text top="342" left="574" width="17" height="13" font="1">++</text>
<text top="343" left="596" width="166" height="16" font="0">programs, respectively.</text>
<text top="404" left="112" width="36" height="16" font="0">4.1.3</text>
<text top="404" left="182" width="81" height="16" font="0">Discussion</text>
<text top="452" left="151" width="659" height="16" font="0">Despite the inconvenience of using compiler intrinsics and the verbosity of the resulting</text>
<text top="488" left="108" width="702" height="16" font="0">code, the SKIR C intrinsics have proven to be quite useful for producing high performance stream</text>
<text top="524" left="108" width="702" height="16" font="0">parallel programs. This is largely because of the abstractions provided by the SKIR operations that</text>
<text top="560" left="108" width="702" height="16" font="0">the SKIR C intrinsics represent. For comparison, imagine the amount of code that would need to</text>
<text top="596" left="108" width="702" height="16" font="0">be written to implement the program in Figure 4.2 using traditional concurrency mechanisms in C.</text>
<text top="632" left="108" width="702" height="16" font="0">The programmer would ﬁrst have to come up with a scheduling scheme to execute the kernels using</text>
<text top="668" left="108" width="702" height="16" font="0">a single thread or multiple threads. If multithreaded execution was desired, the programmer would</text>
<text top="704" left="108" width="702" height="16" font="0">then have to choose an implementation technology for threading, implement the communication</text>
<text top="740" left="108" width="702" height="16" font="0">mechanism, then hook it all together and test it. The stream parallel abstractions in SKIR provide</text>
<text top="776" left="108" width="177" height="16" font="0">all of these things for us.</text>
<text top="833" left="112" width="22" height="16" font="0">4.2</text>
<text top="833" left="170" width="126" height="16" font="0">User Library: C</text>
<text top="833" left="294" width="17" height="13" font="1">++</text>
<text top="888" left="151" width="659" height="16" font="0">It is not uncommon to for high level user libraries and frameworks to provide functionality</text>
<text top="924" left="108" width="702" height="16" font="0">similar to the abstractions provided by SKIR. Such systems often provide runtime code scheduling</text>
<text top="960" left="108" width="702" height="16" font="0">abstractions as well communication abstractions. Examples are the FastFlow, FDP, DoPE, and</text>
<text top="996" left="108" width="270" height="16" font="0">GNU Radio systems, all written in C</text>
<text top="995" left="376" width="17" height="13" font="1">++</text>
<text top="996" left="398" width="412" height="16" font="0">[19][49][51][4]. The main difference between SKIR and</text>
<text top="1032" left="108" width="702" height="16" font="0">these systems is that SKIR is a compiler level representation which allows for code transformation</text>
<text top="1068" left="108" width="702" height="16" font="0">and optimization speciﬁc to the stream parallel model. The other systems provide only runtime</text>
</page>
<page number="59" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">45</text>
<text top="128" left="108" width="702" height="16" font="0">scheduling and communication abstractions and do not allow for stream parallel code transforma-</text>
<text top="164" left="108" width="702" height="16" font="0">tion. Nevertheless, if it is not possible to build such frameworks in high level languages on top of</text>
<text top="200" left="108" width="702" height="16" font="0">SKIR, then its usefulness is reduced. In this section, we show how to build such a framework in</text>
<text top="236" left="108" width="38" height="16" font="0">the C</text>
<text top="236" left="144" width="17" height="13" font="1">++</text>
<text top="236" left="165" width="645" height="16" font="0">language using the SKIR abstractions. The example framework is a simple object oriented</text>
<text top="272" left="108" width="351" height="16" font="0">user library built on top of the SKIR C intrinsics.</text>
<text top="334" left="112" width="36" height="16" font="0">4.2.1</text>
<text top="334" left="182" width="68" height="16" font="0">Example</text>
<text top="382" left="151" width="242" height="16" font="0">An example program using the C</text>
<text top="382" left="391" width="17" height="13" font="1">++</text>
<text top="382" left="413" width="397" height="16" font="0">user library is shown in Figure 4.3. This program con-</text>
<text top="418" left="108" width="702" height="16" font="0">structs and executes a three stage pipeline. There are three classes deﬁned in the program, Adder,</text>
<text top="455" left="108" width="97" height="14" font="0">IntSource</text>
<text top="454" left="205" width="605" height="16" font="0">, and IntSink. Each class represents one type of kernel and contains one kernel</text>
<text top="490" left="108" width="702" height="16" font="0">work function, a static member function named work. In addition, the kernels encapsulate their</text>
<text top="526" left="108" width="326" height="16" font="0">own state as private data ﬁelds. Using the C</text>
<text top="526" left="432" width="17" height="13" font="1">++</text>
<text top="526" left="455" width="355" height="16" font="0">library, the pieces of a stream graph can be con-</text>
<text top="562" left="108" width="357" height="16" font="0">structed procedurally in the typical SKIR fashion:</text>
<text top="604" left="147" width="157" height="13" font="4">StreamVector s0;</text>
<text top="624" left="147" width="157" height="13" font="4">StreamVector s1;</text>
<text top="645" left="147" width="167" height="13" font="4">StreamVector nul;</text>
<text top="685" left="147" width="295" height="13" font="4">s0.push_back(new Stream&lt;int&gt;);</text>
<text top="706" left="147" width="295" height="13" font="4">s1.push_back(new Stream&lt;int&gt;);</text>
<text top="746" left="147" width="88" height="13" font="4">IntSource</text>
<text top="749" left="255" width="245" height="13" font="4">*src = new IntSource(10);</text>
<text top="767" left="147" width="49" height="13" font="4">Adder</text>
<text top="769" left="255" width="196" height="13" font="4">*inc = new Adder(1);</text>
<text top="787" left="147" width="324" height="15" font="4">IntPrinter *snk = new IntPrinter;</text>
<text top="840" left="108" width="702" height="16" font="0">In this code, two new int streams are allocated and added to vectors called StreamVectors.</text>
<text top="876" left="108" width="702" height="16" font="0">These vectors are analogous to the null terminated arrays used in the skir.call operation. After</text>
<text top="912" left="108" width="702" height="16" font="0">adding the streams to the vectors, an instance of each of the kernel types is created. The only thing</text>
<text top="948" left="108" width="326" height="16" font="0">that remains is to execute each of the kernels:</text>
<text top="990" left="147" width="157" height="15" font="4">(*src)(nul, s0);</text>
<text top="1010" left="147" width="98" height="15" font="4">(*inc)(s0,</text>
<text top="1010" left="265" width="39" height="13" font="4">s1);</text>
<text top="1031" left="147" width="157" height="15" font="4">(*snk)(s1, nul);</text>
</page>
<page number="60" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">46</text>
<text top="125" left="190" width="137" height="11" font="3"># i n c l u d e &lt;i o s t r e a m &gt;</text>
<text top="139" left="190" width="135" height="11" font="3"># i n c l u d e ” SKIR . hpp ”</text>
<text top="167" left="190" width="147" height="11" font="3">u s i n g namespace s k i r ;</text>
<text top="196" left="191" width="256" height="11" font="3">c l a s s Adder : p u b l i c K e r n e l &lt;Adder&gt; {</text>
<text top="210" left="191" width="54" height="11" font="3">p r i v a t e :</text>
<text top="224" left="220" width="39" height="11" font="3">i n t a ;</text>
<text top="238" left="191" width="47" height="11" font="3">p u b l i c :</text>
<text top="253" left="219" width="62" height="11" font="3">Adder ( i n t</text>
<text top="253" left="297" width="12" height="11" font="3">a )</text>
<text top="253" left="320" width="69" height="11" font="3">: a ( a ) {}</text>
<text top="267" left="220" width="39" height="11" font="3">s t a t i c</text>
<text top="267" left="270" width="132" height="11" font="3">i n t work ( Adder ∗me ,</text>
<text top="267" left="413" width="118" height="11" font="3">I n p u t S t r e a m s i n s ,</text>
<text top="267" left="542" width="149" height="11" font="3">O u t p u t S t r e a m s o u t s ) {</text>
<text top="281" left="248" width="154" height="11" font="3">S t r e a m&lt;i n t &gt; i n ( i n s , 0 ) ;</text>
<text top="295" left="248" width="169" height="11" font="3">S t r e a m&lt;i n t &gt; o u t ( o u t s , 0 ) ;</text>
<text top="309" left="248" width="18" height="11" font="3">i n t</text>
<text top="309" left="277" width="89" height="11" font="3">i = i n . pop ( ) ;</text>
<text top="323" left="248" width="140" height="11" font="3">o u t . p u s h ( i + me−&gt;a ) ;</text>
<text top="338" left="248" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="351" left="218" width="6" height="11" font="3">}</text>
<text top="365" left="191" width="11" height="12" font="3">} ;</text>
<text top="394" left="191" width="32" height="11" font="3">c l a s s</text>
<text top="394" left="234" width="61" height="11" font="3">I n t S o u r c e</text>
<text top="394" left="306" width="199" height="11" font="3">: p u b l i c K e r n e l &lt;I n t S o u r c e &gt; {</text>
<text top="409" left="220" width="68" height="11" font="3">i n t c o u n t ;</text>
<text top="423" left="191" width="47" height="11" font="3">p u b l i c :</text>
<text top="437" left="220" width="90" height="11" font="3">I n t S o u r c e ( i n t</text>
<text top="437" left="320" width="11" height="11" font="3">i )</text>
<text top="437" left="342" width="91" height="11" font="3">: c o u n t ( i ) {}</text>
<text top="451" left="220" width="39" height="11" font="3">s t a t i c</text>
<text top="451" left="270" width="161" height="11" font="3">i n t work ( I n t S o u r c e ∗me ,</text>
<text top="451" left="442" width="118" height="11" font="3">I n p u t S t r e a m s i n s ,</text>
<text top="451" left="571" width="149" height="11" font="3">O u t p u t S t r e a m s o u t s ) {</text>
<text top="465" left="248" width="169" height="11" font="3">S t r e a m&lt;i n t &gt; o u t ( o u t s , 0 ) ;</text>
<text top="480" left="248" width="26" height="11" font="3">b o o l</text>
<text top="480" left="284" width="161" height="11" font="3">r e t = ( me−&gt;c o u n t &lt;= 0 ) ;</text>
<text top="494" left="249" width="10" height="11" font="3">i f</text>
<text top="494" left="270" width="55" height="11" font="3">( ! r e t ) {</text>
<text top="508" left="277" width="140" height="11" font="3">o u t . p u s h ( me−&gt;c o u n t ) ;</text>
<text top="522" left="275" width="86" height="11" font="3">me−&gt;c o u n t −−;</text>
<text top="536" left="247" width="6" height="11" font="3">}</text>
<text top="551" left="248" width="40" height="11" font="3">r e t u r n</text>
<text top="551" left="299" width="25" height="11" font="3">r e t ;</text>
<text top="564" left="218" width="6" height="11" font="3">}</text>
<text top="578" left="191" width="11" height="12" font="3">} ;</text>
<text top="607" left="191" width="32" height="11" font="3">c l a s s</text>
<text top="607" left="234" width="46" height="11" font="3">I n t S i n k</text>
<text top="607" left="291" width="3" height="11" font="3">:</text>
<text top="607" left="305" width="170" height="11" font="3">p u b l i c K e r n e l &lt;I n t S i n k &gt; {</text>
<text top="621" left="220" width="54" height="11" font="3">i n t sum ;</text>
<text top="636" left="191" width="47" height="11" font="3">p u b l i c :</text>
<text top="650" left="220" width="39" height="11" font="3">s t a t i c</text>
<text top="650" left="270" width="168" height="11" font="3">i n t work ( I n t P r i n t e r ∗me ,</text>
<text top="650" left="449" width="118" height="11" font="3">I n p u t S t r e a m s i n s ,</text>
<text top="650" left="578" width="149" height="11" font="3">O u t p u t S t r e a m s o u t s ) {</text>
<text top="664" left="248" width="154" height="11" font="3">S t r e a m&lt;i n t &gt; i n ( i n s , 0 ) ;</text>
<text top="678" left="247" width="112" height="11" font="3">sum += i n . pop ( ) ;</text>
<text top="692" left="248" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="706" left="218" width="6" height="11" font="3">}</text>
<text top="720" left="191" width="11" height="12" font="3">} ;</text>
<text top="749" left="191" width="234" height="11" font="3">i n t main ( i n t a r g c , c h a r ∗∗ a r g v ) {</text>
<text top="764" left="219" width="111" height="11" font="3">S t r e a m V e c t o r s 0 ;</text>
<text top="778" left="219" width="111" height="11" font="3">S t r e a m V e c t o r s 1 ;</text>
<text top="792" left="219" width="118" height="11" font="3">S t r e a m V e c t o r n u l ;</text>
<text top="820" left="219" width="213" height="11" font="3">s 0 . p u s h b a c k ( new S t r e a m&lt;i n t &gt; ) ;</text>
<text top="835" left="219" width="213" height="11" font="3">s 1 . p u s h b a c k ( new S t r e a m&lt;i n t &gt; ) ;</text>
<text top="863" left="220" width="61" height="11" font="3">I n t S o u r c e</text>
<text top="862" left="297" width="177" height="12" font="3">∗ s r c = new I n t S o u r c e ( 1 0 ) ;</text>
<text top="877" left="219" width="34" height="11" font="3">Adder</text>
<text top="876" left="297" width="141" height="12" font="3">∗ i n c = new Adder ( 1 ) ;</text>
<text top="891" left="220" width="232" height="11" font="3">I n t P r i n t e r ∗ s n k = new I n t P r i n t e r ;</text>
<text top="920" left="219" width="111" height="11" font="3">( ∗ s r c ) ( n u l , s 0 ) ;</text>
<text top="934" left="219" width="68" height="11" font="3">( ∗ i n c ) ( s0 ,</text>
<text top="934" left="305" width="25" height="11" font="3">s 1 ) ;</text>
<text top="948" left="219" width="68" height="11" font="3">( ∗ s n k ) ( s1 ,</text>
<text top="948" left="298" width="32" height="11" font="3">n u l ) ;</text>
<text top="977" left="219" width="83" height="11" font="3">snk−&gt;w a i t ( ) ;</text>
<text top="990" left="189" width="6" height="11" font="3">}</text>
<text top="1032" left="131" width="265" height="16" font="0">Figure 4.3: An example of a SKIR C</text>
<text top="1032" left="394" width="17" height="13" font="1">++</text>
<text top="1032" left="416" width="147" height="16" font="0">program using the C</text>
<text top="1032" left="561" width="17" height="13" font="1">++</text>
<text top="1032" left="582" width="204" height="16" font="0">user library from Figure 4.4.</text>
</page>
<page number="61" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">47</text>
<text top="128" left="108" width="706" height="16" font="0">Here the kernel objects are spawned for execution using a functor interface. The StreamVectors</text>
<text top="164" left="108" width="702" height="16" font="0">describe the edges in the stream graph. The program then blocks the main thread until snk is ﬁn-</text>
<text top="200" left="108" width="530" height="16" font="0">ished, to avoid returning from main before the stream graph has ﬁnished:</text>
<text top="242" left="147" width="118" height="13" font="4">snk-&gt;wait();</text>
<text top="295" left="151" width="659" height="16" font="0">Each of the work functions deﬁned in the three kernel objects have a typical kernel work</text>
<text top="331" left="108" width="702" height="16" font="0">function structure. Inside of the kernel work function, streams are accessed by ﬁrst naming each</text>
<text top="367" left="108" width="350" height="16" font="0">of the input and output streams that will be used:</text>
<text top="409" left="147" width="255" height="15" font="4">static int work(Adder *me,</text>
<text top="429" left="304" width="363" height="13" font="4">InputStreams ins, OutputStreams outs)</text>
<text top="450" left="147" width="10" height="13" font="4">{</text>
<text top="470" left="187" width="216" height="13" font="4">Stream&lt;int&gt; in(ins,0);</text>
<text top="490" left="187" width="236" height="13" font="4">Stream&lt;int&gt; out(outs,0);</text>
<text top="544" left="108" width="702" height="16" font="0">Here the code assigns the name in to the ﬁrst input stream (i.e. index 0) and the name out to the</text>
<text top="580" left="108" width="702" height="16" font="0">ﬁrst output stream. It also declares the types of the streams. The Stream class provides push,</text>
<text top="617" left="108" width="32" height="14" font="0">pop</text>
<text top="616" left="140" width="593" height="16" font="0">, and peek member functions, allowing for the usual SKIR operations on streams:</text>
<text top="657" left="187" width="167" height="13" font="4">int i = in.pop();</text>
<text top="678" left="187" width="196" height="13" font="4">out.push(i + me-&gt;a);</text>
<text top="698" left="187" width="88" height="13" font="4">return 0;</text>
<text top="718" left="147" width="10" height="13" font="4">}</text>
<text top="772" left="108" width="702" height="16" font="0">The other two kernel in the program, IntSource and IntSink, are deﬁned in a similar manner.</text>
<text top="834" left="112" width="36" height="16" font="0">4.2.2</text>
<text top="834" left="182" width="123" height="16" font="0">Implementation</text>
<text top="882" left="151" width="320" height="16" font="0">The complete implementation of the SKIR C</text>
<text top="881" left="470" width="17" height="13" font="1">++</text>
<text top="882" left="491" width="319" height="16" font="0">library is shown in Figure 4.4. As mentioned</text>
<text top="918" left="108" width="702" height="16" font="0">above, it implements stream parallel constructs using the SKIR intrinsics. We brieﬂy describe its</text>
<text top="954" left="108" width="176" height="16" font="0">operation in this section.</text>
<text top="990" left="151" width="659" height="16" font="0">User kernels are deﬁned by deriving a class from the Kernel base class. This class provides</text>
<text top="1026" left="108" width="715" height="16" font="0">the functionality of three SKIR kernel operations, skir.kernel, skir.call, and skir.wait.</text>
<text top="1062" left="108" width="702" height="16" font="0">The SKIR skir.kernel operation is executed in Kernel’s constructor function. Because the</text>
</page>
<page number="62" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="9" size="6" family="Times" color="#000000"/>
<text top="85" left="792" width="18" height="16" font="0">48</text>
<text top="113" left="244" width="64" height="8" font="9">e x t e r n ”C” {</text>
<text top="124" left="243" width="149" height="8" font="9"># i n c l u d e ” s k i r i n t r i n s i c s . h ”</text>
<text top="134" left="243" width="6" height="8" font="9">}</text>
<text top="155" left="244" width="35" height="8" font="9">t y p e d e f</text>
<text top="155" left="288" width="110" height="8" font="9">s k i r s t r e a m e l e m e n t t</text>
<text top="155" left="405" width="73" height="8" font="9">S t r e a m E l e m e n t ;</text>
<text top="166" left="244" width="35" height="8" font="9">t y p e d e f</text>
<text top="166" left="288" width="88" height="8" font="9">s k i r s t r e a m p t r t</text>
<text top="166" left="406" width="51" height="8" font="9">S t r e a m P t r ;</text>
<text top="176" left="244" width="35" height="8" font="9">t y p e d e f</text>
<text top="176" left="288" width="88" height="8" font="9">s k i r k e r n e l p t r t</text>
<text top="176" left="406" width="51" height="8" font="9">K e r n e l P t r ;</text>
<text top="187" left="244" width="170" height="8" font="9">t y p e d e f S t r e a m P t r ∗ I n p u t S t r e a m s ;</text>
<text top="197" left="244" width="175" height="8" font="9">t y p e d e f S t r e a m P t r ∗ O u t p u t S t r e a m s ;</text>
<text top="218" left="244" width="96" height="8" font="9">c l a s s S t r e a m B a s e {</text>
<text top="228" left="244" width="40" height="8" font="9">p r i v a t e :</text>
<text top="239" left="266" width="89" height="8" font="9">S t r e a m P t r s t r e a m ;</text>
<text top="249" left="266" width="13" height="8" font="9">i n t</text>
<text top="249" left="288" width="35" height="8" font="9">o f f s e t ;</text>
<text top="260" left="244" width="35" height="8" font="9">p u b l i c :</text>
<text top="270" left="266" width="73" height="8" font="9">S t r e a m B a s e ( i n t</text>
<text top="270" left="347" width="36" height="8" font="9">s i z e ) {</text>
<text top="281" left="287" width="42" height="8" font="9">s t r e a m =</text>
<text top="281" left="344" width="96" height="8" font="9">S K I R s t r e a m ( s i z e ) ;</text>
<text top="291" left="264" width="6" height="8" font="9">}</text>
<text top="302" left="266" width="143" height="8" font="9">S t r e a m B a s e ( S t r e a m P t r ∗ , i n t</text>
<text top="302" left="417" width="19" height="8" font="9">i ) :</text>
<text top="302" left="444" width="63" height="8" font="9">o f f s e t ( i ) {}</text>
<text top="312" left="266" width="29" height="8" font="9">i n l i n e</text>
<text top="312" left="304" width="13" height="8" font="9">i n t</text>
<text top="312" left="325" width="105" height="8" font="9">g e t O f f s e t ( ) { r e t u r n</text>
<text top="312" left="438" width="47" height="8" font="9">o f f s e t ; }</text>
<text top="323" left="266" width="29" height="8" font="9">i n l i n e</text>
<text top="323" left="303" width="214" height="8" font="9">S t r e a m P t r g e t S t r e a m ( ) { r e t u r n s t r e a m ; }</text>
<text top="333" left="244" width="9" height="9" font="9">};</text>
<text top="354" left="244" width="245" height="8" font="9">t y p e d e f s t d : : v e c t o r &lt;S t r e a m B a s e∗&gt; S t r e a m V e c t o r ;</text>
<text top="375" left="244" width="284" height="8" font="9">t e m p l a t e &lt;c l a s s T&gt; c l a s s S t r e a m : p u b l i c S t r e a m B a s e {</text>
<text top="385" left="244" width="35" height="8" font="9">p u b l i c :</text>
<text top="396" left="266" width="40" height="8" font="9">S t r e a m ( )</text>
<text top="396" left="314" width="139" height="8" font="9">: S t r e a m B a s e ( s i z e o f ( T ) ) {}</text>
<text top="406" left="266" width="105" height="8" font="9">S t r e a m ( S t r e a m P t r ∗p ,</text>
<text top="406" left="379" width="13" height="8" font="9">i n t</text>
<text top="406" left="400" width="8" height="8" font="9">i )</text>
<text top="406" left="417" width="106" height="8" font="9">: S t r e a m B a s e ( p , i ) {}</text>
<text top="427" left="266" width="122" height="8" font="9">i n l i n e v o i d p u s h ( T t ) {</text>
<text top="438" left="287" width="67" height="8" font="9">v o i d ∗p = &amp;t ;</text>
<text top="448" left="296" width="139" height="8" font="9">S K I R p u s h ( g e t O f f s e t ( ) , p ) ;</text>
<text top="458" left="264" width="6" height="8" font="9">}</text>
<text top="469" left="266" width="85" height="8" font="9">i n l i n e T pop ( ) {</text>
<text top="480" left="286" width="20" height="8" font="9">T t ;</text>
<text top="490" left="287" width="67" height="8" font="9">v o i d ∗p = &amp;t ;</text>
<text top="501" left="295" width="134" height="8" font="9">S K I R p o p ( g e t O f f s e t ( ) , p ) ;</text>
<text top="511" left="287" width="46" height="8" font="9">r e t u r n t ;</text>
<text top="521" left="264" width="6" height="8" font="9">}</text>
<text top="532" left="266" width="117" height="8" font="9">i n l i n e T p e e k ( i n t o ) {</text>
<text top="542" left="286" width="20" height="8" font="9">T t ;</text>
<text top="553" left="287" width="67" height="8" font="9">v o i d ∗p = &amp;t ;</text>
<text top="563" left="296" width="156" height="8" font="9">S K I R p e e k ( g e t O f f s e t ( ) , p , o ) ;</text>
<text top="574" left="287" width="46" height="8" font="9">r e t u r n t ;</text>
<text top="584" left="264" width="6" height="8" font="9">}</text>
<text top="594" left="244" width="9" height="9" font="9">};</text>
<text top="616" left="244" width="177" height="8" font="9">t e m p l a t e &lt;c l a s s D&gt; c l a s s K e r n e l {</text>
<text top="626" left="244" width="40" height="8" font="9">p r i v a t e :</text>
<text top="637" left="266" width="46" height="8" font="9">K e r n e l P t r</text>
<text top="637" left="320" width="35" height="8" font="9">k e r n e l ;</text>
<text top="647" left="244" width="35" height="8" font="9">p u b l i c :</text>
<text top="658" left="266" width="7" height="8" font="9">/ /</text>
<text top="658" left="282" width="67" height="8" font="9">c a l l a k e r n e l</text>
<text top="668" left="266" width="365" height="8" font="9">v o i d o p e r a t o r ( ) ( c o n s t S t r e a m V e c t o r&amp; i n s , c o n s t S t r e a m V e c t o r&amp; o u t s ) {</text>
<text top="678" left="287" width="62" height="8" font="9">u n s i g n e d i n t</text>
<text top="678" left="357" width="8" height="8" font="9">i ;</text>
<text top="699" left="287" width="53" height="8" font="9">S t r e a m P t r ∗</text>
<text top="699" left="352" width="180" height="8" font="9">i n s = new S t r e a m P t r [ i n s . s i z e ( ) + 1 ] ;</text>
<text top="710" left="287" width="121" height="8" font="9">f o r ( i = 0 ; i&lt;i n s . s i z e ( ) ;</text>
<text top="710" left="417" width="31" height="8" font="9">i ++) {</text>
<text top="720" left="314" width="153" height="8" font="9">i n s [ i ] = i n s [ i]−&gt;g e t S t r e a m ( ) ;</text>
<text top="730" left="286" width="6" height="8" font="9">}</text>
<text top="741" left="292" width="57" height="8" font="9">i n s [ i ] = 0 ;</text>
<text top="762" left="287" width="53" height="8" font="9">S t r e a m P t r ∗</text>
<text top="762" left="351" width="191" height="8" font="9">o u t s = new S t r e a m P t r [ o u t s . s i z e ( ) + 1 ] ;</text>
<text top="772" left="287" width="126" height="8" font="9">f o r ( i = 0 ; i&lt;o u t s . s i z e ( ) ;</text>
<text top="773" left="422" width="31" height="8" font="9">i ++) {</text>
<text top="783" left="314" width="164" height="8" font="9">o u t s [ i ] = o u t s [ i]−&gt;g e t S t r e a m ( ) ;</text>
<text top="793" left="286" width="6" height="8" font="9">}</text>
<text top="804" left="292" width="63" height="8" font="9">o u t s [ i ] = 0 ;</text>
<text top="825" left="297" width="90" height="8" font="9">S K I R c a l l ( k e r n e l ,</text>
<text top="825" left="399" width="19" height="8" font="9">i n s ,</text>
<text top="825" left="432" width="30" height="8" font="9">o u t s ) ;</text>
<text top="846" left="287" width="40" height="8" font="9">d e l e t e [ ]</text>
<text top="846" left="341" width="19" height="8" font="9">i n s ;</text>
<text top="856" left="287" width="40" height="8" font="9">d e l e t e [ ]</text>
<text top="856" left="341" width="25" height="8" font="9">o u t s ;</text>
<text top="866" left="264" width="6" height="8" font="9">}</text>
<text top="887" left="266" width="29" height="8" font="9">s t a t i c</text>
<text top="887" left="304" width="88" height="8" font="9">i n t work ( v o i d ∗s ,</text>
<text top="888" left="400" width="46" height="8" font="9">S t r e a m P t r</text>
<text top="888" left="454" width="29" height="8" font="9">i n s [ ] ,</text>
<text top="888" left="492" width="101" height="8" font="9">S t r e a m P t r o u t s [ ] ) {</text>
<text top="898" left="288" width="99" height="8" font="9">a s s e r t ( 0 &amp;&amp; ” e r r o r :</text>
<text top="898" left="395" width="29" height="8" font="9">c a l l e d</text>
<text top="898" left="432" width="83" height="8" font="9">K e r n e l : : work ! ” ) ;</text>
<text top="908" left="287" width="46" height="8" font="9">r e t u r n 0 ;</text>
<text top="918" left="264" width="6" height="8" font="9">}</text>
<text top="940" left="266" width="69" height="8" font="9">v o i d w a i t ( ) {</text>
<text top="940" left="350" width="109" height="8" font="9">S K I R w a i t ( k e r n e l ) ; }</text>
<text top="961" left="266" width="122" height="8" font="9">K e r n e l ( v o i d ) { k e r n e l =</text>
<text top="961" left="404" width="161" height="8" font="9">S K I R k e r n e l ( ( v o i d ∗)(&amp;D : : work ) ,</text>
<text top="961" left="573" width="42" height="8" font="9">t h i s ) ; }</text>
<text top="971" left="266" width="155" height="8" font="9">˜ K e r n e l ( v o i d ) { k e r n e l = 0 ; }</text>
<text top="981" left="244" width="9" height="9" font="9">};</text>
<text top="1021" left="108" width="227" height="16" font="0">Figure 4.4: An example of a C</text>
<text top="1021" left="333" width="17" height="13" font="1">++</text>
<text top="1021" left="356" width="454" height="16" font="0">library providing an object oriented interface for stream paral-</text>
<text top="1043" left="108" width="250" height="16" font="0">lelism using the SKIR C intrinsics.</text>
</page>
<page number="63" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">49</text>
<text top="129" left="108" width="118" height="14" font="0">skir.kernel</text>
<text top="128" left="233" width="577" height="16" font="0">operation requires the address of the derived class’s work function, the library</text>
<text top="164" left="108" width="702" height="16" font="0">makes use of static polymorphism. This is the reason that the derived kernel object must provide</text>
<text top="200" left="108" width="702" height="16" font="0">itself as a template argument to the Kernel base class. This is also the reason why the work</text>
<text top="236" left="108" width="702" height="16" font="0">function in the derived class is made static. The result of the skir.kernel operation is</text>
<text top="272" left="108" width="702" height="16" font="0">encapsulated by the Kernel class. This is used in the wait method, which wraps skir.wait,</text>
<text top="308" left="108" width="702" height="16" font="0">and in the operator() method, which wraps skir.call. The operator() method also re-</text>
<text top="344" left="108" width="702" height="16" font="0">ceives two StreamVectors as arguments. The method unwraps the SKIR stream objects stored</text>
<text top="380" left="108" width="460" height="16" font="0">in these vectors, and passes them to the skir.call operation.</text>
<text top="417" left="151" width="140" height="14" font="0">StreamVectors</text>
<text top="416" left="298" width="512" height="18" font="0">are deﬁned as std::vector&lt;StreamBase*&gt;. StreamBase is</text>
<text top="452" left="108" width="702" height="16" font="0">used to call the skir.stream operation (in its constructor) and to store the stream index in-</text>
<text top="488" left="108" width="702" height="16" font="0">formation used by Kernel::operator(). Derived from StreamBase is the Stream class</text>
<text top="524" left="108" width="702" height="16" font="0">that is used directly by user programs. This class extends StreamBase with type information</text>
<text top="560" left="108" width="506" height="16" font="0">and with the implementation of the pop, peek, and push operations.</text>
<text top="596" left="151" width="659" height="16" font="0">The Stream class constructor is overloaded so that the class can be used in two different</text>
<text top="632" left="108" width="702" height="16" font="0">places by programs. The ﬁrst place Stream objects get used is during stream graph construction.</text>
<text top="668" left="108" width="702" height="16" font="0">In this use case, the constructor takes no parameters. The object itself is parameterized using the</text>
<text top="704" left="108" width="702" height="16" font="0">type of data stored in the stream as an argument to the Stream class template. The sizeof this</text>
<text top="740" left="108" width="702" height="16" font="0">type is taken to pass as an argument to the skir.stream operation. The other use of Stream</text>
<text top="776" left="108" width="702" height="16" font="0">objects in user programs is to get a handle on input and output streams inside of the kernel work</text>
<text top="812" left="108" width="702" height="16" font="0">function. In this case the object is constructed taking two parameters. The ﬁrst parameter is</text>
<text top="848" left="108" width="702" height="16" font="0">the StreamVector of input or output streams the desired stream is contained in. The second</text>
<text top="884" left="108" width="642" height="16" font="0">parameter is the index of the desired stream in the given vector. This ensures that writing,</text>
<text top="921" left="194" width="237" height="14" font="0">Stream&lt;int&gt; in(ins,0);</text>
<text top="943" left="194" width="183" height="14" font="0">int i = in.pop();</text>
<text top="993" left="108" width="82" height="16" font="0">using the C</text>
<text top="992" left="188" width="17" height="13" font="1">++</text>
<text top="993" left="209" width="334" height="16" font="0">library compiles into SKIR code equivalent to,</text>
<text top="1035" left="194" width="54" height="14" font="0">int i</text>
<text top="1057" left="194" width="161" height="14" font="0">skir.pop(0, &amp;i)</text>
</page>
<page number="64" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">50</text>
<text top="128" left="112" width="22" height="16" font="0">4.3</text>
<text top="128" left="170" width="297" height="16" font="0">Stream Language Front-end: StreamIt</text>
<text top="183" left="151" width="659" height="16" font="0">StreamIt has in recent years become the most popular stream processing language for re-</text>
<text top="219" left="108" width="702" height="16" font="0">search of stream parallelism [33][36][37][38][54]. It is obvious that a compiler level representation</text>
<text top="255" left="108" width="702" height="16" font="0">like SKIR should be able to represent StreamIt style programs. StreamIt is supported in the SKIR</text>
<text top="291" left="108" width="702" height="16" font="0">environment with a StreamIt to SKIR front-end compiler. This compiler takes StreamIt programs</text>
<text top="327" left="108" width="333" height="16" font="0">as input and produces SKIR bitcode as output.</text>
<text top="363" left="151" width="659" height="16" font="0">An example StreamIt program is shown in Figure 4.5. The program in this ﬁgure is a simple</text>
<text top="399" left="108" width="702" height="16" font="0">three stage pipeline. The IntSource ﬁlter produces integers starting with zero, the Adder</text>
<text top="435" left="108" width="702" height="16" font="0">kernel adds three to its input, and the IntPrinter kernel prints its input. The three kernels are</text>
<text top="471" left="108" width="702" height="16" font="0">connected together into a pipeline in Main. This section describes how this program is compiled</text>
<text top="507" left="108" width="402" height="16" font="0">to SKIR using the StreamIt to SKIR front-end compiler.</text>
<text top="542" left="151" width="659" height="16" font="0">Lexing and parsing of the StreamIt language is accomplished by directly porting the ANTLR</text>
<text top="578" left="108" width="346" height="16" font="0">parser from the StreamIt project from Java to C</text>
<text top="578" left="452" width="17" height="13" font="1">++</text>
<text top="578" left="474" width="336" height="16" font="0">. ANTLR includes support for both languages</text>
<text top="614" left="108" width="702" height="16" font="0">so this is a straightforward porting process. In the StreamIt compiler this parser generates an in-</text>
<text top="650" left="108" width="702" height="16" font="0">termediate representation known as the FEIR, or Front-End IR, which is simply an object oriented</text>
<text top="686" left="108" width="702" height="16" font="0">representation of the StreamIt abstract syntax tree. In the original StreamIt compiler this is a Java</text>
<text top="722" left="108" width="617" height="16" font="0">based representation. The StreamIt to SKIR compiler implements the same FEIR in C</text>
<text top="722" left="723" width="17" height="13" font="1">++</text>
<text top="722" left="745" width="4" height="16" font="0">.</text>
<text top="758" left="151" width="659" height="16" font="0">After generating the FEIR for a StreamIt program, the main task of the StreamIt to SKIR</text>
<text top="794" left="108" width="702" height="16" font="0">compiler is to translate the FEIR into LLVM and SKIR bitcode implementing the program. This is</text>
<text top="830" left="108" width="702" height="16" font="0">done as a direct translation to SKIR without performing optimization. Instead of performing opti-</text>
<text top="866" left="108" width="702" height="16" font="0">mizing code transformations in the language front-end, we rely exclusively on the SKIR compiler</text>
<text top="902" left="108" width="638" height="16" font="0">to perform any optimization and scheduling necessary to efﬁciently execute the program.</text>
<text top="964" left="112" width="36" height="16" font="0">4.3.1</text>
<text top="964" left="182" width="141" height="16" font="0">Generating Filters</text>
<text top="1012" left="151" width="659" height="16" font="0">Computation in StreamIt takes place in ﬁlters. Filters in StreamIt contain an optional initial-</text>
<text top="1048" left="108" width="702" height="16" font="0">ization function, called init, a kernel work function, called work, and optionally contain ﬁlter</text>
</page>
<page number="65" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">51</text>
<text top="108" left="325" width="77" height="13" font="1">v o i d −&gt;i n t</text>
<text top="108" left="417" width="47" height="13" font="1">f i l t e r</text>
<text top="109" left="479" width="96" height="13" font="1">I n t S o u r c e {</text>
<text top="126" left="362" width="49" height="14" font="1">i n t x ;</text>
<text top="144" left="363" width="140" height="13" font="1">i n i t { x = −1; }</text>
<text top="180" left="361" width="115" height="13" font="1">work p u s h 1 {</text>
<text top="198" left="396" width="87" height="13" font="1">x = x + 1 ;</text>
<text top="216" left="397" width="67" height="13" font="1">p u s h ( x ) ;</text>
<text top="233" left="361" width="7" height="14" font="1">}</text>
<text top="251" left="325" width="7" height="14" font="1">}</text>
<text top="288" left="326" width="67" height="13" font="1">i n t −&gt;i n t</text>
<text top="288" left="408" width="184" height="14" font="1">f i l t e r Adder ( i n t A) {</text>
<text top="306" left="361" width="169" height="13" font="1">work pop 1 p u s h 1 {</text>
<text top="324" left="397" width="121" height="13" font="1">p u s h (A+ pop ( ) ) ;</text>
<text top="341" left="361" width="7" height="14" font="1">}</text>
<text top="359" left="325" width="7" height="14" font="1">}</text>
<text top="395" left="326" width="77" height="13" font="1">i n t −&gt;v o i d</text>
<text top="395" left="417" width="47" height="13" font="1">f i l t e r</text>
<text top="396" left="479" width="104" height="13" font="1">I n t P r i n t e r {</text>
<text top="413" left="361" width="106" height="13" font="1">work pop 1 {</text>
<text top="431" left="399" width="128" height="13" font="1">p r i n t l n ( pop ( ) ) ;</text>
<text top="448" left="361" width="7" height="14" font="1">}</text>
<text top="466" left="325" width="7" height="14" font="1">}</text>
<text top="503" left="325" width="231" height="14" font="1">v o i d −&gt;v o i d p i p e l i n e Main {</text>
<text top="521" left="361" width="122" height="14" font="1">add I n t S o u r c e ;</text>
<text top="539" left="361" width="113" height="14" font="1">add Adder ( 3 ) ;</text>
<text top="557" left="361" width="131" height="14" font="1">add I n t P r i n t e r ;</text>
<text top="574" left="325" width="7" height="14" font="1">}</text>
<text top="616" left="242" width="433" height="16" font="0">Figure 4.5: A simple three stage pipeline written in StreamIt</text>
<text top="708" left="108" width="702" height="16" font="0">state. StreamIt kernel work functions are limited to have a single input stream and a single output</text>
<text top="744" left="108" width="702" height="16" font="0">stream. All the basic features of StreamIt ﬁlters are present in the IntSource ﬁlter shown in</text>
<text top="780" left="108" width="702" height="16" font="0">Figure 4.5. The init function initializes the ﬁlter’s state, an integer named x. The work function</text>
<text top="816" left="108" width="400" height="16" font="0">increments x then pushes the result to its output stream.</text>
<text top="852" left="151" width="659" height="16" font="0">The output of the StreamIt to SKIR compiler for IntSource is shown in Figure 4.6. In</text>
<text top="888" left="108" width="702" height="16" font="0">order to implement a StreamIt ﬁlter in SKIR, the compiler creates two functions: an initialization</text>
<text top="924" left="108" width="702" height="16" font="0">function and a kernel work function. The initialization function allocates the ﬁlter’s state and</text>
<text top="960" left="108" width="702" height="16" font="0">contains the contents of the ﬁlter’s init function. In our example, the initialization function</text>
<text top="996" left="108" width="702" height="16" font="0">allocates four bytes, for the integer variable x, then stores the value −1 into this memory location,</text>
<text top="1031" left="108" width="702" height="16" font="0">as in the original init function. A pointer to the allocated state is returned by the generated init</text>
<text top="1067" left="108" width="702" height="16" font="0">function. This value will be passed to the kernel work function as kernel state. The kernel work</text>
</page>
<page number="66" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">52</text>
<text top="128" left="108" width="702" height="16" font="0">function generated for IntSouce is also quite simple. It loads x from the kernel state (which</text>
<text top="164" left="108" width="702" height="16" font="0">was passed in as argument zero), adds one to it, then pushes the result to its output stream using</text>
<text top="201" left="108" width="97" height="14" font="0">skir.push</text>
<text top="200" left="205" width="4" height="16" font="0">.</text>
<text top="272" left="135" width="637" height="14" font="1">define noalias i8* @__streamit_IntSource_init(i8* nocapture) nounwind {</text>
<text top="290" left="135" width="54" height="12" font="1">entry:</text>
<text top="308" left="153" width="377" height="14" font="1">%malloccall = tail call i8* @malloc(i64 4)</text>
<text top="308" left="583" width="152" height="14" font="1">; &lt;i8*&gt; [#uses=2]</text>
<text top="326" left="153" width="323" height="14" font="1">%1 = bitcast i8* %malloccall to i32*</text>
<text top="326" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=1]</text>
<text top="344" left="153" width="188" height="14" font="1">store i32 -1, i32* %1</text>
<text top="362" left="153" width="170" height="14" font="1">ret i8* %malloccall</text>
<text top="380" left="135" width="9" height="12" font="1">}</text>
<text top="415" left="135" width="466" height="14" font="1">define i32 @__streamit_IntSource_work(i8* nocapture,</text>
<text top="433" left="476" width="134" height="14" font="1">i8** nocapture,</text>
<text top="451" left="476" width="233" height="14" font="1">i8** nocapture) nounwind {</text>
<text top="469" left="135" width="54" height="12" font="1">entry:</text>
<text top="487" left="153" width="215" height="12" font="1">%3 = alloca i32, align 4</text>
<text top="487" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=2]</text>
<text top="505" left="153" width="242" height="14" font="1">%4 = bitcast i8* %0 to i32*</text>
<text top="505" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=2]</text>
<text top="523" left="153" width="152" height="14" font="1">%x = load i32* %4</text>
<text top="523" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=1]</text>
<text top="541" left="153" width="161" height="12" font="1">%5 = add i32 %x, 1</text>
<text top="541" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=2]</text>
<text top="559" left="153" width="188" height="14" font="1">store i32 %5, i32* %4</text>
<text top="577" left="153" width="188" height="14" font="1">store i32 %5, i32* %3</text>
<text top="595" left="153" width="242" height="14" font="1">%6 = bitcast i32* %3 to i8*</text>
<text top="595" left="583" width="152" height="14" font="1">; &lt;i8*&gt; [#uses=1]</text>
<text top="613" left="153" width="359" height="14" font="1">call void @llvm.skir.push(i32 0, i8* %6)</text>
<text top="631" left="153" width="81" height="12" font="1">ret i32 0</text>
<text top="649" left="135" width="9" height="12" font="1">}</text>
<text top="703" left="108" width="702" height="16" font="0">Figure 4.6: The result of compiling the IntSource ﬁlter from Figure 4.5 with the StreamIt to</text>
<text top="724" left="108" width="113" height="16" font="0">SKIR compiler.</text>
<text top="797" left="151" width="659" height="16" font="0">At runtime, the SKIR version of the IntSource ﬁlter is constructed using the following</text>
<text top="833" left="108" width="252" height="16" font="0">sequence of generated instructions:</text>
<text top="872" left="117" width="448" height="14" font="1">%1 = call i8* @__streamit_IntSource_init(i8* null)</text>
<text top="890" left="117" width="672" height="14" font="1">%2 = i8* bitcast (i32 (i8*, i8**, i8**)* @__streamit_IntSource_work to i8*)</text>
<text top="908" left="117" width="421" height="14" font="1">%3 = call i8* @llvm.skir.kernel(i8* %2, i8* %1)</text>
<text top="960" left="151" width="659" height="16" font="0">StreamIt ﬁlters can also take parameters that are visible to the entire ﬁlter. An example of</text>
<text top="996" left="108" width="702" height="16" font="0">this is seen in the Adder ﬁlter in Figure 4.5. This ﬁlter takes a parameter A, then uses A inside</text>
<text top="1032" left="108" width="702" height="16" font="0">of its work function. The output of the StreamIt to SKIR compiler for Adder is shown in Figure</text>
<text top="1068" left="108" width="702" height="16" font="0">4.7. The SKIR implementation of the initialization function for Adder is very similar to the one</text>
</page>
<page number="67" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">53</text>
<text top="128" left="108" width="702" height="16" font="0">for IntSource. This is because ﬁlter arguments are captured and stored as part of the ﬁlter’s</text>
<text top="164" left="108" width="702" height="16" font="0">state. The only difference is that instead of being initialized explicitly in the init function, the</text>
<text top="200" left="108" width="702" height="16" font="0">value that was passed as an argument to the kernel is used as the initializer. The initialization</text>
<text top="236" left="108" width="702" height="16" font="0">function generated by the StreamIt to SKIR compiler always takes a single parameter. At runtime,</text>
<text top="272" left="108" width="702" height="16" font="0">any arguments to the ﬁlter are packed into a single structure and passed as a single pointer to the</text>
<text top="308" left="108" width="159" height="16" font="0">initialization function.</text>
<text top="377" left="135" width="601" height="14" font="1">define noalias i8* @__streamit_Adder_init(i8* nocapture) nounwind {</text>
<text top="395" left="135" width="54" height="12" font="1">entry:</text>
<text top="413" left="153" width="377" height="14" font="1">%malloccall = tail call i8* @malloc(i64 4)</text>
<text top="413" left="583" width="152" height="14" font="1">; &lt;i8*&gt; [#uses=2]</text>
<text top="431" left="153" width="242" height="14" font="1">%1 = bitcast i8* %0 to i32*</text>
<text top="431" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=1]</text>
<text top="449" left="153" width="152" height="14" font="1">%2 = load i32* %1</text>
<text top="449" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=1]</text>
<text top="467" left="153" width="323" height="14" font="1">%3 = bitcast i8* %malloccall to i32*</text>
<text top="467" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=1]</text>
<text top="485" left="153" width="188" height="14" font="1">store i32 %2, i32* %3</text>
<text top="503" left="153" width="170" height="14" font="1">ret i8* %malloccall</text>
<text top="521" left="135" width="9" height="12" font="1">}</text>
<text top="557" left="135" width="430" height="14" font="1">define i32 @__streamit_Adder_work(i8* nocapture,</text>
<text top="575" left="440" width="134" height="14" font="1">i8** nocapture,</text>
<text top="593" left="440" width="233" height="14" font="1">i8** nocapture) nounwind {</text>
<text top="611" left="135" width="54" height="12" font="1">entry:</text>
<text top="629" left="153" width="215" height="12" font="1">%3 = alloca i32, align 4</text>
<text top="629" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=2]</text>
<text top="646" left="153" width="215" height="12" font="1">%4 = alloca i32, align 4</text>
<text top="646" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=2]</text>
<text top="664" left="153" width="242" height="14" font="1">%5 = bitcast i8* %0 to i32*</text>
<text top="664" left="583" width="161" height="14" font="1">; &lt;i32*&gt; [#uses=1]</text>
<text top="682" left="153" width="152" height="14" font="1">%A = load i32* %5</text>
<text top="682" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=1]</text>
<text top="700" left="153" width="242" height="14" font="1">%6 = bitcast i32* %3 to i8*</text>
<text top="700" left="583" width="152" height="14" font="1">; &lt;i8*&gt; [#uses=1]</text>
<text top="718" left="153" width="350" height="14" font="1">call void @llvm.skir.pop(i32 0, i8* %6)</text>
<text top="736" left="153" width="152" height="14" font="1">%7 = load i32* %3</text>
<text top="736" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=1]</text>
<text top="754" left="153" width="170" height="12" font="1">%8 = add i32 %7, %A</text>
<text top="754" left="583" width="152" height="12" font="1">; &lt;i32&gt; [#uses=1]</text>
<text top="772" left="153" width="188" height="14" font="1">store i32 %8, i32* %4</text>
<text top="790" left="153" width="242" height="14" font="1">%9 = bitcast i32* %4 to i8*</text>
<text top="790" left="583" width="152" height="14" font="1">; &lt;i8*&gt; [#uses=1]</text>
<text top="808" left="153" width="359" height="14" font="1">call void @llvm.skir.push(i32 0, i8* %9)</text>
<text top="826" left="153" width="81" height="12" font="1">ret i32 0</text>
<text top="844" left="135" width="9" height="12" font="1">}</text>
<text top="898" left="108" width="702" height="16" font="0">Figure 4.7: The result of compiling the Adder ﬁlter from Figure 4.5 with the StreamIt to SKIR</text>
<text top="919" left="108" width="67" height="16" font="0">compiler.</text>
<text top="995" left="151" width="659" height="16" font="0">The construction of the Adder ﬁlter with the argument 3, as in the Main pipeline of Figure</text>
<text top="1031" left="108" width="484" height="16" font="0">4.5, is generated in SKIR as the following sequence of instructions:</text>
<text top="1071" left="144" width="332" height="12" font="1">%1 = alloca %Adder_init_type, align 8</text>
</page>
<page number="68" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">54</text>
<text top="131" left="144" width="556" height="14" font="1">%2 = getelementptr inbounds %Adder_init_type* %1, i64 0, i32 0</text>
<text top="149" left="144" width="260" height="14" font="1">store i32 3, i32* %2, align 8</text>
<text top="167" left="144" width="359" height="14" font="1">%3 = bitcast %Adder_init_type* %1 to i8*</text>
<text top="185" left="144" width="395" height="14" font="1">%4 = call i8* @__streamit_Adder_init(i8* %3)</text>
<text top="203" left="144" width="637" height="14" font="1">%5 = i8* bitcast (i32 (i8*, i8**, i8**)* @__streamit_Adder_work to i8*)</text>
<text top="221" left="144" width="421" height="14" font="1">%6 = call i8* @llvm.skir.kernel(i8* %5, i8* %4)</text>
<text top="280" left="112" width="36" height="16" font="0">4.3.2</text>
<text top="280" left="182" width="279" height="16" font="0">Generating Pipelines and Split-Joins</text>
<text top="328" left="151" width="659" height="16" font="0">StreamIt programs are composed using composite pipeline and split-join ﬁlters. These ﬁlters</text>
<text top="364" left="108" width="702" height="16" font="0">do not perform work themselves. Instead, they describe the interconnection of some number of</text>
<text top="400" left="108" width="702" height="16" font="0">child ﬁlters to do work for them. An example of a pipeline declaration is the Main ﬁlter in Figure</text>
<text top="436" left="108" width="702" height="16" font="0">4.5. This pipeline has three children: an IntSource ﬁlter, an Adder ﬁlter, and an IntSink</text>
<text top="472" left="108" width="702" height="16" font="0">ﬁlter. The output of the IntSource ﬁlter is connected to the input of the Adder ﬁlter, and</text>
<text top="508" left="108" width="702" height="16" font="0">the output of the Adder ﬁlter is connected to the IntSink ﬁlter. In SKIR terminology, Main</text>
<text top="544" left="108" width="222" height="16" font="0">describes a hierarchical kernel.</text>
<text top="580" left="151" width="659" height="16" font="0">The StreamIt to SKIR compiler generates code that instantiates the children of a composite</text>
<text top="616" left="108" width="702" height="16" font="0">ﬁlter in that ﬁlter’s initialization function. The generated work function is then responsible for al-</text>
<text top="652" left="108" width="702" height="16" font="0">locating streams to connect the children kernels using skir.stream and executing the children</text>
<text top="688" left="108" width="702" height="16" font="0">using skir.call. The initialization and kernel work functions for Main are shown in Figure</text>
<text top="724" left="108" width="702" height="16" font="0">4.8. The ﬁgure shows that the children ﬁlters of Main are allocated in its initialization function.</text>
<text top="760" left="108" width="702" height="16" font="0">These ﬁlters will be passed as state to the generated work function when it executes. But the work</text>
<text top="796" left="108" width="702" height="16" font="0">function does not construct a sub-graph from its children itself. Instead it is another hierarchical</text>
<text top="832" left="108" width="702" height="16" font="0">kernel which allocates and calls a single child kernel named pipeline. This helper kernel is part</text>
<text top="868" left="108" width="702" height="16" font="0">of a compiler library written in SKIR C and compiled into a static bitcode library. The compiler</text>
<text top="904" left="108" width="702" height="16" font="0">can import bitcode functions from this library and emit them into the SKIR code module being</text>
<text top="940" left="108" width="702" height="16" font="0">generated. From an implementation perspective, it is much easier and far less error prone to im-</text>
<text top="976" left="108" width="702" height="16" font="0">plement runtime functionality in this manner than it is to directly generate LLVM/SKIR bitcode</text>
<text top="1012" left="108" width="496" height="16" font="0">correctly. The implementation of pipeline is shown in Figure 4.9.</text>
<text top="1048" left="151" width="28" height="16" font="0">The</text>
<text top="1049" left="197" width="235" height="14" font="0">streamit pipeline work</text>
<text top="1048" left="437" width="373" height="16" font="0">function receives as its state a list of children ﬁlters</text>
</page>
<page number="69" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">55</text>
<text top="118" left="188" width="416" height="11" font="3">define i8* @__streamit_Main_init(i8* nocapture) nounwind {</text>
<text top="132" left="188" width="43" height="9" font="3">entry:</text>
<text top="147" left="202" width="165" height="9" font="3">%1 = alloca %3, align 8</text>
<text top="147" left="546" width="122" height="11" font="3">; &lt;%3*&gt; [#uses=2]</text>
<text top="161" left="202" width="323" height="11" font="3">%malloccall = tail call i8* @malloc(i64 4112)</text>
<text top="161" left="546" width="122" height="11" font="3">; &lt;i8*&gt; [#uses=4]</text>
<text top="175" left="202" width="280" height="11" font="3">%state = bitcast i8* %malloccall to %4*</text>
<text top="175" left="546" width="122" height="11" font="3">; &lt;%4*&gt; [#uses=4]</text>
<text top="189" left="202" width="258" height="11" font="3">store %4 zeroinitializer, %4* %state</text>
<text top="203" left="202" width="258" height="11" font="3">%2 = bitcast i8* %malloccall to i32*</text>
<text top="203" left="546" width="129" height="11" font="3">; &lt;i32*&gt; [#uses=8]</text>
<text top="217" left="202" width="143" height="11" font="3">store i32 0, i32* %2</text>
<text top="232" left="202" width="488" height="11" font="3">%3 = getelementptr inbounds i8* %malloccall, i64 8 ; &lt;i8*&gt; [#uses=1]</text>
<text top="246" left="202" width="201" height="11" font="3">%4 = bitcast i8* %3 to i32**</text>
<text top="246" left="546" width="136" height="11" font="3">; &lt;i32**&gt; [#uses=1]</text>
<text top="260" left="202" width="165" height="11" font="3">store i32* %2, i32** %4</text>
<text top="274" left="202" width="488" height="11" font="3">%5 = call i8* @__streamit_IntSource_init(i8* null) ; &lt;i8*&gt; [#uses=1]</text>
<text top="288" left="202" width="230" height="11" font="3">%6 = call i8* @llvm.skir.kernel(</text>
<text top="303" left="216" width="509" height="11" font="3">i8* bitcast (i32 (i8*, i8**, i8**)* @__streamit_IntSource_work to i8*),</text>
<text top="317" left="216" width="179" height="11" font="3">i8* %5) ; &lt;i8*&gt; [#uses=1]</text>
<text top="331" left="202" width="122" height="11" font="3">%7 = load i32* %2</text>
<text top="331" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=2]</text>
<text top="345" left="202" width="165" height="9" font="3">%8 = sext i32 %7 to i64</text>
<text top="345" left="546" width="122" height="9" font="3">; &lt;i64&gt; [#uses=1]</text>
<text top="359" left="202" width="502" height="11" font="3">%9 = getelementptr %4* %state, i64 0, i32 2, i64 %8 ; &lt;i8**&gt; [#uses=1]</text>
<text top="374" left="202" width="151" height="11" font="3">store i8* %6, i8** %9</text>
<text top="388" left="202" width="136" height="9" font="3">%10 = add i32 %7, 1</text>
<text top="388" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=1]</text>
<text top="402" left="202" width="158" height="11" font="3">store i32 %10, i32* %2</text>
<text top="416" left="202" width="488" height="11" font="3">%11 = getelementptr inbounds %3* %1, i64 0, i32 0 ; &lt;i32*&gt; [#uses=1]</text>
<text top="430" left="202" width="215" height="11" font="3">store i32 3, i32* %11, align 8</text>
<text top="445" left="202" width="194" height="11" font="3">%12 = bitcast %3* %1 to i8*</text>
<text top="445" left="546" width="122" height="11" font="3">; &lt;i8*&gt; [#uses=1]</text>
<text top="459" left="202" width="330" height="11" font="3">%13 = call i8* @__streamit_Adder_init(i8* %12)</text>
<text top="459" left="546" width="122" height="11" font="3">; &lt;i8*&gt; [#uses=1]</text>
<text top="473" left="202" width="237" height="11" font="3">%14 = call i8* @llvm.skir.kernel(</text>
<text top="487" left="216" width="481" height="11" font="3">i8* bitcast (i32 (i8*, i8**, i8**)* @__streamit_Adder_work to i8*),</text>
<text top="501" left="216" width="187" height="11" font="3">i8* %13) ; &lt;i8*&gt; [#uses=1]</text>
<text top="516" left="202" width="129" height="11" font="3">%15 = load i32* %2</text>
<text top="516" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=2]</text>
<text top="530" left="202" width="179" height="9" font="3">%16 = sext i32 %15 to i64</text>
<text top="530" left="546" width="122" height="9" font="3">; &lt;i64&gt; [#uses=1]</text>
<text top="544" left="202" width="516" height="11" font="3">%17 = getelementptr %4* %state, i64 0, i32 2, i64 %16 ; &lt;i8**&gt; [#uses=1]</text>
<text top="558" left="202" width="165" height="11" font="3">store i8* %14, i8** %17</text>
<text top="572" left="202" width="143" height="9" font="3">%18 = add i32 %15, 1</text>
<text top="572" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=1]</text>
<text top="587" left="202" width="158" height="11" font="3">store i32 %18, i32* %2</text>
<text top="601" left="202" width="502" height="11" font="3">%19 = call i8* @__streamit_IntPrinter_init(i8* null) ; &lt;i8*&gt; [#uses=1]</text>
<text top="615" left="202" width="237" height="11" font="3">%20 = call i8* @llvm.skir.kernel(</text>
<text top="629" left="216" width="516" height="11" font="3">i8* bitcast (i32 (i8*, i8**, i8**)* @__streamit_IntPrinter_work to i8*),</text>
<text top="643" left="216" width="187" height="11" font="3">i8* %19) ; &lt;i8*&gt; [#uses=1]</text>
<text top="658" left="202" width="129" height="11" font="3">%21 = load i32* %2</text>
<text top="658" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=2]</text>
<text top="672" left="202" width="179" height="9" font="3">%22 = sext i32 %21 to i64</text>
<text top="672" left="546" width="122" height="9" font="3">; &lt;i64&gt; [#uses=1]</text>
<text top="686" left="202" width="516" height="11" font="3">%23 = getelementptr %4* %state, i64 0, i32 2, i64 %22 ; &lt;i8**&gt; [#uses=1]</text>
<text top="700" left="202" width="165" height="11" font="3">store i8* %20, i8** %23</text>
<text top="714" left="202" width="143" height="9" font="3">%24 = add i32 %21, 1</text>
<text top="714" left="546" width="122" height="9" font="3">; &lt;i32&gt; [#uses=1]</text>
<text top="729" left="202" width="158" height="11" font="3">store i32 %24, i32* %2</text>
<text top="743" left="202" width="136" height="11" font="3">ret i8* %malloccall</text>
<text top="757" left="188" width="7" height="9" font="3">}</text>
<text top="800" left="188" width="502" height="11" font="3">define i32 @__streamit_Main_work(i8*, i8** nocapture, i8**) nounwind {</text>
<text top="814" left="188" width="43" height="9" font="3">entry:</text>
<text top="828" left="202" width="509" height="11" font="3">%3 = tail call i8* @__streamit__pipeline_init(i8* %0) ; &lt;i8*&gt; [#uses=1]</text>
<text top="842" left="202" width="265" height="11" font="3">%4 = tail call i8* @llvm.skir.kernel(</text>
<text top="856" left="216" width="509" height="11" font="3">i8* bitcast (i32 (i8*, %0**, %0**)* @__streamit__pipeline_work to i8*),</text>
<text top="871" left="216" width="179" height="11" font="3">i8* %3) ; &lt;i8*&gt; [#uses=1]</text>
<text top="885" left="202" width="416" height="11" font="3">tail call void @llvm.skir.call(i8* %4, i8** null, i8** %2)</text>
<text top="899" left="202" width="65" height="9" font="3">ret i32 1</text>
<text top="913" left="188" width="7" height="9" font="3">}</text>
<text top="951" left="108" width="702" height="16" font="0">Figure 4.8: The result of compiling the Main ﬁlter from Figure 4.5 with the StreamIt to SKIR</text>
<text top="973" left="108" width="67" height="16" font="0">compiler.</text>
</page>
<page number="70" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">56</text>
<text top="98" left="187" width="54" height="14" font="1">void *</text>
<text top="116" left="187" width="305" height="14" font="1">__streamit__pipeline_init(void *s)</text>
<text top="134" left="187" width="9" height="12" font="1">{</text>
<text top="152" left="223" width="81" height="12" font="1">return s;</text>
<text top="169" left="187" width="9" height="12" font="1">}</text>
<text top="205" left="187" width="27" height="12" font="1">int</text>
<text top="223" left="187" width="305" height="14" font="1">__streamit__pipeline_work(void *s,</text>
<text top="241" left="420" width="215" height="12" font="1">skir_stream_ptr_t ins[],</text>
<text top="259" left="420" width="224" height="12" font="1">skir_stream_ptr_t outs[])</text>
<text top="277" left="187" width="9" height="12" font="1">{</text>
<text top="295" left="223" width="269" height="14" font="1">state_t *state = (state_t *)s;</text>
<text top="313" left="223" width="251" height="12" font="1">int n = state-&gt;num_children;</text>
<text top="349" left="223" width="99" height="12" font="1">if (n == 0)</text>
<text top="367" left="259" width="81" height="12" font="1">return 1;</text>
<text top="385" left="223" width="161" height="12" font="1">else if (n == 1) {</text>
<text top="403" left="259" width="386" height="12" font="1">__SKIR_call(state-&gt;children[0], ins, outs);</text>
<text top="421" left="223" width="72" height="12" font="1">} else {</text>
<text top="438" left="259" width="179" height="12" font="1">skir_kernel_ptr_t k;</text>
<text top="456" left="259" width="305" height="12" font="1">skir_stream_ptr_t tmpi[2] = {0,0};</text>
<text top="474" left="259" width="305" height="12" font="1">skir_stream_ptr_t tmpo[2] = {0,0};</text>
<text top="492" left="259" width="54" height="12" font="1">int i;</text>
<text top="510" left="259" width="206" height="12" font="1">for (i=0; i&lt;n-1; i++) {</text>
<text top="528" left="295" width="206" height="12" font="1">k = state-&gt;children[i];</text>
<text top="546" left="295" width="332" height="12" font="1">tmpo[0] = __SKIR_stream(sizeof(int));</text>
<text top="564" left="295" width="81" height="12" font="1">if (i==0)</text>
<text top="582" left="331" width="233" height="12" font="1">__SKIR_call(k, ins, tmpo);</text>
<text top="600" left="295" width="36" height="12" font="1">else</text>
<text top="618" left="331" width="242" height="12" font="1">__SKIR_call(k, tmpi, tmpo);</text>
<text top="636" left="295" width="161" height="12" font="1">tmpi[0] = tmpo[0];</text>
<text top="654" left="259" width="9" height="12" font="1">}</text>
<text top="672" left="259" width="206" height="12" font="1">k = state-&gt;children[i];</text>
<text top="690" left="259" width="242" height="12" font="1">__SKIR_call(k, tmpi, outs);</text>
<text top="707" left="223" width="9" height="12" font="1">}</text>
<text top="743" left="223" width="81" height="12" font="1">return 1;</text>
<text top="761" left="187" width="9" height="12" font="1">}</text>
<text top="789" left="163" width="593" height="16" font="0">Figure 4.9: The pipeline ﬁlter from the StreamIt to SKIR compiler runtime library.</text>
<text top="881" left="108" width="702" height="16" font="0">to call. For the Main ﬁlter in our example, this list was constructed during the initialization</text>
<text top="917" left="108" width="702" height="16" font="0">function. If there are zero children in the list then the pipeline is empty, and the pipeline work</text>
<text top="953" left="108" width="702" height="16" font="0">function does nothing. If there is one child in the list, the pipeline work function only has to</text>
<text top="989" left="108" width="702" height="16" font="0">execute skir.call for this kernel and is done. If there are two or more children, the pipeline</text>
<text top="1025" left="108" width="702" height="16" font="0">work function has to execute skir.call for each child and also connect them together serially</text>
<text top="1061" left="108" width="430" height="16" font="0">using streams allocated with the skir.stream operation.</text>
</page>
<page number="71" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">57</text>
<text top="98" left="147" width="143" height="9" font="3">template&lt; int NOUT &gt;</text>
<text top="112" left="147" width="301" height="11" font="3">static int split_dup_work_N_ (void *state,</text>
<text top="126" left="362" width="172" height="9" font="3">skir_stream_ptr_t ins[],</text>
<text top="140" left="362" width="179" height="9" font="3">skir_stream_ptr_t outs[])</text>
<text top="154" left="147" width="7" height="9" font="3">{</text>
<text top="169" left="176" width="265" height="11" font="3">split_dup_t *s = (split_dup_t*)state;</text>
<text top="197" left="176" width="43" height="9" font="3">int e;</text>
<text top="211" left="176" width="129" height="9" font="3">__SKIR_pop(0, &amp;e);</text>
<text top="225" left="176" width="187" height="9" font="3">for (int i=0; i&lt;NOUT; i++)</text>
<text top="240" left="204" width="129" height="9" font="3">__SKIR_push(i,&amp;e);</text>
<text top="254" left="176" width="65" height="9" font="3">return 0;</text>
<text top="268" left="147" width="7" height="9" font="3">}</text>
<text top="296" left="147" width="179" height="9" font="3">#define SPLIT_DUP(DNUM) \</text>
<text top="311" left="161" width="610" height="11" font="3">static int (* split_dup_work_##DNUM)(void*,skir_stream_ptr_t*,skir_stream_ptr_t*) = \</text>
<text top="325" left="154" width="194" height="9" font="3">&amp;split_dup_work_N_&lt; DNUM &gt;;</text>
<text top="353" left="147" width="86" height="9" font="3">SPLIT_DUP(4)</text>
<text top="367" left="147" width="22" height="9" font="3">...</text>
<text top="392" left="118" width="683" height="16" font="0">Figure 4.10: A generic duplicating splitter from the StreamIt to SKIR compiler runtime library.</text>
<text top="483" left="151" width="659" height="16" font="0">Composite split-join ﬁlters are constructed in the same way as pipeline ﬁlters. That is, the</text>
<text top="519" left="108" width="702" height="16" font="0">initialization function of the ﬁlter is generated to allocate and initialize each child ﬁlter. Then, the</text>
<text top="555" left="108" width="702" height="16" font="0">appropriate function from the compiler bitcode library is used to connect and execute the children</text>
<text top="591" left="108" width="702" height="16" font="0">ﬁlters in the work function. In addition, the compiler must allocate the actual split and join kernels.</text>
<text top="627" left="108" width="702" height="16" font="0">These are also implemented in the compiler library. There are two type of splitting kernels, split rr</text>
<text top="663" left="108" width="702" height="16" font="0">kernels, which implement round-robin splitting of an input stream, and split dup kernels, which</text>
<text top="699" left="108" width="702" height="16" font="0">duplicate the input stream among the children kernels. Figure 4.10 shows a generic duplicating</text>
<text top="735" left="108" width="702" height="16" font="0">split kernel deﬁned in the compiler library. In practice, it is often possible to emit split and join</text>
<text top="771" left="108" width="702" height="16" font="0">kernels specialized for a speciﬁc number children. This allows for easier kernel analysis (e.g. rate</text>
<text top="807" left="108" width="702" height="16" font="0">detection) and optimization (e.g. loop unrolling) by the SKIR and LLVM optimization routines</text>
<text top="843" left="108" width="702" height="16" font="0">in the back-end compiler. The runtime library predeﬁnes a number of common versions of these</text>
<text top="879" left="108" width="702" height="16" font="0">kernels and also includes a fallback version which takes the number of children kernels (i.e. NOUT)</text>
<text top="915" left="108" width="702" height="16" font="0">as a runtime parameter. It is also possible to generate specialized versions on the ﬂy, but this is</text>
<text top="951" left="108" width="116" height="16" font="0">unimplemented.</text>
</page>
<page number="72" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">58</text>
<text top="128" left="112" width="36" height="16" font="0">4.3.3</text>
<text top="128" left="182" width="196" height="16" font="0">Other Language Features</text>
<text top="176" left="151" width="659" height="16" font="0">Several StreamIt language features remain unimplemented in the StreamIt to SKIR at the</text>
<text top="212" left="108" width="702" height="16" font="0">time of writing this dissertation. This is simply because they do not show up in any of the bench-</text>
<text top="248" left="108" width="617" height="16" font="0">marks we used. They are feedback loops, pre-work functions, and teleport messaging.</text>
<text top="284" left="151" width="659" height="16" font="0">Prework functions are StreamIt ﬁlter work functions that execute instead of the actual work</text>
<text top="320" left="108" width="702" height="16" font="0">function the ﬁrst time the ﬁlter executes. An example of a prework function is shown in Figure</text>
<text top="356" left="108" width="36" height="16" font="0">4.11.</text>
<text top="390" left="268" width="305" height="12" font="1">float-&gt;float filter Delay(int N) {</text>
<text top="408" left="304" width="143" height="12" font="1">prework push N {</text>
<text top="426" left="340" width="224" height="12" font="1">for (int i=0; i&lt;N; i++) {</text>
<text top="444" left="376" width="90" height="12" font="1">push(0.0);</text>
<text top="462" left="340" width="9" height="12" font="1">}</text>
<text top="479" left="304" width="9" height="12" font="1">}</text>
<text top="515" left="304" width="161" height="12" font="1">work push 1 pop 1{</text>
<text top="533" left="340" width="108" height="12" font="1">push(pop());</text>
<text top="551" left="304" width="9" height="12" font="1">}</text>
<text top="569" left="268" width="9" height="12" font="1">}</text>
<text top="597" left="254" width="411" height="16" font="0">Figure 4.11: An example of a StreamIt prework function.</text>
<text top="672" left="151" width="659" height="16" font="0">Prework functions could easily be added to SKIR using the skir.become operation. With</text>
<text top="708" left="108" width="702" height="16" font="0">this scheme, the compiler would simply generate the ﬁlter as usual, but use the prework function as</text>
<text top="744" left="108" width="702" height="16" font="0">the kernel work function. Then, instead of generating a return statement at the end of the prework</text>
<text top="780" left="108" width="494" height="16" font="0">kernel work function, a skir.become would be generated instead.</text>
<text top="816" left="151" width="659" height="16" font="0">An example of a StreamIt feedbackloop construct is shown in Figure 4.12. A feedback</text>
<text top="861" left="268" width="430" height="12" font="1">float-&gt;float feedbackloop AddFb(float scaling) {</text>
<text top="879" left="304" width="143" height="12" font="1">join roundrobin;</text>
<text top="897" left="304" width="161" height="12" font="1">body FloatAdder();</text>
<text top="915" left="304" width="233" height="12" font="1">loop FloatScaler(scaling);</text>
<text top="933" left="304" width="143" height="12" font="1">split duplicate;</text>
<text top="951" left="304" width="108" height="12" font="1">enqueue 0.0;</text>
<text top="969" left="268" width="9" height="12" font="1">}</text>
<text top="996" left="265" width="388" height="16" font="0">Figure 4.12: An example of a StreamIt feedback loop.</text>
<text top="1068" left="108" width="702" height="16" font="0">loop contains a join, a split, and exactly two children. The inputs to the join are the input</text>
</page>
<page number="73" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">59</text>
<text top="128" left="108" width="702" height="16" font="0">stream of the entire feedbackloop and a back edge stream created by the split. The output</text>
<text top="164" left="108" width="702" height="16" font="0">of the join goes to a body ﬁlter. The output of the body ﬁlter is the input of the split. One</text>
<text top="200" left="108" width="702" height="16" font="0">output of the split is the back edge of the loop. This stream is feed through the loop ﬁlter before</text>
<text top="236" left="108" width="696" height="16" font="0">ending at the join. The other output of the split is the output of the entire feedbackloop.</text>
<text top="272" left="151" width="659" height="16" font="0">StreamIt feedback loops could be supported in SKIR the same way pipelines and split-joins</text>
<text top="308" left="108" width="702" height="16" font="0">are supported; a hierarchical kernel work function in the compiler library implements the details</text>
<text top="344" left="108" width="702" height="16" font="0">of constructing the composite structure and the compiler itself generates the code to build the feed-</text>
<text top="380" left="108" width="702" height="16" font="0">back loop at runtime using that library function. The enqueue operation shown in the ﬁgure adds</text>
<text top="416" left="108" width="702" height="16" font="0">data to the backward edge of the feedback loop before the program starts running. This operation</text>
<text top="452" left="108" width="702" height="16" font="0">can be thought of as syntactic sugar on top of the prework construct, and could be supported in</text>
<text top="488" left="108" width="631" height="16" font="0">SKIR in the same way prework functions could be implemented using skir.become.</text>
<text top="524" left="151" width="659" height="16" font="0">Teleport messaging is a unique StreamIt feature which allows inter-kernel synchronization</text>
<text top="560" left="108" width="702" height="16" font="0">outside of the SDF model [53]. Filters can receive messages from other ﬁlters by deﬁning special</text>
<text top="596" left="108" width="702" height="16" font="0">handler methods to be called when a message is delivered. Filters can send messages with a syntax</text>
<text top="632" left="108" width="449" height="16" font="0">similar to calling these handler methods directly. For example,</text>
<text top="664" left="194" width="398" height="14" font="0">GainFilter.changeGain(1.2) [min:max];</text>
<text top="708" left="108" width="702" height="16" font="0">causes the value 1.2 to be delivered to the changeGain handler of the ﬁlter GainFilter.</text>
<text top="744" left="108" width="702" height="16" font="0">The notation [min:max] indicates the minimum and maximum latency for handler invocation at</text>
<text top="780" left="108" width="702" height="16" font="0">the receiver. Latency is deﬁned in terms of iterations of the sending ﬁlter S. A latency of k means</text>
<text top="816" left="108" width="702" height="16" font="0">that the message should be delivered k iterations of S after the message was sent. To compute</text>
<text top="852" left="108" width="702" height="16" font="0">the iteration of the receiving ﬁlter R corresponding to latency k, a function called the stream</text>
<text top="888" left="108" width="214" height="16" font="0">dependence function, SDEP</text>
<text top="895" left="322" width="30" height="11" font="3">R←S</text>
<text top="888" left="353" width="457" height="16" font="0">(n), is used. This function determines, for all valid execution</text>
<text top="924" left="108" width="702" height="16" font="0">schedules of the stream graph, the minimum number of iterations of R required for S to execute</text>
<text top="960" left="108" width="379" height="16" font="0">n times. So, if S sends a message with latency [k</text>
<text top="966" left="487" width="23" height="11" font="3">min</text>
<text top="961" left="511" width="11" height="14" font="0">:</text>
<text top="960" left="521" width="9" height="16" font="0">k</text>
<text top="966" left="531" width="25" height="11" font="3">max</text>
<text top="961" left="556" width="11" height="14" font="0">]</text>
<text top="960" left="573" width="237" height="16" font="0">during its nth iteration, then the</text>
<text top="996" left="108" width="455" height="16" font="0">message must be delivered during R’s mth iteration where n + k</text>
<text top="1002" left="563" width="23" height="11" font="3">min</text>
<text top="995" left="592" width="71" height="17" font="0">≤ SDEP</text>
<text top="1002" left="663" width="30" height="11" font="3">R←S</text>
<text top="996" left="695" width="89" height="16" font="0">(m) ≤ n + k</text>
<text top="1002" left="784" width="25" height="11" font="3">max</text>
<text top="1032" left="108" width="281" height="16" font="0">if R is a downstream ﬁlter and SDEP</text>
<text top="1038" left="389" width="30" height="11" font="3">R←S</text>
<text top="1032" left="420" width="49" height="16" font="0">(n + k</text>
<text top="1038" left="470" width="23" height="11" font="3">min</text>
<text top="1032" left="494" width="128" height="16" font="0">) ≤ m ≤ SDEP</text>
<text top="1038" left="622" width="30" height="11" font="3">R←S</text>
<text top="1032" left="653" width="49" height="16" font="0">(n + k</text>
<text top="1038" left="703" width="25" height="11" font="3">max</text>
<text top="1032" left="729" width="81" height="16" font="0">) if R is an</text>
<text top="1068" left="108" width="108" height="16" font="0">upstream ﬁlter.</text>
</page>
<page number="74" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">60</text>
<text top="128" left="151" width="659" height="16" font="0">Teleport messaging could be supported in SKIR by counting kernel iterations and constrain-</text>
<text top="164" left="108" width="702" height="16" font="0">ing the execution schedule appropriately. When a teleport message is sent by S, its iteration count</text>
<text top="200" left="108" width="702" height="16" font="0">could be used to compute a valid iteration of R before which the message handler should execute.</text>
<text top="236" left="108" width="702" height="16" font="0">It is not difﬁcult to add iteration counting to SKIR kernels. In fact, this is already done for pro-</text>
<text top="272" left="108" width="701" height="16" font="0">ﬁling. The challenge is in constraining the scheduler so that R does not run too far ahead of S</text>
<text top="308" left="108" width="702" height="16" font="0">and vice versa. One way to implement such constraints in a dynamically scheduled stream graph</text>
<text top="344" left="108" width="702" height="16" font="0">is to size the stream buffers between S and R appropriately. However, to support this we would</text>
<text top="380" left="108" width="702" height="16" font="0">need to provide an annotation mechanism for language frontends to communicate scheduling con-</text>
<text top="416" left="108" width="702" height="16" font="0">straints to the SKIR scheduler, which we currently do not provide. Such a mechanism would be</text>
<text top="452" left="108" width="702" height="16" font="0">easy to provide in our LLVM based implementation, but the correct form for such annotations is</text>
<text top="488" left="108" width="213" height="16" font="0">the subject of future research.</text>
<text top="545" left="112" width="22" height="16" font="0">4.4</text>
<text top="545" left="170" width="214" height="16" font="0">Embedded DSL: JavaScript</text>
<text top="600" left="151" width="659" height="16" font="0">A key beneﬁt of the SKIR approach to stream parallelism is the potential for dynamic compi-</text>
<text top="636" left="108" width="702" height="16" font="0">lation and scheduling. It is hard to ﬁnd programming languages more dynamic than weakly typed</text>
<text top="672" left="108" width="702" height="16" font="0">dynamic languages like JavaScript. Since its introduction by Netscape in the 1990’s, JavaScript –</text>
<text top="708" left="108" width="702" height="16" font="0">formally known as ECMAScript – has long been the dominant language for client-side web devel-</text>
<text top="744" left="108" width="702" height="16" font="0">opment. The size and complexity of client-side JavaScript programs has grown considerably since</text>
<text top="780" left="108" width="702" height="16" font="0">that time, and now includes applications such as games, ofﬁce suites, and image editing tools tradi-</text>
<text top="816" left="108" width="702" height="16" font="0">tionally developed using high performance statically compiled languages. More recently, develop-</text>
<text top="852" left="108" width="702" height="16" font="0">ers have been expanding the use of JavaScript with standards and implementations for server-side</text>
<text top="888" left="108" width="702" height="16" font="0">JavaScript such as CommonJS [3] and node.js [8]. JavaScript based query processing also pow-</text>
<text top="924" left="108" width="702" height="16" font="0">ers several popular “NoSQL” style databases such as Riak [2] and CouchDB [1]. This is largely</text>
<text top="960" left="108" width="702" height="16" font="0">due to the wide use of JavaScript in these communities and the ease with which JavaScript exe-</text>
<text top="996" left="108" width="702" height="16" font="0">cution engines can be embedded into larger projects. These trends are all driving a need for high</text>
<text top="1032" left="108" width="298" height="16" font="0">performance JavaScript implementations.</text>
<text top="1068" left="151" width="659" height="16" font="0">The stream parallel model can help with two of JavaScript’s main shortcomings moving</text>
</page>
<page number="75" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">61</text>
<text top="98" left="151" width="260" height="12" font="1">function array_adder(A, B, n)</text>
<text top="116" left="151" width="9" height="12" font="1">{</text>
<text top="134" left="169" width="99" height="12" font="1">var C = [];</text>
<text top="152" left="169" width="117" height="12" font="1">while (n--) {</text>
<text top="169" left="187" width="170" height="12" font="1">C[n] = A[n] + B[n];</text>
<text top="187" left="169" width="9" height="12" font="1">}</text>
<text top="205" left="169" width="81" height="12" font="1">return C;</text>
<text top="223" left="151" width="9" height="12" font="1">}</text>
<text top="98" left="466" width="296" height="12" font="1">function stream_adder(s0, s1, s2)</text>
<text top="116" left="466" width="9" height="12" font="1">{</text>
<text top="134" left="484" width="152" height="12" font="1">var a = s0.pop();</text>
<text top="152" left="484" width="152" height="12" font="1">var b = s1.pop();</text>
<text top="169" left="484" width="126" height="12" font="1">var c = a + b;</text>
<text top="187" left="484" width="99" height="12" font="1">s2.push(c);</text>
<text top="205" left="484" width="117" height="12" font="1">return false;</text>
<text top="223" left="466" width="9" height="12" font="1">}</text>
<text top="251" left="227" width="464" height="16" font="0">Figure 4.13: Array based vs. stream based addition in JavaScript</text>
<text top="343" left="108" width="702" height="16" font="0">forward: lack of performance and lack of a parallel programming model. The ways in which</text>
<text top="379" left="108" width="702" height="16" font="0">stream parallelism can help with performance are discussed below. The reasons stream parallelism</text>
<text top="415" left="108" width="702" height="16" font="0">can help with parallel programming should be fairly obvious. Stream parallel programs contain</text>
<text top="451" left="108" width="702" height="16" font="0">concurrency by default. Furthermore, the lack of shared state between kernel work functions in the</text>
<text top="487" left="108" width="702" height="16" font="0">stream parallel model helps bypass one of the main barriers to parallel programming in JavaScript</text>
<text top="523" left="108" width="702" height="16" font="0">– the complete lack of any synchronization or mutual exclusion mechanisms. When using stream</text>
<text top="559" left="108" width="702" height="16" font="0">parallelism, all synchronization is handled by the communication abstraction and explicit mutual</text>
<text top="594" left="108" width="486" height="16" font="0">exclusion is not needed because state is not shared between kernels.</text>
<text top="630" left="151" width="659" height="16" font="0">The JavaScript language itself is difﬁcult to implement in a high performance fashion. This is</text>
<text top="666" left="108" width="702" height="16" font="0">largely due to the language’s types, or more correctly, the lack of types. The fundamental problem</text>
<text top="702" left="108" width="702" height="16" font="0">is that the type of a variable can change between executions of the same expression. This means</text>
<text top="738" left="108" width="702" height="16" font="0">that unless the runtime compiler can prove that something is always of a certain type, it has to</text>
<text top="774" left="108" width="702" height="16" font="0">insert dynamic checks into the generated code. The use of the stream parallel programing model</text>
<text top="810" left="108" width="702" height="16" font="0">can make it much easier to perform this kind of type inference. To see how this might work, we</text>
<text top="846" left="108" width="287" height="16" font="0">can look at the examples in Figure 4.13.</text>
<text top="882" left="151" width="659" height="16" font="0">The array adder function in the ﬁgure takes two arrays as parameters, adds them to-</text>
<text top="918" left="108" width="702" height="16" font="0">gether, then returns the result. The other function, stream adder, does the same thing using a</text>
<text top="954" left="108" width="702" height="16" font="0">stream-like API. In this stream parallel version, the computation is deﬁned as a kernel work func-</text>
<text top="990" left="108" width="702" height="16" font="0">tion. Instead of passing the data into the function as arrays, it is read into the kernel using stream</text>
<text top="1026" left="108" width="702" height="16" font="0">operations. If we assume that streams are typed, then in this version of the computation there is</text>
<text top="1062" left="108" width="702" height="16" font="0">little doubt as to the type of the addition expression or the type of the output data c at the time the</text>
</page>
<page number="76" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">62</text>
<text top="128" left="108" width="702" height="16" font="0">call to stream adder is made. This is because streams are deﬁned to be a homogeneous data</text>
<text top="164" left="108" width="702" height="16" font="0">structure. In contrast, the implementation of the array based method has to check the type of A[n]</text>
<text top="200" left="108" width="540" height="16" font="0">and B[n] for each iteration of the loop, since arrays can be heterogeneous.</text>
<text top="262" left="112" width="36" height="16" font="0">4.4.1</text>
<text top="262" left="182" width="46" height="16" font="0">Sluice</text>
<text top="310" left="151" width="659" height="16" font="0">We have implemented an API similar to the one shown in Figure 4.13 as the Sluice library for</text>
<text top="346" left="108" width="702" height="16" font="0">the node.js JavaScript environment [27]. Node.js [8] is built on the high performance V8 JavaScript</text>
<text top="382" left="108" width="702" height="16" font="0">execution engine [15] and is intended to be used as a platform for creating network services, in</text>
<text top="418" left="108" width="702" height="16" font="0">particular web servers. We choose node.js over other JavaScript implementations as the target for</text>
<text top="454" left="108" width="702" height="16" font="0">Sluice because it runs on the server and not in a browser (i.e. no DOM and accessible from a</text>
<text top="490" left="108" width="441" height="16" font="0">command line), because V8 is fairly easy to extend using C</text>
<text top="490" left="547" width="17" height="13" font="1">++</text>
<text top="490" left="570" width="240" height="16" font="0">, and because the stream parallel</text>
<text top="526" left="108" width="700" height="16" font="0">model has already been shown to be a useful programming model for real time web services [13].</text>
<text top="562" left="151" width="659" height="16" font="0">Stream program kernels in Sluice are simply JavaScript objects containing a method called</text>
<text top="599" left="108" width="43" height="14" font="0">work</text>
<text top="598" left="151" width="659" height="16" font="0">. This work function is called to do work on behalf of the kernel when it is scheduled to</text>
<text top="634" left="108" width="702" height="16" font="0">run. Once a kernel is executing as part of a streaming computation, its work function is called</text>
<text top="670" left="108" width="702" height="16" font="0">repeatedly by the Sluice scheduling algorithm until the kernel ﬁnishes executing. A kernel ﬁnishes</text>
<text top="706" left="108" width="702" height="16" font="0">executing when it becomes blocked on an empty input stream whose source has ﬁnished executing</text>
<text top="742" left="108" width="702" height="16" font="0">or when its work function returns true. This is the only requirement of a kernel work function –</text>
<text top="778" left="108" width="702" height="16" font="0">that it return a value of true if it has ﬁnished executing or return a value of false if it can keep</text>
<text top="814" left="108" width="702" height="16" font="0">processing input data if more is available. This is essentially the same execution model used by</text>
<text top="850" left="108" width="496" height="16" font="0">SKIR kernels. Two example Sluice kernels are shown in Figure 4.14.</text>
<text top="886" left="151" width="659" height="16" font="0">Sluice uses StreamIt style stream graph construction. The following code shows how we</text>
<text top="922" left="108" width="702" height="16" font="0">can create and run a three stage pipeline using the two kernels from Figure 4.14 and an additional</text>
<text top="958" left="108" width="538" height="16" font="0">kernel called Printer which simply prints everything in its input stream:</text>
<text top="998" left="144" width="233" height="12" font="1">var src = new Counter(10);</text>
<text top="1016" left="144" width="206" height="12" font="1">var add = new Adder(1);</text>
<text top="1034" left="144" width="215" height="12" font="1">var snk = new Printer();</text>
<text top="1052" left="144" width="332" height="12" font="1">var p = Sluice.Pipeline(src,add,snk);</text>
<text top="1070" left="144" width="72" height="12" font="1">p.run();</text>
</page>
<page number="77" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">63</text>
<text top="98" left="108" width="206" height="12" font="1">function Counter(cnt) {</text>
<text top="116" left="144" width="99" height="12" font="1">this.i = 0;</text>
<text top="134" left="144" width="134" height="12" font="1">this.cnt = cnt;</text>
<text top="152" left="144" width="215" height="12" font="1">this.work = function() {</text>
<text top="169" left="180" width="215" height="12" font="1">if (this.i &lt; this.cnt) {</text>
<text top="187" left="216" width="179" height="12" font="1">this.push(this.i++);</text>
<text top="205" left="216" width="117" height="12" font="1">return false;</text>
<text top="223" left="180" width="9" height="12" font="1">}</text>
<text top="241" left="180" width="108" height="12" font="1">return true;</text>
<text top="259" left="144" width="18" height="12" font="1">};</text>
<text top="277" left="108" width="9" height="12" font="1">}</text>
<text top="98" left="498" width="188" height="12" font="1">function Adder(arg) {</text>
<text top="116" left="533" width="117" height="12" font="1">this.a = arg;</text>
<text top="134" left="533" width="215" height="12" font="1">this.work = function() {</text>
<text top="152" left="569" width="170" height="12" font="1">var e = this.pop();</text>
<text top="169" left="569" width="134" height="12" font="1">e = e + this.a;</text>
<text top="187" left="569" width="117" height="12" font="1">this.push(e);</text>
<text top="205" left="569" width="117" height="12" font="1">return false;</text>
<text top="223" left="533" width="18" height="12" font="1">};</text>
<text top="241" left="498" width="9" height="12" font="1">}</text>
<text top="305" left="108" width="702" height="16" font="0">Figure 4.14: Two simple Sluice kernels. The kernel on the left implements a simple counter. The</text>
<text top="326" left="108" width="702" height="16" font="0">kernel on the right adds the same value to each item popped the input stream and pushes the result</text>
<text top="348" left="108" width="142" height="16" font="0">to its output stream.</text>
<text top="440" left="108" width="702" height="16" font="0">The result of running this code is to print the numbers 1 through 10. We can obtain the same result</text>
<text top="476" left="108" width="324" height="16" font="0">in a more complicated way using a split-join:</text>
<text top="516" left="144" width="215" height="12" font="1">var add0 = new Adder(1);</text>
<text top="534" left="144" width="215" height="12" font="1">var add1 = new Adder(1);</text>
<text top="552" left="144" width="215" height="12" font="1">var add2 = new Adder(1);</text>
<text top="570" left="144" width="493" height="12" font="1">var sj = Sluice.SplitRR(1, add0, add1, add2).JoinRR(1);</text>
<text top="588" left="144" width="538" height="12" font="1">var p = Sluice.Pipeline(new Counter(10), sj, new Printer());</text>
<text top="606" left="144" width="72" height="12" font="1">p.run();</text>
<text top="658" left="108" width="702" height="16" font="0">In this example, the split-join distributes one element at a time, in a round-robin fashion, to each</text>
<text top="694" left="108" width="702" height="16" font="0">of the three Adder kernels. The results of the Adder kernels are then combined in the same</text>
<text top="730" left="108" width="637" height="16" font="0">round-robin manner. The entire split-join is then used as a stage in a three stage pipeline.</text>
<text top="766" left="151" width="659" height="16" font="0">The run method is used to execute the top level pipeline or split-join in a Sluice compu-</text>
<text top="802" left="108" width="702" height="16" font="0">tation. This is an asynchronous method. That is, it does not wait for the Sluice computation to</text>
<text top="838" left="108" width="702" height="16" font="0">complete before returning. Instead, it optionally takes as an argument a callback function that will</text>
<text top="874" left="108" width="702" height="16" font="0">be called when the computation ﬁnishes. This style of asynchronous programming is very common</text>
<text top="910" left="108" width="97" height="16" font="0">in JavaScript.</text>
<text top="946" left="151" width="659" height="16" font="0">As long as a Sluice kernel contains a work method that returns true or false, the rest</text>
<text top="982" left="108" width="702" height="16" font="0">of the kernel and kernel work function can contain arbitrary JavaScript code. However, as we</text>
<text top="1018" left="108" width="702" height="16" font="0">will show in the next section, it is advantageous for us follow a few simple coding conventions</text>
<text top="1054" left="108" width="702" height="16" font="0">when creating Sluice kernels. First, we prefer that program state encapsulated in kernel objects be</text>
</page>
<page number="78" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">64</text>
<text top="128" left="108" width="702" height="16" font="0">stored in the this scope of that kernel object. Second, we prefer that such state be initialized by</text>
<text top="164" left="108" width="702" height="16" font="0">the kernel object constructor. These conventions allow the implementation described in the next</text>
<text top="200" left="108" width="702" height="16" font="0">section to more easily obtain the program information it needs to perform optimization. A more</text>
<text top="236" left="108" width="702" height="16" font="0">mature implementation or one more tightly integrated into the JavaScript engine could relax these</text>
<text top="272" left="108" width="82" height="16" font="0">constraints.</text>
<text top="334" left="112" width="36" height="16" font="0">4.4.2</text>
<text top="334" left="182" width="260" height="16" font="0">Dynamic Recompilation for SKIR</text>
<text top="382" left="151" width="659" height="16" font="0">Using Sluice, program kernels are written in an object oriented style, encapsulating program</text>
<text top="418" left="108" width="702" height="16" font="0">state within program kernels. Because of this, we can more easily inspect and manipulate the</text>
<text top="454" left="108" width="702" height="16" font="0">state associated with a given program kernel at runtime. In addition, communication and syn-</text>
<text top="490" left="108" width="702" height="16" font="0">chronization within the streaming computation is limited to push and pop operations on streams.</text>
<text top="526" left="108" width="702" height="16" font="0">Together, these characteristics provide a great deal of ﬂexibility in deciding where and when code</text>
<text top="562" left="108" width="702" height="16" font="0">should execute. We can take advantage of this ﬂexibility to dynamically recompile Sluice kernels</text>
<text top="598" left="108" width="702" height="16" font="0">from JavaScript to SKIR then ofﬂoad their execution to a SKIR runtime executing in a separate</text>
<text top="634" left="108" width="702" height="16" font="0">process. Stream communication and communication of kernel state between SKIR and Sluice is</text>
<text top="670" left="108" width="702" height="16" font="0">maintained using shared memory between the two processes. Because we restrict the features of</text>
<text top="706" left="108" width="702" height="16" font="0">JavaScript that we can use with Sluice and because we sometimes recompile Sluice code to execute</text>
<text top="742" left="108" width="702" height="16" font="0">outside of the JavaScript execution engine, we prefer to call Sluice an embedded domain speciﬁc</text>
<text top="778" left="108" width="69" height="16" font="0">language.</text>
<text top="814" left="151" width="659" height="16" font="0">JavaScript applications are distributed as source code and the source code for a particular</text>
<text top="850" left="108" width="702" height="16" font="0">function is available to the program itself. Because of this, we can implement runtime code trans-</text>
<text top="886" left="108" width="702" height="16" font="0">lation as part of the Sluice user library. For the purposes of this thesis, kernels to be accelerated</text>
<text top="922" left="108" width="702" height="16" font="0">are identiﬁed to the library by the programmer. This is equivalent to using program annotations</text>
<text top="958" left="108" width="702" height="16" font="0">or pragmas in a statically compiled language. Instances of kernels are translated after they are</text>
<text top="994" left="108" width="702" height="16" font="0">allocated (using the new operation), but before they are added to a stream graph using the pipeline</text>
<text top="1030" left="108" width="702" height="16" font="0">or split-join constructs. The following code example shows how a Sluice kernel can be translated</text>
<text top="1066" left="108" width="308" height="16" font="0">to SKIR using our current implementation:</text>
</page>
<page number="79" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">65</text>
<text top="131" left="144" width="233" height="12" font="1">var k = new MyKernel(...);</text>
<text top="149" left="144" width="332" height="12" font="1">sluice.toSkir(k, function(err, ret) {</text>
<text top="167" left="323" width="332" height="12" font="1">sluice.Pipeline(..., ret, ...).run();</text>
<text top="185" left="269" width="27" height="12" font="1">});</text>
<text top="237" left="108" width="702" height="16" font="0">In this code, the kernel k is translated to SKIR using the Sluice library’s toSkir method. The</text>
<text top="273" left="108" width="702" height="16" font="0">result is passed to the anonymous callback then added to a pipeline which is immediately executed</text>
<text top="309" left="108" width="702" height="16" font="0">by calling run. The toSkir method transparently compiles the Sluice kernel to SKIR, sends it</text>
<text top="345" left="108" width="525" height="16" font="0">off to the SKIR runtime, and sets up the required shared memory buffers.</text>
<text top="381" left="151" width="659" height="16" font="0">Once a kernel has been identiﬁed for optimization with SKIR, its source code is parsed and</text>
<text top="417" left="108" width="702" height="16" font="0">an abstract syntax tree (AST) for its work function is constructed. This AST is then used to generate</text>
<text top="453" left="108" width="702" height="16" font="0">SKIR code corresponding to the original Sluice kernel. The main problem we face in this process</text>
<text top="489" left="108" width="702" height="16" font="0">is the same one faced by any code generation system for JavaScript - mapping dynamic types to</text>
<text top="525" left="108" width="702" height="16" font="0">static types. The issue is that the type of a particular variable cannot, in general, be statically</text>
<text top="561" left="108" width="702" height="16" font="0">determined by a compiler whereas the machine code generated by a JavaScript compiler or the</text>
<text top="597" left="108" width="471" height="16" font="0">SKIR code generated by the Sluice compiler requires static types.</text>
<text top="633" left="151" width="659" height="16" font="0">All high performance JavaScript implementations obtain that performance in part by making</text>
<text top="669" left="108" width="702" height="16" font="0">assumptions about the types contained in a piece of code. In trace-based compilers, type infor-</text>
<text top="705" left="108" width="702" height="16" font="0">mation is recorded during trace collection. For types that remain static during trace collection,</text>
<text top="741" left="108" width="702" height="16" font="0">machine code specialized to that type can be emitted [28]. In compilers employing direct transla-</text>
<text top="777" left="108" width="702" height="16" font="0">tion from JavaScript to machine code, such as the V8 compiler [15], code is emitted for the ﬁrst</text>
<text top="813" left="108" width="702" height="16" font="0">type seen, then patched if the type changes. Both approaches are based on the observation that</text>
<text top="849" left="108" width="702" height="16" font="0">although JavaScript supports dynamic types, in practice types remain fairly stable at runtime. Both</text>
<text top="885" left="108" width="702" height="16" font="0">approaches must also insert checks into the generated machine code to make sure assumptions</text>
<text top="921" left="108" width="203" height="16" font="0">about types are not violated.</text>
<text top="957" left="151" width="659" height="16" font="0">For Sluice kernels written using the coding conventions discussed in Section 4.4.1, most</text>
<text top="993" left="108" width="702" height="16" font="0">types will be known before kernel execution. This is the direct result of the use of encapsulated</text>
<text top="1029" left="108" width="702" height="16" font="0">program state and the use of the stream communication abstraction. The use of encapsulated</text>
<text top="1065" left="108" width="702" height="16" font="0">program state means that any program state used by the kernel is already initialized when a kernel</text>
</page>
<page number="80" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">66</text>
<text top="128" left="108" width="702" height="16" font="0">object is passed to Sluice for translation to SKIR. This in turn means that the Sluice compiler can</text>
<text top="164" left="108" width="702" height="16" font="0">simply access the data to determine its type. The type must be rechecked each time the kernel is</text>
<text top="200" left="108" width="702" height="16" font="0">executed. However, because the kernel work function is typically called many times during kernel</text>
<text top="236" left="108" width="702" height="16" font="0">execution, the cost of these type checks is very small when compared to the inline checks generated</text>
<text top="272" left="108" width="234" height="16" font="0">by a typical JavaScript compiler.</text>
<text top="308" left="151" width="659" height="16" font="0">The stream operations pop and push are trivially translated to SKIR as they are supported</text>
<text top="344" left="108" width="702" height="16" font="0">directly by the representation. Stream communication is the only source of data from outside of</text>
<text top="380" left="108" width="702" height="16" font="0">the kernel during its execution. By deﬁnition we know that the streams contain only a single type.</text>
<text top="416" left="108" width="656" height="16" font="0">Thus we know that interaction with stream objects will not result in dynamic type behavior.</text>
<text top="452" left="151" width="659" height="16" font="0">A remaining source of dynamic types is from variables created during execution of the ker-</text>
<text top="488" left="108" width="702" height="16" font="0">nel work function. For example, different types could be assigned to the same variable depending</text>
<text top="524" left="108" width="702" height="16" font="0">on the path taken through an if-then-else statement. The Sluice to SKIR compiler does not cur-</text>
<text top="560" left="108" width="702" height="16" font="0">rently handle this behavior, however this is a limitation of our current implementation, not of our</text>
<text top="596" left="108" width="612" height="16" font="0">approach. Existing mechanisms such as those used in the V8 compiler could be used.</text>
<text top="632" left="151" width="659" height="16" font="0">Once static type information is computed for a Sluice kernel, the system translates the AST</text>
<text top="668" left="108" width="702" height="16" font="0">form of the kernel work function to SKIR code. Instead of generating low level SKIR code (i.e.</text>
<text top="704" left="108" width="702" height="16" font="0">LLVM code) directly, Sluice generates C code which includes the SKIR C intrinsics. Because</text>
<text top="740" left="108" width="702" height="16" font="0">JavaScript is syntactically similar to C and because good C to LLVM compilers already exist, this</text>
<text top="776" left="108" width="702" height="16" font="0">design decision simpliﬁes our implementation enormously. The C code is then compiled down to</text>
<text top="812" left="108" width="702" height="16" font="0">SKIR code. A side beneﬁt of this approach is that much of the compilation process automatically</text>
<text top="848" left="108" width="289" height="16" font="0">runs in parallel with the Sluice program.</text>
<text top="910" left="112" width="36" height="16" font="0">4.4.3</text>
<text top="910" left="182" width="219" height="16" font="0">Ofﬂoading Kernel Execution</text>
<text top="958" left="151" width="659" height="16" font="0">Because the SKIR scheduler executes as a separate process from Sluice, our main challenge</text>
<text top="994" left="108" width="702" height="16" font="0">is in obtaining high performance communication between ofﬂoaded Sluice kernels and the rest</text>
<text top="1030" left="108" width="702" height="16" font="0">of the JavaScript program. Two things must be communicated efﬁciently between the separate</text>
<text top="1066" left="108" width="702" height="16" font="0">parts of the program; these are any program state used by ofﬂoaded kernels and any streaming</text>
</page>
<page number="81" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="10" size="19" family="Times" color="#000000"/>
	<fontspec id="11" size="14" family="Times" color="#1a1a1a"/>
	<fontspec id="12" size="19" family="Times" color="#1a1a1a"/>
	<fontspec id="13" size="16" family="Times" color="#000000"/>
	<fontspec id="14" size="10" family="Times" color="#000000"/>
	<fontspec id="15" size="11" family="Times" color="#000000"/>
<text top="85" left="792" width="18" height="16" font="0">67</text>
<text top="128" left="108" width="702" height="16" font="0">communication between Sluice kernels and SKIR kernels. An overview of kernel ofﬂoad is shown</text>
<text top="164" left="108" width="106" height="16" font="0">in Figure 4.15.</text>
<text top="193" left="361" width="51" height="24" font="10">SKIR</text>
<text top="438" left="201" width="21" height="19" font="11">K2</text>
<text top="457" left="174" width="75" height="18" font="7">(offloaded)</text>
<text top="299" left="198" width="27" height="24" font="12">K1</text>
<text top="457" left="398" width="27" height="24" font="12">K2</text>
<text top="565" left="198" width="27" height="24" font="12">K3</text>
<text top="418" left="193" width="37" height="19" font="11">state</text>
<text top="420" left="380" width="61" height="15" font="2">state copy</text>
<text top="193" left="185" width="102" height="24" font="10">JavaScript</text>
<text top="410" left="291" width="41" height="15" font="2">shared</text>
<text top="425" left="287" width="48" height="15" font="2">memory</text>
<text top="361" left="291" width="41" height="15" font="2">shared</text>
<text top="376" left="287" width="48" height="15" font="2">memory</text>
<text top="494" left="291" width="41" height="15" font="2">shared</text>
<text top="508" left="287" width="48" height="15" font="2">memory</text>
<text top="226" left="507" width="50" height="20" font="13">Sluice</text>
<text top="257" left="504" width="210" height="19" font="4">1) Compile K2 to SKIR code</text>
<text top="284" left="504" width="166" height="19" font="4">2) Transfer SKIR code</text>
<text top="312" left="504" width="143" height="19" font="4">3) Allocate streams</text>
<text top="339" left="504" width="176" height="19" font="4">4) Allocate &amp; copy state</text>
<text top="366" left="504" width="74" height="19" font="4">5) Call K2</text>
<text top="432" left="507" width="43" height="20" font="13">SKIR</text>
<text top="464" left="504" width="130" height="19" font="4">6) JIT compile K2</text>
<text top="491" left="504" width="105" height="19" font="4">7) Execute K2</text>
<text top="559" left="506" width="46" height="19" font="4">Sluice</text>
<text top="588" left="504" width="183" height="19" font="4">8) Copy state back to JS</text>
<text top="231" left="316" width="0" height="14" font="14">P</text>
<text top="239" left="316" width="0" height="18" font="14">ro</text>
<text top="250" left="316" width="0" height="21" font="14">ce</text>
<text top="264" left="316" width="0" height="21" font="14">ss</text>
<text top="276" left="316" width="0" height="18" font="14"> b</text>
<text top="287" left="316" width="0" height="21" font="14">ou</text>
<text top="301" left="316" width="0" height="21" font="14">nd</text>
<text top="315" left="316" width="0" height="21" font="14">ar</text>
<text top="326" left="316" width="0" height="14" font="14">y</text>
<text top="357" left="371" width="74" height="15" font="15">input stream</text>
<text top="513" left="369" width="82" height="15" font="15">output stream</text>
<text top="333" left="726" width="31" height="16" font="1">RPC</text>
<text top="678" left="278" width="363" height="16" font="0">Figure 4.15: An overview of Sluice kernel ofﬂoad.</text>
<text top="744" left="151" width="659" height="16" font="0">Stream communication between processes is made efﬁcient by mapping the streams onto</text>
<text top="780" left="108" width="702" height="16" font="0">lock free queues in shared memory. For SKIR, this means that nothing further is needed be-</text>
<text top="816" left="108" width="702" height="16" font="0">cause we are using the ordinary SKIR mechanism which supports shared memory. For Sluice, this</text>
<text top="852" left="108" width="487" height="16" font="0">functionality is provided using stream objects implemented as a C</text>
<text top="851" left="594" width="17" height="13" font="1">++</text>
<text top="852" left="617" width="193" height="16" font="0">extension to V8 and made</text>
<text top="888" left="108" width="702" height="16" font="0">accessible through a JavaScript module. In both cases, the runtime remapping of the stream imple-</text>
<text top="924" left="108" width="702" height="16" font="0">mentation is made possible because the program is written using the stream abstractions provided</text>
<text top="960" left="108" width="501" height="16" font="0">by Sluice and SKIR which do not assume any implementation details.</text>
<text top="996" left="151" width="659" height="16" font="0">It is more difﬁcult to efﬁciently communicate non-stream data used by a Sluice kernel from</text>
<text top="1032" left="108" width="702" height="16" font="0">JavaScript to SKIR. Program state lacks the features that make implementing streaming commu-</text>
<text top="1068" left="108" width="702" height="16" font="0">nication fairly easy. It is not made structured or abstract by the programming model itself. Instead,</text>
</page>
<page number="82" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">68</text>
<text top="128" left="108" width="702" height="16" font="0">it’s structure depends on the algorithms used by the programmer and can vary greatly from program</text>
<text top="164" left="108" width="84" height="16" font="0">to program.</text>
<text top="200" left="151" width="659" height="16" font="0">Because it is intractable to ﬁgure out what parts of a kernel’s state are read or written during</text>
<text top="236" left="108" width="702" height="16" font="0">an execution of its work function, all state must be copied from Sluice to SKIR when a kernel is</text>
<text top="272" left="108" width="702" height="16" font="0">called. As long as the kernel is executing, this data remains in the SKIR runtime. When the kernel</text>
<text top="308" left="108" width="276" height="16" font="0">ﬁnishes, the state is returned to Sluice.</text>
<text top="344" left="151" width="659" height="16" font="0">Copying data between processes can incur high overheads compared to the granularity of</text>
<text top="380" left="108" width="702" height="16" font="0">computation the streaming model exposes. To reduce this overhead as much as possible, we again</text>
<text top="416" left="108" width="702" height="16" font="0">use shared memory between the processes. The ﬁrst time the program state for a particular kernel</text>
<text top="452" left="108" width="702" height="16" font="0">is copied, the Sluice runtime requests a piece of shared memory from the SKIR runtime. The size</text>
<text top="488" left="108" width="702" height="16" font="0">of this memory is the same as the C language struct formed by combining all the state into a single</text>
<text top="524" left="108" width="46" height="16" font="0">buffer.</text>
<text top="560" left="151" width="659" height="16" font="0">Each time a kernel is called to run in the SKIR layer, the kernel’s state is copied from</text>
<text top="596" left="108" width="702" height="16" font="0">JavaScript into the shared memory buffer. The kernel executing in the SKIR runtime interprets</text>
<text top="632" left="108" width="702" height="16" font="0">the data as a C struct, and can directly address the data without an additional copy. When the</text>
<text top="668" left="108" width="702" height="16" font="0">kernel ﬁnishes execution, the shared memory can be translated back into its JavaScript version.</text>
<text top="704" left="108" width="702" height="16" font="0">Thus the data is copied twice – once as it is translated from JavaScript to the C struct at the start of</text>
<text top="740" left="108" width="608" height="16" font="0">execution, and once as it is translated back to JavaScript data at the end of execution.</text>
<text top="776" left="151" width="659" height="16" font="0">Other than the shared memory for streams and state, all interaction between SKIR and other</text>
<text top="812" left="108" width="702" height="16" font="0">processes is done through remote procedure calls (RPC) implemented using protocol buffers [11]</text>
<text top="848" left="108" width="702" height="16" font="0">over sockets. There are RPC interfaces corresponding to skir.stream, skir.kernel, and</text>
<text top="885" left="108" width="97" height="14" font="0">skir.call</text>
<text top="884" left="210" width="600" height="16" font="0">used to create and execute stream graphs. There are also commands to pass SKIR</text>
<text top="920" left="108" width="702" height="16" font="0">bitcode to the SKIR runtime and to create, read, and write shared memory buffers for kernel state.</text>
<text top="982" left="112" width="36" height="16" font="0">4.4.4</text>
<text top="982" left="182" width="81" height="16" font="0">Discussion</text>
<text top="1030" left="151" width="659" height="16" font="0">We evaluate the performance of the Sluice to SKIR accelerator in Chapter 7. The approach</text>
<text top="1066" left="108" width="702" height="16" font="0">taken by Sluice is similar to several other projects. The RiverTrail project [12] introduces typed</text>
</page>
<page number="83" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">69</text>
<text top="128" left="108" width="702" height="16" font="0">parallel arrays into JavaScript and provides ﬁve data parallel methods for operating on them: map,</text>
<text top="164" left="108" width="702" height="16" font="0">combine, scan, ﬁlter, and scatter. By restricting the programming model around this speciﬁc data</text>
<text top="200" left="108" width="702" height="16" font="0">type, RiverTrail is able to perform type inference at runtime and generate OpenCL code for com-</text>
<text top="236" left="108" width="702" height="16" font="0">putation using the provided operators. This is analogous to Sluice restricting the programming</text>
<text top="272" left="108" width="702" height="16" font="0">model around stream parallel kernels and emitting and executing SKIR code. A Python embedded</text>
<text top="308" left="108" width="702" height="16" font="0">domain speciﬁc language similar to Sluice and RiverTrail is the Copperhead project [26]. Copper-</text>
<text top="344" left="108" width="702" height="16" font="0">head provides acceleration of computation involving nested parallel arrays by translating Python to</text>
<text top="380" left="108" width="702" height="16" font="0">CUDA code at runtime and running the result on graphics processors. Like Sluice and RiverTrail,</text>
<text top="416" left="108" width="678" height="16" font="0">it does this by restricting the host language until type inference can be successfully performed.</text>
<text top="474" left="112" width="22" height="16" font="0">4.5</text>
<text top="474" left="170" width="86" height="16" font="0">Conclusion</text>
<text top="529" left="151" width="659" height="16" font="0">This chapter has shown that SKIR can support a variety of stream parallel programming</text>
<text top="565" left="108" width="702" height="16" font="0">environments. Exposed as low level C language compiler intrinsics, SKIR serves as a compilation</text>
<text top="600" left="108" width="702" height="16" font="0">target for the Sluice source to source compiler, serves as a implementation language for compiler</text>
<text top="636" left="108" width="702" height="16" font="0">libraries as part of our StreamIt to SKIR compiler, and provides stream parallel abstractions for</text>
<text top="672" left="108" width="702" height="16" font="0">our C++ library. A high level compiler can also emit SKIR code directly, as demonstrated by our</text>
<text top="708" left="108" width="197" height="16" font="0">StreamIt to SKIR compiler.</text>
</page>
<page number="84" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 5</text>
<text top="292" left="356" width="206" height="16" font="0">SKIR Dynamic Scheduling</text>
<text top="408" left="151" width="659" height="16" font="0">For streaming computations containing only synchronous kernels, a static schedule can be</text>
<text top="444" left="108" width="702" height="16" font="0">computed at compile time before the program executes. A valid static schedule guarantees bounded</text>
<text top="479" left="108" width="702" height="16" font="0">communication queues between program kernels and will not introduce deadlock. If the execution</text>
<text top="515" left="108" width="702" height="16" font="0">characteristics of kernels are known, static scheduling for this type of stream graph can also provide</text>
<text top="551" left="108" width="152" height="16" font="0">static load balancing.</text>
<text top="587" left="151" width="659" height="16" font="0">For general purpose use, there are serious limitations with the synchronous dataﬂow model</text>
<text top="623" left="108" width="702" height="16" font="0">and associated static scheduling techniques. One problem is that static scheduling algorithms re-</text>
<text top="659" left="108" width="702" height="16" font="0">quire accurate knowledge of both application and hardware execution characteristics as well as</text>
<text top="695" left="108" width="702" height="16" font="0">inter-kernel communication costs in order to make good scheduling and load balancing decisions</text>
<text top="731" left="108" width="702" height="16" font="0">[50]. Many factors found in real systems can cause static schedules to perform poorly. Some ex-</text>
<text top="767" left="108" width="702" height="16" font="0">amples of these factors are kernels with variable runtimes, interference from other workloads, and</text>
<text top="803" left="108" width="702" height="16" font="0">hardware with dynamic performance characteristics. The problem is exacerbated when compiled</text>
<text top="839" left="108" width="702" height="16" font="0">software is widely distributed for use on many different end user machines. Another problem is</text>
<text top="875" left="108" width="702" height="16" font="0">that the synchronous model is quite restrictive for general purpose programming. One cannot, for</text>
<text top="911" left="108" width="702" height="16" font="0">example, write a program kernel that conditionally writes to an output stream. To do so would</text>
<text top="947" left="108" width="404" height="16" font="0">make it impossible to determine the kernel’s output rate.</text>
<text top="983" left="151" width="659" height="16" font="0">Even if it were desirable, static scheduling is not possible for all SKIR programs. The main</text>
<text top="1019" left="108" width="702" height="16" font="0">reason for this is that program kernels are not required to be synchronous. This means that a com-</text>
<text top="1055" left="108" width="702" height="16" font="0">piler or scheduler cannot, in general, compute bounded buffer sizes for communication in a ﬁxed</text>
</page>
<page number="85" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">71</text>
<text top="128" left="108" width="702" height="16" font="0">schedule. In addition, the runtime construction of the stream graph means that a SKIR compiler</text>
<text top="164" left="108" width="702" height="16" font="0">cannot in general determine the stream graph structure until the program is running. In fact, entire</text>
<text top="200" left="108" width="702" height="16" font="0">portions of a program graph may conditionally execute (or not execute) based on program input</text>
<text top="236" left="108" width="702" height="16" font="0">and nothing prevents short running portions of the program graph from ﬁnishing before other por-</text>
<text top="272" left="108" width="702" height="16" font="0">tions of the graph are instantiated. Finally, for programs containing dynamic stream graphs, static</text>
<text top="308" left="108" width="233" height="16" font="0">scheduling may not be practical.</text>
<text top="344" left="151" width="659" height="16" font="0">Instead of static scheduling, we use dynamic scheduling to coordinate the execution of SKIR</text>
<text top="380" left="108" width="702" height="16" font="0">kernels. In a dynamic scheduling algorithm, decisions about when to run a particular kernel are</text>
<text top="416" left="108" width="702" height="16" font="0">made dynamically at runtime. The goal of the SKIR dynamic scheduling algorithm is to provide</text>
<text top="452" left="108" width="702" height="16" font="0">the same things for a SKIR program that a static scheduling algorithm provides for a synchronous</text>
<text top="488" left="108" width="702" height="16" font="0">dataﬂow graph. In particular, such an algorithm should provide high performance, work with</text>
<text top="524" left="108" width="585" height="16" font="0">bounded communication queues, provide load balancing, and not cause deadlock.</text>
<text top="560" left="151" width="659" height="16" font="0">This chapter describes the approach to dynamic scheduling implemented in the SKIR system.</text>
<text top="596" left="108" width="702" height="16" font="0">Section 5.2 describes how cooperative multitasking can be used to schedule SKIR kernels within</text>
<text top="632" left="108" width="702" height="16" font="0">a single thread. Section 5.3 shows how to extend this method using a randomized work stealing</text>
<text top="668" left="108" width="387" height="16" font="0">scheduler to provide multithreaded parallel execution.</text>
<text top="725" left="112" width="22" height="16" font="0">5.1</text>
<text top="725" left="170" width="182" height="16" font="0">Stream Implementation</text>
<text top="780" left="151" width="659" height="16" font="0">Before discussing the SKIR scheduling algorithms, it is helpful to describe the baseline im-</text>
<text top="816" left="108" width="702" height="16" font="0">plementation of streams used by SKIR. We say baseline implementation because the actual stream</text>
<text top="852" left="108" width="702" height="16" font="0">implementation used changes slightly depending on the SKIR program optimizations employed,</text>
<text top="888" left="108" width="702" height="16" font="0">as discussed in Chapter 6. There are also implementations of SKIR streams that stray far from</text>
<text top="924" left="108" width="702" height="16" font="0">the baseline. For example there is an implementation that works over TCP/IP sockets and an im-</text>
<text top="960" left="108" width="702" height="16" font="0">plementation that enables communication with discrete GPU devices. This ﬂexibility is a direct</text>
<text top="996" left="108" width="702" height="16" font="0">beneﬁt of the stream abstraction provided by the SKIR representation. Baseline stream commu-</text>
<text top="1032" left="108" width="702" height="16" font="0">nication is implemented by the SKIR compiler using concurrent lock-free queue operations on a</text>
<text top="1068" left="108" width="702" height="16" font="0">circular buffer. This data structure has been shown to efﬁciently support high speed communication</text>
</page>
<page number="86" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">72</text>
<text top="97" left="301" width="84" height="13" font="1">1: procedure</text>
<text top="99" left="390" width="33" height="11" font="3">PUSH</text>
<text top="97" left="423" width="53" height="13" font="1">(s, data)</text>
<text top="115" left="301" width="12" height="13" font="1">2:</text>
<text top="115" left="343" width="215" height="14" font="1">while NEXT(s.head) == s.tail do</text>
<text top="133" left="301" width="12" height="13" font="1">3:</text>
<text top="133" left="365" width="50" height="13" font="1">blocked</text>
<text top="151" left="301" width="12" height="13" font="1">4:</text>
<text top="151" left="343" width="61" height="13" font="1">end while</text>
<text top="169" left="301" width="12" height="13" font="1">5:</text>
<text top="169" left="343" width="138" height="13" font="1">s.buf [s.head] ← data</text>
<text top="187" left="301" width="12" height="13" font="1">6:</text>
<text top="187" left="343" width="155" height="14" font="1">s.head ←NEXT(s.head)</text>
<text top="205" left="301" width="111" height="13" font="1">7: end procedure</text>
<text top="241" left="301" width="84" height="13" font="1">8: procedure</text>
<text top="243" left="390" width="23" height="11" font="3">POP</text>
<text top="241" left="413" width="17" height="13" font="1">(s)</text>
<text top="259" left="301" width="12" height="13" font="1">9:</text>
<text top="259" left="343" width="166" height="13" font="1">while s.head == s.tail do</text>
<text top="277" left="295" width="19" height="13" font="1">10:</text>
<text top="277" left="367" width="50" height="13" font="1">blocked</text>
<text top="295" left="295" width="19" height="13" font="1">11:</text>
<text top="295" left="344" width="61" height="13" font="1">end while</text>
<text top="313" left="295" width="19" height="13" font="1">12:</text>
<text top="312" left="344" width="141" height="14" font="1">data ← s.buf [s.tail] 1</text>
<text top="331" left="295" width="19" height="13" font="1">13:</text>
<text top="330" left="344" width="139" height="14" font="1">s.tail ←NEXT(s.tail)</text>
<text top="349" left="295" width="19" height="13" font="1">14:</text>
<text top="348" left="344" width="74" height="13" font="1">return data</text>
<text top="366" left="295" width="119" height="13" font="1">15: end procedure</text>
<text top="402" left="295" width="92" height="13" font="1">16: procedure</text>
<text top="404" left="391" width="32" height="11" font="3">PEEK</text>
<text top="402" left="423" width="68" height="13" font="1">(s, of f set)</text>
<text top="420" left="295" width="19" height="13" font="1">17:</text>
<text top="420" left="344" width="191" height="13" font="1">while !available(s, of f set) do</text>
<text top="438" left="295" width="19" height="13" font="1">18:</text>
<text top="438" left="367" width="50" height="13" font="1">blocked</text>
<text top="456" left="295" width="19" height="13" font="1">19:</text>
<text top="456" left="344" width="61" height="13" font="1">end while</text>
<text top="474" left="295" width="19" height="13" font="1">20:</text>
<text top="474" left="344" width="270" height="14" font="1">data ← s.buf [NEXT(s.tail + of f set − 1)]</text>
<text top="492" left="295" width="19" height="13" font="1">21:</text>
<text top="492" left="344" width="74" height="13" font="1">return data</text>
<text top="510" left="295" width="119" height="13" font="1">22: end procedure</text>
<text top="546" left="295" width="92" height="13" font="1">23: procedure</text>
<text top="548" left="391" width="34" height="11" font="3">NEXT</text>
<text top="546" left="425" width="47" height="13" font="1">(index)</text>
<text top="564" left="295" width="19" height="13" font="1">24:</text>
<text top="564" left="344" width="225" height="14" font="1">return (index + 1)%BUFFER SIZE</text>
<text top="582" left="295" width="119" height="13" font="1">25: end procedure</text>
<text top="611" left="300" width="318" height="16" font="0">Figure 5.1: Basic lock free queue operations</text>
<text top="703" left="108" width="702" height="16" font="0">between processors in pipeline parallel applications as well as in streaming applications on shared</text>
<text top="739" left="108" width="702" height="16" font="0">memory multiprocessors [19][30]. The skir.push, skir.pop, and skir.peek operations</text>
<text top="775" left="108" width="702" height="16" font="0">for this data structure are shown in Figure 5.1. The available function referenced by the PEEK</text>
<text top="811" left="108" width="702" height="16" font="0">operation simply represents the calculation necessary to determine if there is data available at the</text>
<text top="847" left="108" width="702" height="16" font="0">given offset in the stream. During compilation, the low level code corresponding to the ﬁgure is</text>
<text top="883" left="108" width="702" height="16" font="0">emitted for each of the operations. A simpliﬁed version of the circular buffer data structure used</text>
<text top="919" left="108" width="702" height="16" font="0">by SKIR is shown in Figure 5.2. It contains the rates (if they are known), pointers to the source and</text>
<text top="955" left="108" width="702" height="16" font="0">destination kernels, the head and tail indexes, and the actual data buffer. Details such as alignment</text>
<text top="991" left="108" width="538" height="16" font="0">restrictions and padding to ensure proper cache line separation are omitted.</text>
</page>
<page number="87" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">73</text>
<text top="97" left="282" width="143" height="12" font="1">typedef struct {</text>
<text top="133" left="317" width="170" height="12" font="1">unsigned elem_size;</text>
<text top="151" left="317" width="117" height="12" font="1">int pop_rate;</text>
<text top="169" left="317" width="126" height="12" font="1">int push_rate;</text>
<text top="187" left="317" width="126" height="12" font="1">int peek_rate;</text>
<text top="223" left="317" width="90" height="14" font="1">void *src;</text>
<text top="223" left="425" width="143" height="12" font="1">// source kernel</text>
<text top="241" left="317" width="90" height="14" font="1">void *dst;</text>
<text top="241" left="425" width="188" height="12" font="1">// destination kernel</text>
<text top="277" left="317" width="108" height="12" font="1">size_t head;</text>
<text top="295" left="317" width="108" height="12" font="1">size_t tail;</text>
<text top="330" left="317" width="108" height="12" font="1">char buf[0];</text>
<text top="348" left="282" width="143" height="12" font="1">} skir_stream_t;</text>
<text top="376" left="205" width="509" height="16" font="0">Figure 5.2: Simpliﬁed version of the SKIR stream buffer data structure</text>
<text top="468" left="112" width="22" height="16" font="0">5.2</text>
<text top="468" left="170" width="207" height="16" font="0">Single Threaded Execution</text>
<text top="523" left="151" width="659" height="16" font="0">The challenge in providing efﬁcient implementations of the operations of Figure 5.1 is ﬁg-</text>
<text top="559" left="108" width="702" height="16" font="0">uring out how to implement lines 3, 10, and 18 in the ﬁgure. Because of the blocking semantics</text>
<text top="594" left="108" width="702" height="16" font="0">of the skir.push, skir.pop, and skir.peek operations, the easiest way to generate code</text>
<text top="630" left="108" width="702" height="16" font="0">for SKIR kernels is to place each kernel in its own operating system thread. Using this method,</text>
<text top="666" left="108" width="702" height="16" font="0">one can perform a simple translation of the stream operations into ones that sleep or busy-wait</text>
<text top="702" left="108" width="702" height="16" font="0">while input data or buffer space becomes available. The disadvantage of this approach is that for</text>
<text top="738" left="108" width="702" height="16" font="0">programs where the number of kernels is much higher than the number of processors, the overhead</text>
<text top="774" left="108" width="702" height="16" font="0">of thread creation, operating system context switching, and frequent signaling or busy-waiting is</text>
<text top="810" left="108" width="36" height="16" font="0">high.</text>
<text top="846" left="151" width="659" height="16" font="0">The only alternative to using a thread per kernel is to map multiple kernels into a single</text>
<text top="882" left="108" width="702" height="16" font="0">thread. Multiple SKIR kernels are scheduled onto a single thread using a form of cooperative</text>
<text top="918" left="108" width="702" height="16" font="0">multitasking. Cooperative multitasking is a well known scheme for sharing a resource such as</text>
<text top="954" left="108" width="702" height="16" font="0">a CPU between multiple tasks or processes. Under this scheme a task uses a resource until it is</text>
<text top="990" left="108" width="702" height="16" font="0">ﬁnished then relinquishes control back to the system so that the resource can be assigned to another</text>
<text top="1026" left="108" width="702" height="16" font="0">task. This stands in contrast with preemptive multitasking, where the underlying system forcefully</text>
<text top="1062" left="108" width="533" height="16" font="0">suspends the execution of a task so that another task may use the resource.</text>
</page>
<page number="88" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">74</text>
<text top="128" left="151" width="659" height="16" font="0">A problem with cooperative multitasking is that a single poorly written task can tie up the</text>
<text top="164" left="108" width="702" height="16" font="0">resources of a system and starve other tasks. This is not a problem for SKIR programs for several</text>
<text top="200" left="108" width="702" height="16" font="0">reasons. First of all, SKIR kernel work functions are implicitly looped and typically written to</text>
<text top="236" left="108" width="702" height="16" font="0">do a single unit of work. That is, they pop some inputs, perform some computation, push some</text>
<text top="272" left="108" width="702" height="16" font="0">output, then return. Second, the resource sharing is between tasks in the same program working</text>
<text top="308" left="108" width="702" height="16" font="0">toward a common goal. So as long as a kernel is doing useful work (i.e. the kernel is not buggy or</text>
<text top="344" left="108" width="702" height="16" font="0">malicious), forward progress is being made by the program and starvation is not a concern. Third,</text>
<text top="380" left="108" width="702" height="16" font="0">stream communication buffers are implemented as ﬁxed sized queues (despite being conceptually</text>
<text top="416" left="108" width="702" height="16" font="0">unbounded). This implies that a kernel can only execute until it runs out of input data or until it</text>
<text top="452" left="108" width="702" height="16" font="0">ﬁlls its output stream. Finally, the implementation of cooperative multitasking is controlled by the</text>
<text top="488" left="108" width="286" height="16" font="0">SKIR compiler, not by the programmer.</text>
<text top="524" left="151" width="659" height="16" font="0">Cooperative multitasking is obtained in SKIR by transforming program kernels into corou-</text>
<text top="560" left="108" width="702" height="16" font="0">tines. A coroutine is a special type of subroutine that can transfer control to another coroutine</text>
<text top="596" left="108" width="702" height="16" font="0">by executing a yield operation. When another coroutine yields execution back to the original</text>
<text top="632" left="108" width="702" height="16" font="0">coroutine, execution picks up where it left off. To the coroutine executing the yield, the operation</text>
<text top="668" left="108" width="329" height="16" font="0">looks just like and an ordinary procedure call.</text>
<text top="704" left="151" width="659" height="16" font="0">Coroutines naturally support producer-consumer relationships and this pattern is a common</text>
<text top="740" left="108" width="702" height="16" font="0">example of how coroutines can be used. Figure 5.3 shows an example of two coroutines in a</text>
<text top="776" left="108" width="702" height="16" font="0">producer-consumer relationship. In the ﬁgure, two coroutines communicate using a bounded</text>
<text top="812" left="108" width="702" height="16" font="0">queue. The program is executed by calling the sched routine, which initially calls produce.</text>
<text top="848" left="108" width="702" height="16" font="0">The coroutine produce runs until it has ﬁlled the queue. It then yields execution back to the</text>
<text top="885" left="108" width="54" height="14" font="0">sched</text>
<text top="884" left="167" width="643" height="16" font="0">routine, returning the address of the next routine to run (consume). Thus the consume</text>
<text top="920" left="108" width="702" height="16" font="0">coroutine will run next, drain the queue, yield control back to sched, and the whole process starts</text>
<text top="956" left="108" width="702" height="16" font="0">over again. This form of coroutines is often used to implement generators. The yield statement</text>
<text top="992" left="108" width="702" height="16" font="0">returns a value just like a return statement but does not unwind the call stack. Instead, it sus-</text>
<text top="1027" left="108" width="702" height="16" font="0">pends execution of the current coroutine then jumps to the calling function. When the coroutine is</text>
<text top="1063" left="108" width="580" height="16" font="0">called again later, execution resumes immediately following the original yield.</text>
</page>
<page number="89" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">75</text>
<text top="97" left="295" width="143" height="12" font="1">produce(queue q)</text>
<text top="115" left="295" width="9" height="12" font="1">{</text>
<text top="133" left="313" width="126" height="12" font="1">while (true) {</text>
<text top="151" left="331" width="197" height="12" font="1">while (q.not_full()) {</text>
<text top="169" left="349" width="90" height="12" font="1">data = ...</text>
<text top="187" left="349" width="152" height="12" font="1">q.push_back(data)</text>
<text top="205" left="331" width="9" height="12" font="1">}</text>
<text top="223" left="331" width="126" height="12" font="1">yield(consume)</text>
<text top="241" left="313" width="9" height="12" font="1">}</text>
<text top="259" left="295" width="9" height="12" font="1">}</text>
<text top="295" left="295" width="143" height="12" font="1">consume(queue q)</text>
<text top="313" left="295" width="9" height="12" font="1">{</text>
<text top="330" left="313" width="126" height="12" font="1">while (true) {</text>
<text top="348" left="331" width="206" height="12" font="1">while (q.not_empty()) {</text>
<text top="366" left="349" width="224" height="12" font="1">data = queue.pop_front();</text>
<text top="384" left="349" width="27" height="12" font="1">...</text>
<text top="402" left="331" width="9" height="12" font="1">}</text>
<text top="420" left="331" width="126" height="12" font="1">yield(produce)</text>
<text top="438" left="313" width="9" height="12" font="1">}</text>
<text top="456" left="295" width="9" height="12" font="1">}</text>
<text top="492" left="295" width="63" height="12" font="1">sched()</text>
<text top="510" left="295" width="9" height="12" font="1">{</text>
<text top="528" left="313" width="108" height="12" font="1">fn = produce</text>
<text top="546" left="313" width="197" height="12" font="1">while (true) fn = fn()</text>
<text top="564" left="295" width="9" height="12" font="1">}</text>
<text top="591" left="252" width="413" height="16" font="0">Figure 5.3: An example of producer-consumer coroutines</text>
<text top="683" left="151" width="659" height="16" font="0">We can extend the ideas of Figure 5.3 to the scheduling of stream parallelism. Figure 5.4</text>
<text top="719" left="108" width="702" height="16" font="0">shows the SKIR stream operations from Figure 5.1 using coroutine semantics to implement block-</text>
<text top="755" left="108" width="702" height="16" font="0">ing. If we then inline these operations into the SKIR TRANSDUCER kernel from Figure 3.2, we</text>
<text top="791" left="108" width="702" height="16" font="0">get something like the kernel CORO TRANSDUCER shown in Figure 5.5. The use of coroutines</text>
<text top="827" left="108" width="702" height="16" font="0">allows the SKIR scheduler to suspend the execution of a kernel work function without resorting to</text>
<text top="863" left="108" width="415" height="16" font="0">unwieldy code transformations such as stack ripping [17].</text>
<text top="899" left="151" width="659" height="16" font="0">The translation of the kernel from SKIR TRANSDUCER to CORO TRANSDUCER is essen-</text>
<text top="935" left="108" width="702" height="16" font="0">tially the code transformation that must be performed by the SKIR compiler during code generation</text>
<text top="971" left="108" width="702" height="16" font="0">in order to use coroutine scheduling. This transformation is described in more detail in Chapter</text>
<text top="1007" left="108" width="702" height="16" font="0">6. In Figure 5.5, the skir.pop and skir.push operations have been expanded into two parts.</text>
<text top="1043" left="108" width="702" height="16" font="0">The ﬁrst part of the expanded skir.pop (skir.push) checks to see if there is data (space)</text>
</page>
<page number="90" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">76</text>
<text top="97" left="301" width="84" height="13" font="1">1: procedure</text>
<text top="99" left="390" width="33" height="11" font="3">PUSH</text>
<text top="97" left="423" width="53" height="13" font="1">(s, data)</text>
<text top="115" left="301" width="12" height="13" font="1">2:</text>
<text top="115" left="343" width="215" height="14" font="1">while NEXT(s.head) == s.tail do</text>
<text top="133" left="301" width="12" height="13" font="1">3:</text>
<text top="133" left="365" width="66" height="13" font="1">yield s.dst</text>
<text top="151" left="301" width="12" height="13" font="1">4:</text>
<text top="151" left="343" width="61" height="13" font="1">end while</text>
<text top="169" left="301" width="12" height="13" font="1">5:</text>
<text top="169" left="343" width="138" height="13" font="1">s.buf [s.head] ← data</text>
<text top="187" left="301" width="12" height="13" font="1">6:</text>
<text top="187" left="343" width="155" height="14" font="1">s.head ←NEXT(s.head)</text>
<text top="205" left="301" width="111" height="13" font="1">7: end procedure</text>
<text top="241" left="301" width="84" height="13" font="1">8: procedure</text>
<text top="243" left="390" width="23" height="11" font="3">POP</text>
<text top="241" left="413" width="17" height="13" font="1">(s)</text>
<text top="259" left="301" width="12" height="13" font="1">9:</text>
<text top="259" left="343" width="166" height="13" font="1">while s.head == s.tail do</text>
<text top="277" left="295" width="19" height="13" font="1">10:</text>
<text top="277" left="367" width="66" height="13" font="1">yield s.src</text>
<text top="295" left="295" width="19" height="13" font="1">11:</text>
<text top="295" left="344" width="61" height="13" font="1">end while</text>
<text top="313" left="295" width="19" height="13" font="1">12:</text>
<text top="312" left="344" width="130" height="13" font="1">data ← s.buf [s.tail]</text>
<text top="331" left="295" width="19" height="13" font="1">13:</text>
<text top="330" left="344" width="139" height="14" font="1">s.tail ←NEXT(s.tail)</text>
<text top="349" left="295" width="19" height="13" font="1">14:</text>
<text top="348" left="344" width="74" height="13" font="1">return data</text>
<text top="366" left="295" width="119" height="13" font="1">15: end procedure</text>
<text top="402" left="295" width="92" height="13" font="1">16: procedure</text>
<text top="404" left="391" width="32" height="11" font="3">PEEK</text>
<text top="402" left="423" width="68" height="13" font="1">(s, of f set)</text>
<text top="420" left="295" width="19" height="13" font="1">17:</text>
<text top="420" left="344" width="191" height="13" font="1">while !available(s, of f set) do</text>
<text top="438" left="295" width="19" height="13" font="1">18:</text>
<text top="438" left="367" width="66" height="13" font="1">yield s.src</text>
<text top="456" left="295" width="19" height="13" font="1">19:</text>
<text top="456" left="344" width="61" height="13" font="1">end while</text>
<text top="474" left="295" width="19" height="13" font="1">20:</text>
<text top="474" left="344" width="270" height="14" font="1">data ← s.buf [NEXT(s.tail + of f set − 1)]</text>
<text top="492" left="295" width="19" height="13" font="1">21:</text>
<text top="492" left="344" width="74" height="13" font="1">return data</text>
<text top="510" left="295" width="119" height="13" font="1">22: end procedure</text>
<text top="546" left="295" width="92" height="13" font="1">23: procedure</text>
<text top="548" left="391" width="34" height="11" font="3">NEXT</text>
<text top="546" left="425" width="47" height="13" font="1">(index)</text>
<text top="564" left="295" width="19" height="13" font="1">24:</text>
<text top="564" left="344" width="225" height="14" font="1">return (index + 1)%BUFFER SIZE</text>
<text top="582" left="295" width="119" height="13" font="1">25: end procedure</text>
<text top="611" left="289" width="340" height="16" font="0">Figure 5.4: Yielding lock free queue operations</text>
<text top="703" left="108" width="702" height="16" font="0">available in the stream buffer. If there is not, then the kernel yields to the kernel attached the</text>
<text top="739" left="108" width="702" height="16" font="0">other end of the stream. If there is, then the second part of the expanded operation can proceed.</text>
<text top="775" left="108" width="702" height="16" font="0">For skir.pop, this means reading data out of the stream buffer. For skir.push, this means</text>
<text top="811" left="108" width="234" height="16" font="0">writing data to the stream buffer.</text>
<text top="847" left="151" width="659" height="16" font="0">In Figure 5.3, the producer and consumer coroutines are scheduled using a very simple</text>
<text top="883" left="108" width="702" height="16" font="0">scheduler – it simply runs the coroutine yielded by the previous coroutine. In the SKIR form</text>
<text top="919" left="108" width="702" height="16" font="0">of coroutine this does not work because we have kernel work function coroutines that sometimes</text>
<text top="955" left="108" width="702" height="16" font="0">return another kernel coroutine (when they are blocked) and sometimes return a boolean (when</text>
<text top="991" left="108" width="702" height="16" font="0">they are not blocked). Instead, a scheduling routine like the one in Figure 5.6 can be used. Using</text>
<text top="1027" left="108" width="702" height="16" font="0">this scheduling algorithm, a single thread is assigned some number of coroutines (i.e. kernel work</text>
<text top="1063" left="108" width="702" height="16" font="0">functions) to execute. The coroutines are added to a single work queue, named run q in the ﬁg-</text>
</page>
<page number="91" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">77</text>
<text top="196" left="124" width="36" height="12" font="1">bool</text>
<text top="214" left="124" width="251" height="14" font="1">SKIR_TRANSDUCER (int *state,</text>
<text top="232" left="277" width="108" height="14" font="1">void *ins[],</text>
<text top="250" left="277" width="117" height="14" font="1">void *outs[])</text>
<text top="268" left="124" width="9" height="12" font="1">{</text>
<text top="286" left="160" width="45" height="12" font="1">int d</text>
<text top="304" left="160" width="134" height="12" font="1">skir.pop(0, &amp;d)</text>
<text top="322" left="160" width="126" height="14" font="1">data += *state</text>
<text top="340" left="160" width="143" height="12" font="1">skir.push(0, &amp;d)</text>
<text top="358" left="160" width="108" height="12" font="1">return false</text>
<text top="376" left="124" width="9" height="12" font="1">}</text>
<text top="98" left="412" width="54" height="14" font="1">void *</text>
<text top="116" left="412" width="242" height="14" font="1">CORO_TRANSDUCER(int *state,</text>
<text top="134" left="556" width="108" height="14" font="1">void *ins[],</text>
<text top="152" left="556" width="117" height="14" font="1">void *outs[])</text>
<text top="169" left="412" width="9" height="12" font="1">{</text>
<text top="187" left="448" width="224" height="12" font="1">skir_stream_t in = ins[0]</text>
<text top="205" left="448" width="242" height="12" font="1">skir_stream_t out = outs[0]</text>
<text top="241" left="448" width="99" height="12" font="1">// skir.pop</text>
<text top="259" left="448" width="251" height="12" font="1">while (in-&gt;head == in-&gt;tail)</text>
<text top="277" left="484" width="134" height="12" font="1">yield (in-&gt;src)</text>
<text top="313" left="448" width="323" height="14" font="1">int d = in-&gt;buf[ in-&gt;tail ] + *state</text>
<text top="349" left="448" width="108" height="12" font="1">// skir.push</text>
<text top="367" left="448" width="323" height="12" font="1">while (NEXT(out-&gt;head) == out-&gt;tail)</text>
<text top="385" left="484" width="143" height="12" font="1">yield (out-&gt;dst)</text>
<text top="403" left="448" width="224" height="12" font="1">out-&gt;buf[ out-&gt;head ] = d</text>
<text top="421" left="448" width="242" height="12" font="1">out-&gt;head = NEXT(out-&gt;head)</text>
<text top="456" left="448" width="72" height="12" font="1">return 0</text>
<text top="474" left="412" width="9" height="12" font="1">}</text>
<text top="502" left="159" width="600" height="16" font="0">Figure 5.5: An example of transforming a SKIR kernel to use coroutine scheduling.</text>
<text top="545" left="241" width="197" height="14" font="1">kernel_coro *next = 0;</text>
<text top="581" left="241" width="296" height="12" font="1">// while there are kernels to run</text>
<text top="599" left="241" width="179" height="12" font="1">while (run_q.size())</text>
<text top="617" left="241" width="9" height="12" font="1">{</text>
<text top="635" left="277" width="134" height="14" font="1">kernel_coro *k;</text>
<text top="670" left="277" width="386" height="12" font="1">// only run kernels assigned to this thread</text>
<text top="688" left="277" width="224" height="12" font="1">if (run_q.contains(next))</text>
<text top="706" left="313" width="287" height="12" font="1">k = run_q.find_and_remove(next);</text>
<text top="724" left="277" width="36" height="12" font="1">else</text>
<text top="742" left="313" width="197" height="12" font="1">k = run_q.pop_front();</text>
<text top="778" left="277" width="81" height="12" font="1">next = 0;</text>
<text top="796" left="277" width="36" height="12" font="1">do {</text>
<text top="814" left="295" width="99" height="12" font="1">next = k();</text>
<text top="832" left="277" width="170" height="12" font="1">} while (next == 0)</text>
<text top="868" left="277" width="269" height="12" font="1">// k returned true, it is done</text>
<text top="886" left="277" width="206" height="12" font="1">if (next &amp; 1) continue;</text>
<text top="921" left="277" width="108" height="12" font="1">// k yielded</text>
<text top="939" left="277" width="170" height="12" font="1">run_q.push_back(k);</text>
<text top="957" left="241" width="9" height="12" font="1">}</text>
<text top="985" left="124" width="669" height="16" font="0">Figure 5.6: A single threaded scheduling algorithm for coroutine style kernel work functions.</text>
</page>
<page number="92" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">78</text>
<text top="128" left="108" width="702" height="16" font="0">ure, during the execution of the skir.call operation. The main outer loop of the scheduling</text>
<text top="164" left="108" width="702" height="16" font="0">algorithm runs as long as there are kernel coroutines present in the work queue. Each iteration</text>
<text top="200" left="108" width="702" height="16" font="0">of this loop ﬁrst checks the value of the next pointer against the contents of run q. If next is</text>
<text top="236" left="108" width="702" height="16" font="0">found in the queue, it is removed from the queue and executed. Otherwise, the kernel at the front</text>
<text top="272" left="108" width="702" height="16" font="0">of the queue is removed and executed. As mentioned above, the return value of a kernel work</text>
<text top="308" left="108" width="702" height="16" font="0">function coroutine can be a boolean or it can be the address of another coroutine. It is easy to</text>
<text top="344" left="108" width="702" height="16" font="0">represent boolean values within pointers using the old trick of pointer tagging. A pointer with its</text>
<text top="380" left="108" width="702" height="16" font="0">low order bit set represents true, while a null pointer represents false. Because pointers are always</text>
<text top="416" left="108" width="702" height="16" font="0">aligned to at least byte boundaries, the low bit of a valid address is never set. After executing a</text>
<text top="452" left="108" width="702" height="16" font="0">kernel work function coroutine, the scheduling algorithm checks this low order bit. If the bit is</text>
<text top="488" left="108" width="702" height="16" font="0">set, then the kernel returned true, indicating that it has ﬁnished. If the bit is not set, the kernel is</text>
<text top="524" left="108" width="702" height="16" font="0">either blocked and yielded a pointer to a coroutine, or it returned false indicating that it returned</text>
<text top="560" left="108" width="702" height="16" font="0">normally and is ready to run again. The inner loop of the scheduling algorithm runs the kernel until</text>
<text top="596" left="108" width="702" height="16" font="0">it becomes blocked or returns true. If the inner loop was exited because the kernel work function</text>
<text top="632" left="108" width="442" height="16" font="0">coroutine yielded, it is re-added to the end of the work queue.</text>
<text top="668" left="151" width="659" height="16" font="0">The left side of Figure 5.7 shows the operation of the single threaded coroutine scheduling</text>
<text top="704" left="108" width="702" height="16" font="0">algorithm running the balanced three stage pipeline shown on the right side of the ﬁgure. The</text>
<text top="740" left="108" width="702" height="16" font="0">large block arrows represent the execution of program kernels and the horizontal arrows represent</text>
<text top="776" left="108" width="702" height="16" font="0">scheduling events. We can assume the three kernels have been added the work queue in the order</text>
<text top="812" left="108" width="702" height="16" font="0">K0, K1, K2 and that all input and output rates are one. The portions of the ﬁgure that correspond to</text>
<text top="848" left="108" width="702" height="16" font="0">overhead introduced by the scheduler and the portions of the ﬁgure that correspond to work present</text>
<text top="884" left="108" width="702" height="16" font="0">in the original program are labeled. Clearly, the ratio of work to overhead is not to scale in this</text>
<text top="920" left="108" width="63" height="16" font="0">diagram.</text>
<text top="956" left="151" width="659" height="16" font="0">The scheduling algorithm begins by executing kernel K0. According to the algorithm, K0</text>
<text top="992" left="108" width="702" height="16" font="0">will run until there is no buffer space available for it to write data to its output stream. It will then</text>
<text top="1027" left="108" width="702" height="16" font="0">yield the blocking kernel, K1, to the scheduling algorithm. K1 then runs until it has consumed</text>
<text top="1063" left="108" width="702" height="16" font="0">all the data in its input stream or it has ﬁlled its output stream. In this example, these conditions</text>
</page>
<page number="93" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">79</text>
<text top="632" left="108" width="702" height="16" font="0">Figure 5.7: An example of single threaded execution of a three stage pipeline. The large downward</text>
<text top="654" left="108" width="702" height="16" font="0">arrows represent work being done by a kernel, the dotted lines represent work stealing, and the</text>
<text top="675" left="108" width="466" height="16" font="0">horizontal arrows represent scheduling events. Time ﬂows down.</text>
<text top="767" left="108" width="702" height="16" font="0">happen at the same time but K1 will encounter the empty input stream ﬁrst. Thus K0 executes</text>
<text top="803" left="108" width="702" height="16" font="0">next, and continues executing until it ﬁlls the buffer for its output stream. At this point K0 will</text>
<text top="839" left="108" width="702" height="16" font="0">yield to K1, which will immediately yield to K2. Kernel K2 runs until it consumes all its input,</text>
<text top="875" left="108" width="702" height="16" font="0">then yields to K1, which does the same. The state of the program is now the same as it was during</text>
<text top="911" left="108" width="702" height="16" font="0">a previous iteration of the scheduling loop (i.e. K1 has a full output buffer, but all other stream</text>
<text top="947" left="108" width="702" height="16" font="0">buffers are empty). For this example, we can observe the steady state execution schedule, K1 →</text>
<text top="983" left="108" width="465" height="16" font="0">K0 → K2. This is depicted by the dotted line arrow in the ﬁgure.</text>
</page>
<page number="94" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">80</text>
<text top="128" left="112" width="22" height="16" font="0">5.3</text>
<text top="128" left="170" width="192" height="16" font="0">Multithreaded Execution</text>
<text top="183" left="151" width="659" height="16" font="0">Coroutines alone do not provide parallel execution. To obtain parallel execution, we intro-</text>
<text top="219" left="108" width="702" height="16" font="0">duce the concept of task stealing into our scheduler. In task stealing systems, the total work to be</text>
<text top="255" left="108" width="702" height="16" font="0">done by a program is divided up into smaller tasks which can be executed in parallel. The tasks</text>
<text top="291" left="108" width="702" height="16" font="0">execute the work of the program and may spawn more tasks to further divide up their workload.</text>
<text top="327" left="108" width="702" height="16" font="0">Some number of worker threads (usually the number of processors) execute the tasks. When a task</text>
<text top="363" left="108" width="702" height="16" font="0">is spawned, it is placed in a work queue local to the currently executing worker thread. After a</text>
<text top="399" left="108" width="702" height="16" font="0">worker thread ﬁnishes a task, it looks in its work queue for more work. If the local queue is empty,</text>
<text top="435" left="108" width="702" height="16" font="0">then the worker thread randomly chooses another worker thread and attempts to steal tasks from</text>
<text top="471" left="108" width="140" height="16" font="0">that thread’s queue.</text>
<text top="507" left="151" width="659" height="16" font="0">The work stealing algorithm for parallel execution described in this dissertation is built on</text>
<text top="542" left="108" width="702" height="16" font="0">top the algorithm found in Intel Thread Building Blocks (TBB) [6]. In this framework, tasks are</text>
<text top="578" left="108" width="12" height="16" font="0">C</text>
<text top="578" left="118" width="17" height="13" font="1">++</text>
<text top="578" left="140" width="670" height="16" font="0">objects containing a method named execute. Each worker thread contains a double ended</text>
<text top="614" left="108" width="496" height="16" font="0">work queue (deque) and uses the following algorithm to obtain tasks:</text>
<text top="665" left="141" width="669" height="16" font="0">(1) Get the task returned by method execute for the previous task. This rule does not apply</text>
<text top="701" left="171" width="212" height="16" font="0">if execute returned NULL.</text>
<text top="751" left="141" width="669" height="16" font="0">(2) Pop a task from the bottom of its own deque. This rule does not apply if the deque is</text>
<text top="787" left="171" width="48" height="16" font="0">empty.</text>
<text top="838" left="141" width="669" height="16" font="0">(3) Steal a task from the top of another randomly chosen deque. If the chosen deque is empty,</text>
<text top="874" left="171" width="337" height="16" font="0">the thread tries this rule again until it succeeds.</text>
<text top="924" left="151" width="659" height="16" font="0">At a high level the SKIR parallel scheduling algorithm is similar to the single threaded algo-</text>
<text top="960" left="108" width="702" height="16" font="0">rithm in Figure 5.6. However, instead of explicitly running the kernel coroutines, the multithreaded</text>
<text top="996" left="108" width="310" height="16" font="0">SKIR scheduler creates TBB tasks called K</text>
<text top="998" left="419" width="50" height="13" font="1">ERNEL</text>
<text top="996" left="468" width="11" height="16" font="0">T</text>
<text top="998" left="479" width="30" height="13" font="1">ASK</text>
<text top="996" left="510" width="300" height="16" font="0">s, and spawns them for execution. Spawn-</text>
<text top="1032" left="108" width="702" height="16" font="0">ing a task causes the task to be pushed to the top of the currently executing worker thread’s deque.</text>
<text top="1068" left="108" width="702" height="16" font="0">It is also possible for the scheduler to recycle a completed task, which causes it to be pushed onto</text>
</page>
<page number="95" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">81</text>
<text top="128" left="108" width="702" height="16" font="0">the worker thread’s deque as if it were a freshly spawned task, but avoids some of the overheads</text>
<text top="164" left="108" width="373" height="16" font="0">associated with allocating and spawning a new task.</text>
<text top="200" left="151" width="53" height="16" font="0">Each K</text>
<text top="203" left="205" width="50" height="13" font="1">ERNEL</text>
<text top="200" left="254" width="11" height="16" font="0">T</text>
<text top="203" left="264" width="30" height="13" font="1">ASK</text>
<text top="200" left="299" width="338" height="16" font="0">encapsulates one SKIR kernel coroutine. The K</text>
<text top="203" left="637" width="50" height="13" font="1">ERNEL</text>
<text top="200" left="686" width="11" height="16" font="0">T</text>
<text top="203" left="697" width="30" height="13" font="1">ASK</text>
<text top="200" left="728" width="23" height="16" font="0">::E</text>
<text top="203" left="752" width="61" height="13" font="1">XECUTE</text>
<text top="236" left="108" width="702" height="16" font="0">method is shown in Figure 5.8. This method is called whenever the task stealing scheduler selects</text>
<text top="272" left="108" width="702" height="16" font="0">a kernel to run. It runs the kernel’s work function until it ﬁnishes or until it yields a pointer to a</text>
<text top="308" left="108" width="702" height="16" font="0">blocking kernel. If a blocking kernel is returned and it is not active in the scheduler, then a new</text>
<text top="344" left="108" width="13" height="16" font="0">K</text>
<text top="346" left="122" width="50" height="13" font="1">ERNEL</text>
<text top="344" left="171" width="11" height="16" font="0">T</text>
<text top="346" left="182" width="30" height="13" font="1">ASK</text>
<text top="344" left="217" width="593" height="16" font="0">is allocated and spawned. Otherwise an attempt is made to steal the task corre-</text>
<text top="380" left="108" width="702" height="16" font="0">sponding to the blocking kernel. The steal may fail (e.g. if another thread stole it ﬁrst), returning</text>
<text top="416" left="108" width="702" height="16" font="0">zero. The current task is then recycled, which causes it to be placed back into the thread’s work</text>
<text top="452" left="108" width="702" height="16" font="0">queue and makes it available to be stolen by another thread. If a new task was spawned or stolen,</text>
<text top="488" left="108" width="702" height="16" font="0">it is returned to the scheduler which will then run that task immediately, bypassing work stealing.</text>
<text top="524" left="108" width="28" height="16" font="0">If E</text>
<text top="526" left="137" width="61" height="13" font="1">XECUTE</text>
<text top="524" left="203" width="600" height="16" font="0">returns zero, then the worker thread will revert to the basic work stealing algorithm.</text>
<text top="563" left="253" width="12" height="13" font="1">1:</text>
<text top="561" left="273" width="96" height="16" font="0">procedure K</text>
<text top="563" left="370" width="50" height="13" font="1">ERNEL</text>
<text top="561" left="419" width="11" height="16" font="0">T</text>
<text top="563" left="430" width="30" height="13" font="1">ASK</text>
<text top="561" left="461" width="23" height="16" font="0">::E</text>
<text top="563" left="485" width="61" height="13" font="1">XECUTE</text>
<text top="584" left="253" width="12" height="13" font="1">2:</text>
<text top="582" left="300" width="43" height="16" font="0">t ← 0</text>
<text top="606" left="253" width="12" height="13" font="1">3:</text>
<text top="604" left="300" width="48" height="16" font="0">repeat</text>
<text top="628" left="253" width="12" height="13" font="1">4:</text>
<text top="625" left="327" width="195" height="16" font="0">ret ← this.kernel.work()</text>
<text top="649" left="253" width="12" height="13" font="1">5:</text>
<text top="647" left="300" width="129" height="16" font="0">until ret = f alse</text>
<text top="671" left="253" width="12" height="13" font="1">6:</text>
<text top="669" left="300" width="142" height="16" font="0">if ret = true then</text>
<text top="693" left="253" width="12" height="13" font="1">7:</text>
<text top="691" left="327" width="138" height="16" font="0">/* ret is a kernel */</text>
<text top="714" left="253" width="12" height="13" font="1">8:</text>
<text top="712" left="327" width="247" height="16" font="0">if ret has not been spawned then</text>
<text top="736" left="253" width="12" height="13" font="1">9:</text>
<text top="734" left="354" width="136" height="16" font="0">t ← spawn new K</text>
<text top="737" left="491" width="50" height="13" font="1">ERNEL</text>
<text top="734" left="540" width="11" height="16" font="0">T</text>
<text top="737" left="550" width="30" height="13" font="1">ASK</text>
<text top="734" left="581" width="35" height="16" font="0">(ret)</text>
<text top="758" left="245" width="19" height="13" font="1">10:</text>
<text top="756" left="327" width="291" height="16" font="0">else if ret is not currently running then</text>
<text top="779" left="245" width="19" height="13" font="1">11:</text>
<text top="777" left="354" width="86" height="16" font="0">t ← steal K</text>
<text top="780" left="442" width="50" height="13" font="1">ERNEL</text>
<text top="777" left="491" width="11" height="16" font="0">T</text>
<text top="780" left="501" width="30" height="13" font="1">ASK</text>
<text top="777" left="536" width="137" height="16" font="0">associated with ret</text>
<text top="801" left="245" width="19" height="13" font="1">12:</text>
<text top="799" left="327" width="43" height="16" font="0">end if</text>
<text top="823" left="245" width="19" height="13" font="1">13:</text>
<text top="821" left="327" width="89" height="16" font="0">recycle this</text>
<text top="844" left="245" width="19" height="13" font="1">14:</text>
<text top="842" left="300" width="43" height="16" font="0">end if</text>
<text top="866" left="245" width="19" height="13" font="1">15:</text>
<text top="864" left="300" width="60" height="16" font="0">return t</text>
<text top="888" left="245" width="19" height="13" font="1">16:</text>
<text top="886" left="273" width="110" height="16" font="0">end procedure</text>
<text top="938" left="108" width="143" height="16" font="0">Figure 5.8: The K</text>
<text top="940" left="252" width="50" height="13" font="1">ERNEL</text>
<text top="938" left="301" width="11" height="16" font="0">T</text>
<text top="940" left="312" width="30" height="13" font="1">ASK</text>
<text top="938" left="343" width="23" height="16" font="0">::E</text>
<text top="940" left="367" width="61" height="13" font="1">XECUTE</text>
<text top="938" left="436" width="374" height="16" font="0">method runs the kernel work function and makes</text>
<text top="959" left="108" width="702" height="16" font="0">scheduling decisions in conjunction with a work stealing algorithm. The next task to run is re-</text>
<text top="981" left="108" width="50" height="16" font="0">turned.</text>
<text top="1049" left="151" width="659" height="16" font="0">Figure 5.9 shows the operation of the multithreaded scheduling algorithm running a three</text>
</page>
<page number="96" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">82</text>
<text top="717" left="108" width="702" height="16" font="0">Figure 5.9: An example of two processors executing a three stage pipeline. The large downward</text>
<text top="739" left="108" width="702" height="16" font="0">arrows represent work being done by a kernel, the dotted lines represent work stealing, and the</text>
<text top="760" left="108" width="466" height="16" font="0">horizontal arrows represent scheduling events. Time ﬂows down.</text>
<text top="852" left="108" width="702" height="16" font="0">stage pipeline, K0 → K1 → K2, using two worker threads. In this example, Processor 1 begins</text>
<text top="888" left="108" width="702" height="16" font="0">by executing kernel K0. Processor 2 begins by task stealing, and steals kernel K0 as soon as</text>
<text top="924" left="108" width="702" height="16" font="0">Processor 1 starts to run kernel K1. At this point kernel K0 runs in parallel with kernel K1 until</text>
<text top="960" left="108" width="300" height="16" font="0">kernel K1 runs out of output buffer space.</text>
<text top="996" left="151" width="659" height="16" font="0">The execution continues with K1 moving between processors one and two. The ﬁgure indi-</text>
<text top="1032" left="108" width="702" height="16" font="0">cates each time that a kernel is moved from one processor to the other as a steal. The initial steal</text>
</page>
<page number="97" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">83</text>
<text top="128" left="108" width="702" height="16" font="0">of K0 by Processor 2 is potentially the most expensive, because it was done by randomized task</text>
<text top="164" left="108" width="702" height="16" font="0">stealing. The steal of K1 by Processor 2 is less expensive, because the K0 kernel task identiﬁed</text>
<text top="200" left="108" width="702" height="16" font="0">K1 as the task to steal, bypassing the randomized task stealing algorithm. The subsequent steals of</text>
<text top="236" left="108" width="702" height="16" font="0">K1 are potentially the least expensive because they are also targeted steals and because it is more</text>
<text top="272" left="108" width="521" height="16" font="0">likely that the kernel code is already in the processor’s instruction cache.</text>
<text top="308" left="151" width="659" height="16" font="0">Because there are three kernels and two processors in the example, one of the processors</text>
<text top="344" left="108" width="702" height="16" font="0">is always producing data that the other is consuming. This can increase communication costs</text>
<text top="380" left="108" width="702" height="16" font="0">because the data must be communicated between processors through a shared cache or through</text>
<text top="416" left="108" width="702" height="16" font="0">system memory. This can be a much higher latency operation than communicating through the L1</text>
<text top="452" left="108" width="702" height="16" font="0">cache as would happen in a single threaded system. However, we can see in the ﬁgure that this</text>
<text top="488" left="108" width="702" height="16" font="0">occurs only part of the time. The rest of the time, data is written and read by kernels on the same</text>
<text top="524" left="108" width="702" height="16" font="0">processor, thus keeping the data in the L1 cache. Current hardware also uses techniques such as</text>
<text top="560" left="108" width="542" height="16" font="0">hardware prefetching to hide the cost of accessing higher levels of memory.</text>
<text top="596" left="151" width="659" height="16" font="0">We note that when Processor 2 steals K1, the scheduling algorithm is effectively choosing</text>
<text top="632" left="108" width="702" height="16" font="0">to communicate code instead of data, since there is already a full buffer of data in the processor’s</text>
<text top="668" left="108" width="702" height="16" font="0">cache. This is often a good choice, because the size of the data buffer is usually larger than the</text>
<text top="704" left="108" width="633" height="16" font="0">kernel code and because the kernel code will usually enjoy a much higher cache hit rate.</text>
<text top="761" left="112" width="22" height="16" font="0">5.4</text>
<text top="761" left="170" width="81" height="16" font="0">Discussion</text>
<text top="816" left="151" width="659" height="16" font="0">Overall this scheduling scheme has several nice properties. It is fairly simple and makes</text>
<text top="852" left="108" width="702" height="16" font="0">scheduling decisions in a distributed manner only using information local to the kernel that is</text>
<text top="888" left="108" width="702" height="16" font="0">executing and its immediate neighbors in the stream graph. It also maintains locality by choosing</text>
<text top="924" left="108" width="702" height="16" font="0">to run neighboring kernels when possible. Because it is a dynamic algorithm built on randomized</text>
<text top="960" left="108" width="360" height="16" font="0">task stealing, it naturally performs load balancing.</text>
<text top="996" left="151" width="659" height="16" font="0">The use of coroutines for scheduling stream parallel programs was ﬁrst proposed by Kahn</text>
<text top="1032" left="108" width="702" height="16" font="0">and MacQueen [40]. In their single threaded formulation, the execution of kernels is demand</text>
<text top="1068" left="108" width="46" height="15" font="0">driven</text>
<text top="1068" left="154" width="656" height="16" font="0">. As in SKIR, when a kernel attempts to read from an empty stream, that kernel is suspended</text>
</page>
<page number="98" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">84</text>
<text top="128" left="108" width="702" height="16" font="0">and the producer at the other end of the stream is activated. In addition, the empty stream is marked</text>
<text top="164" left="108" width="702" height="16" font="0">as hungry, indicating that the consumer is waiting for data. When data is written to a hungry</text>
<text top="200" left="108" width="702" height="16" font="0">stream, execution yields back to the consumer kernel. Demand driven schemes ensure that kernels</text>
<text top="236" left="108" width="702" height="16" font="0">never produce unnecessary results, but can result in an excessive number of context switches to</text>
<text top="272" left="108" width="136" height="16" font="0">propagate demand.</text>
<text top="308" left="151" width="659" height="16" font="0">To enable parallel execution, Kahn and MacQueen suggest that after writing data to a hungry</text>
<text top="344" left="108" width="702" height="16" font="0">stream and re-activating the consumer kernel, the producer kernel be allowed to continue execut-</text>
<text top="380" left="108" width="702" height="16" font="0">ing in anticipation of the consumer needing more data later on. This technique is an alternative</text>
<text top="416" left="108" width="702" height="16" font="0">to demand driven execution known as data driven execution. With data driven scheduling, ker-</text>
<text top="452" left="108" width="702" height="16" font="0">nels are allowed to execute as soon as they have enough input to run. That is, they are either</text>
<text top="488" left="108" width="702" height="16" font="0">blocking waiting for input, or they are running. The problem with this approach is that a kernel</text>
<text top="524" left="108" width="702" height="16" font="0">or an entire sub-graph of the program may produce unnecessary output which may also lead to</text>
<text top="560" left="108" width="702" height="16" font="0">unbounded accumulation of stream data [48]. Kahn and MacQueen addressed this problem by</text>
<text top="596" left="108" width="702" height="16" font="0">adding a parameter called an anticipation coefﬁcient, A, to their streams. When running in a data</text>
<text top="632" left="108" width="702" height="16" font="0">driven mode, a kernel was not allowed to write more than A unconsumed items to its output stream.</text>
<text top="668" left="108" width="702" height="16" font="0">The main problem with this approach is the overhead associated with keeping track of the number</text>
<text top="704" left="108" width="702" height="16" font="0">of unconsumed items and the overhead of context switching to propagate demand when A is too</text>
<text top="740" left="108" width="43" height="16" font="0">small.</text>
<text top="776" left="151" width="659" height="16" font="0">The SKIR scheduling algorithm improves on Kahn and MacQueen in several ways. First,</text>
<text top="812" left="108" width="702" height="16" font="0">by using work stealing, SKIR provides the potential for parallel execution, but does not require it.</text>
<text top="848" left="108" width="702" height="16" font="0">Parallel execution only occurs in a work stealing system if a task is actually stolen. This partially</text>
<text top="884" left="108" width="702" height="16" font="0">alleviates the problem of performing unnecessary work because the work is only performed if</text>
<text top="920" left="108" width="702" height="16" font="0">there is excess processing capacity in the system. Second, by using a ﬁxed sized circular buffer for</text>
<text top="956" left="108" width="702" height="16" font="0">the stream communication implementation, SKIR makes the backpressure mechanism provided</text>
<text top="992" left="108" width="702" height="16" font="0">by anticipation coefﬁcients implicit, rather than explicit. No additional calculation is needed other</text>
<text top="1027" left="108" width="702" height="16" font="0">than the standard enqueue and dequeue operations to guard against excessive data driven execution.</text>
<text top="1063" left="108" width="652" height="16" font="0">Finally, there is no need to maintain a distinction between hungry and non-hungry streams.</text>
</page>
<page number="99" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">85</text>
<text top="128" left="151" width="659" height="16" font="0">Parks presents a theoretical treatment of demand driven, data driven, and hybrid scheduling</text>
<text top="164" left="108" width="702" height="16" font="0">methods for Kahn process networks in his Ph.D. thesis [48]. He also gives two requirements that</text>
<text top="200" left="108" width="524" height="16" font="0">should be met by any scheduling mechanism for Kahn process networks:</text>
<text top="249" left="141" width="669" height="16" font="0">(1) Complete Execution – The scheduler should implement a complete execution of the Kahn</text>
<text top="285" left="171" width="639" height="16" font="0">process network program. In particular, if the program is non-terminating, then it should</text>
<text top="321" left="171" width="291" height="16" font="0">be executed forever without terminating.</text>
<text top="371" left="141" width="669" height="16" font="0">(2) Bounded Execution – The scheduler should, if possible, execute the Kahn process net-</text>
<text top="407" left="171" width="639" height="16" font="0">work program so that only a bounded number of tokens ever accumulate on any of the</text>
<text top="443" left="171" width="183" height="16" font="0">communication channels.</text>
<text top="492" left="108" width="702" height="16" font="0">Parks proves that limiting the capacity of stream buffers is sufﬁcient to ensure both requirements,</text>
<text top="528" left="108" width="702" height="16" font="0">with the exception that artiﬁcial deadlock may occur. To see how artiﬁcial deadlock is possible,</text>
<text top="564" left="108" width="702" height="16" font="0">simply imagine a SKIR kernel with a peek rate of 101 and a ﬁxed stream buffer size of 100. The</text>
<text top="600" left="108" width="702" height="16" font="0">input stream will never accumulate enough data for the kernel to become unblocked. Luckily it</text>
<text top="636" left="108" width="702" height="16" font="0">is easy to distinguish artiﬁcial deadlock from real deadlock. If artiﬁcial deadlock is present, all</text>
<text top="672" left="108" width="702" height="16" font="0">kernels will be blocked, and at least one kernel will be blocked trying to write to a full stream</text>
<text top="708" left="108" width="702" height="16" font="0">buffer. If real deadlock is present, all kernels will be blocked on empty buffers. To eliminate</text>
<text top="744" left="108" width="702" height="16" font="0">artiﬁcial deadlock while maintaining bounded execution (i.e. requirement 2 above), it is sufﬁcient</text>
<text top="780" left="108" width="648" height="16" font="0">to increase the size of the smallest full buffer whenever artiﬁcial deadlock is detected [48].</text>
<text top="816" left="151" width="659" height="16" font="0">Because the SKIR scheduling mechanism uses a hybrid of data and demand driven execution,</text>
<text top="852" left="108" width="702" height="16" font="0">and because it uses bounded stream buffers, SKIR meets both of Parks’ requirements for a dynamic</text>
<text top="888" left="108" width="702" height="16" font="0">scheduler of process networks. In addition, for programs with a bounded number of kernels, the</text>
<text top="924" left="108" width="702" height="16" font="0">scheduling algorithm uses a bounded amount of memory for task allocation. This follows from the</text>
<text top="960" left="108" width="702" height="16" font="0">fact that the algorithm in Figure 5.8 never allocates more tasks than there are kernels in the stream</text>
<text top="996" left="108" width="702" height="16" font="0">graph. Similarly, kernels have a ﬁnite number of input and output streams so the system will never</text>
<text top="1032" left="108" width="351" height="16" font="0">allocate an unbounded number of stream buffers.</text>
<text top="1068" left="151" width="659" height="16" font="0">We have implemented the D4R deadlock detection algorithm [20] in SKIR for completeness</text>
</page>
<page number="100" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">86</text>
<text top="128" left="108" width="702" height="16" font="0">and to ensure that our scheduling algorithm is not incompatible with low overhead detection. The</text>
<text top="164" left="108" width="702" height="16" font="0">D4R distributed algorithm detects both local and global deadlock, makes a distinction between</text>
<text top="200" left="108" width="702" height="16" font="0">artiﬁcial and true deadlock, and identiﬁes the bottleneck stream buffer. Like our scheduling al-</text>
<text top="236" left="108" width="702" height="16" font="0">gorithm it never requires global data and only requires that kernels share information with their</text>
<text top="272" left="108" width="702" height="16" font="0">immediate neighbors. Because both artiﬁcial and true deadlock are exceptional conditions we can</text>
<text top="308" left="108" width="702" height="16" font="0">allow the detection algorithm to converge slowly. We take advantage of this fact by executing the</text>
<text top="344" left="108" width="702" height="16" font="0">algorithm on a sampled basis. That is, we do not run the algorithm each time a kernel blocks.</text>
<text top="380" left="108" width="702" height="16" font="0">This has no impact on the correctness or convergence of the algorithm and allows it to run with</text>
<text top="416" left="108" width="146" height="16" font="0">negligible overhead.</text>
<text top="452" left="151" width="659" height="16" font="0">The benchmarks we run on SKIR do not suffer from artiﬁcial deadlock. For such a situation</text>
<text top="488" left="108" width="702" height="16" font="0">to occur a program must require more data in ﬂight between two kernels than the stream buffers</text>
<text top="524" left="108" width="702" height="16" font="0">on the path between them can hold. In the implementation of SKIR we study in this thesis, stream</text>
<text top="560" left="108" width="702" height="16" font="0">buffers are more than large enough for most applications. In addition, an application that requires a</text>
<text top="596" left="108" width="702" height="16" font="0">large amount of data in ﬂight often packages such data into its own data buffers or structured pack-</text>
<text top="632" left="108" width="702" height="16" font="0">ets then communicates pointers to this data between kernels. This is done for reasons of efﬁciency</text>
<text top="668" left="108" width="702" height="16" font="0">and is how the dedup and swps3 benchmarks used in our evaluation (Chapter 7) were originally</text>
<text top="704" left="108" width="702" height="16" font="0">written. Because we do not have a use case for artiﬁcial deadlock, we have not implemented arti-</text>
<text top="740" left="108" width="702" height="16" font="0">ﬁcial deadlock mitigation. Since SKIR is implemented as a JIT compiler, such an implementation</text>
<text top="776" left="108" width="435" height="16" font="0">would simply JIT compile new kernels to use a larger buffer.</text>
</page>
<page number="101" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 6</text>
<text top="292" left="387" width="144" height="16" font="0">SKIR Compilation</text>
<text top="408" left="151" width="659" height="16" font="0">The SKIR compiler is implemented as a just-in-time (JIT) compiler. Runtime compilation</text>
<text top="444" left="108" width="702" height="16" font="0">is driven by the execution of the program and can be broadly divided into three parts: kernel</text>
<text top="480" left="108" width="59" height="15" font="0">analysis</text>
<text top="479" left="167" width="643" height="16" font="0">, which determines static characteristics of kernel work functions; kernel specialization,</text>
<text top="515" left="108" width="702" height="16" font="0">which optimizes kernel work functions using the results of kernel analysis; and code generation,</text>
<text top="551" left="108" width="702" height="16" font="0">which lowers the SKIR representation to vanilla LLVM bitcode, runs standard compiler optimiza-</text>
<text top="587" left="108" width="702" height="16" font="0">tion passes, and performs machine code generation. These phases of compilation are closely tied</text>
<text top="623" left="108" width="702" height="16" font="0">to the dynamic scheduling mechanisms described in Chapter 5. Together, the dynamic compila-</text>
<text top="659" left="108" width="702" height="16" font="0">tion and scheduling techniques described in this thesis provide efﬁcient parallel execution of SKIR</text>
<text top="695" left="108" width="72" height="16" font="0">programs.</text>
<text top="731" left="151" width="659" height="16" font="0">This chapter also describes three additional uses of the JIT compiler for high level code trans-</text>
<text top="767" left="108" width="702" height="16" font="0">formation: reduction of parallelism using dynamic kernel fusion, parallel execution of data parallel</text>
<text top="803" left="108" width="702" height="16" font="0">kernels using dynamic kernel ﬁssion, and acceleration of kernels on heterogeneous hardware using</text>
<text top="839" left="108" width="152" height="16" font="0">an OpenCL backend.</text>
<text top="897" left="112" width="22" height="16" font="0">6.1</text>
<text top="897" left="170" width="291" height="16" font="0">Static vs. Dynamic SKIR Compilation</text>
<text top="952" left="151" width="659" height="16" font="0">For some application domains, it may be preferable to compile some or all of a stream par-</text>
<text top="988" left="108" width="702" height="16" font="0">allel program graph using existing static techniques. Examples of this type of application domain</text>
<text top="1024" left="108" width="702" height="16" font="0">are compiling a synchronous dataﬂow graph to target a FPGA or compiling a DSP algorithm for</text>
<text top="1060" left="108" width="702" height="16" font="0">embedded hardware. In both of these cases, dynamic JIT compilation makes little sense, due to</text>
</page>
<page number="102" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">88</text>
<text top="128" left="108" width="702" height="16" font="0">very high compilation time (e.g. place and route time for an FPGA), or completely static program</text>
<text top="164" left="108" width="435" height="16" font="0">and platform characteristics (e.g. an embedded DSP design).</text>
<text top="200" left="151" width="659" height="16" font="0">Despite the fact that SKIR is implemented as a dynamic compiler and runtime for this thesis,</text>
<text top="236" left="108" width="702" height="16" font="0">the representation itself is not restricted to a dynamic model. In most situations the compilation</text>
<text top="272" left="108" width="702" height="16" font="0">of individual kernels could be implemented as an ordinary ahead-of-time compiler (i.e. not JIT).</text>
<text top="308" left="108" width="702" height="16" font="0">In general, however, it is not possible for a SKIR compiler to extract a static graph structure from</text>
<text top="344" left="108" width="702" height="16" font="0">a SKIR program. A simple example of why this is not always possible is a stream graph that is</text>
<text top="380" left="108" width="702" height="16" font="0">constructed differently depending on runtime parameters. StreamIt programs, for example, contain</text>
<text top="416" left="108" width="702" height="16" font="0">static program graphs but allow values calculated at runtime to determine the number of stages in</text>
<text top="452" left="108" width="702" height="16" font="0">a pipeline, the number of children kernels in a split-join, or the input and output rates of kernels.</text>
<text top="488" left="108" width="702" height="16" font="0">Techniques that perform complex static transformations on StreamIt programs simply choose to</text>
<text top="524" left="108" width="311" height="16" font="0">ignore this subset of the StreamIt language.</text>
<text top="560" left="151" width="659" height="16" font="0">To enable static compilation, a front-end compiler or programmer generating SKIR code</text>
<text top="596" left="108" width="702" height="16" font="0">only needs to make the structure of the stream graph obvious to a static SKIR compiler. Consider</text>
<text top="632" left="108" width="702" height="16" font="0">for example the SKIR C program shown in Figure 6.1. It should be obvious that this program is</text>
<text top="668" left="108" width="702" height="16" font="0">easily analyzable and that a compiler would be able to extract the structure of the stream graph</text>
<text top="704" left="108" width="702" height="16" font="0">by examining the skir.kernel and skir.call operations and the kernels and streams they</text>
<text top="740" left="108" width="702" height="16" font="0">reference. In fact, a SKIR compiler pass exists to do just that. If we run this pass on SKIR bitcode</text>
<text top="776" left="108" width="702" height="16" font="0">from the command line, it prints any static graph structures found in the program. For example,</text>
<text top="812" left="108" width="333" height="16" font="0">we can run it on the code shown in Figure 6.1:</text>
<text top="852" left="144" width="502" height="12" font="1">$ llvm-g++ -emit-llvm -c -o simple_add.bc simple_add.cpp</text>
<text top="870" left="144" width="520" height="12" font="1">$ opt -skir-c-to-intr &lt; simple_add.bc &gt; simple_add-skir.bc</text>
<text top="888" left="144" width="529" height="12" font="1">$ opt -skir-extract-graph -o=/dev/null &lt; simple_add-skir.bc</text>
<text top="906" left="144" width="81" height="12" font="1">digraph {</text>
<text top="924" left="162" width="457" height="12" font="1">_ZL15simple_0_1_workPvPS_S0_ -&gt; _Z8add_workPvPS_S0_</text>
<text top="942" left="162" width="457" height="12" font="1">_ZL15simple_0_1_workPvPS_S0_ -&gt; _Z8add_workPvPS_S0_</text>
<text top="959" left="162" width="466" height="12" font="1">_Z8add_workPvPS_S0_ -&gt; _ZL16int_printer_workPvPS_S0_</text>
<text top="977" left="144" width="9" height="12" font="1">}</text>
<text top="1030" left="151" width="659" height="16" font="0">It should also be obvious that code for arbitrarily complex static stream graphs could be</text>
<text top="1066" left="108" width="702" height="16" font="0">written in a style similar to the code in Figure 6.1, thus enabling static extraction of those graph</text>
</page>
<page number="103" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">89</text>
<text top="108" left="136" width="130" height="11" font="3"># i n c l u d e &lt; s t d i o . h&gt;</text>
<text top="122" left="136" width="199" height="11" font="3"># i n c l u d e ” s k i r i n t r i n s i c s . h ”</text>
<text top="136" left="136" width="192" height="11" font="3"># i n c l u d e ” s i m p l e k e r n e l s . h ”</text>
<text top="165" left="137" width="18" height="11" font="3">i n t</text>
<text top="179" left="136" width="119" height="11" font="3">a d d w o r k ( v o i d ∗ s ,</text>
<text top="179" left="266" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="179" left="395" width="39" height="11" font="3">i n s [ ] ,</text>
<text top="179" left="446" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="179" left="574" width="46" height="11" font="3">o u t s [ ] )</text>
<text top="192" left="135" width="6" height="11" font="3">{</text>
<text top="207" left="166" width="68" height="11" font="3">i n t a , b , c ;</text>
<text top="222" left="176" width="114" height="11" font="3">S K I R p o p ( 0 , &amp;a ) ;</text>
<text top="236" left="176" width="114" height="11" font="3">S K I R p o p ( 1 , &amp;b ) ;</text>
<text top="250" left="165" width="69" height="11" font="3">c = a + b ;</text>
<text top="264" left="176" width="121" height="11" font="3">S K I R p u s h ( 0 , &amp;c ) ;</text>
<text top="278" left="165" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="292" left="135" width="6" height="11" font="3">}</text>
<text top="321" left="137" width="18" height="11" font="3">i n t</text>
<text top="335" left="136" width="197" height="11" font="3">main ( i n t a r g c , c h a r ∗ a r g v [ ] )</text>
<text top="348" left="135" width="6" height="11" font="3">{</text>
<text top="363" left="166" width="10" height="11" font="3">i f</text>
<text top="364" left="187" width="91" height="11" font="3">( a r g c ! = 2 ) {</text>
<text top="378" left="195" width="318" height="11" font="3">p r i n t f ( ” u s a g e : %s &lt;num s a m p l e s &gt;\n ” , a r g v [ 0 ] ) ;</text>
<text top="392" left="195" width="53" height="11" font="3">e x i t ( 0 ) ;</text>
<text top="405" left="164" width="6" height="11" font="3">}</text>
<text top="434" left="166" width="18" height="11" font="3">i n t</text>
<text top="435" left="194" width="139" height="11" font="3">c n t = a t o i ( a r g v [ 1 ] ) ;</text>
<text top="449" left="166" width="104" height="11" font="3">i n t c n t 0 = c n t ;</text>
<text top="463" left="166" width="104" height="11" font="3">i n t c n t 1 = c n t ;</text>
<text top="491" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="491" left="294" width="61" height="11" font="3">i n 0 , i n 1 ,</text>
<text top="491" left="366" width="25" height="11" font="3">o u t ;</text>
<text top="506" left="165" width="34" height="11" font="3">i n 0 =</text>
<text top="506" left="220" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="520" left="165" width="34" height="11" font="3">i n 1 =</text>
<text top="520" left="220" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="534" left="165" width="34" height="11" font="3">o u t =</text>
<text top="534" left="220" width="178" height="11" font="3">S K I R s t r e a m ( s i z e o f ( i n t ) ) ;</text>
<text top="562" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="562" left="295" width="41" height="11" font="3">s r c 0 =</text>
<text top="562" left="357" width="307" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) s i m p l e 0 1 w o r k , &amp;c n t 0 ) ;</text>
<text top="576" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="576" left="295" width="140" height="11" font="3">s r c 0 i n s [ 1 ] = { 0 } ;</text>
<text top="591" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="591" left="295" width="183" height="11" font="3">s r c 0 o u t s [ 2 ] = { i n 0 , 0 } ;</text>
<text top="605" left="178" width="106" height="11" font="3">S K I R c a l l ( s r c 0 ,</text>
<text top="605" left="295" width="61" height="11" font="3">s r c 0 i n s ,</text>
<text top="605" left="367" width="75" height="11" font="3">s r c 0 o u t s ) ;</text>
<text top="633" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="633" left="295" width="41" height="11" font="3">s r c 1 =</text>
<text top="633" left="357" width="307" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) s i m p l e 0 1 w o r k , &amp;c n t 1 ) ;</text>
<text top="647" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="647" left="295" width="140" height="11" font="3">s r c 1 i n s [ 1 ] = { 0 } ;</text>
<text top="662" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="662" left="295" width="183" height="11" font="3">s r c 1 o u t s [ 2 ] = { i n 1 , 0 } ;</text>
<text top="676" left="178" width="106" height="11" font="3">S K I R c a l l ( s r c 1 ,</text>
<text top="676" left="295" width="61" height="11" font="3">s r c 1 i n s ,</text>
<text top="676" left="367" width="75" height="11" font="3">s r c 1 o u t s ) ;</text>
<text top="704" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="704" left="294" width="35" height="11" font="3">add =</text>
<text top="704" left="349" width="200" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) a d d w o r k ,</text>
<text top="704" left="560" width="17" height="11" font="3">0 ) ;</text>
<text top="718" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="718" left="295" width="205" height="11" font="3">a d d i n s [ 3 ] = { i n 0 , i n 1 , 0 } ;</text>
<text top="733" left="166" width="117" height="11" font="3">s k i r s t r e a m p t r t</text>
<text top="733" left="295" width="176" height="11" font="3">a d d o u t s [ 2 ] = { o u t , 0 } ;</text>
<text top="747" left="178" width="99" height="11" font="3">S K I R c a l l ( add ,</text>
<text top="747" left="287" width="54" height="11" font="3">a d d i n s ,</text>
<text top="747" left="352" width="68" height="11" font="3">a d d o u t s ) ;</text>
<text top="775" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="775" left="295" width="41" height="11" font="3">s i n k =</text>
<text top="775" left="357" width="429" height="11" font="3">S K I R k e r n e l ( ( v o i d ∗ ) i n t p r i n t e r w o r k , new i n t p r i n t e r t ( ” ” ) ) ;</text>
<text top="789" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="789" left="295" width="176" height="11" font="3">s i n k i n s [ 2 ] = { o u t , 0 } ;</text>
<text top="804" left="166" width="117" height="11" font="3">s k i r k e r n e l p t r t</text>
<text top="804" left="295" width="147" height="11" font="3">s i n k o u t s [ 1 ] = { 0 } ;</text>
<text top="818" left="178" width="106" height="11" font="3">S K I R c a l l ( s i n k ,</text>
<text top="818" left="295" width="61" height="11" font="3">s i n k i n s ,</text>
<text top="818" left="367" width="75" height="11" font="3">s i n k o u t s ) ;</text>
<text top="846" left="177" width="114" height="11" font="3">S K I R w a i t ( s i n k ) ;</text>
<text top="874" left="165" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="888" left="135" width="6" height="11" font="3">}</text>
<text top="930" left="143" width="631" height="16" font="0">Figure 6.1: An example of a SKIR C program with a statically analyzable stream graph.</text>
<text top="1022" left="108" width="702" height="16" font="0">structures as well. Furthermore, if each of the kernel work functions found in the static graph</text>
<text top="1058" left="108" width="702" height="16" font="0">conform to the synchronous dataﬂow model, then the graph can be statically scheduled and trans-</text>
</page>
<page number="104" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">90</text>
<text top="128" left="108" width="702" height="16" font="0">formed using any number of existing static scheduling and code generation techniques. The point</text>
<text top="164" left="108" width="702" height="16" font="0">is that the use of SKIR does not preclude the use of existing static techniques. Instead, it extends</text>
<text top="200" left="108" width="702" height="16" font="0">the reach of those techniques and permits their use where appropriate while allowing more gen-</text>
<text top="236" left="108" width="702" height="16" font="0">eral and dynamic programs. The advantage of a JIT compiler is that we can perform compilation</text>
<text top="272" left="108" width="702" height="16" font="0">specializing a particular dynamically generated program graph to the hardware that the program is</text>
<text top="308" left="108" width="582" height="16" font="0">running on. As discussed in Chapter 1, this greatly increases program portability.</text>
<text top="366" left="112" width="22" height="16" font="0">6.2</text>
<text top="366" left="170" width="121" height="16" font="0">Kernel Analysis</text>
<text top="421" left="151" width="659" height="16" font="0">Kernel analysis can begin when a skir.kernel operation is executed by a SKIR program.</text>
<text top="457" left="108" width="702" height="16" font="0">It is not until this point that the SKIR runtime is given a pointer to a kernel work function. The</text>
<text top="493" left="108" width="702" height="16" font="0">SKIR JIT compiler maintains an internal mapping from function pointers to LLVM bitcode. When</text>
<text top="529" left="108" width="702" height="16" font="0">a pointer is obtained by the SKIR runtime by a skir.kernel operation, the bitcode correspond-</text>
<text top="565" left="108" width="702" height="16" font="0">ing to the pointer is looked up for analysis and compilation. Because the SKIR JIT operates in a</text>
<text top="600" left="108" width="702" height="16" font="0">lazy mode of operation, the pointer passed to the skir.kernel operation is actually a stub, and</text>
<text top="636" left="108" width="303" height="16" font="0">the overhead of re-compilation is avoided.</text>
<text top="672" left="151" width="659" height="16" font="0">Kernel analysis has three essential tasks: identify hierarchical kernels; identify data parallel</text>
<text top="708" left="108" width="702" height="16" font="0">kernels; and attempt to determine the rates at which data is read from a kernel’s input streams and</text>
<text top="744" left="108" width="257" height="16" font="0">written to a kernel’s output streams.</text>
<text top="806" left="112" width="36" height="16" font="0">6.2.1</text>
<text top="806" left="182" width="237" height="16" font="0">Detecting Hierarchical Kernels</text>
<text top="855" left="151" width="659" height="16" font="0">Determining whether or not a kernel is hierarchical is a straightforward process. We can</text>
<text top="891" left="108" width="702" height="16" font="0">simply scan all of the instructions in the kernel, looking for SKIR operations. If skir.push,</text>
<text top="928" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="927" left="194" width="616" height="16" font="0">, or skir.peek operations are not encountered, then the kernel is marked as hier-</text>
<text top="963" left="108" width="702" height="16" font="0">archical and the analysis is ﬁnished. If stream operations are found, then analysis continues with</text>
<text top="999" left="108" width="208" height="16" font="0">detection of data parallelism.</text>
</page>
<page number="105" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">91</text>
<text top="128" left="112" width="36" height="16" font="0">6.2.2</text>
<text top="128" left="182" width="205" height="16" font="0">Detecting Data Parallelism</text>
<text top="176" left="151" width="659" height="16" font="0">To support data parallel execution, a kernel must be free from side-effects. The SKIR com-</text>
<text top="212" left="108" width="702" height="16" font="0">piler can conservatively identify two classes of actions performed by kernel work functions that</text>
<text top="248" left="108" width="702" height="16" font="0">can cause state modiﬁcation or other side-effects. The ﬁrst is calls to functions that cannot be an-</text>
<text top="284" left="108" width="702" height="16" font="0">alyzed. This includes system calls, calls to external libraries, or calls to any other function whose</text>
<text top="320" left="108" width="702" height="16" font="0">code is not available for analysis. If such a function call is found, the kernel is marked as having</text>
<text top="356" left="108" width="702" height="16" font="0">side-effects. For function calls where the body of the called function is available for analysis, we</text>
<text top="392" left="108" width="463" height="16" font="0">can simply apply the same analysis as for kernel work functions.</text>
<text top="428" left="151" width="659" height="16" font="0">The second class of actions causing state or side-effects are writes to memory locations that</text>
<text top="464" left="108" width="702" height="16" font="0">are not part of the program stack. That is, writes to memory locations that may be read during</text>
<text top="500" left="108" width="702" height="16" font="0">subsequent executions of the same kernel instance or by other parts of the program. It is assumed</text>
<text top="536" left="108" width="702" height="16" font="0">that writes to the program stack are to local variables or other temporary state. If a work function</text>
<text top="572" left="108" width="702" height="16" font="0">only writes to stack locations, then we can assume that stores executed by the kernel do not cause</text>
<text top="608" left="108" width="702" height="16" font="0">side-effects. In an implementation based on the LLVM representation, pointers to stack memory</text>
<text top="644" left="108" width="411" height="16" font="0">locations are always the result of an alloca instruction.</text>
<text top="680" left="151" width="659" height="16" font="0">Stores to the stack are identiﬁed using a simple and conservative algorithm. For each store</text>
<text top="716" left="108" width="702" height="16" font="0">instruction in the kernel work function, we check to see if the destination is an alloca instruction.</text>
<text top="752" left="108" width="702" height="16" font="0">If it is, we can move on to examine the next store instruction. If the destination address is the result</text>
<text top="788" left="108" width="702" height="16" font="0">of simple pointer arithmetic, then we recursively examine the operands of the pointer arithmetic</text>
<text top="824" left="108" width="702" height="16" font="0">until we determine whether or not the base pointer in the arithmetic is an alloca instruction. If a</text>
<text top="860" left="108" width="702" height="16" font="0">pointer is encountered that is deﬁned outside of the kernel work function, then the kernel is marked</text>
<text top="896" left="108" width="159" height="16" font="0">as having side-effects.</text>
<text top="958" left="112" width="36" height="16" font="0">6.2.3</text>
<text top="958" left="182" width="144" height="16" font="0">Determining Rates</text>
<text top="1006" left="151" width="659" height="16" font="0">An important class of stream program kernels are those that perform a ﬁxed number of stream</text>
<text top="1042" left="108" width="702" height="16" font="0">operations each time they are executed. We call these kernels synchronous since they conform to</text>
</page>
<page number="106" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">92</text>
<text top="128" left="108" width="702" height="16" font="0">the synchronous dataﬂow model. Optimization of this subset of stream parallel programs makes</text>
<text top="164" left="108" width="702" height="16" font="0">up the bulk of recent research in the area of compiling for stream processing. This is because</text>
<text top="200" left="108" width="702" height="16" font="0">when the input and output rates of each kernel are constant and known, a static schedule for the</text>
<text top="236" left="108" width="702" height="16" font="0">program can be computed and the size of buffers between the kernels can be determined – both at</text>
<text top="272" left="108" width="702" height="16" font="0">compile time. Constant rates also make it easier for a compiler to merge and split kernels based on</text>
<text top="308" left="108" width="249" height="16" font="0">scheduling or resource constraints.</text>
<text top="344" left="151" width="659" height="16" font="0">One of the advantages of SKIR is that stream program graphs can contain a mix of syn-</text>
<text top="380" left="108" width="702" height="16" font="0">chronous and non-synchronous kernels; SKIR program kernels are not restricted to have constant</text>
<text top="416" left="108" width="702" height="16" font="0">input and output rates. Some systems, like StreamIt, choose to make the rate information of kernels</text>
<text top="452" left="108" width="702" height="16" font="0">explicit using programmer annotation. While SKIR does not currently provide a way to annotate</text>
<text top="488" left="108" width="702" height="16" font="0">a program with such information, we could easily extended the LLVM based implementation of</text>
<text top="524" left="108" width="702" height="16" font="0">SKIR to provide such annotations. Similar annotations are used by other language front ends to</text>
<text top="560" left="108" width="702" height="16" font="0">provide meta-information to backend LLVM passes. Debug information is one example. However,</text>
<text top="596" left="108" width="702" height="16" font="0">in keeping with a minimalist design we instead choose to extract this information using static anal-</text>
<text top="632" left="108" width="702" height="16" font="0">ysis. It is our experience that when a high-level language makes input and output rate information</text>
<text top="668" left="108" width="702" height="16" font="0">available, it is usually not difﬁcult for the front-end compiler to emit SKIR code that is analyzable</text>
<text top="704" left="108" width="702" height="16" font="0">enough to recover this information. An example of this is our front end compiler for the StreamIt</text>
<text top="740" left="108" width="559" height="16" font="0">language described in Section 4.3, which generally produces analyzable code.</text>
<text top="776" left="151" width="659" height="16" font="0">Kernel analysis to determine work function input and output rates is done by a single com-</text>
<text top="812" left="108" width="702" height="16" font="0">piler pass called SKIRKernelInfoPass. This pass runs once for each kernel work function.</text>
<text top="848" left="108" width="702" height="16" font="0">For each SKIR stream operation intrinsic in a work function, a simple analysis routine is run to try</text>
<text top="884" left="108" width="702" height="16" font="0">to determine the input rate (for skir.pop and skir.peek) or output rate (for skir.push)</text>
<text top="920" left="108" width="702" height="16" font="0">for that single instruction. The routine begins by determining whether or not the stream operation</text>
<text top="956" left="108" width="702" height="16" font="0">is contained in a loop. If it is not, and the basic block containing the operation post-dominates the</text>
<text top="992" left="108" width="702" height="16" font="0">entry block of the work function, then we know that the operation executes exactly once. Recall</text>
<text top="1027" left="108" width="702" height="16" font="0">that a basic block A post-dominates another basic block B if all paths from B to an exit block must</text>
<text top="1063" left="108" width="702" height="16" font="0">pass through A. Thus, if a block post-dominates the entry block, it is unconditionally executed.</text>
</page>
<page number="107" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">93</text>
<text top="128" left="108" width="702" height="16" font="0">If the stream operation is contained in a loop, then further analysis must be done. If the loop is</text>
<text top="164" left="108" width="702" height="16" font="0">unconditionally entered and has a computable constant trip count, then we can also compute the</text>
<text top="200" left="108" width="702" height="16" font="0">number of times the stream operation executes (i.e. the rate). If the loop is contained in another</text>
<text top="236" left="108" width="413" height="16" font="0">loop, we recursively apply the analysis to the parent loop.</text>
<text top="272" left="151" width="659" height="16" font="0">For skir.peek operations, we must also determine the range of the offset parameter. It is</text>
<text top="308" left="108" width="702" height="16" font="0">not uncommon, for example, to read a windowed region of a stream using a skir.peek inside</text>
<text top="344" left="108" width="702" height="16" font="0">of a for loop. In this case the offset argument of the skir.peek is a variable. For the rate</text>
<text top="380" left="108" width="702" height="16" font="0">computation, we want to know the maximum value of that variable. In many cases this is easily</text>
<text top="416" left="108" width="702" height="16" font="0">obtainable using the Scalar Evolution analysis pass available in LLVM. This analysis pass is used</text>
<text top="452" left="108" width="702" height="16" font="0">for representing recurrences corresponding to the value of loop oriented expressions, such as loop</text>
<text top="488" left="108" width="702" height="16" font="0">trip count and induction variables. Once we have a recurrence corresponding to the offset compu-</text>
<text top="524" left="108" width="702" height="16" font="0">tation, we can perform a search over the space deﬁned by the recurrence, and obtain the maximum.</text>
<text top="560" left="108" width="702" height="16" font="0">This is possible because we already know the rate of the skir.peek instruction (i.e. the trip</text>
<text top="596" left="108" width="702" height="16" font="0">count of the loop containing the skir.peek) from the previous analysis and we can evaluate the</text>
<text top="632" left="108" width="702" height="16" font="0">recurrence at each iteration. If a recurrence which produces constants when evaluated cannot be</text>
<text top="668" left="108" width="702" height="16" font="0">obtained for a particular skir.peek, then the peek rate for that instruction cannot be determined.</text>
<text top="704" left="151" width="659" height="16" font="0">If rates have been determined for each of the SKIR stream operations in a kernel work func-</text>
<text top="740" left="108" width="702" height="16" font="0">tion, the rates for the kernel as a whole are easily computed. The push rate for a stream is simply</text>
<text top="776" left="108" width="702" height="16" font="0">the sum of the rate of all the skir.push operations on that stream, and the pop rate of a stream</text>
<text top="812" left="108" width="702" height="16" font="0">is the sum of the rate of all the skir.pop operations on that stream. The peek rate of a stream is</text>
<text top="848" left="108" width="536" height="16" font="0">the maximum of the rate of all the skir.peek operations on that stream.</text>
<text top="884" left="151" width="659" height="16" font="0">It could be argued that the set of kernel work functions that SKIRKernelInfoPass can</text>
<text top="920" left="108" width="702" height="16" font="0">compute input and output rates for is fairly small compared to the set of all possible work functions.</text>
<text top="956" left="108" width="702" height="16" font="0">The counter argument is that most of those aren’t synchronous anyway, and the limitations are</text>
<text top="992" left="108" width="702" height="16" font="0">not any different for a static synchronous dataﬂow compiler. The main limitation with the SKIR</text>
<text top="1027" left="108" width="702" height="16" font="0">analysis is that it misses case of dynamic synchronous behavior, where the rate is a runtime variable</text>
<text top="1063" left="108" width="702" height="16" font="0">but either does not change, or changes slowly. Of course a static SDF compiler can’t handle</text>
</page>
<page number="108" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">94</text>
<text top="128" left="108" width="702" height="16" font="0">these cases either, but with a dynamic implementation of SKIR, it should be possible to do better.</text>
<text top="164" left="108" width="702" height="16" font="0">As an example, if dynamic proﬁling can determine that a kernel appears to be synchronous, but</text>
<text top="200" left="108" width="702" height="16" font="0">analysis did not, then maybe it would be beneﬁcial to re-compile the kernel as synchronous, with</text>
<text top="236" left="108" width="702" height="16" font="0">an abort and re-compile mechanism if the synchronous assumptions are broken. This is possible</text>
<text top="272" left="108" width="702" height="16" font="0">in a dynamic SKIR environment but would not be feasible with a traditional static ahead of time</text>
<text top="308" left="108" width="702" height="16" font="0">approach. The reason this type of a scheme has not been explored in this work is that there is not</text>
<text top="344" left="108" width="374" height="16" font="0">a compelling use case for it among our benchmarks.</text>
<text top="402" left="112" width="22" height="16" font="0">6.3</text>
<text top="402" left="170" width="163" height="16" font="0">Kernel Specialization</text>
<text top="457" left="151" width="659" height="16" font="0">Before machine code generation, SKIR kernel work functions are transformed and opti-</text>
<text top="493" left="108" width="702" height="16" font="0">mized. This is necessary to improve performance, to lower SKIR stream operations to LLVM</text>
<text top="529" left="108" width="702" height="16" font="0">instruction sequences implementing the operation, and to support dynamic scheduling. The re-</text>
<text top="565" left="108" width="702" height="16" font="0">sults of kernel analysis, the hardware target, and the desired scheduling mechanism all determine</text>
<text top="600" left="108" width="702" height="16" font="0">how various SKIR compiler passes will be run on the work function. We call this step kernel</text>
<text top="637" left="108" width="100" height="15" font="0">specialization</text>
<text top="636" left="213" width="597" height="16" font="0">because the kernel is being specialized with respect to its own characteristics and</text>
<text top="672" left="108" width="702" height="16" font="0">the characteristics of the target architecture. This section describes the compiler transformations</text>
<text top="708" left="108" width="702" height="16" font="0">used when compiling SKIR code to run using a single or multiple threads using the scheduling</text>
<text top="744" left="108" width="248" height="16" font="0">techniques discussed in Chapter 5.</text>
<text top="780" left="151" width="659" height="16" font="0">The ﬁrst step in kernel specialization is to make a copy of the kernel work function. This is</text>
<text top="816" left="108" width="702" height="16" font="0">done for several reasons. First, it preserves the original procedure to be used by other optimiza-</text>
<text top="852" left="108" width="702" height="16" font="0">tions, such as dynamic fusion. Second, it modiﬁes the function signature to take an additional</text>
<text top="888" left="108" width="702" height="16" font="0">parameter, called rt state. This parameter can be used by the SKIR runtime to pass additional</text>
<text top="924" left="108" width="702" height="16" font="0">arguments to the transformed kernel. It is currently used for runtime proﬁling. Third, the kernel</text>
<text top="960" left="108" width="702" height="16" font="0">work function must be transformed to return tagged pointers instead of boolean values, in support</text>
<text top="996" left="108" width="376" height="16" font="0">of the scheduling algorithms discussed in Chapter 5.</text>
</page>
<page number="109" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">95</text>
<text top="128" left="112" width="36" height="16" font="0">6.3.1</text>
<text top="128" left="182" width="125" height="16" font="0">Kernel Batching</text>
<text top="176" left="151" width="659" height="16" font="0">Many stream parallel programs have kernels that are quite small. For example DSP appli-</text>
<text top="212" left="108" width="702" height="16" font="0">cations such as the benchmarks distributed with the StreamIt compiler contain kernels that require</text>
<text top="248" left="108" width="702" height="16" font="0">only a few tens or hundreds of cycles of computation per input item consumed (see Chapter 7,</text>
<text top="284" left="108" width="702" height="16" font="0">Table 7.1). The reason for this is that the programmers of these benchmarks have tried to expose as</text>
<text top="320" left="108" width="702" height="16" font="0">much concurrency as possible to the compiler. When kernels are this small the overhead of simply</text>
<text top="356" left="108" width="702" height="16" font="0">running the kernel via a function call or of incurring a cache miss when reading stream data can be</text>
<text top="392" left="108" width="702" height="16" font="0">signiﬁcant. To reduce these overheads, the SKIR compiler performs an optimization called batch-</text>
<text top="428" left="108" width="23" height="15" font="0">ing</text>
<text top="428" left="135" width="675" height="16" font="0">on all kernels. Batching simply wraps the body of a kernel work function in a while loop. As</text>
<text top="464" left="108" width="702" height="16" font="0">a high level example, we can applying this transformation to the SKIR CONSUMER kernel from</text>
<text top="500" left="108" width="702" height="16" font="0">Figure 3.2 to produce a new kernel, BATCHED CONSUMER, shown in Figure 6.2. Performing this</text>
<text top="600" left="124" width="233" height="14" font="1">SKIR_CONSUMER (int *state)</text>
<text top="618" left="124" width="9" height="12" font="1">{</text>
<text top="636" left="142" width="45" height="12" font="1">int d</text>
<text top="654" left="142" width="143" height="14" font="1">if (*state == 0)</text>
<text top="672" left="160" width="99" height="12" font="1">return true</text>
<text top="690" left="142" width="134" height="12" font="1">skir.pop(0, &amp;d)</text>
<text top="708" left="142" width="72" height="12" font="1">print(d)</text>
<text top="728" left="142" width="170" height="12" font="1">*state = *state - 1</text>
<text top="744" left="142" width="108" height="12" font="1">return false</text>
<text top="762" left="124" width="9" height="12" font="1">}</text>
<text top="538" left="466" width="260" height="14" font="1">BATCHED_CONSUMER (int *state)</text>
<text top="556" left="466" width="9" height="12" font="1">{</text>
<text top="573" left="484" width="126" height="12" font="1">bool r = false</text>
<text top="591" left="484" width="99" height="12" font="1">while(!r) {</text>
<text top="609" left="502" width="143" height="12" font="1">// SKIR_CONSUMER</text>
<text top="627" left="502" width="45" height="12" font="1">int d</text>
<text top="645" left="502" width="161" height="14" font="1">if (*state == 0) {</text>
<text top="663" left="520" width="161" height="12" font="1">r = true; goto ret</text>
<text top="681" left="502" width="9" height="12" font="1">}</text>
<text top="699" left="502" width="134" height="12" font="1">skir.pop(0, &amp;d)</text>
<text top="717" left="502" width="72" height="12" font="1">print(d)</text>
<text top="737" left="502" width="170" height="12" font="1">*state = *state - 1</text>
<text top="753" left="502" width="81" height="12" font="1">r = false</text>
<text top="771" left="502" width="36" height="12" font="1">ret:</text>
<text top="789" left="484" width="9" height="12" font="1">}</text>
<text top="807" left="484" width="72" height="12" font="1">return r</text>
<text top="825" left="466" width="9" height="12" font="1">}</text>
<text top="852" left="148" width="623" height="16" font="0">Figure 6.2: Applying batching to SKIR CONSUMER produces BATCHED CONSUMER.</text>
<text top="924" left="108" width="702" height="16" font="0">optimization ensures that the kernel will remain running as long as there is data or free space avail-</text>
<text top="960" left="108" width="702" height="16" font="0">able in the kernel’s stream buffers. This reduces scheduling and communication overhead and may</text>
<text top="996" left="108" width="702" height="16" font="0">improve the performance of hardware optimizations such as memory prefetching and loop stream</text>
<text top="1032" left="108" width="70" height="16" font="0">detection.</text>
<text top="1068" left="151" width="659" height="16" font="0">Figure 6.2 shows the batching transformation applied to pseudo-code. The actual transforma-</text>
</page>
<page number="110" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">96</text>
<text top="128" left="108" width="702" height="16" font="0">tion operates on SKIR bitcode using a code transformation pass called SKIROuterLoopPass,</text>
<text top="164" left="108" width="702" height="16" font="0">so named because it adds an outer loop to a kernel. The technique used by the outer loop pass</text>
<text top="200" left="108" width="702" height="16" font="0">is simple, ﬂexible, and powerful. When the pass is instantiated by the code generator, it is given</text>
<text top="236" left="108" width="702" height="16" font="0">a work function sufﬁx. In the case of the simple batching described in this section, the sufﬁx</text>
<text top="272" left="108" width="702" height="16" font="0">is “loop”. The sufﬁx is used to lookup a work function template from a bitcode library. Work</text>
<text top="308" left="108" width="309" height="16" font="0">function templates have names of the form</text>
<text top="309" left="435" width="136" height="14" font="0">SKIRRT workfn</text>
<text top="308" left="577" width="38" height="15" font="0">sufﬁx</text>
<text top="308" left="615" width="195" height="16" font="0">. The C source code corre-</text>
<text top="344" left="108" width="241" height="16" font="0">sponding to the template function</text>
<text top="344" left="366" width="328" height="16" font="0">SKIRRT workfn loop is shown in Figure 6.3.</text>
<text top="380" left="133" width="90" height="12" font="1">extern &#34;C&#34;</text>
<text top="398" left="133" width="664" height="14" font="1">void * __SKIRRT_workfn_loop(skir_rt_state_t *rt_state, void *kernel_state,</text>
<text top="416" left="384" width="395" height="14" font="1">skir_stream_t *ins[], skir_stream_t *outs[])</text>
<text top="434" left="133" width="9" height="12" font="1">{</text>
<text top="452" left="169" width="108" height="14" font="1">void *k = 0;</text>
<text top="470" left="169" width="143" height="12" font="1">while (k == 0) {</text>
<text top="488" left="205" width="556" height="12" font="1">k = __SKIRRT_workfn_extern(rt_state, kernel_state, ins, outs);</text>
<text top="506" left="205" width="161" height="12" font="1">rt_state-&gt;niter++;</text>
<text top="524" left="169" width="9" height="12" font="1">}</text>
<text top="542" left="169" width="81" height="12" font="1">return k;</text>
<text top="560" left="133" width="9" height="12" font="1">}</text>
<text top="587" left="219" width="479" height="16" font="0">Figure 6.3: Kernel work function template implementing batching.</text>
<text top="659" left="151" width="659" height="16" font="0">The SKIROuterLoopPass makes a copy of the work function template bitcode, replaces</text>
<text top="695" left="108" width="70" height="16" font="0">the call to</text>
<text top="696" left="195" width="207" height="14" font="0">SKIRRT workfn extern</text>
<text top="695" left="406" width="404" height="16" font="0">with a call to the kernel being compiled, then inlines that</text>
<text top="731" left="108" width="702" height="16" font="0">call. The result is a batched kernel of the form shown in Figure 6.2. This approach of writing</text>
<text top="767" left="108" width="702" height="16" font="0">the template function in C, compiling it to bitcode, then using that bitcode as a template for code</text>
<text top="803" left="108" width="702" height="16" font="0">transformation is pragmatic and powerful. Not only does it reduce bugs trying to, for example,</text>
<text top="839" left="108" width="702" height="16" font="0">generate proper loops, it also allows for easy experimentation and optional insertion of additional</text>
<text top="875" left="108" width="405" height="16" font="0">code (e.g. proﬁling code) using conditional compilation.</text>
<text top="937" left="112" width="36" height="16" font="0">6.3.2</text>
<text top="937" left="182" width="259" height="16" font="0">Generating Kernels as Coroutines</text>
<text top="985" left="151" width="659" height="16" font="0">As discussed in Chapter 5, it is necessary to suspend the execution of kernel work functions</text>
<text top="1021" left="108" width="702" height="16" font="0">when a blocking condition is encountered during the execution of skir.push, skir.pop, and</text>
<text top="1058" left="108" width="97" height="14" font="0">skir.peek</text>
<text top="1057" left="208" width="602" height="16" font="0">operations. This is because dependent kernels might share the same operating system</text>
</page>
<page number="111" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">97</text>
<text top="128" left="108" width="702" height="16" font="0">thread and blocking the execution of the thread for a stream operation can easily cause deadlock.</text>
<text top="164" left="108" width="702" height="16" font="0">To avoid this situation, kernel work functions are transformed to voluntarily yield control of the</text>
<text top="200" left="108" width="702" height="16" font="0">processor to the dynamic scheduler when such a condition occurs. This is done by transforming</text>
<text top="236" left="108" width="273" height="16" font="0">kernel work functions into coroutines.</text>
<text top="272" left="151" width="659" height="16" font="0">Kernel work functions can be transformed into coroutines by inlining the yielding stream</text>
<text top="308" left="108" width="702" height="16" font="0">operations from Figure 5.4 into the work function body. The actual inlining of stream operations</text>
<text top="344" left="108" width="702" height="16" font="0">takes place in several steps and will be described in Section 6.3.5. Brieﬂy, functions like the</text>
<text top="381" left="108" width="86" height="14" font="0">skir.pop</text>
<text top="380" left="198" width="612" height="16" font="0">implementation shown in Figure 6.4 are inlined into the kernel work function for each</text>
<text top="416" left="108" width="702" height="16" font="0">of the stream operations. Once this has been accomplished, it is easy to ﬁnd the potential block-</text>
<text top="452" left="108" width="494" height="16" font="0">ing points in the kernel work function. They are simply the calls to</text>
<text top="453" left="620" width="185" height="14" font="0">SKIRRT would block</text>
<text top="452" left="806" width="4" height="16" font="0">.</text>
<text top="488" left="108" width="109" height="16" font="0">Like the call to</text>
<text top="489" left="234" width="207" height="14" font="0">SKIRRT workfn extern</text>
<text top="488" left="446" width="364" height="16" font="0">in the kernel work function template in Figure 6.3,</text>
<text top="525" left="120" width="185" height="14" font="0">SKIRRT would block</text>
<text top="524" left="311" width="499" height="16" font="0">is never emitted as generated code. It is simply a placeholder used</text>
<text top="560" left="108" width="702" height="16" font="0">by the SKIR compiler to locate certain points in the program. For coroutine scheduling, calls</text>
<text top="596" left="108" width="14" height="16" font="0">to</text>
<text top="597" left="141" width="185" height="14" font="0">SKIRRT would block</text>
<text top="596" left="331" width="479" height="16" font="0">get replaced with calls to the SKIR yield operator skir.yield</text>
<text top="632" left="108" width="702" height="16" font="0">and all return statements get replaced with the coroutine return operator skir.return. The</text>
<text top="669" left="108" width="108" height="14" font="0">skir.yield</text>
<text top="668" left="221" width="589" height="16" font="0">and skir.return operations are implemented as SKIR operations (i.e. LLVM</text>
<text top="704" left="108" width="692" height="16" font="0">intrinsics), but are only used internally. They are not exposed as part of the SKIR instruction set.</text>
<text top="738" left="241" width="403" height="14" font="1">void __SKIRRT_inline_pop (skir_stream_t *p[],</text>
<text top="756" left="474" width="197" height="12" font="1">skir_stream_idx_t idx,</text>
<text top="774" left="474" width="215" height="12" font="1">skir_stream_element_t e)</text>
<text top="792" left="241" width="9" height="12" font="1">{</text>
<text top="810" left="277" width="233" height="14" font="1">skir_stream_t *s = p[idx];</text>
<text top="828" left="277" width="197" height="12" font="1">size_t tail = s-&gt;tail;</text>
<text top="846" left="277" width="224" height="12" font="1">while (s-&gt;head == tail) {</text>
<text top="864" left="313" width="332" height="12" font="1">__SKIRRT_would_block(s-&gt;dst, s-&gt;src);</text>
<text top="882" left="277" width="9" height="12" font="1">}</text>
<text top="900" left="277" width="350" height="12" font="1">memcpy(e, &amp;s-&gt;buf[tail], e-&gt;elem_size);</text>
<text top="918" left="277" width="475" height="12" font="1">s-&gt;tail = (tail + e-&gt;elem_size) % STREAM_BUFFER_SIZE;</text>
<text top="936" left="241" width="9" height="12" font="1">}</text>
<text top="963" left="241" width="436" height="16" font="0">Figure 6.4: An implementation of the skir.pop operation.</text>
<text top="1032" left="151" width="659" height="16" font="0">During code generation, the SKIR skir.yield and skir.return operators are low-</text>
<text top="1068" left="108" width="702" height="16" font="0">ered to calls to the assembly routine shown in Figures 6.6 and 6.7. Additionally, the runtime</text>
</page>
<page number="112" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">98</text>
<text top="128" left="108" width="702" height="16" font="0">scheduler does not call coroutine kernel work functions directly. Instead it calls them through the</text>
<text top="164" left="108" width="702" height="16" font="0">assembly routine koro workfn 64 shown in Figure 6.5. It is not important to understand the</text>
<text top="200" left="108" width="702" height="16" font="0">routines shown in the ﬁgures, only to understand what they do. The primary task of the assembly</text>
<text top="236" left="108" width="702" height="16" font="0">routines is to perform context switching for the coroutines. Recall that coroutines do not unwind</text>
<text top="272" left="108" width="702" height="16" font="0">the stack when they yield. Instead, they suspend their execution and jump to another routine. This</text>
<text top="308" left="108" width="702" height="16" font="0">means that each coroutine executes using a separate program stack. During a context switch three</text>
<text top="344" left="108" width="702" height="16" font="0">things must be saved and restored: the stack pointer, the program counter, and the callee save</text>
<text top="380" left="108" width="421" height="16" font="0">registers. The three assembly routines perform these tasks.</text>
<text top="417" left="242" width="430" height="11" font="3">extern &#34;C&#34; void *koro_workfn_64(void *rt_state, void *state,</text>
<text top="432" left="471" width="237" height="11" font="3">void *impl_ins, void *impl_outs);</text>
<text top="446" left="242" width="29" height="9" font="3">asm(</text>
<text top="446" left="292" width="7" height="9" font="3">\</text>
<text top="460" left="270" width="65" height="9" font="3">&#34;.text\n&#34;</text>
<text top="460" left="356" width="7" height="9" font="3">\</text>
<text top="474" left="270" width="187" height="9" font="3">&#34;.global koro_workfn_64\n&#34;</text>
<text top="474" left="478" width="7" height="9" font="3">\</text>
<text top="488" left="270" width="244" height="9" font="3">&#34;.type koro_workfn_64 @function\n&#34;</text>
<text top="488" left="536" width="7" height="9" font="3">\</text>
<text top="503" left="270" width="93" height="9" font="3">&#34;.align 16\n&#34;</text>
<text top="503" left="385" width="7" height="9" font="3">\</text>
<text top="517" left="256" width="136" height="9" font="3">&#34;koro_workfn_64:\n&#34;</text>
<text top="517" left="421" width="7" height="9" font="3">\</text>
<text top="531" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="531" left="320" width="115" height="9" font="3">0(%rdi), %r10\n&#34;</text>
<text top="531" left="457" width="7" height="9" font="3">\</text>
<text top="545" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="545" left="320" width="108" height="9" font="3">0(%r10), %r8\n&#34;</text>
<text top="545" left="450" width="7" height="9" font="3">\</text>
<text top="559" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="559" left="320" width="115" height="9" font="3">8(%r10), %r11\n&#34;</text>
<text top="559" left="457" width="7" height="9" font="3">\</text>
<text top="574" left="270" width="100" height="9" font="3">&#34;pushq %rbx\n&#34;</text>
<text top="574" left="392" width="7" height="9" font="3">\</text>
<text top="588" left="270" width="100" height="9" font="3">&#34;pushq %rbp\n&#34;</text>
<text top="588" left="392" width="7" height="9" font="3">\</text>
<text top="602" left="270" width="100" height="9" font="3">&#34;pushq %r12\n&#34;</text>
<text top="602" left="392" width="7" height="9" font="3">\</text>
<text top="616" left="270" width="100" height="9" font="3">&#34;pushq %r13\n&#34;</text>
<text top="616" left="392" width="7" height="9" font="3">\</text>
<text top="630" left="270" width="100" height="9" font="3">&#34;pushq %r14\n&#34;</text>
<text top="630" left="392" width="7" height="9" font="3">\</text>
<text top="645" left="270" width="100" height="9" font="3">&#34;pushq %r15\n&#34;</text>
<text top="645" left="392" width="7" height="9" font="3">\</text>
<text top="659" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="659" left="320" width="122" height="9" font="3">%rsp, 24(%r10)\n&#34;</text>
<text top="659" left="464" width="7" height="9" font="3">\</text>
<text top="673" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="673" left="320" width="86" height="9" font="3">%r8, %rsp\n&#34;</text>
<text top="673" left="428" width="7" height="9" font="3">\</text>
<text top="687" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="687" left="320" width="50" height="9" font="3">%r15\n&#34;</text>
<text top="687" left="392" width="7" height="9" font="3">\</text>
<text top="701" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="701" left="320" width="50" height="9" font="3">%r14\n&#34;</text>
<text top="701" left="392" width="7" height="9" font="3">\</text>
<text top="716" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="716" left="320" width="50" height="9" font="3">%r13\n&#34;</text>
<text top="716" left="392" width="7" height="9" font="3">\</text>
<text top="730" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="730" left="320" width="50" height="9" font="3">%r12\n&#34;</text>
<text top="730" left="392" width="7" height="9" font="3">\</text>
<text top="744" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="744" left="320" width="50" height="9" font="3">%rbp\n&#34;</text>
<text top="744" left="392" width="7" height="9" font="3">\</text>
<text top="758" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="758" left="320" width="50" height="9" font="3">%rbx\n&#34;</text>
<text top="758" left="392" width="7" height="9" font="3">\</text>
<text top="772" left="270" width="29" height="9" font="3">&#34;jmp</text>
<text top="774" left="320" width="57" height="9" font="3">*%r11\n&#34;</text>
<text top="772" left="399" width="7" height="9" font="3">\</text>
<text top="787" left="270" width="65" height="9" font="3">&#34;ud2\n&#34;);</text>
<text top="812" left="261" width="396" height="16" font="0">Figure 6.5: SKIR coroutine helper function for x86-64.</text>
<text top="884" left="151" width="659" height="16" font="0">To the runtime scheduler, koro workfn 64 (Figure 6.5) looks like an ordinary work func-</text>
<text top="920" left="108" width="702" height="16" font="0">tion. The ﬁrst thing this assembly routine does is load the saved program counter from the kernel’s</text>
<text top="956" left="108" width="702" height="16" font="0">state. Initially, this is simply the ordinary entry point for the kernel work function being called. The</text>
<text top="992" left="108" width="702" height="16" font="0">routine then saves the current execution context, loads the rest of the coroutine execution context,</text>
<text top="1028" left="108" width="702" height="16" font="0">and jumps to the saved program counter. The kernel work function then executes normally until it</text>
<text top="1064" left="108" width="349" height="16" font="0">encounters a skir.yield or skir.return.</text>
</page>
<page number="113" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="792" width="18" height="16" font="0">99</text>
<text top="98" left="242" width="452" height="11" font="3">extern &#34;C&#34; void __SKIRRT_yield64(void *from_rtk, void *to_rtk);</text>
<text top="112" left="242" width="29" height="9" font="3">asm(</text>
<text top="112" left="292" width="7" height="9" font="3">\</text>
<text top="126" left="270" width="65" height="9" font="3">&#34;.text\n&#34;</text>
<text top="126" left="356" width="7" height="9" font="3">\</text>
<text top="140" left="270" width="201" height="9" font="3">&#34;.global __SKIRRT_yield64\n&#34;</text>
<text top="140" left="493" width="7" height="9" font="3">\</text>
<text top="154" left="270" width="258" height="9" font="3">&#34;.type __SKIRRT_yield64 @function\n&#34;</text>
<text top="154" left="550" width="7" height="9" font="3">\</text>
<text top="169" left="270" width="93" height="9" font="3">&#34;.align 16\n&#34;</text>
<text top="169" left="385" width="7" height="9" font="3">\</text>
<text top="183" left="256" width="151" height="9" font="3">&#34;__SKIRRT_yield64:\n&#34;</text>
<text top="183" left="428" width="7" height="9" font="3">\</text>
<text top="197" left="270" width="93" height="9" font="3">&#34;popq %rcx\n&#34;</text>
<text top="197" left="385" width="7" height="9" font="3">\</text>
<text top="211" left="270" width="158" height="9" font="3">&#34;movq 8(%rdi), %rdi\n&#34;</text>
<text top="211" left="450" width="7" height="9" font="3">\</text>
<text top="225" left="270" width="158" height="9" font="3">&#34;movq 0(%rdi), %rdi\n&#34;</text>
<text top="225" left="450" width="7" height="9" font="3">\</text>
<text top="240" left="270" width="165" height="9" font="3">&#34;movq 24(%rdi), %r11\n&#34;</text>
<text top="240" left="457" width="7" height="9" font="3">\</text>
<text top="254" left="270" width="165" height="9" font="3">&#34;movq 48(%r11), %r10\n&#34;</text>
<text top="254" left="457" width="7" height="9" font="3">\</text>
<text top="268" left="270" width="100" height="9" font="3">&#34;pushq %rbx\n&#34;</text>
<text top="268" left="392" width="7" height="9" font="3">\</text>
<text top="282" left="270" width="100" height="9" font="3">&#34;pushq %rbp\n&#34;</text>
<text top="282" left="392" width="7" height="9" font="3">\</text>
<text top="296" left="270" width="100" height="9" font="3">&#34;pushq %r12\n&#34;</text>
<text top="296" left="392" width="7" height="9" font="3">\</text>
<text top="311" left="270" width="100" height="9" font="3">&#34;pushq %r13\n&#34;</text>
<text top="311" left="392" width="7" height="9" font="3">\</text>
<text top="325" left="270" width="100" height="9" font="3">&#34;pushq %r14\n&#34;</text>
<text top="325" left="392" width="7" height="9" font="3">\</text>
<text top="339" left="270" width="100" height="9" font="3">&#34;pushq %r15\n&#34;</text>
<text top="339" left="392" width="7" height="9" font="3">\</text>
<text top="353" left="270" width="158" height="9" font="3">&#34;movq %rsp, 0(%rdi)\n&#34;</text>
<text top="353" left="450" width="7" height="9" font="3">\</text>
<text top="367" left="270" width="158" height="9" font="3">&#34;movq %rcx, 8(%rdi)\n&#34;</text>
<text top="367" left="450" width="7" height="9" font="3">\</text>
<text top="382" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="382" left="320" width="93" height="9" font="3">%r11, %rsp\n&#34;</text>
<text top="382" left="435" width="7" height="9" font="3">\</text>
<text top="396" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="396" left="320" width="50" height="9" font="3">%r15\n&#34;</text>
<text top="396" left="392" width="7" height="9" font="3">\</text>
<text top="410" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="410" left="320" width="50" height="9" font="3">%r14\n&#34;</text>
<text top="410" left="392" width="7" height="9" font="3">\</text>
<text top="424" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="424" left="320" width="50" height="9" font="3">%r13\n&#34;</text>
<text top="424" left="392" width="7" height="9" font="3">\</text>
<text top="438" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="438" left="320" width="50" height="9" font="3">%r12\n&#34;</text>
<text top="438" left="392" width="7" height="9" font="3">\</text>
<text top="453" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="453" left="320" width="50" height="9" font="3">%rbp\n&#34;</text>
<text top="453" left="392" width="7" height="9" font="3">\</text>
<text top="467" left="270" width="36" height="9" font="3">&#34;popq</text>
<text top="467" left="320" width="50" height="9" font="3">%rbx\n&#34;</text>
<text top="467" left="392" width="7" height="9" font="3">\</text>
<text top="481" left="270" width="36" height="9" font="3">&#34;movq</text>
<text top="481" left="320" width="93" height="9" font="3">%rsi, %rax\n&#34;</text>
<text top="481" left="435" width="7" height="9" font="3">\</text>
<text top="495" left="270" width="36" height="9" font="3">&#34;addq</text>
<text top="495" left="320" width="79" height="9" font="3">$8, %rsp\n&#34;</text>
<text top="495" left="421" width="7" height="9" font="3">\</text>
<text top="509" left="270" width="93" height="11" font="3">&#34;jmp *%r10\n&#34;</text>
<text top="509" left="385" width="7" height="9" font="3">\</text>
<text top="524" left="270" width="65" height="9" font="3">&#34;ud2\n&#34;);</text>
<text top="549" left="252" width="414" height="16" font="0">Figure 6.6: Implementation of skir.yield for x86-64.</text>
<text top="641" left="151" width="659" height="16" font="0">To a yielding coroutine, the skir.yield operation looks like an ordinary procedure call.</text>
<text top="677" left="108" width="702" height="16" font="0">The operation takes two arguments: the yielding kernel and the blocking kernel. These pointers</text>
<text top="713" left="108" width="702" height="16" font="0">correspond to the runtime kernel objects returned by skir.kernel and are stored inside in the</text>
<text top="749" left="108" width="702" height="16" font="0">SKIR runtime stream object (see Figure 5.2). Because skir.yield executes inside of a stream</text>
<text top="785" left="108" width="702" height="16" font="0">operation, this information is readily available. The implementation of the skir.yield opera-</text>
<text top="821" left="108" width="702" height="16" font="0">tion (Figure 6.6) saves the kernel work function’s execution context context and restores the sched-</text>
<text top="857" left="108" width="702" height="16" font="0">uler context saved by koro workfn 64. It then emulates the return from koro workfn 64.</text>
<text top="893" left="108" width="702" height="16" font="0">The value returned is the blocking kernel. Thus program control ends up back in the scheduler as</text>
<text top="929" left="108" width="702" height="16" font="0">if the kernel work function was called directly then returned a blocking kernel using an ordinary</text>
<text top="964" left="108" width="121" height="16" font="0">return statement.</text>
<text top="1000" left="151" width="659" height="16" font="0">Similar to the skir.yield operation, the implementation of skir.return (Figure 6.7)</text>
<text top="1036" left="108" width="702" height="16" font="0">emulates a return from koro workfn 64 back into the scheduler. Instead of returning a pointer</text>
</page>
<page number="114" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">100</text>
<text top="98" left="242" width="452" height="11" font="3">extern &#34;C&#34; void __SKIRRT_return64(void *rt_state, int ret_val);</text>
<text top="112" left="242" width="29" height="9" font="3">asm(</text>
<text top="112" left="292" width="7" height="9" font="3">\</text>
<text top="126" left="270" width="65" height="9" font="3">&#34;.text\n&#34;</text>
<text top="126" left="356" width="7" height="9" font="3">\</text>
<text top="140" left="270" width="208" height="9" font="3">&#34;.global __SKIRRT_return64\n&#34;</text>
<text top="140" left="500" width="7" height="9" font="3">\</text>
<text top="154" left="270" width="265" height="9" font="3">&#34;.type __SKIRRT_return64 @function\n&#34;</text>
<text top="154" left="557" width="7" height="9" font="3">\</text>
<text top="169" left="270" width="93" height="9" font="3">&#34;.align 16\n&#34;</text>
<text top="169" left="385" width="7" height="9" font="3">\</text>
<text top="183" left="256" width="158" height="9" font="3">&#34;__SKIRRT_return64:\n&#34;</text>
<text top="183" left="435" width="7" height="9" font="3">\</text>
<text top="197" left="270" width="158" height="9" font="3">&#34;movq 0(%rdi), %rdi\n&#34;</text>
<text top="197" left="450" width="7" height="9" font="3">\</text>
<text top="211" left="270" width="165" height="9" font="3">&#34;movq 24(%rdi), %r11\n&#34;</text>
<text top="211" left="457" width="7" height="9" font="3">\</text>
<text top="225" left="270" width="165" height="9" font="3">&#34;movq 32(%rdi), %rdx\n&#34;</text>
<text top="225" left="457" width="7" height="9" font="3">\</text>
<text top="240" left="270" width="165" height="9" font="3">&#34;movq 40(%rdi), %rcx\n&#34;</text>
<text top="240" left="457" width="7" height="9" font="3">\</text>
<text top="254" left="270" width="165" height="9" font="3">&#34;addq 48(%rdi), %rcx\n&#34;</text>
<text top="254" left="457" width="7" height="9" font="3">\</text>
<text top="268" left="270" width="165" height="9" font="3">&#34;movq 48(%r11), %r10\n&#34;</text>
<text top="268" left="457" width="7" height="9" font="3">\</text>
<text top="282" left="270" width="129" height="9" font="3">&#34;subq $56, %rcx\n&#34;</text>
<text top="282" left="421" width="7" height="9" font="3">\</text>
<text top="296" left="270" width="158" height="9" font="3">&#34;movq %rcx, 0(%rdi)\n&#34;</text>
<text top="296" left="450" width="7" height="9" font="3">\</text>
<text top="311" left="270" width="158" height="9" font="3">&#34;movq %rdx, 8(%rdi)\n&#34;</text>
<text top="311" left="450" width="7" height="9" font="3">\</text>
<text top="325" left="270" width="136" height="9" font="3">&#34;movq %r11, %rsp\n&#34;</text>
<text top="325" left="435" width="7" height="9" font="3">\</text>
<text top="339" left="270" width="93" height="9" font="3">&#34;popq %r15\n&#34;</text>
<text top="339" left="385" width="7" height="9" font="3">\</text>
<text top="353" left="270" width="93" height="9" font="3">&#34;popq %r14\n&#34;</text>
<text top="353" left="385" width="7" height="9" font="3">\</text>
<text top="367" left="270" width="93" height="9" font="3">&#34;popq %r13\n&#34;</text>
<text top="367" left="385" width="7" height="9" font="3">\</text>
<text top="382" left="270" width="93" height="9" font="3">&#34;popq %r12\n&#34;</text>
<text top="382" left="385" width="7" height="9" font="3">\</text>
<text top="396" left="270" width="93" height="9" font="3">&#34;popq %rbp\n&#34;</text>
<text top="396" left="385" width="7" height="9" font="3">\</text>
<text top="410" left="270" width="93" height="9" font="3">&#34;popq %rbx\n&#34;</text>
<text top="410" left="385" width="7" height="9" font="3">\</text>
<text top="424" left="270" width="136" height="9" font="3">&#34;movq %rsi, %rax\n&#34;</text>
<text top="424" left="428" width="7" height="9" font="3">\</text>
<text top="438" left="270" width="122" height="9" font="3">&#34;addq $8, %rsp\n&#34;</text>
<text top="438" left="414" width="7" height="9" font="3">\</text>
<text top="453" left="270" width="93" height="11" font="3">&#34;jmp *%r10\n&#34;</text>
<text top="453" left="385" width="7" height="9" font="3">\</text>
<text top="467" left="270" width="65" height="9" font="3">&#34;ud2\n&#34;);</text>
<text top="492" left="246" width="425" height="16" font="0">Figure 6.7: Implementation of skir.return for x86-64.</text>
<text top="584" left="108" width="702" height="16" font="0">to a blocking kernel, however, it returns whatever the kernel work function wants to return. That is,</text>
<text top="620" left="108" width="702" height="16" font="0">it returns a tagged pointer representing a boolean value. The difference from skir.yield is that</text>
<text top="656" left="108" width="702" height="16" font="0">the kernel work function actually wants to return. This means that skir.return implements</text>
<text top="692" left="108" width="702" height="16" font="0">the semantics of a return statement by unwinding the stack. In addition, it resets the context</text>
<text top="728" left="108" width="702" height="16" font="0">information saved for the coroutine, so that next time koro workfn 64 calls the work function,</text>
<text top="764" left="108" width="406" height="16" font="0">it is entered from the top like an ordinary procedure call.</text>
<text top="800" left="151" width="659" height="16" font="0">It should be apparent that the coroutine scheme described in this section adds some overhead</text>
<text top="836" left="108" width="702" height="16" font="0">to the execution of kernel work functions when compared to statically scheduling their execution.</text>
<text top="872" left="108" width="702" height="16" font="0">There are a small number of additional memory operations and procedure calls involved. More</text>
<text top="908" left="108" width="702" height="16" font="0">subtly, the coroutine routines don’t follow normal call and return semantics. This can impact</text>
<text top="944" left="108" width="702" height="16" font="0">hardware branch prediction and therefore overall performance. For kernel work functions that</text>
<text top="980" left="108" width="702" height="16" font="0">require many thousands of cycles per iteration, this overhead is negligible. For simpler kernels, the</text>
<text top="1016" left="108" width="702" height="16" font="0">overhead may be more signiﬁcant. In any case, the overhead of coroutine context switching is less</text>
<text top="1052" left="108" width="702" height="16" font="0">than the overhead of some other dynamic methods such as signaling and context switching at the</text>
</page>
<page number="115" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">101</text>
<text top="128" left="108" width="142" height="16" font="0">level of OS threads.</text>
<text top="190" left="112" width="36" height="16" font="0">6.3.3</text>
<text top="190" left="182" width="173" height="16" font="0">Coroutine Elimination</text>
<text top="239" left="151" width="659" height="16" font="0">For synchronous kernels, it is possible to do better than dynamic scheduling using coroutines</text>
<text top="274" left="108" width="702" height="16" font="0">without relying on static scheduling. In fact, we can eliminate the use of coroutines completely</text>
<text top="310" left="108" width="702" height="16" font="0">for these kernels, while still using coroutines for other kernels in the program. Recall that the</text>
<text top="346" left="108" width="702" height="16" font="0">motivation for using coroutines is that the SKIR compiler cannot know, in general, how much data</text>
<text top="382" left="108" width="702" height="16" font="0">a kernel will read or write each time it is executed. However, for static kernels this information is</text>
<text top="418" left="108" width="702" height="16" font="0">often available via static compiler analysis. We could obtain this information from other sources</text>
<text top="454" left="108" width="702" height="16" font="0">as well. For instance, runtime proﬁling or programmer annotation are realistic options which are</text>
<text top="490" left="108" width="189" height="16" font="0">not explored in this thesis.</text>
<text top="526" left="151" width="659" height="16" font="0">The coroutine elimination optimization pass eliminates the use of coroutines for synchronous</text>
<text top="562" left="108" width="702" height="16" font="0">kernels by computing, each time the kernel is scheduled, how many times the kernel work function</text>
<text top="598" left="108" width="702" height="16" font="0">can execute. It does this by computing how much data is in each input stream and how much</text>
<text top="634" left="108" width="702" height="16" font="0">space is available in each output stream then dividing the results by the kernel’s input and output</text>
<text top="670" left="108" width="702" height="16" font="0">rates. The baseline work function template used by this transformation is shown in Figure 6.8.</text>
<text top="706" left="108" width="114" height="16" font="0">In the ﬁgure the</text>
<text top="707" left="240" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="706" left="462" width="348" height="16" font="0">function computes the number of iterations. The</text>
<text top="742" left="108" width="702" height="16" font="0">result of this function is either the number of iterations niter, or a blocking kernel. The coroutine</text>
<text top="778" left="108" width="702" height="16" font="0">elimination transformation is implemented using the same SKIROuterLoopPass compiler pass</text>
<text top="814" left="108" width="702" height="16" font="0">used for the batching transformation, just with different runtime parameters to use the “nocheck”</text>
<text top="850" left="108" width="130" height="16" font="0">template function.</text>
<text top="886" left="151" width="213" height="16" font="0">We can observe that the use of</text>
<text top="887" left="381" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="886" left="602" width="208" height="16" font="0">makes the conditional checks</text>
<text top="922" left="108" width="702" height="16" font="0">performed by the SKIR stream operations (Figure 5.1) redundant. By precomputing the num-</text>
<text top="958" left="108" width="702" height="16" font="0">ber of iterations, it is guaranteed that there will be data or buffer space available in the input</text>
<text top="994" left="108" width="702" height="16" font="0">and output streams when stream operations execute. We can think of this as hoisting the con-</text>
<text top="1030" left="108" width="702" height="16" font="0">ditional code out of the stream operations, out of the template function while loop, and into the</text>
<text top="1067" left="120" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="1066" left="344" width="466" height="16" font="0">procedure. As a result, when coroutine elimination is used we</text>
</page>
<page number="116" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">102</text>
<text top="104" left="188" width="552" height="11" font="3">void * __SKIRRT_workfn_nocheck(skir_rt_state_t *rt_state, void *kernel_state,</text>
<text top="118" left="410" width="316" height="11" font="3">skir_stream_t *ins[], skir_stream_t *outs[])</text>
<text top="132" left="188" width="7" height="9" font="3">{</text>
<text top="147" left="216" width="57" height="11" font="3">void *v;</text>
<text top="161" left="216" width="430" height="9" font="3">size_t niter = __SKIRRT_compute_niters(&amp;v, ins, 1, outs, 1);</text>
<text top="175" left="216" width="115" height="9" font="3">if (v) return v;</text>
<text top="203" left="216" width="108" height="9" font="3">// start timing</text>
<text top="217" left="216" width="201" height="9" font="3">START_TSC(rt_state-&gt;cycles);</text>
<text top="246" left="216" width="86" height="11" font="3">void *k = 0;</text>
<text top="260" left="216" width="122" height="9" font="3">while (niter--) {</text>
<text top="274" left="245" width="129" height="9" font="3">rt_state-&gt;niter++;</text>
<text top="288" left="245" width="445" height="9" font="3">k = __SKIRRT_workfn_extern(rt_state, kernel_state, ins, outs);</text>
<text top="303" left="245" width="93" height="9" font="3">if (k) break;</text>
<text top="317" left="216" width="7" height="9" font="3">}</text>
<text top="345" left="216" width="100" height="9" font="3">// stop timing</text>
<text top="359" left="216" width="187" height="9" font="3">GET_TSC(rt_state-&gt;cycles);</text>
<text top="388" left="216" width="65" height="9" font="3">return k;</text>
<text top="416" left="188" width="7" height="9" font="3">}</text>
<text top="445" left="188" width="287" height="11" font="3">size_t __SKIRRT_compute_niters(void **v,</text>
<text top="459" left="410" width="222" height="11" font="3">skir_stream_t *ins[], int nins,</text>
<text top="473" left="410" width="237" height="11" font="3">skir_stream_t *outs[], int nouts)</text>
<text top="487" left="188" width="7" height="9" font="3">{</text>
<text top="501" left="216" width="43" height="9" font="3">int i;</text>
<text top="516" left="216" width="194" height="9" font="3">int n = STREAM_BUFFER_SIZE;</text>
<text top="544" left="216" width="179" height="9" font="3">for (i=0; i&lt;nouts; i++) {</text>
<text top="558" left="245" width="194" height="11" font="3">skir_stream_t *s = outs[i];</text>
<text top="572" left="245" width="395" height="9" font="3">size_t space = (__SKIRRT_push_space(s)) / s-&gt;elem_size;</text>
<text top="587" left="245" width="280" height="9" font="3">long long npush = space / s-&gt;push_rate;</text>
<text top="601" left="245" width="301" height="11" font="3">if (npush &lt;= 0) { *v = s-&gt;dst; return 0; }</text>
<text top="615" left="245" width="122" height="9" font="3">n = min(n,npush);</text>
<text top="629" left="216" width="7" height="9" font="3">}</text>
<text top="658" left="216" width="172" height="9" font="3">for (i=0; i&lt;nins; i++) {</text>
<text top="672" left="245" width="187" height="11" font="3">skir_stream_t *s = ins[i];</text>
<text top="686" left="245" width="387" height="9" font="3">size_t space = (__SKIRRT_pop_space(s)) / s-&gt;elem_size;</text>
<text top="700" left="245" width="387" height="9" font="3">long long npop = (space - s-&gt;peek_rate) / s-&gt;pop_rate;</text>
<text top="714" left="245" width="294" height="11" font="3">if (npop &lt;= 0) { *v = s-&gt;src; return 0; }</text>
<text top="729" left="245" width="115" height="9" font="3">n = min(n,npop);</text>
<text top="743" left="216" width="7" height="9" font="3">}</text>
<text top="773" left="216" width="50" height="9" font="3">*v = 0;</text>
<text top="785" left="216" width="65" height="9" font="3">return n;</text>
<text top="800" left="188" width="7" height="9" font="3">}</text>
<text top="825" left="243" width="432" height="16" font="0">Figure 6.8: A coroutine elimination work function template.</text>
<text top="917" left="108" width="702" height="16" font="0">can generate a stream operation implementation that is much simpler. Instead of inlining stream</text>
<text top="953" left="108" width="702" height="16" font="0">operations of the form shown in Figure 6.4, the compiler inlines code of the form shown in Figure</text>
<text top="989" left="108" width="27" height="16" font="0">6.9.</text>
<text top="1025" left="151" width="659" height="16" font="0">Besides eliminating the branch and conditional checking associated with the baseline SKIR</text>
<text top="1061" left="108" width="702" height="16" font="0">stream operations, using stream operations of the form shown in Figure 6.9 has another potential</text>
</page>
<page number="117" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">103</text>
<text top="98" left="187" width="475" height="14" font="1">void __SKIRRT_inline_pop_nocheck (skir_stream_t *p[],</text>
<text top="116" left="492" width="197" height="12" font="1">skir_stream_idx_t idx,</text>
<text top="134" left="492" width="215" height="12" font="1">skir_stream_element_t e)</text>
<text top="152" left="187" width="9" height="12" font="1">{</text>
<text top="169" left="223" width="233" height="14" font="1">skir_stream_t *s = p[idx];</text>
<text top="187" left="223" width="197" height="12" font="1">size_t tail = s-&gt;tail;</text>
<text top="205" left="223" width="350" height="12" font="1">memcpy(e, &amp;s-&gt;buf[tail], s-&gt;elem_size);</text>
<text top="223" left="223" width="475" height="12" font="1">s-&gt;tail = (tail + s-&gt;elem_size) % STREAM_BUFFER_SIZE;</text>
<text top="241" left="187" width="9" height="12" font="1">}</text>
<text top="269" left="166" width="586" height="16" font="0">Figure 6.9: An implementation of skir.pop for use with coroutine elimination.</text>
<text top="361" left="108" width="702" height="16" font="0">beneﬁt. Giacamoni, et. al. [30] argue that not reading both the head and tail each time the</text>
<text top="397" left="108" width="702" height="16" font="0">stream data structure is accessed improves the performance of the operation. This is because while</text>
<text top="433" left="108" width="702" height="16" font="0">pop operations only write tail and push operation only write head, each operation must read</text>
<text top="469" left="108" width="702" height="16" font="0">both. Thus the cache line(s) corresponding to head and tail must be frequently communicated</text>
<text top="505" left="108" width="702" height="16" font="0">between the caches of concurrently executing kernels. In FastForward, this is solved by storing</text>
<text top="540" left="108" width="702" height="16" font="0">a sentinel value in the queue to indicate an empty condition [30]. Because FastForward commu-</text>
<text top="576" left="108" width="702" height="16" font="0">nicates only pointers, this is achievable by using a sentinel of NULL. In SKIR, it is impossible to</text>
<text top="612" left="108" width="702" height="16" font="0">pick such a value because each application communicates using its own internal data types. Us-</text>
<text top="648" left="108" width="702" height="16" font="0">ing coroutine elimination partially solves this problem without a sentinel value. For each input</text>
<text top="684" left="108" width="467" height="16" font="0">(output) stream, the head (tail) index is read only once in the</text>
<text top="685" left="593" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="720" left="108" width="702" height="16" font="0">function. The cost of the access is then spread across many iterations of the kernel work function.</text>
<text top="756" left="108" width="638" height="16" font="0">In addition, in SKIR programs dependent kernels might not always execute concurrently.</text>
<text top="792" left="151" width="659" height="16" font="0">In summary, the coroutine elimination pass does two things. It eliminates the overheads asso-</text>
<text top="828" left="108" width="702" height="16" font="0">ciated with coroutines: separate stacks for each kernel work function, context switching overhead,</text>
<text top="864" left="108" width="702" height="16" font="0">and indirect branching. And, it eliminates some of the overhead associated with the SKIR stream</text>
<text top="900" left="108" width="656" height="16" font="0">communication mechanism: additional branch instructions and inter-cache communication.</text>
<text top="962" left="112" width="36" height="16" font="0">6.3.4</text>
<text top="962" left="182" width="189" height="16" font="0">Specialization Templates</text>
<text top="1010" left="151" width="659" height="16" font="0">In the code transformations discussed in the previous sections, a common technique is to use</text>
<text top="1046" left="108" width="82" height="16" font="0">compiled C</text>
<text top="1046" left="188" width="17" height="13" font="1">++</text>
<text top="1046" left="209" width="601" height="16" font="0">code as a bitcode template for the transformation. For example, this technique is used</text>
</page>
<page number="118" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">104</text>
<text top="128" left="108" width="702" height="16" font="0">with the SKIROuterLoopPass pass to implement the kernel blocking and coroutine elimination</text>
<text top="164" left="108" width="448" height="16" font="0">loop transformations. Within the work function templates, the</text>
<text top="165" left="574" width="207" height="14" font="0">SKIRRT workfn extern</text>
<text top="164" left="785" width="25" height="16" font="0">is a</text>
<text top="200" left="108" width="594" height="16" font="0">parameter replaced by the body of the kernel work function that is being compiled.</text>
<text top="236" left="151" width="659" height="16" font="0">The template technique is also used when lowering SKIR stream operations. For example,</text>
<text top="272" left="108" width="424" height="16" font="0">when generating yielding versions of stream operations, the</text>
<text top="273" left="549" width="185" height="14" font="0">SKIRRT would block</text>
<text top="272" left="738" width="72" height="16" font="0">procedure</text>
<text top="308" left="108" width="702" height="16" font="0">call is a stream operation template parameter, replaced during the code transformation with the</text>
<text top="344" left="108" width="151" height="16" font="0">desired functionality.</text>
<text top="380" left="151" width="659" height="16" font="0">This mechanism is taken a step further in the SKIR implementation by using bitcode tem-</text>
<text top="416" left="108" width="552" height="16" font="0">plates which are themselves parameterized at the source code level using C</text>
<text top="415" left="658" width="17" height="13" font="1">++</text>
<text top="416" left="681" width="129" height="16" font="0">templates. Figure</text>
<text top="452" left="108" width="702" height="16" font="0">6.9 showed a skir.pop implementation that can be used by the coroutine elimination pass. We</text>
<text top="488" left="108" width="702" height="16" font="0">can note two things that are undesirable about the code in that ﬁgure. One is that the size of the</text>
<text top="524" left="108" width="376" height="16" font="0">stream buffer is hard coded to be the maximum size:</text>
<text top="564" left="147" width="520" height="13" font="4">s-&gt;tail = (tail + s-&gt;elem_size) % STREAM_BUFFER_SIZE;</text>
<text top="616" left="108" width="702" height="16" font="0">The other is that the read of data out of the stream buffer requires a lookup of the size of the data</text>
<text top="652" left="108" width="172" height="16" font="0">contained in the stream:</text>
<text top="692" left="147" width="393" height="13" font="4">memcpy(e, &amp;s-&gt;buf[tail], s-&gt;elem_size)}.</text>
<text top="744" left="108" width="702" height="16" font="0">In practice, however, it is preferable to have a version of this function that is specialized with</text>
<text top="780" left="108" width="702" height="16" font="0">respect to the size of the data items in the stream and which allows other stream buffer sizes to be</text>
<text top="816" left="108" width="702" height="16" font="0">used. The parameterized versions of skir.pop actually used by the coroutine elimination pass</text>
<text top="852" left="108" width="702" height="16" font="0">are shown in Figure 6.10. It can be seen in this ﬁgure that the version of skir.pop shown in</text>
<text top="888" left="108" width="702" height="16" font="0">Figure 6.9 is generated as a special case. It can be used when there isn’t a specialized version of</text>
<text top="924" left="108" width="206" height="16" font="0">the operation available. The</text>
<text top="925" left="333" width="256" height="14" font="0">SKIRRT INLINE POP NOCHECK</text>
<text top="924" left="595" width="215" height="16" font="0">macro in the ﬁgure is used to</text>
<text top="960" left="108" width="702" height="16" font="0">statically instantiate different versions of the operation at compile time (i.e. when the compiler</text>
<text top="996" left="108" width="421" height="16" font="0">library is compiled, not when a user program is compiled).</text>
<text top="1032" left="151" width="659" height="16" font="0">Using versions of the bitcode templates parametrized in this way results in better code gen-</text>
<text top="1068" left="108" width="702" height="16" font="0">eration by the compiler. For the example above, the use of a constant in the memcpy operation</text>
</page>
<page number="119" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">105</text>
<text top="98" left="108" width="230" height="9" font="3">template&lt; int ELMSZ, int BUFSZ &gt;</text>
<text top="112" left="108" width="409" height="11" font="3">void __SKIRRT_inline_pop_nocheck_E_B_(skir_stream_t *p[],</text>
<text top="126" left="381" width="158" height="9" font="3">skir_stream_idx_t idx,</text>
<text top="140" left="381" width="172" height="9" font="3">skir_stream_element_t e)</text>
<text top="154" left="108" width="7" height="9" font="3">{</text>
<text top="169" left="137" width="187" height="11" font="3">skir_stream_t *s = p[idx];</text>
<text top="183" left="137" width="158" height="9" font="3">size_t tail = s-&gt;tail;</text>
<text top="197" left="137" width="172" height="9" font="3">memcpy(e, &amp;s-&gt;buf[tail],</text>
<text top="197" left="323" width="50" height="9" font="3">ELMSZ);</text>
<text top="211" left="137" width="237" height="9" font="3">s-&gt;tail = (tail + ELMSZ) % BUFSZ;</text>
<text top="225" left="108" width="7" height="9" font="3">}</text>
<text top="254" left="108" width="72" height="9" font="3">template&lt;&gt;</text>
<text top="268" left="108" width="473" height="11" font="3">void __SKIRRT_inline_pop_nocheck_E_B_&lt; 0, 0 &gt; (skir_stream_t *p[],</text>
<text top="282" left="445" width="158" height="9" font="3">skir_stream_idx_t idx,</text>
<text top="296" left="445" width="172" height="9" font="3">skir_stream_element_t e)</text>
<text top="311" left="108" width="7" height="9" font="3">{</text>
<text top="325" left="137" width="187" height="11" font="3">skir_stream_t *s = p[idx];</text>
<text top="339" left="137" width="158" height="9" font="3">size_t tail = s-&gt;tail;</text>
<text top="353" left="137" width="172" height="9" font="3">memcpy(e, &amp;s-&gt;buf[tail],</text>
<text top="353" left="323" width="100" height="9" font="3">s-&gt;elem_size);</text>
<text top="367" left="137" width="380" height="9" font="3">s-&gt;tail = (tail + s-&gt;elem_size) % STREAM_BUFFER_SIZE;</text>
<text top="382" left="108" width="7" height="9" font="3">}</text>
<text top="410" left="108" width="717" height="11" font="3">void (* __SKIRRT_inline_pop_nocheck)(skir_stream_t **, skir_stream_idx_t, skir_stream_element_t) = \</text>
<text top="424" left="137" width="301" height="9" font="3">&amp;__SKIRRT_inline_pop_nocheck_E_B_&lt; 0, 0 &gt;;</text>
<text top="453" left="108" width="459" height="9" font="3">#define __SKIRRT_INLINE_POP_NOCHECK(ELEMENT_SIZE, BUFFER_SIZE) \</text>
<text top="467" left="137" width="617" height="11" font="3">void (* __SKIRRT_inline_pop_nocheck_##ELEMENT_SIZE##_##BUFFER_SIZE)(skir_stream_t **,\</text>
<text top="481" left="624" width="143" height="9" font="3">skir_stream_idx_t, \</text>
<text top="495" left="624" width="187" height="9" font="3">skir_stream_element_t) = \</text>
<text top="509" left="137" width="452" height="9" font="3">&amp;__SKIRRT_inline_pop_nocheck_E_B_&lt; ELEMENT_SIZE, BUFFER_SIZE &gt;;</text>
<text top="538" left="108" width="265" height="9" font="3">__SKIRRT_INLINE_POP_NOCHECK(4,16384);</text>
<text top="552" left="108" width="265" height="9" font="3">__SKIRRT_INLINE_POP_NOCHECK(8,16384);</text>
<text top="566" left="108" width="265" height="9" font="3">__SKIRRT_INLINE_POP_NOCHECK(4,32768);</text>
<text top="580" left="108" width="265" height="9" font="3">__SKIRRT_INLINE_POP_NOCHECK(8,32768);</text>
<text top="595" left="108" width="22" height="9" font="3">...</text>
<text top="628" left="157" width="605" height="16" font="0">Figure 6.10: Generating specialized skir.pop templates with meta-programming.</text>
<text top="720" left="108" width="702" height="16" font="0">ensures that the compiler generates a move instruction, instead of an expensive call to memcpy.</text>
<text top="756" left="108" width="702" height="16" font="0">Most of the bitcode templates used by the SKIR compiler are parameterized in this way with re-</text>
<text top="792" left="108" width="702" height="16" font="0">spect to stream buffer size and data size. As another example of how this can improve performance,</text>
<text top="828" left="108" width="88" height="16" font="0">consider the</text>
<text top="829" left="215" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="828" left="438" width="372" height="16" font="0">procedure shown in Figure 6.8. One of the expres-</text>
<text top="864" left="108" width="702" height="16" font="0">sions in this function is a division based on the size of the data elements in the stream. When the</text>
<text top="900" left="108" width="179" height="16" font="0">parameterized version of</text>
<text top="901" left="305" width="217" height="14" font="0">SKIRRT compute niters</text>
<text top="900" left="527" width="283" height="16" font="0">is used, the divisor in this expression is</text>
<text top="936" left="108" width="702" height="16" font="0">a constant power of two instead of a value loaded from memory. As a result, the optimizer can</text>
<text top="972" left="108" width="702" height="16" font="0">use strength reduction to change the operation into a shift operation which is much cheaper than</text>
<text top="1008" left="108" width="62" height="16" font="0">division.</text>
</page>
<page number="120" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">106</text>
<text top="128" left="112" width="36" height="16" font="0">6.3.5</text>
<text top="128" left="182" width="76" height="16" font="0">Summary</text>
<text top="189" left="455" width="9" height="17" font="0">↓</text>
<text top="212" left="399" width="119" height="16" font="0">Outer Loop Pass</text>
<text top="232" left="455" width="9" height="17" font="0">↓</text>
<text top="255" left="347" width="223" height="16" font="0">Standard LLVM Optimizations</text>
<text top="276" left="455" width="9" height="17" font="0">↓</text>
<text top="298" left="363" width="193" height="16" font="0">Stream Specialization Pass</text>
<text top="319" left="455" width="9" height="17" font="0">↓</text>
<text top="342" left="385" width="148" height="16" font="0">Stream Inlining Pass</text>
<text top="362" left="455" width="9" height="17" font="0">↓</text>
<text top="385" left="324" width="271" height="16" font="0">Coroutine Inlining Pass (if necessary)</text>
<text top="406" left="455" width="9" height="17" font="0">↓</text>
<text top="458" left="219" width="480" height="16" font="0">Figure 6.11: Execution order of SKIR kernel specialization passes.</text>
<text top="528" left="151" width="659" height="16" font="0">This section has described most of the code transformations that run during kernel specializa-</text>
<text top="564" left="108" width="702" height="16" font="0">tion. These can be summarized by describing the compiler passes implementing this functionality</text>
<text top="600" left="108" width="702" height="16" font="0">and describing the order in which they run. The SKIR kernel specialization passes run in the order</text>
<text top="636" left="108" width="156" height="16" font="0">shown in Figure 6.11.</text>
<text top="672" left="151" width="659" height="16" font="0">The ﬁrst pass that runs is the outer loop pass, SKIROuterLoopPass, which was par-</text>
<text top="708" left="108" width="702" height="16" font="0">tially described above. This pass takes a kernel work function template representing the desired</text>
<text top="744" left="108" width="702" height="16" font="0">scheduling methodology (e.g. coroutines or coroutine elimination), and inlines the actual ker-</text>
<text top="780" left="108" width="702" height="16" font="0">nel work function into that template. At the same time, SKIROuterLoopPass replaces any</text>
<text top="817" left="108" width="97" height="14" font="0">skir.push</text>
<text top="816" left="205" width="605" height="16" font="0">, skir.pop, or skir.peek operations with calls to their desired implementa-</text>
<text top="852" left="108" width="702" height="16" font="0">tion. As with the kernel work function template, an optional sufﬁx string determines which ver-</text>
<text top="888" left="108" width="702" height="16" font="0">sion of the operation gets used (for example the “nocheck” sufﬁx seen in Figure 6.10). After</text>
<text top="925" left="108" width="183" height="14" font="0">SKIROuterLoopPass</text>
<text top="924" left="291" width="519" height="16" font="0">, a set of standard LLVM passes run to clean up any messes left behind</text>
<text top="960" left="108" width="98" height="16" font="0">after inlining.</text>
<text top="996" left="151" width="659" height="16" font="0">The stream specialization pass, called SKIRStreamOptsPass, runs next. This function</text>
<text top="1032" left="108" width="702" height="16" font="0">further specializes stream operations to the size of data in the stream and the size of the stream</text>
<text top="1068" left="108" width="328" height="16" font="0">buffer by replacing function calls of the form,</text>
</page>
<page number="121" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">107</text>
<text top="130" left="147" width="314" height="13" font="4">__SKIRRT_inline_pop_suffix (...)</text>
<text top="184" left="108" width="280" height="16" font="0">With function calls similar to the form,</text>
<text top="225" left="147" width="393" height="13" font="4">__SKIRRT_inline_pop_suffix_4_32768 (...)</text>
<text top="279" left="108" width="702" height="16" font="0">In this case 4 is the size of data stored in the stream and 32768 is the size of the stream buffer.</text>
<text top="315" left="108" width="702" height="16" font="0">This transformation can take place for all stream operations because we always know both of these</text>
<text top="351" left="108" width="66" height="16" font="0">numbers.</text>
<text top="387" left="151" width="659" height="16" font="0">After stream specialization, the stream operation inlining pass, SKIRStreamInlining,</text>
<text top="423" left="108" width="702" height="16" font="0">can run. As its name implies, this transformation pass simply inlines the implementation of the</text>
<text top="459" left="108" width="702" height="16" font="0">specialized stream operations into the kernel work function. It also inlines skir.become as a</text>
<text top="495" left="108" width="702" height="16" font="0">call into the SKIR runtime. After inlining, we are done for synchronous kernels if we are running</text>
<text top="531" left="108" width="702" height="16" font="0">them under coroutine elimination. That is, all SKIR operations have been completely lowered</text>
<text top="567" left="108" width="702" height="16" font="0">to stock LLVM operations. For other kernels or scheduling options, we still have to handle the</text>
<text top="603" left="108" width="406" height="16" font="0">blocking condition of the stream operations by replacing</text>
<text top="603" left="531" width="185" height="14" font="0">SKIRRT would block</text>
<text top="603" left="716" width="4" height="16" font="0">.</text>
<text top="638" left="151" width="684" height="16" font="0">For coroutine scheduling, we handle the blocking condition with a pass called SKIRKoroPass.</text>
<text top="674" left="108" width="271" height="16" font="0">This pass is very simple. It replaces</text>
<text top="675" left="398" width="185" height="14" font="0">SKIRRT would block</text>
<text top="674" left="590" width="220" height="16" font="0">with skir.yield and it re-</text>
<text top="710" left="108" width="702" height="16" font="0">places LLVM return statements with skir.return. These two operations are lowered during</text>
<text top="746" left="108" width="702" height="16" font="0">code generation to calls to the appropriate assembly routines. This is done during code generation</text>
<text top="782" left="108" width="702" height="16" font="0">instead of in a kernel specialization pass because for architectures other than x86, it may be prefer-</text>
<text top="818" left="108" width="702" height="16" font="0">able to emit machine code implementing skir.yield and skir.return directly into the</text>
<text top="854" left="108" width="702" height="16" font="0">kernel work function. This cannot be performed in a LLVM level transformation pass because</text>
<text top="890" left="108" width="702" height="16" font="0">the functionality of skir.yield and skir.return are architecture speciﬁc and because the</text>
<text top="926" left="108" width="702" height="16" font="0">LLVM JIT does not support inline assembly. For x86, this is not an issue because we must use</text>
<text top="962" left="108" width="702" height="16" font="0">a procedure call to obtain the program counter, allowing the skir.yield and skir.return</text>
<text top="998" left="108" width="513" height="16" font="0">routines to be written in assembly and compiled into the SKIR runtime.</text>
</page>
<page number="122" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">108</text>
<text top="128" left="112" width="22" height="16" font="0">6.4</text>
<text top="128" left="170" width="131" height="16" font="0">Code Generation</text>
<text top="183" left="151" width="659" height="16" font="0">After kernel specialization there will not be any SKIR operations remaining in the kernel</text>
<text top="219" left="108" width="702" height="16" font="0">work function except for possibly some skir.yield and skir.return operations. The rest</text>
<text top="255" left="108" width="702" height="16" font="0">of code generation can be performed using the ordinary LLVM JIT compiler. Before this is done,</text>
<text top="291" left="108" width="702" height="16" font="0">a set of standard optimization passes is run on the specialized kernel. This cleans up any dead</text>
<text top="327" left="108" width="702" height="16" font="0">code or other messes left by the transformations of kernel specialization and takes advantage of</text>
<text top="363" left="108" width="702" height="16" font="0">any optimization opportunities they created. The set of passes is roughly equal to LLVM’s -O2</text>
<text top="399" left="108" width="702" height="16" font="0">command line ﬂag. Many JIT compilers uses a multi-stage approach to optimization, where the</text>
<text top="435" left="108" width="702" height="16" font="0">code is initially JIT compiled as quickly as possible, without much optimization. Optimization</text>
<text top="471" left="108" width="702" height="16" font="0">might be applied later, but only after runtime proﬁling has identiﬁed a section of code as hot. In</text>
<text top="507" left="108" width="702" height="16" font="0">SKIR, the assumption is made that kernels are always long running and hot. LLVM is not known</text>
<text top="542" left="108" width="702" height="16" font="0">for its fast JIT times, so the trade-off between latency and throughput with respect to JIT time is a</text>
<text top="578" left="108" width="607" height="16" font="0">potential area for future research, both in SKIR speciﬁcally and in LLVM in general.</text>
<text top="614" left="151" width="659" height="16" font="0">Code generation (i.e. from LLVM bitcode to machine code), along with all of the other kernel</text>
<text top="650" left="108" width="702" height="16" font="0">transformation passes, takes place the ﬁrst time the kernel is picked by the dynamic scheduler for</text>
<text top="686" left="108" width="702" height="16" font="0">execution. That is, it is done lazily. This allows the code generation to potentially take place in</text>
<text top="722" left="108" width="702" height="16" font="0">parallel with the rest of the program. The main limitation to this parallelism is that access to the</text>
<text top="758" left="108" width="702" height="16" font="0">JIT itself must be serialized, because that is what LLVM currently requires. Up to n kernels could</text>
<text top="794" left="108" width="702" height="16" font="0">contend for access to the JIT during the beginning phase of execution, where n is the number of</text>
<text top="830" left="108" width="263" height="16" font="0">worker threads running the program.</text>
<text top="888" left="112" width="22" height="16" font="0">6.5</text>
<text top="888" left="170" width="157" height="16" font="0">Compiling for GPUs</text>
<text top="943" left="151" width="659" height="16" font="0">Stream parallelism is known to be an appropriate programming model for non-CPU hard-</text>
<text top="979" left="108" width="702" height="16" font="0">ware such as graphics processors [23][38][54]. This is largely due to the stream communication</text>
<text top="1015" left="108" width="702" height="16" font="0">abstraction, good encapsulation of kernel state, and abundant parallelism. A stream parallel pro-</text>
<text top="1051" left="108" width="702" height="16" font="0">gram representation like SKIR coupled with a dynamic compilation environment is ideally suited</text>
</page>
<page number="123" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">109</text>
<text top="128" left="108" width="702" height="16" font="0">for heterogeneous computing. Not only does SKIR enable existing static program transformations</text>
<text top="164" left="108" width="702" height="16" font="0">and scheduling techniques for heterogeneous platforms, it allows dynamic re-targeting of code to</text>
<text top="200" left="108" width="702" height="16" font="0">these same types of systems. Furthermore SKIR allows for applications where only select parts of</text>
<text top="236" left="108" width="702" height="16" font="0">the program are designed around stream parallelism, and with only parts of those stream graphs</text>
<text top="272" left="108" width="702" height="16" font="0">running on hardware accelerators. This section demonstrates this ability by describing how SKIR</text>
<text top="308" left="108" width="702" height="16" font="0">can take advantage of a heterogeneous platform consisting of a CPU coupled with a discrete GPU</text>
<text top="344" left="108" width="243" height="16" font="0">to accelerate data parallel kernels.</text>
<text top="380" left="151" width="659" height="16" font="0">Data parallel portions of stream programs, like many data parallel computations, are suitable</text>
<text top="416" left="108" width="702" height="16" font="0">for acceleration by graphics processors. GPU acceleration is supported by the SKIR compiler using</text>
<text top="452" left="108" width="702" height="16" font="0">an OpenCL backend. OpenCL deﬁnes programming, execution, and memory models tailored for</text>
<text top="488" left="108" width="702" height="16" font="0">heterogeneous computing. The primary programming model for OpenCL applications is to specify</text>
<text top="524" left="108" width="702" height="16" font="0">data parallel kernels in a kernel language derived from C. These kernels execute on one or more</text>
<text top="560" left="108" width="702" height="16" font="0">OpenCL compute devices which are physically or logically separate from the host processor. The</text>
<text top="596" left="108" width="702" height="16" font="0">execution model deﬁnes how many instances of a particular kernel execute on the compute device.</text>
<text top="632" left="108" width="702" height="16" font="0">Using the OpenCL API, the host program deﬁnes a 1, 2, or 3 dimensional iteration space for each</text>
<text top="668" left="108" width="702" height="16" font="0">kernel. This iteration space is called a NDRange. One instance of the kernel runs for each point in</text>
<text top="704" left="108" width="702" height="16" font="0">the NDRange. Each NDRange is also divided into sub-spaces called work groups. The OpenCL</text>
<text top="740" left="108" width="702" height="16" font="0">memory model provides four levels of memory to an OpenCL kernel: global, constant, local, and</text>
<text top="776" left="108" width="702" height="16" font="0">private. Global memory is large and accessible from all kernel instances. Constant memory is read</text>
<text top="812" left="108" width="702" height="16" font="0">only and initialized by the host program. Local memory is smaller and faster than global memory</text>
<text top="848" left="108" width="702" height="16" font="0">and is shared by all kernel instances within a work group. Private memory is a small region of</text>
<text top="884" left="108" width="439" height="16" font="0">memory private to each kernel instance in the iteration space.</text>
<text top="920" left="151" width="659" height="16" font="0">The SKIR compiler maps data parallel SKIR kernels onto the OpenCL execution model by</text>
<text top="956" left="108" width="702" height="16" font="0">deﬁning one dimensional NDRanges. Each time an OpenCL version of a SKIR kernel executes, it</text>
<text top="992" left="108" width="702" height="16" font="0">computes the amount of input data and output space available in its stream buffers. The result and</text>
<text top="1027" left="108" width="702" height="16" font="0">the kernel’s rates determine how many iterations of the kernel can run. This is similar to the calcu-</text>
<text top="1063" left="108" width="702" height="16" font="0">lation performed in kernels transformed by coroutine elimination. To run the kernel work function</text>
</page>
<page number="124" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="16" size="17" family="Times" color="#1a1a1a"/>
	<fontspec id="17" size="17" family="Times" color="#1a1a1a"/>
	<fontspec id="18" size="27" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">110</text>
<text top="128" left="108" width="702" height="16" font="0">a one dimensional NDRange with size equal to the number of computed iterations is created. This</text>
<text top="164" left="108" width="702" height="16" font="0">ensures that the OpenCL runtime will execute one instance of the kernel work function for each of</text>
<text top="200" left="108" width="702" height="16" font="0">the necessary iterations. Each kernel instance uses its point in the NDRange to read and write the</text>
<text top="236" left="108" width="656" height="16" font="0">appropriate region of the stream buffer. This execution strategy is illustrated in Figure 6.12.</text>
<text top="398" left="174" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="198" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="198" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="217" width="10" height="15" font="2">...</text>
<text top="456" left="195" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="195" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="195" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="174" width="6" height="15" font="2">}</text>
<text top="398" left="263" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="286" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="286" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="305" width="10" height="15" font="2">...</text>
<text top="456" left="284" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="283" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="284" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="263" width="6" height="15" font="2">}</text>
<text top="398" left="351" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="375" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="375" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="394" width="10" height="15" font="2">...</text>
<text top="456" left="372" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="372" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="372" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="351" width="6" height="15" font="2">}</text>
<text top="398" left="440" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="463" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="463" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="482" width="10" height="15" font="2">...</text>
<text top="456" left="461" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="460" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="461" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="440" width="6" height="15" font="2">}</text>
<text top="398" left="529" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="552" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="552" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="571" width="10" height="15" font="2">...</text>
<text top="456" left="550" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="549" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="550" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="529" width="6" height="15" font="2">}</text>
<text top="398" left="617" width="55" height="15" font="2">work(...) {</text>
<text top="412" left="640" width="48" height="15" font="2">pop(0, a)</text>
<text top="427" left="640" width="49" height="15" font="2">pop(0, b)</text>
<text top="441" left="660" width="10" height="15" font="2">...</text>
<text top="456" left="638" width="53" height="15" font="2">push(0, c)</text>
<text top="470" left="638" width="54" height="15" font="2">push(0, d)</text>
<text top="485" left="638" width="53" height="15" font="2">push(0, e)</text>
<text top="499" left="617" width="6" height="15" font="2">}</text>
<text top="629" left="355" width="176" height="22" font="16">output stream buffer</text>
<text top="271" left="371" width="164" height="22" font="16">input stream buffer</text>
<text top="511" left="204" width="44" height="22" font="17"><i>iter 0</i></text>
<text top="511" left="292" width="44" height="22" font="17"><i>iter 1</i></text>
<text top="511" left="381" width="44" height="22" font="17"><i>iter 2</i></text>
<text top="511" left="470" width="44" height="22" font="17"><i>iter 3</i></text>
<text top="511" left="558" width="44" height="22" font="17"><i>iter 4</i></text>
<text top="511" left="647" width="44" height="22" font="17"><i>iter 5</i></text>
<text top="289" left="647" width="25" height="33" font="18">...</text>
<text top="584" left="735" width="25" height="33" font="18">...</text>
<text top="452" left="735" width="25" height="33" font="18">...</text>
<text top="676" left="108" width="702" height="16" font="0">Figure 6.12: An example of the one work function instance per iteration execution strategy used</text>
<text top="698" left="108" width="697" height="16" font="0">by the OpenCL backend. In this example the kernel has an input rate of 2 and an output rate of 3.</text>
<text top="770" left="151" width="659" height="16" font="0">To emit a kernel as OpenCL code, the runtime compiler must be able to statically determine</text>
<text top="806" left="108" width="702" height="16" font="0">all read-only state used by the kernel. This is because all such state must be packaged up and</text>
<text top="842" left="108" width="702" height="16" font="0">transferred to the GPU device before the kernel can execute there. In the current implementation,</text>
<text top="878" left="108" width="702" height="16" font="0">the SKIR compiler is able to obtain this information if the program gives a typed pointer as state</text>
<text top="914" left="108" width="702" height="16" font="0">information to the skir.call operation and it can be determined that a shallow copy is sufﬁcient</text>
<text top="950" left="108" width="702" height="16" font="0">to transfer the state. A shallow copy is sufﬁcient when the kernel state does not contain any pointers</text>
<text top="986" left="108" width="702" height="16" font="0">to other memory. These are similar to the requirements placed on Sluice kernels in Section 4.4 only</text>
<text top="1022" left="108" width="702" height="16" font="0">instead of using SKIR as a compiler backend to accelerate JavaScript, we are using OpenCL as a</text>
<text top="1058" left="108" width="272" height="16" font="0">compiler backend to accelerate SKIR.</text>
</page>
<page number="125" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="19" size="20" family="Times" color="#1a1a1a"/>
	<fontspec id="20" size="15" family="Times" color="#1a1a1a"/>
	<fontspec id="21" size="13" family="Times" color="#000000"/>
<text top="85" left="783" width="27" height="16" font="0">111</text>
<text top="393" left="335" width="28" height="25" font="19">K1</text>
<text top="405" left="567" width="20" height="18" font="11">K2</text>
<text top="409" left="563" width="20" height="18" font="11">K2</text>
<text top="414" left="557" width="20" height="18" font="11">K2</text>
<text top="418" left="552" width="20" height="18" font="11">K2</text>
<text top="399" left="339" width="20" height="18" font="11">K2</text>
<text top="212" left="335" width="27" height="25" font="19">K1</text>
<text top="578" left="335" width="27" height="25" font="19">K3</text>
<text top="375" left="316" width="64" height="20" font="20">r/o state</text>
<text top="376" left="528" width="69" height="17" font="7">state copy</text>
<text top="109" left="340" width="40" height="21" font="13">CPU</text>
<text top="111" left="509" width="41" height="21" font="13">GPU</text>
<text top="309" left="520" width="83" height="17" font="21">input stream</text>
<text top="483" left="518" width="92" height="17" font="21">output stream</text>
<text top="333" left="310" width="75" height="13" font="6">OpenCL Buffer</text>
<text top="478" left="310" width="75" height="13" font="6">OpenCL Buffer</text>
<text top="438" left="299" width="99" height="15" font="2">OpenCL Control</text>
<text top="396" left="423" width="64" height="18" font="11">OpenCL </text>
<text top="414" left="442" width="26" height="18" font="11">API</text>
<text top="702" left="201" width="516" height="16" font="0">Figure 6.13: The structure of OpenCL ofﬂoad within the SKIR runtime.</text>
<text top="794" left="151" width="659" height="16" font="0">Because the buffers allocated for stream communication must ﬁt in the processor’s L1 cache</text>
<text top="830" left="108" width="702" height="16" font="0">(for performance reasons), they can be much smaller than the amount of data needed to proﬁtably</text>
<text top="866" left="108" width="702" height="16" font="0">execute a computation on a discrete GPU. For small amounts of data, the communication overhead</text>
<text top="902" left="108" width="702" height="16" font="0">between the GPU and the CPU can dwarf the performance gains. The kernel to be accelerated</text>
<text top="938" left="108" width="702" height="16" font="0">is therefore replaced by a stub kernel that primarily reads data from the input and output streams</text>
<text top="974" left="108" width="702" height="16" font="0">into and out of larger device buffers. These buffers are mapped into the OpenCL runtime. When</text>
<text top="1010" left="108" width="702" height="16" font="0">enough data has been buffered, the kernel state is copied to the device and the OpenCL version of</text>
<text top="1046" left="108" width="702" height="16" font="0">the kernel is executed. Output data is pushed to the output stream of the original kernel as space</text>
</page>
<page number="126" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">112</text>
<text top="128" left="108" width="702" height="16" font="0">becomes available. This enables enough data to be buffered to proﬁtably execute on the GPU while</text>
<text top="164" left="108" width="702" height="16" font="0">decoupling the execution of the OpenCL kernel from the rest of the program. The decoupling effect</text>
<text top="200" left="108" width="702" height="16" font="0">is similar to manual double-buffering and allows the upstream and downstream kernels to execute</text>
<text top="236" left="108" width="702" height="16" font="0">without knowing that the accelerated kernel is executing on an OpenCL device. The structure of a</text>
<text top="272" left="108" width="628" height="16" font="0">SKIR kernel running using OpenCL acceleration is depicted graphically in Figure 6.13.</text>
<text top="330" left="112" width="22" height="16" font="0">6.6</text>
<text top="330" left="170" width="289" height="16" font="0">Stream Graph Level Transformations</text>
<text top="385" left="151" width="659" height="16" font="0">There are two basic stream graph transformations that are building blocks for stream graph</text>
<text top="421" left="108" width="702" height="16" font="0">manipulation. They are kernel fusion and kernel ﬁssion. These transformations can be applied stat-</text>
<text top="457" left="108" width="702" height="16" font="0">ically at compile time based on the output of a static scheduling algorithm, or they can be applied</text>
<text top="493" left="108" width="702" height="16" font="0">dynamically at runtime, based on the results of runtime proﬁling. In this section we describe how</text>
<text top="529" left="108" width="461" height="16" font="0">SKIR supports these transformations in a dynamic environment.</text>
<text top="565" left="151" width="659" height="16" font="0">Kernel fusion is simply the merging of two kernels into one kernel. When the number of</text>
<text top="600" left="108" width="702" height="16" font="0">program kernels is larger than the number of worker threads or when kernels are excessively ﬁne</text>
<text top="636" left="108" width="702" height="16" font="0">grained, it can be beneﬁcial to apply kernel fusion to eliminate unnecessary stream communication</text>
<text top="672" left="108" width="702" height="16" font="0">between program kernels and reduce the number of kernels to be scheduled. After kernels are</text>
<text top="708" left="108" width="702" height="16" font="0">merged, the stream communication between them can be optimized by replacing stream operations</text>
<text top="744" left="108" width="702" height="16" font="0">with reads and writes to registers or to the stack. If the original kernels are part of a stream graph,</text>
<text top="780" left="108" width="466" height="16" font="0">then they can be replaced in the graph with the new fused kernel.</text>
<text top="816" left="151" width="659" height="16" font="0">Kernel ﬁssion is simply the splitting of a data parallel kernel in to many kernels. When a</text>
<text top="852" left="108" width="702" height="16" font="0">stream graph is dominated by one or a few coarse grained kernels, it can be beneﬁcial to increase</text>
<text top="888" left="108" width="702" height="16" font="0">parallelism by splitting data into multiple kernels. As with any data parallel computation, there</text>
<text top="924" left="108" width="702" height="16" font="0">are many ways this can be done. One method, described in Section 6.5, is to use data parallel</text>
<text top="960" left="108" width="702" height="16" font="0">hardware. Another method, described below, is to leverage the stream parallel environment and</text>
<text top="996" left="108" width="702" height="16" font="0">replace the data parallel kernel with a split-join, provisioning a split kernel to divide the work to</text>
<text top="1032" left="108" width="625" height="16" font="0">be done among copies of the original kernel, and a join kernel to recombine the results.</text>
</page>
<page number="127" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">113</text>
<text top="128" left="112" width="36" height="16" font="0">6.6.1</text>
<text top="128" left="182" width="227" height="16" font="0">Fusion: Reducing Parallelism</text>
<text top="176" left="151" width="659" height="16" font="0">We implement fusion as a dynamic runtime optimization. Dynamic fusion is desirable be-</text>
<text top="212" left="108" width="702" height="16" font="0">cause it is not until runtime that good decisions on the proﬁtability of fusion can be made. If there</text>
<text top="248" left="108" width="702" height="16" font="0">are 16 processors available we may make very different decisions about when to employ fusion</text>
<text top="284" left="108" width="702" height="16" font="0">compared to when there is just one processor available. At runtime we have better proﬁle infor-</text>
<text top="320" left="108" width="702" height="16" font="0">mation through the use of cycle counters, we have better information about stream graph structure,</text>
<text top="356" left="108" width="484" height="16" font="0">and we have better information about available hardware resources.</text>
<text top="392" left="151" width="659" height="16" font="0">Our basic fusion algorithm for merging two SKIR kernels is shown in Figures 6.14 and 6.15.</text>
<text top="428" left="108" width="702" height="16" font="0">The algorithm begins by computing the set of streams that are common to the two kernels, the set</text>
<text top="464" left="108" width="702" height="16" font="0">of streams that will be inputs to the fused kernel, and the set of streams that will be outputs to the</text>
<text top="500" left="108" width="702" height="16" font="0">fused kernel. The set of common streams is the set of streams that the fusion algorithm is trying to</text>
<text top="536" left="108" width="71" height="16" font="0">eliminate.</text>
<text top="569" left="273" width="85" height="15" font="4">procedure F</text>
<text top="572" left="358" width="26" height="12" font="15">USE</text>
<text top="569" left="386" width="12" height="15" font="4">K</text>
<text top="572" left="398" width="53" height="12" font="15">ERNELS</text>
<text top="569" left="452" width="19" height="15" font="4">(K</text>
<text top="575" left="472" width="6" height="11" font="3">0</text>
<text top="569" left="479" width="22" height="15" font="4">, K</text>
<text top="575" left="501" width="6" height="11" font="3">1</text>
<text top="569" left="508" width="5" height="15" font="4">)</text>
<text top="589" left="297" width="10" height="15" font="4">S</text>
<text top="595" left="307" width="9" height="11" font="3">C</text>
<text top="590" left="322" width="207" height="15" font="4">= ComputeCommonStreams(K</text>
<text top="595" left="529" width="6" height="11" font="3">0</text>
<text top="589" left="537" width="21" height="15" font="4">, K</text>
<text top="595" left="558" width="6" height="11" font="3">1</text>
<text top="589" left="565" width="6" height="15" font="4">)</text>
<text top="610" left="297" width="10" height="15" font="4">S</text>
<text top="615" left="307" width="17" height="11" font="3">IN</text>
<text top="610" left="330" width="181" height="15" font="4">= ComputeInputStreams(K</text>
<text top="615" left="511" width="6" height="11" font="3">0</text>
<text top="610" left="518" width="21" height="15" font="4">, K</text>
<text top="615" left="539" width="6" height="11" font="3">1</text>
<text top="610" left="546" width="6" height="15" font="4">)</text>
<text top="630" left="297" width="10" height="15" font="4">S</text>
<text top="636" left="307" width="27" height="11" font="3">OU T</text>
<text top="630" left="341" width="192" height="15" font="4">= ComputeOutputStreams(K</text>
<text top="636" left="533" width="6" height="11" font="3">0</text>
<text top="630" left="540" width="21" height="15" font="4">, K</text>
<text top="636" left="561" width="6" height="11" font="3">1</text>
<text top="630" left="568" width="6" height="15" font="4">)</text>
<text top="671" left="297" width="161" height="15" font="4">RenumberStreamOps(K</text>
<text top="676" left="459" width="6" height="11" font="3">0</text>
<text top="671" left="466" width="17" height="15" font="4">, S</text>
<text top="676" left="483" width="17" height="11" font="3">IN</text>
<text top="671" left="502" width="17" height="15" font="4">, S</text>
<text top="676" left="519" width="27" height="11" font="3">OU T</text>
<text top="671" left="549" width="17" height="15" font="4">, S</text>
<text top="676" left="566" width="9" height="11" font="3">C</text>
<text top="671" left="577" width="6" height="15" font="4">)</text>
<text top="691" left="297" width="161" height="15" font="4">RenumberStreamOps(K</text>
<text top="697" left="459" width="6" height="11" font="3">1</text>
<text top="691" left="466" width="17" height="15" font="4">, S</text>
<text top="697" left="483" width="17" height="11" font="3">IN</text>
<text top="691" left="502" width="17" height="15" font="4">, S</text>
<text top="697" left="519" width="27" height="11" font="3">OU T</text>
<text top="691" left="549" width="17" height="15" font="4">, S</text>
<text top="697" left="566" width="9" height="11" font="3">C</text>
<text top="691" left="577" width="6" height="15" font="4">)</text>
<text top="732" left="297" width="14" height="15" font="4">K</text>
<text top="737" left="311" width="23" height="11" font="3">new</text>
<text top="732" left="339" width="58" height="15" font="4">= new K</text>
<text top="734" left="398" width="45" height="12" font="15">ERNEL</text>
<text top="732" left="444" width="12" height="15" font="4">()</text>
<text top="752" left="297" width="43" height="15" font="4">(niter</text>
<text top="758" left="340" width="6" height="11" font="3">0</text>
<text top="752" left="347" width="44" height="15" font="4">, niter</text>
<text top="758" left="391" width="6" height="11" font="3">1</text>
<text top="752" left="398" width="126" height="15" font="4">) = MatchRates(K</text>
<text top="758" left="524" width="6" height="11" font="3">0</text>
<text top="752" left="531" width="21" height="15" font="4">, K</text>
<text top="758" left="552" width="6" height="11" font="3">1</text>
<text top="752" left="560" width="17" height="15" font="4">, S</text>
<text top="758" left="577" width="9" height="11" font="3">C</text>
<text top="752" left="587" width="6" height="15" font="4">)</text>
<text top="773" left="297" width="56" height="15" font="4">Inline K</text>
<text top="778" left="354" width="6" height="11" font="3">0</text>
<text top="773" left="365" width="43" height="15" font="4">into K</text>
<text top="778" left="408" width="23" height="11" font="3">new</text>
<text top="773" left="436" width="70" height="15" font="4">with niter</text>
<text top="778" left="506" width="6" height="11" font="3">0</text>
<text top="773" left="517" width="61" height="15" font="4">iterations</text>
<text top="793" left="297" width="56" height="15" font="4">Inline K</text>
<text top="798" left="354" width="6" height="11" font="3">1</text>
<text top="793" left="365" width="43" height="15" font="4">into K</text>
<text top="798" left="408" width="23" height="11" font="3">new</text>
<text top="793" left="436" width="70" height="15" font="4">with niter</text>
<text top="798" left="506" width="6" height="11" font="3">1</text>
<text top="793" left="517" width="61" height="15" font="4">iterations</text>
<text top="833" left="297" width="62" height="15" font="4">for s ∈ S</text>
<text top="839" left="360" width="9" height="11" font="3">C</text>
<text top="833" left="374" width="17" height="15" font="4">do</text>
<text top="854" left="322" width="217" height="15" font="4">Reserve stack space for in s in K</text>
<text top="859" left="539" width="23" height="11" font="3">new</text>
<text top="874" left="322" width="162" height="15" font="4">Replace all pop(s) in K</text>
<text top="879" left="484" width="23" height="11" font="3">new</text>
<text top="874" left="512" width="105" height="15" font="4">with stack reads</text>
<text top="895" left="322" width="193" height="15" font="4">Replace all peek(s, ...) in K</text>
<text top="900" left="515" width="23" height="11" font="3">new</text>
<text top="895" left="542" width="105" height="15" font="4">with stack reads</text>
<text top="915" left="322" width="193" height="15" font="4">Replace all push(s, ...) in K</text>
<text top="920" left="515" width="23" height="11" font="3">new</text>
<text top="915" left="542" width="111" height="15" font="4">with stack writes</text>
<text top="935" left="297" width="50" height="15" font="4">end for</text>
<text top="955" left="273" width="101" height="15" font="4">end procedure</text>
<text top="1006" left="303" width="311" height="16" font="0">Figure 6.14: SKIR kernel fusion algorithm.</text>
</page>
<page number="128" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="22" size="10" family="Times" color="#1a1a1a"/>
	<fontspec id="23" size="10" family="Times" color="#1a1a1a"/>
	<fontspec id="24" size="5" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">114</text>
<text top="317" left="238" width="54" height="14" font="22">work(...) {</text>
<text top="331" left="255" width="47" height="14" font="22">pop(0, e)</text>
<text top="345" left="274" width="10" height="14" font="22">...</text>
<text top="360" left="253" width="50" height="14" font="22">push(0, f)</text>
<text top="374" left="238" width="6" height="14" font="22">}</text>
<text top="180" left="238" width="54" height="14" font="22">work(...) {</text>
<text top="195" left="255" width="47" height="14" font="22">pop(0, a)</text>
<text top="209" left="255" width="47" height="14" font="22">pop(1, b)</text>
<text top="223" left="274" width="10" height="14" font="22">...</text>
<text top="237" left="253" width="52" height="14" font="22">push(0, c)</text>
<text top="252" left="252" width="52" height="14" font="22">push(0, d)</text>
<text top="266" left="238" width="6" height="14" font="22">}</text>
<text top="300" left="430" width="35" height="14" font="22">pop(0)</text>
<text top="315" left="442" width="10" height="14" font="22">...</text>
<text top="329" left="427" width="40" height="14" font="22">push(0)</text>
<text top="195" left="424" width="47" height="14" font="22">pop(0, a)</text>
<text top="209" left="423" width="47" height="14" font="22">pop(1, b)</text>
<text top="223" left="442" width="10" height="14" font="22">...</text>
<text top="237" left="419" width="56" height="14" font="22">push(<i>M</i>, c)</text>
<text top="252" left="419" width="57" height="14" font="22">push(<i>M</i>, d)</text>
<text top="300" left="421" width="44" height="14" font="22">pop(<i>N</i>, e</text>
<text top="311" left="465" width="4" height="8" font="24">0</text>
<text top="300" left="469" width="4" height="14" font="22">)</text>
<text top="319" left="442" width="10" height="14" font="22">...</text>
<text top="333" left="420" width="46" height="14" font="22">push(0, f</text>
<text top="343" left="466" width="4" height="8" font="24">0</text>
<text top="333" left="470" width="4" height="14" font="22">)</text>
<text top="378" left="419" width="44" height="14" font="22">pop(<i>N</i>, e</text>
<text top="388" left="464" width="4" height="8" font="24">1</text>
<text top="378" left="467" width="4" height="14" font="22">)</text>
<text top="396" left="441" width="10" height="14" font="22">...</text>
<text top="410" left="418" width="46" height="14" font="22">push(0, f</text>
<text top="421" left="465" width="4" height="8" font="24">1</text>
<text top="410" left="468" width="4" height="14" font="22">)</text>
<text top="183" left="578" width="54" height="14" font="22">work(...) {</text>
<text top="383" left="578" width="6" height="14" font="22">}</text>
<text top="157" left="402" width="54" height="14" font="22">work(...) {</text>
<text top="441" left="402" width="6" height="14" font="22">}</text>
<text top="503" left="236" width="100" height="17" font="7">Original Graph</text>
<text top="501" left="387" width="129" height="17" font="7">After Renumbering</text>
<text top="501" left="558" width="129" height="17" font="7">Final Fused Kernel</text>
<text top="201" left="594" width="47" height="14" font="22">pop(0, a)</text>
<text top="215" left="594" width="47" height="14" font="22">pop(1, b)</text>
<text top="229" left="594" width="13" height="14" font="22">…</text>
<text top="243" left="594" width="34" height="14" font="22">store c</text>
<text top="257" left="594" width="35" height="14" font="22">store d</text>
<text top="272" left="594" width="13" height="14" font="22">…</text>
<text top="286" left="594" width="31" height="14" font="22">load c</text>
<text top="300" left="594" width="13" height="14" font="22">…</text>
<text top="314" left="594" width="46" height="14" font="22">push(0, f</text>
<text top="325" left="640" width="4" height="8" font="24">0</text>
<text top="314" left="644" width="4" height="14" font="22">)</text>
<text top="333" left="594" width="32" height="14" font="22">load d</text>
<text top="347" left="594" width="13" height="14" font="22">…</text>
<text top="361" left="594" width="46" height="14" font="22">push(0, f</text>
<text top="372" left="640" width="4" height="8" font="24">1</text>
<text top="361" left="644" width="4" height="14" font="22">)</text>
<text top="556" left="303" width="311" height="16" font="0">Figure 6.15: SKIR kernel fusion algorithm.</text>
<text top="648" left="151" width="659" height="16" font="0">After determining the set of common streams, the input and output rates of the common</text>
<text top="684" left="108" width="702" height="16" font="0">streams must be matched so that we can allocate small bounded buffers for stream communication</text>
<text top="719" left="108" width="702" height="16" font="0">internal to the fused kernel. We compute the minimum number of iterations that each of the</text>
<text top="755" left="108" width="702" height="16" font="0">original kernels must execute to make this happen. This is just the least common multiple of the</text>
<text top="791" left="108" width="702" height="16" font="0">rates. The rate matching process is a step that is required in a fully static scheduling algorithm and</text>
<text top="827" left="108" width="668" height="16" font="0">it is sometimes convenient to think of kernel fusion as local static scheduling for two kernels.</text>
<text top="863" left="151" width="659" height="16" font="0">After matching rates we perform a step called stream renumbering. Recall from Chapter 3</text>
<text top="899" left="108" width="702" height="16" font="0">that stream operations identify the input or output stream to read or write using an integer index.</text>
<text top="935" left="108" width="702" height="16" font="0">This index must be replaced with one corresponding to the new set of input or output streams for</text>
<text top="971" left="108" width="702" height="16" font="0">the new fused kernel. The operations referencing common streams are renumbered by adding a</text>
<text top="1007" left="108" width="702" height="16" font="0">large constant value to the stream index. After renumbering, the bodies of the two kernel work</text>
<text top="1043" left="108" width="702" height="16" font="0">functions are inlined into a new function, creating the new fused kernel work function. This is</text>
</page>
<page number="129" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">115</text>
<text top="128" left="108" width="702" height="16" font="0">easily accomplished using kernel work function templates designed for kernel fusion. The al-</text>
<text top="164" left="108" width="702" height="16" font="0">gorithm then reserves space on the stack for the common streams and replaces skir.pop and</text>
<text top="201" left="108" width="97" height="14" font="0">skir.push</text>
<text top="200" left="211" width="599" height="16" font="0">operations on the common streams with references to the stack. These operations</text>
<text top="236" left="108" width="702" height="16" font="0">are easily located in the fused kernel because they are the ones with large stream indexes (due to</text>
<text top="272" left="108" width="102" height="16" font="0">renumbering).</text>
<text top="308" left="151" width="659" height="16" font="0">The fusion algorithm as described only works on the synchronous subset of SKIR kernels.</text>
<text top="344" left="108" width="702" height="16" font="0">However, these are often the exact kernels we wish to fuse, since they tend to be small simple</text>
<text top="380" left="108" width="702" height="16" font="0">kernels where the cost of stream communication is large relative to the execution time of the</text>
<text top="416" left="108" width="702" height="16" font="0">kernel. For the more general case we could employ a weaker form of fusion, where the two</text>
<text top="452" left="108" width="702" height="16" font="0">kernels are always scheduled together but the inter-kernel stream communication mechanism is</text>
<text top="488" left="108" width="702" height="16" font="0">left intact. Although this weaker form of fusion may give beneﬁts with respect to data locality, it</text>
<text top="524" left="108" width="205" height="16" font="0">is not explored in this thesis.</text>
<text top="560" left="151" width="659" height="16" font="0">In Chapter 7 we evaluate a simple dynamic optimization using this fusion algorithm. At</text>
<text top="596" left="108" width="702" height="16" font="0">runtime, we proﬁle kernel execution time using processor time stamp counters. As the program</text>
<text top="632" left="108" width="702" height="16" font="0">runs, we sample blocked kernels to determine two properties. First, we check to see if the kernel</text>
<text top="668" left="108" width="702" height="16" font="0">is blocked on an empty input stream; we only fuse across empty streams. Second, we check the</text>
<text top="704" left="108" width="702" height="16" font="0">proﬁle information to see if the blocked kernel and the blocking kernel have runtimes under some</text>
<text top="740" left="108" width="702" height="16" font="0">threshold (we used 512 cycles). If both these conditions are true, the optimizer applies fusion to</text>
<text top="776" left="108" width="702" height="16" font="0">obtain a new kernel and removes the old kernels from the stream graph. The optimizer then invokes</text>
<text top="813" left="108" width="97" height="14" font="0">skir.call</text>
<text top="812" left="210" width="600" height="16" font="0">on the new kernel. This causes the new kernel to be inserted into the stream graph,</text>
<text top="848" left="108" width="702" height="16" font="0">JIT compiled, and passed to the scheduler for execution. For this simple dynamic optimization,</text>
<text top="884" left="108" width="702" height="16" font="0">dynamic fusion remains active as long as there are more than 2 ∗ (number of worker threads)</text>
<text top="920" left="108" width="199" height="16" font="0">kernels in the stream graph.</text>
<text top="982" left="112" width="36" height="16" font="0">6.6.2</text>
<text top="982" left="182" width="237" height="16" font="0">Fission: Increasing Parallelism</text>
<text top="1030" left="151" width="659" height="16" font="0">As with kernel fusion, we can and do perform ﬁssion at runtime with SKIR. As mentioned</text>
<text top="1066" left="108" width="702" height="16" font="0">above, the SKIR compiler does this by leveraging the streaming environment and simply replacing</text>
</page>
<page number="130" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="25" size="31" family="Times" color="#1a1a1a"/>
	<fontspec id="26" size="18" family="Times" color="#1a1a1a"/>
	<fontspec id="27" size="24" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">116</text>
<text top="128" left="108" width="702" height="16" font="0">the data parallel kernel with a split-join. The split-join consists of a split kernel that distributes</text>
<text top="164" left="108" width="702" height="16" font="0">the input of the original kernel to some number of duplicates of the original. The output of the</text>
<text top="200" left="108" width="702" height="16" font="0">duplicate kernels is recombined using a join kernel and written to the original output stream. The</text>
<text top="236" left="108" width="702" height="16" font="0">computation is parallelized among the duplicate kernels with the added overhead of the split and</text>
<text top="272" left="108" width="329" height="16" font="0">join kernels. This is illustrated in Figure 6.16.</text>
<text top="401" left="287" width="22" height="38" font="25">K</text>
<text top="405" left="499" width="14" height="23" font="26">K</text>
<text top="422" left="513" width="7" height="13" font="6">1</text>
<text top="405" left="567" width="14" height="23" font="26">K</text>
<text top="422" left="580" width="7" height="13" font="6">2</text>
<text top="405" left="634" width="14" height="23" font="26">K</text>
<text top="422" left="648" width="7" height="13" font="6">3</text>
<text top="405" left="432" width="14" height="23" font="26">K</text>
<text top="422" left="446" width="7" height="13" font="6">0</text>
<text top="346" left="504" width="77" height="29" font="27">splitter</text>
<text top="464" left="511" width="64" height="29" font="27">joiner</text>
<text top="541" left="255" width="108" height="19" font="11">Before Fission</text>
<text top="541" left="502" width="94" height="19" font="11">After Fission</text>
<text top="588" left="339" width="239" height="16" font="0">Figure 6.16: SKIR kernel ﬁssion.</text>
<text top="660" left="151" width="659" height="16" font="0">Because this transformation adds edges to the stream graph instead of destroying them, it has</text>
<text top="696" left="108" width="702" height="16" font="0">a simpler implementation than kernel fusion. All it has to do is remove the original kernel from the</text>
<text top="732" left="108" width="702" height="16" font="0">stream graph, create the duplicates, connect everything together using special split and join kernels</text>
<text top="768" left="108" width="702" height="16" font="0">provided in the compiler bitcode library, then call each of the kernels with skir.call. This is</text>
<text top="804" left="108" width="568" height="16" font="0">not much different than constructing a hierarchical kernel from a user program.</text>
<text top="840" left="151" width="659" height="16" font="0">A variety of runtime strategies for choosing the number of threads (i.e. the width of the</text>
<text top="876" left="108" width="702" height="16" font="0">split-join) to assign to a data parallel kernel are possible depending on the power, throughput, and</text>
<text top="912" left="108" width="702" height="16" font="0">latency goals for the system [49][51]. All of these strategies result in the assignment of some</text>
<text top="948" left="108" width="702" height="16" font="0">number of worker threads to each data parallel kernel. This is equivalent to selecting the ﬁssion</text>
<text top="984" left="108" width="702" height="16" font="0">width of our split-join transformation. In this thesis, the focus is on evaluating the use of the split-</text>
<text top="1020" left="108" width="702" height="16" font="0">join as a static or dynamic mechanism for data parallelism and not on developing new allocation</text>
<text top="1056" left="108" width="702" height="16" font="0">strategies. For the benchmarks used in Chapter 7 we try to match the allocation strategy of the</text>
</page>
<page number="131" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">117</text>
<text top="128" left="108" width="702" height="16" font="0">original application as closely as possible. In each case, this means simply using the number of</text>
<text top="164" left="108" width="702" height="16" font="0">available processors as the ﬁssion width. Although this is not the best strategy for all use cases, it</text>
<text top="200" left="108" width="262" height="16" font="0">is the most commonly implemented.</text>
</page>
<page number="132" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 7</text>
<text top="292" left="366" width="187" height="16" font="0">Performance Evaluation</text>
<text top="408" left="151" width="659" height="16" font="0">One of the stated goals of this work is to demonstrate a stream parallel compilation and</text>
<text top="444" left="108" width="702" height="16" font="0">scheduling framework more general and more ﬂexible than existing approaches without sacri-</text>
<text top="479" left="108" width="702" height="16" font="0">ﬁcing performance. Chapters 3 and 4 presented the SKIR representation for stream parallelism</text>
<text top="515" left="108" width="702" height="16" font="0">which achieves the goals of generality and ﬂexibility. Chapters 5 and 6 presented scheduling and</text>
<text top="551" left="108" width="702" height="16" font="0">compilation techniques which we claim can be used to execute SKIR computation efﬁciently. In</text>
<text top="587" left="108" width="702" height="16" font="0">this chapter we validate these claims of efﬁcient execution using existing benchmarks taken from</text>
<text top="623" left="108" width="204" height="16" font="0">several application domains.</text>
<text top="681" left="112" width="22" height="16" font="0">7.1</text>
<text top="681" left="170" width="97" height="16" font="0">Benchmarks</text>
<text top="736" left="151" width="659" height="16" font="0">We use a set of six benchmarks distributed with the StreamIt compiler. They are beamformer,</text>
<text top="772" left="108" width="249" height="15" font="0">channel vocoder, dct, fft, ﬁlterbank</text>
<text top="772" left="357" width="453" height="16" font="0">, and fm. Most of these are applications from the area of digital</text>
<text top="808" left="108" width="702" height="16" font="0">signal processing. We choose these benchmarks because they represent algorithms that have been</text>
<text top="844" left="108" width="126" height="15" font="0">over-decomposed</text>
<text top="844" left="234" width="576" height="16" font="0">. That is, the programmers of the benchmarks have expressed most or all of the</text>
<text top="880" left="108" width="702" height="16" font="0">parallelism present in the application without regard to the number of processors in the system that</text>
<text top="916" left="108" width="702" height="16" font="0">they will run on. For these benchmarks, it important that the compiler or runtime system coarsen</text>
<text top="952" left="108" width="408" height="16" font="0">granularity and/or schedule parallel execution efﬁciently.</text>
<text top="988" left="151" width="659" height="16" font="0">Although we can compile StreamIt programs directly to SKIR, we have also ported these</text>
<text top="1024" left="108" width="702" height="16" font="0">benchmarks to C++. This was done to separate the concerns of frontend and backend compiler</text>
<text top="1060" left="108" width="702" height="16" font="0">development and to enable better comparison of SKIR performance with the performance of C++</text>
</page>
<page number="133" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">119</text>
<text top="128" left="108" width="702" height="16" font="0">frameworks. We also take the C++ versions of the benchmarks and port them to the GNU Radio</text>
<text top="164" left="108" width="702" height="16" font="0">dynamic scheduling framework. The most signiﬁcant changes required of the kernels are to add</text>
<text top="200" left="108" width="702" height="16" font="0">explicit looping to the kernel work functions and to replace SKIR style stream operations with</text>
<text top="236" left="108" width="702" height="16" font="0">direct memory accesses. We also have to implement SWIG bindings for each of the C++ kernels</text>
<text top="272" left="108" width="702" height="16" font="0">so that they are accessible from the GNU Radio Python programming environment. Finally, we</text>
<text top="308" left="108" width="702" height="16" font="0">have to implement stream graph construction for each of the benchmarks as a GNU Radio Python</text>
<text top="344" left="108" width="65" height="16" font="0">program.</text>
<text top="380" left="151" width="659" height="16" font="0">We found during this porting process that implementing a stream parallel program in GNU</text>
<text top="416" left="108" width="702" height="16" font="0">Radio when the kernels (processing blocks) do not already exist in the GNU Radio libraries is</text>
<text top="452" left="108" width="702" height="16" font="0">more work implementing the same program in low level SKIR using compiler intrinsics, even for</text>
<text top="488" left="108" width="702" height="16" font="0">a programmer experienced in both systems. This productivity gap is due to the two language design</text>
<text top="524" left="108" width="702" height="16" font="0">of GNU Radio, the requirement for explicit looping in kernels, and the fact that the programmer</text>
<text top="560" left="108" width="702" height="16" font="0">must manually interface with the stream communication implementation. Again, this illustrates</text>
<text top="596" left="108" width="375" height="16" font="0">the advantage of the abstractions provided by SKIR.</text>
<text top="632" left="151" width="659" height="16" font="0">We note that SKIR and GNU Radio are at a slight disadvantage to StreamIt with respect to</text>
<text top="668" left="108" width="702" height="16" font="0">split-join patterns found in StreamIt benchmarks. In StreamIt, these are language constructs and</text>
<text top="704" left="108" width="702" height="16" font="0">are not instantiated as individual kernels as they are in SKIR C code, in the StreamIt to SKIR</text>
<text top="740" left="108" width="702" height="16" font="0">compiler, or in GNU Radio. This allows the StreamIt compiler to better reason about the memory</text>
<text top="776" left="108" width="520" height="16" font="0">access patterns implied by split-joins and to better optimize across them.</text>
<text top="812" left="151" width="659" height="16" font="0">All StreamIt programs have a single source kernel and a single sink kernel. We measure the</text>
<text top="848" left="108" width="702" height="16" font="0">performance of the StreamIt benchmarks by measuring throughput at the sink kernel. In all cases,</text>
<text top="884" left="108" width="702" height="16" font="0">this measurement is taken by counting the number samples consumed by the sink ﬁlter during an</text>
<text top="920" left="108" width="702" height="16" font="0">approximately one second interval and reporting the rate. The results shown in this section are</text>
<text top="956" left="108" width="702" height="16" font="0">the average of 30 such measurements. This implies that we are only measuring the steady state</text>
<text top="992" left="108" width="702" height="16" font="0">performance of each of the three systems. In particular, we are not measuring the JIT compilation</text>
<text top="1027" left="108" width="702" height="16" font="0">costs of SKIR or costs of using Python in GNU Radio. We are only measuring the performance of</text>
<text top="1063" left="108" width="450" height="16" font="0">the compiled code, the schedulers, and stream communication.</text>
</page>
<page number="134" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">120</text>
<text top="128" left="151" width="659" height="16" font="0">We also evaluate our system with a set of coarse-grained pipeline parallel benchmarks. These</text>
<text top="164" left="108" width="702" height="16" font="0">are dedup, black-scholes, swps3, and nbody. dedup and black-scholes are from the PARSEC 2.1</text>
<text top="200" left="108" width="702" height="16" font="0">benchmark suite [21]. swps3 is an implementation of the Smith-Waterman sequence alignment</text>
<text top="236" left="108" width="702" height="16" font="0">algorithm originally ported to the stream parallel model by the FastFlow project [18]. nbody is</text>
<text top="272" left="108" width="702" height="16" font="0">a n-body simulation taken from the NVIDIA CUDA SDK. In these benchmarks the challenge is</text>
<text top="308" left="108" width="702" height="16" font="0">not too much parallelism, it is not enough; the system must efﬁciently execute copies of the data</text>
<text top="344" left="108" width="647" height="16" font="0">parallel kernels in parallel. Each of these benchmarks are ported to SKIR with little effort.</text>
<text top="380" left="151" width="659" height="16" font="0">We evaluate the performance of the Sluice approach to parallel JavaScript execution using a</text>
<text top="416" left="108" width="702" height="16" font="0">set of compute intense JavaScript benchmarks that can be written using the stream parallel model.</text>
<text top="452" left="108" width="702" height="16" font="0">Four of the benchmarks are taken from the Pixastic library of image processing routines [10]. We</text>
<text top="488" left="108" width="702" height="16" font="0">also include a JavaScript version of the nbody benchmark. This evaluation is presented in Section</text>
<text top="524" left="108" width="27" height="16" font="0">7.3.</text>
<text top="560" left="151" width="44" height="15" font="0">dedup</text>
<text top="560" left="200" width="610" height="16" font="0">is organized as a ﬁve stage pipeline with 3 data parallel stages. The original version</text>
<text top="596" left="108" width="702" height="16" font="0">uses Pthreads and assigns a number of threads equal to the number of processors to each parallel</text>
<text top="632" left="108" width="702" height="16" font="0">stage. We easily port dedup to SKIR by replacing the programmer managed queues between each</text>
<text top="668" left="108" width="702" height="16" font="0">of the pipeline stages with streams. We rely on the SKIR JIT to perform runtime ﬁssion on the data</text>
<text top="704" left="108" width="702" height="16" font="0">parallel stages using the same allocation strategy as original code (i.e. ﬁssion width equal to the</text>
<text top="740" left="108" width="702" height="16" font="0">number of processors). We note that the resulting application is a much simpler than the original</text>
<text top="776" left="108" width="599" height="16" font="0">with many lines of code removed. We run the benchmark using the native input set.</text>
<text top="812" left="151" width="659" height="16" font="0">Black-Scholes is essentially a single data parallel kernel parallelized using a TBB parallel for</text>
<text top="848" left="108" width="702" height="16" font="0">construct. We port this benchmark to SKIR by introducing an input kernel and a split kernel. The</text>
<text top="884" left="108" width="702" height="16" font="0">input kernel emits the iteration space of the original parallel for loop to its output stream and the</text>
<text top="920" left="108" width="702" height="16" font="0">split kernel distributes this work to copies of the original data parallel kernel. That is, we perform</text>
<text top="956" left="108" width="465" height="16" font="0">manual ﬁssion. We run the benchmark using the native input set.</text>
<text top="992" left="151" width="659" height="16" font="0">For the Smith-Waterman benchmark, we use the version of swps3 already ported to the</text>
<text top="1027" left="108" width="702" height="16" font="0">stream parallel model by the authors of the FastFlow framework. It has already been shown that</text>
<text top="1063" left="108" width="702" height="16" font="0">the FastFlow version outperforms the original Pthreads version of the program [18]. It is straight-</text>
</page>
<page number="135" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">121</text>
<text top="128" left="108" width="377" height="16" font="0">forward to port FastFlow programs to the SKIR C</text>
<text top="128" left="483" width="17" height="13" font="1">++</text>
<text top="128" left="507" width="303" height="16" font="0">library since they already use the stream</text>
<text top="164" left="108" width="155" height="16" font="0">parallel model in a C</text>
<text top="164" left="261" width="17" height="13" font="1">++</text>
<text top="164" left="284" width="526" height="16" font="0">framework. As in the original FastFlow version, we use manual ﬁssion.</text>
<text top="200" left="108" width="702" height="16" font="0">We run the benchmark using a query sequence of length 4000 against the UniProtKB/Swiss-Prot</text>
<text top="236" left="108" width="122" height="16" font="0">protein database.</text>
<text top="272" left="151" width="591" height="16" font="0">We port the nbody benchmark to SKIR as a three stage pipeline using the SKIR C</text>
<text top="272" left="740" width="17" height="13" font="1">++</text>
<text top="272" left="762" width="48" height="16" font="0">library</text>
<text top="308" left="108" width="702" height="16" font="0">with either dynamic ﬁssion or the OpenCL backend. The second and third pipeline stages corre-</text>
<text top="344" left="108" width="702" height="16" font="0">spond to the two main kernels in the original benchmark. Most of the work is in the second stage</text>
<text top="380" left="108" width="702" height="16" font="0">which is parallelized by the SKIR JIT compiler using runtime ﬁssion. In this stage the program</text>
<text top="416" left="108" width="702" height="16" font="0">computes the force on a single particle in the simulation due to the gravitational pull of all the other</text>
<text top="452" left="108" width="702" height="16" font="0">particles in the simulation. The ﬁrst pipeline stage drives the simulation by emitting a list of parti-</text>
<text top="488" left="108" width="702" height="16" font="0">cles to its output stream. The nbody benchmark is slightly different from the other benchmarks we</text>
<text top="524" left="108" width="702" height="16" font="0">use. The nbody stream graph runs inside of a larger OpenGL program which displays the state of</text>
<text top="560" left="108" width="702" height="16" font="0">the simulation at each step. Instead of executing as a single long running stream graph, the stream</text>
<text top="596" left="108" width="702" height="16" font="0">graph is constructed once then run to completion for each iteration of the nbody simulation (i.e. for</text>
<text top="632" left="108" width="276" height="16" font="0">each frame of OpenGL output). The C</text>
<text top="631" left="382" width="17" height="13" font="1">++</text>
<text top="632" left="403" width="407" height="16" font="0">class implementing the main kernel of nbody is shown in</text>
<text top="668" left="108" width="484" height="16" font="0">Figure 7.1. We run nbody with a simulation size of 10240 particles.</text>
<text top="704" left="151" width="659" height="16" font="0">Table 7.1 summarizes the number of kernels and the distribution of kernel size for each of the</text>
<text top="740" left="108" width="702" height="16" font="0">benchmarks. The sizes are given in cycles per kernel iteration and were recorded during a single</text>
<text top="776" left="108" width="702" height="16" font="0">threaded execution of the benchmarks optimized using coroutine elimination. It is easy to see that</text>
<text top="812" left="108" width="702" height="16" font="0">the StreamIt benchmarks contain a large number of very small kernels. Any overhead introduced</text>
<text top="848" left="108" width="702" height="16" font="0">into these kernels will be large compared to the amount of work performed. The table also shows</text>
<text top="884" left="108" width="573" height="16" font="0">that the non-StreamIt benchmarks are dominated by single data parallel kernels.</text>
<text top="941" left="112" width="22" height="16" font="0">7.2</text>
<text top="941" left="170" width="56" height="16" font="0">Results</text>
<text top="996" left="151" width="659" height="16" font="0">We evaluate the effectiveness of the SKIR compiler optimizations relative to our baseline</text>
<text top="1032" left="108" width="702" height="16" font="0">scheduling algorithm using the StreamIt benchmarks. The StreamIt benchmarks are used because</text>
<text top="1068" left="108" width="702" height="16" font="0">of their sensitivity to scheduling and communication overhead. Figure 7.2 shows an overview of</text>
</page>
<page number="136" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">122</text>
<text top="108" left="245" width="32" height="11" font="3">c l a s s</text>
<text top="108" left="288" width="104" height="11" font="3">C a l c u l a t e F o r c e s</text>
<text top="108" left="403" width="3" height="11" font="3">:</text>
<text top="108" left="417" width="215" height="11" font="3">p u b l i c K e r n e l &lt;C a l c u l a t e F o r c e s &gt;</text>
<text top="121" left="243" width="6" height="11" font="3">{</text>
<text top="150" left="245" width="47" height="11" font="3">p u b l i c :</text>
<text top="179" left="274" width="182" height="11" font="3">f l o a t m p o s r d [ 4 ∗ NBODIES ] ;</text>
<text top="193" left="274" width="32" height="11" font="3">f l o a t</text>
<text top="193" left="316" width="133" height="11" font="3">m s o f t e n i n g S q u a r e d ;</text>
<text top="221" left="273" width="26" height="11" font="3">v o i d</text>
<text top="222" left="310" width="175" height="11" font="3">i n t e r a c t i o n ( f l o a t ∗ a c c e l ,</text>
<text top="221" left="496" width="61" height="11" font="3">i n t pos0 ,</text>
<text top="221" left="568" width="61" height="11" font="3">i n t p o s 1 )</text>
<text top="235" left="272" width="6" height="11" font="3">{</text>
<text top="250" left="302" width="118" height="11" font="3">f l o a t r 0 , r 1 , r 2 ;</text>
<text top="278" left="302" width="291" height="11" font="3">r 0 = m p o s r d [ p o s 0 + 0 ] − m p o s r d [ p o s 1 + 0 ] ;</text>
<text top="293" left="302" width="291" height="11" font="3">r 1 = m p o s r d [ p o s 0 + 1 ] − m p o s r d [ p o s 1 + 1 ] ;</text>
<text top="307" left="302" width="291" height="11" font="3">r 2 = m p o s r d [ p o s 0 + 2 ] − m p o s r d [ p o s 1 + 2 ] ;</text>
<text top="335" left="302" width="32" height="11" font="3">f l o a t</text>
<text top="335" left="345" width="269" height="11" font="3">d i s t S q r = r 0 ∗ r 0 + r 1 ∗ r 1 + r 2 ∗ r 2 ;</text>
<text top="349" left="302" width="211" height="11" font="3">d i s t S q r += m s o f t e n i n g S q u a r e d ;</text>
<text top="378" left="302" width="32" height="11" font="3">f l o a t</text>
<text top="378" left="345" width="97" height="11" font="3">i n v D i s t = 1 . 0 f</text>
<text top="378" left="453" width="3" height="11" font="3">/</text>
<text top="378" left="468" width="103" height="11" font="3">s q r t f ( d i s t S q r ) ;</text>
<text top="392" left="302" width="32" height="11" font="3">f l o a t</text>
<text top="392" left="345" width="91" height="11" font="3">i n v D i s t C u b e =</text>
<text top="392" left="453" width="197" height="11" font="3">i n v D i s t ∗ i n v D i s t ∗ i n v D i s t ;</text>
<text top="420" left="302" width="290" height="11" font="3">f l o a t s = m p o s r d [ p o s 1 + 3 ] ∗ i n v D i s t C u b e ;</text>
<text top="449" left="302" width="132" height="11" font="3">a c c e l [ 0 ] += r 0 ∗ s ;</text>
<text top="463" left="302" width="132" height="11" font="3">a c c e l [ 1 ] += r 1 ∗ s ;</text>
<text top="477" left="302" width="132" height="11" font="3">a c c e l [ 2 ] += r 2 ∗ s ;</text>
<text top="490" left="272" width="6" height="11" font="3">}</text>
<text top="520" left="274" width="283" height="11" font="3">C a l c u l a t e F o r c e s ( f l o a t &amp;s o f t e n i n g S q u a r e d )</text>
<text top="534" left="302" width="3" height="11" font="3">:</text>
<text top="534" left="316" width="255" height="11" font="3">m s o f t e n i n g S q u a r e d ( s o f t e n i n g S q u a r e d )</text>
<text top="547" left="272" width="6" height="11" font="3">{</text>
<text top="561" left="272" width="6" height="11" font="3">}</text>
<text top="591" left="274" width="39" height="11" font="3">s t a t i c</text>
<text top="591" left="324" width="204" height="11" font="3">i n t work ( C a l c u l a t e F o r c e s ∗me ,</text>
<text top="605" left="388" width="61" height="11" font="3">S t r e a m P t r</text>
<text top="605" left="460" width="39" height="11" font="3">i n s [ ] ,</text>
<text top="605" left="510" width="118" height="11" font="3">S t r e a m P t r o u t s [ ] )</text>
<text top="618" left="272" width="6" height="11" font="3">{</text>
<text top="633" left="302" width="154" height="11" font="3">S t r e a m&lt;i n t &gt; i n ( i n s , 0 ) ;</text>
<text top="647" left="302" width="183" height="11" font="3">S t r e a m&lt;f l o a t &gt; o u t ( o u t s , 0 ) ;</text>
<text top="676" left="302" width="32" height="11" font="3">f l o a t</text>
<text top="676" left="345" width="197" height="11" font="3">f o r c e [ 3 ] = { 0 . 0 f , 0 . 0 f , 0 . 0 f } ;</text>
<text top="704" left="302" width="18" height="11" font="3">i n t</text>
<text top="704" left="331" width="104" height="11" font="3">i = i n . pop ( ) ∗ 4 ;</text>
<text top="718" left="302" width="132" height="11" font="3">i n t N = i n . pop ( ) ∗ 4 ;</text>
<text top="747" left="302" width="54" height="11" font="3">f o r ( i n t</text>
<text top="747" left="367" width="61" height="11" font="3">j = 0 ; j &lt;N ;</text>
<text top="747" left="439" width="48" height="11" font="3">j +=4) {</text>
<text top="761" left="329" width="177" height="11" font="3">me−&gt;i n t e r a c t i o n ( f o r c e , j ,</text>
<text top="761" left="518" width="17" height="11" font="3">i ) ;</text>
<text top="774" left="301" width="6" height="11" font="3">}</text>
<text top="803" left="302" width="32" height="11" font="3">f l o a t</text>
<text top="804" left="345" width="54" height="11" font="3">f = i / 4 ;</text>
<text top="832" left="302" width="82" height="11" font="3">o u t . p u s h ( f ) ;</text>
<text top="846" left="302" width="132" height="11" font="3">o u t . p u s h ( f o r c e [ 0 ] ) ;</text>
<text top="860" left="302" width="132" height="11" font="3">o u t . p u s h ( f o r c e [ 1 ] ) ;</text>
<text top="875" left="302" width="132" height="11" font="3">o u t . p u s h ( f o r c e [ 2 ] ) ;</text>
<text top="903" left="302" width="61" height="11" font="3">r e t u r n 0 ;</text>
<text top="916" left="272" width="6" height="11" font="3">}</text>
<text top="931" left="245" width="11" height="12" font="3">} ;</text>
<text top="969" left="108" width="702" height="16" font="0">Figure 7.1: A SKIR version of the CalculateForces kernel from the nbody benchmark. The code is</text>
<text top="991" left="108" width="485" height="16" font="0">written in C++ using a class library interface to the SKIR intrinsics.</text>
</page>
<page number="137" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">123</text>
<text top="101" left="391" width="14" height="16" font="0">&lt;</text>
<text top="101" left="437" width="33" height="16" font="0">101-</text>
<text top="101" left="509" width="33" height="16" font="0">501-</text>
<text top="101" left="584" width="42" height="16" font="0">1001-</text>
<text top="101" left="656" width="42" height="16" font="0">5001-</text>
<text top="122" left="217" width="90" height="16" font="0">Benchmark</text>
<text top="122" left="327" width="39" height="16" font="0">Total</text>
<text top="122" left="384" width="27" height="16" font="0">100</text>
<text top="122" left="440" width="27" height="16" font="0">500</text>
<text top="122" left="507" width="36" height="16" font="0">1000</text>
<text top="122" left="587" width="36" height="16" font="0">5000</text>
<text top="122" left="655" width="45" height="16" font="0">20000</text>
<text top="145" left="214" width="95" height="16" font="0">beamformer</text>
<text top="145" left="338" width="18" height="16" font="0">56</text>
<text top="145" left="389" width="18" height="16" font="0">23</text>
<text top="145" left="449" width="9" height="16" font="0">6</text>
<text top="145" left="516" width="18" height="16" font="0">27</text>
<text top="145" left="600" width="9" height="16" font="0">0</text>
<text top="145" left="673" width="9" height="16" font="0">0</text>
<text top="166" left="217" width="89" height="16" font="0">ch. vocoder</text>
<text top="166" left="338" width="18" height="16" font="0">57</text>
<text top="166" left="393" width="9" height="16" font="0">4</text>
<text top="166" left="445" width="18" height="16" font="0">52</text>
<text top="166" left="521" width="9" height="16" font="0">0</text>
<text top="166" left="600" width="9" height="16" font="0">0</text>
<text top="166" left="673" width="9" height="16" font="0">1</text>
<text top="188" left="250" width="24" height="16" font="0">dct</text>
<text top="188" left="338" width="18" height="16" font="0">40</text>
<text top="188" left="393" width="9" height="16" font="0">4</text>
<text top="188" left="449" width="9" height="16" font="0">2</text>
<text top="188" left="516" width="18" height="16" font="0">32</text>
<text top="188" left="600" width="9" height="16" font="0">2</text>
<text top="188" left="673" width="9" height="16" font="0">0</text>
<text top="210" left="253" width="18" height="16" font="0">fft</text>
<text top="210" left="338" width="18" height="16" font="0">17</text>
<text top="210" left="393" width="9" height="16" font="0">5</text>
<text top="210" left="449" width="9" height="16" font="0">4</text>
<text top="210" left="521" width="9" height="16" font="0">2</text>
<text top="210" left="600" width="9" height="16" font="0">5</text>
<text top="210" left="673" width="9" height="16" font="0">1</text>
<text top="231" left="224" width="76" height="16" font="0">ﬁlterbank</text>
<text top="231" left="338" width="18" height="16" font="0">85</text>
<text top="231" left="389" width="18" height="16" font="0">52</text>
<text top="231" left="449" width="9" height="16" font="0">1</text>
<text top="231" left="516" width="18" height="16" font="0">32</text>
<text top="231" left="600" width="9" height="16" font="0">0</text>
<text top="231" left="673" width="9" height="16" font="0">0</text>
<text top="253" left="251" width="21" height="16" font="0">fm</text>
<text top="253" left="338" width="18" height="16" font="0">43</text>
<text top="253" left="389" width="18" height="16" font="0">30</text>
<text top="253" left="449" width="9" height="16" font="0">0</text>
<text top="253" left="516" width="18" height="16" font="0">13</text>
<text top="253" left="600" width="9" height="16" font="0">0</text>
<text top="253" left="673" width="9" height="16" font="0">0</text>
<text top="278" left="217" width="90" height="16" font="0">Benchmark</text>
<text top="278" left="391" width="14" height="16" font="0">&lt;</text>
<text top="278" left="433" width="42" height="16" font="0">1000-</text>
<text top="278" left="498" width="55" height="16" font="0">10,001-</text>
<text top="278" left="573" width="64" height="16" font="0">100,001-</text>
<text top="278" left="670" width="14" height="16" font="0">&gt;</text>
<text top="300" left="242" width="40" height="16" font="0">(n=1)</text>
<text top="300" left="327" width="39" height="16" font="0">Total</text>
<text top="300" left="384" width="27" height="16" font="0">100</text>
<text top="300" left="429" width="49" height="16" font="0">10,000</text>
<text top="300" left="496" width="58" height="16" font="0">100,000</text>
<text top="300" left="592" width="26" height="16" font="0">1e6</text>
<text top="300" left="664" width="26" height="16" font="0">1e6</text>
<text top="322" left="253" width="17" height="16" font="0">bs</text>
<text top="322" left="342" width="9" height="16" font="0">3</text>
<text top="322" left="393" width="9" height="16" font="0">1</text>
<text top="322" left="449" width="9" height="16" font="0">1</text>
<text top="322" left="521" width="9" height="16" font="0">0</text>
<text top="322" left="600" width="9" height="16" font="0">0</text>
<text top="322" left="673" width="9" height="16" font="0">1</text>
<text top="344" left="238" width="48" height="16" font="0">dedup</text>
<text top="344" left="342" width="9" height="16" font="0">5</text>
<text top="344" left="393" width="9" height="16" font="0">1</text>
<text top="344" left="449" width="9" height="16" font="0">3</text>
<text top="344" left="521" width="9" height="16" font="0">0</text>
<text top="344" left="600" width="9" height="16" font="0">1</text>
<text top="344" left="673" width="9" height="16" font="0">0</text>
<text top="365" left="239" width="46" height="16" font="0">swps3</text>
<text top="366" left="342" width="9" height="16" font="0">2</text>
<text top="366" left="393" width="9" height="16" font="0">0</text>
<text top="366" left="449" width="9" height="16" font="0">1</text>
<text top="366" left="521" width="9" height="16" font="0">0</text>
<text top="366" left="600" width="9" height="16" font="0">0</text>
<text top="366" left="673" width="9" height="16" font="0">1</text>
<text top="387" left="238" width="48" height="16" font="0">nbody</text>
<text top="387" left="342" width="9" height="16" font="0">3</text>
<text top="387" left="393" width="9" height="16" font="0">2</text>
<text top="387" left="449" width="9" height="16" font="0">0</text>
<text top="387" left="521" width="9" height="16" font="0">0</text>
<text top="387" left="600" width="9" height="16" font="0">1</text>
<text top="387" left="673" width="9" height="16" font="0">0</text>
<text top="423" left="108" width="702" height="16" font="0">Table 7.1: The number and size of kernels for each benchmark. We bin the kernels in each bench-</text>
<text top="445" left="108" width="702" height="16" font="0">mark according to their execution time in cycles. The table shows the number of kernels in each</text>
<text top="466" left="108" width="27" height="16" font="0">bin.</text>
<text top="555" left="108" width="702" height="16" font="0">the result of running the StreamIt benchmarks on a two-socket, 8-core, Intel Xeon X5550 system</text>
<text top="591" left="108" width="702" height="16" font="0">using four different conﬁgurations and 1, 2, 4, 6, or 8 processor cores. For conﬁgurations using</text>
<text top="627" left="108" width="702" height="16" font="0">less than eight cores, we pin the benchmarks to a speciﬁc subset of cores using the numactl</text>
<text top="663" left="108" width="702" height="16" font="0">command line tool. For 1, 2, and 4 core conﬁgurations, we make sure that the benchmark runs</text>
<text top="699" left="108" width="702" height="16" font="0">on only one processor socket. For the 6 core conﬁguration, we make sure benchmarks use 3</text>
<text top="734" left="108" width="702" height="16" font="0">cores on each socket. For every conﬁguration, we allow the operating system (Linux version:</text>
<text top="771" left="108" width="334" height="14" font="0">2.6.32-33-server #70-Ubuntu SMP</text>
<text top="770" left="442" width="368" height="16" font="0">) to schedule threads within the subset of cores be-</text>
<text top="806" left="108" width="462" height="16" font="0">ing used. That is, we do not pin worker threads to speciﬁc cores.</text>
<text top="842" left="151" width="659" height="16" font="0">The no-elim conﬁguration uses the coroutine scheduling method with the simple batching</text>
<text top="878" left="108" width="702" height="16" font="0">transformation. cpp is the baseline conﬁguration plus the coroutine elimination optimization run-</text>
<text top="914" left="108" width="79" height="16" font="0">ning the C</text>
<text top="914" left="185" width="17" height="13" font="1">++</text>
<text top="914" left="209" width="601" height="16" font="0">source code of each benchmark and str is the same conﬁguration using StreamIt</text>
<text top="950" left="108" width="702" height="16" font="0">source code as input. Finally, fuse adds dynamic kernel fusion to the cpp conﬁguration. The</text>
<text top="986" left="108" width="307" height="16" font="0">results shown in the ﬁgure indicate that C</text>
<text top="986" left="413" width="17" height="13" font="1">++</text>
<text top="986" left="436" width="374" height="16" font="0">and StreamIt versions of the same benchmark have</text>
<text top="1022" left="108" width="525" height="16" font="0">similar performance. Examining the data more closely, we see that the C</text>
<text top="1022" left="631" width="17" height="13" font="1">++</text>
<text top="1022" left="653" width="157" height="16" font="0">source code generally</text>
<text top="1058" left="108" width="702" height="16" font="0">outperforms the StreamIt source code by a small amount. This is not surprising since the front-end</text>
</page>
<page number="138" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="28" size="8" family="Times" color="#1a1a1a"/>
	<fontspec id="29" size="10" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">124</text>
<text top="317" left="203" width="6" height="12" font="28">1</text>
<text top="317" left="263" width="6" height="12" font="28">2</text>
<text top="317" left="323" width="6" height="12" font="28">4</text>
<text top="317" left="384" width="6" height="12" font="28">6</text>
<text top="317" left="444" width="6" height="12" font="28">8</text>
<text top="301" left="150" width="47" height="12" font="28">0.00E+00</text>
<text top="279" left="150" width="47" height="12" font="28">5.00E+05</text>
<text top="256" left="150" width="47" height="12" font="28">1.00E+06</text>
<text top="234" left="150" width="47" height="12" font="28">1.50E+06</text>
<text top="211" left="150" width="47" height="12" font="28">2.00E+06</text>
<text top="189" left="150" width="47" height="12" font="28">2.50E+06</text>
<text top="166" left="150" width="47" height="12" font="28">3.00E+06</text>
<text top="143" left="150" width="47" height="12" font="28">3.50E+06</text>
<text top="121" left="150" width="47" height="12" font="28">4.00E+06</text>
<text top="95" left="246" width="93" height="20" font="20">Beamformer</text>
<text top="359" left="219" width="18" height="12" font="28">cpp</text>
<text top="359" left="258" width="13" height="12" font="28">str</text>
<text top="359" left="292" width="29" height="12" font="28">fusion</text>
<text top="359" left="342" width="35" height="12" font="28">no-elim</text>
<text top="335" left="250" width="100" height="14" font="22">number of threads</text>
<text top="270" left="140" width="0" height="14" font="29">sa</text>
<text top="256" left="140" width="0" height="14" font="29">m</text>
<text top="246" left="140" width="0" height="14" font="29">p</text>
<text top="239" left="140" width="0" height="14" font="29">le</text>
<text top="229" left="140" width="0" height="14" font="29">s </text>
<text top="220" left="140" width="0" height="14" font="29">p</text>
<text top="213" left="140" width="0" height="14" font="29">e</text>
<text top="205" left="140" width="0" height="14" font="29">r </text>
<text top="198" left="140" width="0" height="14" font="29">se</text>
<text top="185" left="140" width="0" height="14" font="29">co</text>
<text top="172" left="140" width="0" height="14" font="29">n</text>
<text top="165" left="140" width="0" height="14" font="29">d</text>
<text top="610" left="203" width="6" height="12" font="28">1</text>
<text top="610" left="263" width="6" height="12" font="28">2</text>
<text top="610" left="323" width="6" height="12" font="28">4</text>
<text top="610" left="384" width="6" height="12" font="28">6</text>
<text top="610" left="444" width="6" height="12" font="28">8</text>
<text top="594" left="150" width="47" height="12" font="28">0.00E+00</text>
<text top="564" left="150" width="47" height="12" font="28">2.00E+07</text>
<text top="534" left="150" width="47" height="12" font="28">4.00E+07</text>
<text top="504" left="150" width="47" height="12" font="28">6.00E+07</text>
<text top="474" left="150" width="47" height="12" font="28">8.00E+07</text>
<text top="444" left="150" width="47" height="12" font="28">1.00E+08</text>
<text top="414" left="150" width="47" height="12" font="28">1.20E+08</text>
<text top="388" left="275" width="35" height="20" font="20">DCT</text>
<text top="652" left="219" width="18" height="12" font="28">cpp</text>
<text top="652" left="258" width="13" height="12" font="28">str</text>
<text top="652" left="292" width="29" height="12" font="28">fusion</text>
<text top="652" left="342" width="35" height="12" font="28">no-elim</text>
<text top="628" left="250" width="100" height="14" font="22">number of threads</text>
<text top="562" left="140" width="0" height="14" font="29">sa</text>
<text top="549" left="140" width="0" height="14" font="29">m</text>
<text top="539" left="140" width="0" height="14" font="29">p</text>
<text top="532" left="140" width="0" height="14" font="29">le</text>
<text top="522" left="140" width="0" height="14" font="29">s </text>
<text top="512" left="140" width="0" height="14" font="29">p</text>
<text top="505" left="140" width="0" height="14" font="29">e</text>
<text top="498" left="140" width="0" height="14" font="29">r </text>
<text top="491" left="140" width="0" height="14" font="29">se</text>
<text top="478" left="140" width="0" height="14" font="29">co</text>
<text top="465" left="140" width="0" height="14" font="29">n</text>
<text top="458" left="140" width="0" height="14" font="29">d</text>
<text top="610" left="545" width="6" height="12" font="28">1</text>
<text top="610" left="605" width="6" height="12" font="28">2</text>
<text top="610" left="665" width="6" height="12" font="28">4</text>
<text top="610" left="725" width="6" height="12" font="28">6</text>
<text top="610" left="785" width="6" height="12" font="28">8</text>
<text top="594" left="491" width="47" height="12" font="28">0.00E+00</text>
<text top="576" left="491" width="47" height="12" font="28">2.00E+07</text>
<text top="558" left="491" width="47" height="12" font="28">4.00E+07</text>
<text top="540" left="491" width="47" height="12" font="28">6.00E+07</text>
<text top="522" left="491" width="47" height="12" font="28">8.00E+07</text>
<text top="504" left="491" width="47" height="12" font="28">1.00E+08</text>
<text top="486" left="491" width="47" height="12" font="28">1.20E+08</text>
<text top="468" left="491" width="47" height="12" font="28">1.40E+08</text>
<text top="450" left="491" width="47" height="12" font="28">1.60E+08</text>
<text top="432" left="491" width="47" height="12" font="28">1.80E+08</text>
<text top="414" left="491" width="47" height="12" font="28">2.00E+08</text>
<text top="388" left="619" width="31" height="20" font="20">FFT</text>
<text top="652" left="561" width="18" height="12" font="28">cpp</text>
<text top="652" left="600" width="13" height="12" font="28">str</text>
<text top="652" left="634" width="29" height="12" font="28">fusion</text>
<text top="652" left="684" width="35" height="12" font="28">no-elim</text>
<text top="628" left="591" width="100" height="14" font="22">number of threads</text>
<text top="562" left="482" width="0" height="14" font="29">sa</text>
<text top="549" left="482" width="0" height="14" font="29">m</text>
<text top="539" left="482" width="0" height="14" font="29">p</text>
<text top="532" left="482" width="0" height="14" font="29">le</text>
<text top="522" left="482" width="0" height="14" font="29">s </text>
<text top="512" left="482" width="0" height="14" font="29">p</text>
<text top="505" left="482" width="0" height="14" font="29">e</text>
<text top="498" left="482" width="0" height="14" font="29">r </text>
<text top="491" left="482" width="0" height="14" font="29">se</text>
<text top="478" left="482" width="0" height="14" font="29">co</text>
<text top="465" left="482" width="0" height="14" font="29">n</text>
<text top="458" left="482" width="0" height="14" font="29">d</text>
<text top="907" left="208" width="6" height="12" font="28">1</text>
<text top="907" left="268" width="6" height="12" font="28">2</text>
<text top="907" left="328" width="6" height="12" font="28">4</text>
<text top="907" left="388" width="6" height="12" font="28">6</text>
<text top="907" left="448" width="6" height="12" font="28">8</text>
<text top="891" left="155" width="47" height="12" font="28">0.00E+00</text>
<text top="866" left="155" width="47" height="12" font="28">2.00E+05</text>
<text top="840" left="155" width="47" height="12" font="28">4.00E+05</text>
<text top="814" left="155" width="47" height="12" font="28">6.00E+05</text>
<text top="789" left="155" width="47" height="12" font="28">8.00E+05</text>
<text top="763" left="155" width="47" height="12" font="28">1.00E+06</text>
<text top="737" left="155" width="47" height="12" font="28">1.20E+06</text>
<text top="712" left="155" width="47" height="12" font="28">1.40E+06</text>
<text top="680" left="252" width="82" height="20" font="20">Filter Bank</text>
<text top="944" left="219" width="18" height="12" font="28">cpp</text>
<text top="944" left="258" width="13" height="12" font="28">str</text>
<text top="944" left="292" width="29" height="12" font="28">fusion</text>
<text top="944" left="342" width="35" height="12" font="28">no-elim</text>
<text top="925" left="254" width="101" height="14" font="22">number of threads</text>
<text top="860" left="145" width="0" height="14" font="29">sa</text>
<text top="847" left="145" width="0" height="14" font="29">m</text>
<text top="837" left="145" width="0" height="14" font="29">p</text>
<text top="829" left="145" width="0" height="14" font="29">le</text>
<text top="819" left="145" width="0" height="14" font="29">s </text>
<text top="810" left="145" width="0" height="14" font="29">p</text>
<text top="803" left="145" width="0" height="14" font="29">e</text>
<text top="796" left="145" width="0" height="14" font="29">r </text>
<text top="789" left="145" width="0" height="14" font="29">se</text>
<text top="776" left="145" width="0" height="14" font="29">co</text>
<text top="762" left="145" width="0" height="14" font="29">n</text>
<text top="755" left="145" width="0" height="14" font="29">d</text>
<text top="903" left="545" width="6" height="12" font="28">1</text>
<text top="903" left="605" width="6" height="12" font="28">2</text>
<text top="903" left="665" width="6" height="12" font="28">4</text>
<text top="903" left="725" width="6" height="12" font="28">6</text>
<text top="903" left="785" width="6" height="12" font="28">8</text>
<text top="887" left="491" width="47" height="12" font="28">0.00E+00</text>
<text top="861" left="491" width="47" height="12" font="28">5.00E+05</text>
<text top="835" left="491" width="47" height="12" font="28">1.00E+06</text>
<text top="810" left="491" width="47" height="12" font="28">1.50E+06</text>
<text top="784" left="491" width="47" height="12" font="28">2.00E+06</text>
<text top="758" left="491" width="47" height="12" font="28">2.50E+06</text>
<text top="732" left="491" width="47" height="12" font="28">3.00E+06</text>
<text top="707" left="491" width="47" height="12" font="28">3.50E+06</text>
<text top="680" left="598" width="74" height="20" font="20">FM Radio</text>
<text top="944" left="561" width="18" height="12" font="28">cpp</text>
<text top="944" left="600" width="13" height="12" font="28">str</text>
<text top="944" left="634" width="29" height="12" font="28">fusion</text>
<text top="944" left="684" width="35" height="12" font="28">no-elim</text>
<text top="921" left="591" width="100" height="14" font="22">number of threads</text>
<text top="855" left="482" width="0" height="14" font="29">sa</text>
<text top="842" left="482" width="0" height="14" font="29">m</text>
<text top="832" left="482" width="0" height="14" font="29">p</text>
<text top="825" left="482" width="0" height="14" font="29">le</text>
<text top="814" left="482" width="0" height="14" font="29">s </text>
<text top="805" left="482" width="0" height="14" font="29">p</text>
<text top="798" left="482" width="0" height="14" font="29">e</text>
<text top="791" left="482" width="0" height="14" font="29">r </text>
<text top="784" left="482" width="0" height="14" font="29">se</text>
<text top="771" left="482" width="0" height="14" font="29">co</text>
<text top="758" left="482" width="0" height="14" font="29">n</text>
<text top="750" left="482" width="0" height="14" font="29">d</text>
<text top="317" left="545" width="6" height="12" font="28">1</text>
<text top="317" left="605" width="6" height="12" font="28">2</text>
<text top="317" left="665" width="6" height="12" font="28">4</text>
<text top="317" left="725" width="6" height="12" font="28">6</text>
<text top="317" left="785" width="6" height="12" font="28">8</text>
<text top="301" left="491" width="47" height="12" font="28">0.00E+00</text>
<text top="271" left="491" width="47" height="12" font="28">2.00E+05</text>
<text top="241" left="491" width="47" height="12" font="28">4.00E+05</text>
<text top="211" left="491" width="47" height="12" font="28">6.00E+05</text>
<text top="181" left="491" width="47" height="12" font="28">8.00E+05</text>
<text top="151" left="491" width="47" height="12" font="28">1.00E+06</text>
<text top="121" left="491" width="47" height="12" font="28">1.20E+06</text>
<text top="95" left="569" width="130" height="20" font="20">Channel Vocoder</text>
<text top="359" left="561" width="18" height="12" font="28">cpp</text>
<text top="359" left="600" width="13" height="12" font="28">str</text>
<text top="359" left="634" width="29" height="12" font="28">fusion</text>
<text top="359" left="684" width="35" height="12" font="28">no-elim</text>
<text top="335" left="591" width="100" height="14" font="22">number of threads</text>
<text top="270" left="482" width="0" height="14" font="29">sa</text>
<text top="256" left="482" width="0" height="14" font="29">m</text>
<text top="246" left="482" width="0" height="14" font="29">p</text>
<text top="239" left="482" width="0" height="14" font="29">le</text>
<text top="229" left="482" width="0" height="14" font="29">s </text>
<text top="220" left="482" width="0" height="14" font="29">p</text>
<text top="213" left="482" width="0" height="14" font="29">e</text>
<text top="205" left="482" width="0" height="14" font="29">r </text>
<text top="198" left="482" width="0" height="14" font="29">se</text>
<text top="185" left="482" width="0" height="14" font="29">co</text>
<text top="172" left="482" width="0" height="14" font="29">n</text>
<text top="165" left="482" width="0" height="14" font="29">d</text>
<text top="981" left="108" width="702" height="16" font="0">Figure 7.2: Throughput obtained by the SKIR compiler and scheduler for the StreamIt benchmarks</text>
<text top="1003" left="108" width="559" height="16" font="0">using a varying number of threads. Error bars indicate one standard deviation.</text>
</page>
<page number="139" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="30" size="12" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">125</text>
<text top="460" left="216" width="80" height="14" font="22">Beam Former</text>
<text top="460" left="311" width="72" height="14" font="22">Ch. Vocoder</text>
<text top="460" left="425" width="27" height="14" font="22">DCT</text>
<text top="460" left="518" width="24" height="14" font="22">FFT</text>
<text top="460" left="590" width="61" height="14" font="22">Filter Bank</text>
<text top="460" left="683" width="56" height="14" font="22">FM Radio</text>
<text top="443" left="195" width="8" height="16" font="8">1</text>
<text top="414" left="195" width="8" height="16" font="8">2</text>
<text top="385" left="195" width="8" height="16" font="8">3</text>
<text top="356" left="195" width="8" height="16" font="8">4</text>
<text top="327" left="195" width="8" height="16" font="8">5</text>
<text top="299" left="195" width="8" height="16" font="8">6</text>
<text top="270" left="195" width="8" height="16" font="8">7</text>
<text top="241" left="195" width="8" height="16" font="8">8</text>
<text top="212" left="195" width="8" height="16" font="8">9</text>
<text top="183" left="187" width="16" height="16" font="8">10</text>
<text top="154" left="187" width="16" height="16" font="8">11</text>
<text top="125" left="187" width="16" height="16" font="8">12</text>
<text top="95" left="351" width="237" height="16" font="8">Speedup due to Coroutine Elimination</text>
<text top="196" left="284" width="33" height="16" font="8">N = 1</text>
<text top="214" left="284" width="33" height="16" font="8">N = 2</text>
<text top="231" left="284" width="33" height="16" font="8">N = 4</text>
<text top="249" left="284" width="33" height="16" font="8">N = 6</text>
<text top="267" left="284" width="33" height="16" font="8">N = 8</text>
<text top="180" left="236" width="120" height="16" font="8">Number of Threads</text>
<text top="312" left="171" width="0" height="16" font="30">S</text>
<text top="303" left="171" width="0" height="16" font="30">p</text>
<text top="295" left="171" width="0" height="16" font="30">e</text>
<text top="287" left="171" width="0" height="16" font="30">e</text>
<text top="279" left="171" width="0" height="16" font="30">d</text>
<text top="271" left="171" width="0" height="16" font="30">u</text>
<text top="263" left="171" width="0" height="16" font="30">p</text>
<text top="496" left="108" width="702" height="16" font="0">Figure 7.3: The results of performing coroutine elimination on the StreamIt benchmarks using the</text>
<text top="518" left="108" width="201" height="16" font="0">SKIR just-in-time compiler.</text>
<text top="610" left="108" width="115" height="16" font="0">used with the C</text>
<text top="610" left="221" width="17" height="13" font="1">++</text>
<text top="610" left="244" width="566" height="16" font="0">code (llvm-gcc) is much more mature than our StreamIt to SKIR compiler</text>
<text top="646" left="108" width="702" height="16" font="0">and performs optimization. We also see in the results that coroutine elimination results in signiﬁ-</text>
<text top="682" left="108" width="702" height="16" font="0">cantly better performance and that dynamic fusion often gives a slight performance improvement.</text>
<text top="718" left="108" width="702" height="16" font="0">For the two most ﬁne-grained benchmarks (fft and dct), the conﬁguration without coroutine elimi-</text>
<text top="754" left="108" width="395" height="16" font="0">nation does not scale beyond a single processor socket.</text>
<text top="790" left="151" width="659" height="16" font="0">Figure 7.3 gives a more detailed view of the data shown in Figure 7.2 with respect to perfor-</text>
<text top="826" left="108" width="702" height="16" font="0">mance improvements resulting from coroutine elimination. It shows the speedup obtained by the</text>
<text top="862" left="108" width="702" height="16" font="0">coroutine elimination optimization compared to the baseline conﬁguration. The data shows that</text>
<text top="898" left="108" width="702" height="16" font="0">coroutine elimination results in signiﬁcant performance improvements for programs with the most</text>
<text top="934" left="108" width="702" height="16" font="0">ﬁne-grained kernels, typically 2-4x. For the fft benchmark, the improvement is over 12x. This</text>
<text top="970" left="108" width="702" height="16" font="0">is because of the high number of skir.peek operations in this benchmark, each of which re-</text>
<text top="1006" left="108" width="702" height="16" font="0">quires offset calculation and bounds checking, and a low amount of work per input item consumed.</text>
<text top="1042" left="108" width="702" height="16" font="0">Hoisting the computation associated with the skir.peek operations out of the kernel loop is sig-</text>
</page>
<page number="140" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="31" size="11" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">126</text>
<text top="128" left="108" width="702" height="16" font="0">niﬁcant. The speedup is the least signiﬁcant for the beamformer program which is dominated by</text>
<text top="164" left="108" width="445" height="16" font="0">kernels taking more than 500 cycles per input item consumed.</text>
<text top="563" left="264" width="84" height="15" font="2">Beam Former</text>
<text top="563" left="420" width="29" height="15" font="2">DCT</text>
<text top="563" left="530" width="67" height="15" font="2">Filter Bank</text>
<text top="563" left="662" width="60" height="15" font="2">FM Radio</text>
<text top="547" left="190" width="44" height="15" font="2">-2.00%</text>
<text top="511" left="194" width="39" height="15" font="2">0.00%</text>
<text top="475" left="194" width="39" height="15" font="2">2.00%</text>
<text top="439" left="194" width="39" height="15" font="2">4.00%</text>
<text top="403" left="194" width="39" height="15" font="2">6.00%</text>
<text top="367" left="194" width="39" height="15" font="2">8.00%</text>
<text top="331" left="186" width="47" height="15" font="2">10.00%</text>
<text top="294" left="186" width="47" height="15" font="2">12.00%</text>
<text top="258" left="186" width="47" height="15" font="2">14.00%</text>
<text top="222" left="186" width="47" height="15" font="2">16.00%</text>
<text top="199" left="394" width="146" height="15" font="2">Speedup Due to Fusion</text>
<text top="292" left="630" width="33" height="15" font="2">N = 1</text>
<text top="309" left="630" width="33" height="15" font="2">N = 2</text>
<text top="327" left="630" width="33" height="15" font="2">N = 4</text>
<text top="344" left="630" width="33" height="15" font="2">N = 6</text>
<text top="362" left="630" width="33" height="15" font="2">N = 8</text>
<text top="271" left="583" width="119" height="15" font="2">Number of Threads</text>
<text top="438" left="171" width="0" height="15" font="31">P</text>
<text top="428" left="171" width="0" height="15" font="31">e</text>
<text top="421" left="171" width="0" height="15" font="31">rc</text>
<text top="409" left="171" width="0" height="15" font="31">e</text>
<text top="402" left="171" width="0" height="15" font="31">n</text>
<text top="394" left="171" width="0" height="15" font="31">t C</text>
<text top="376" left="171" width="0" height="15" font="31">h</text>
<text top="369" left="171" width="0" height="15" font="31">a</text>
<text top="361" left="171" width="0" height="15" font="31">n</text>
<text top="353" left="171" width="0" height="15" font="31">g</text>
<text top="345" left="171" width="0" height="15" font="31">e</text>
<text top="600" left="108" width="702" height="16" font="0">Figure 7.4: The results of performing dynamic fusion on the StreamIt benchmarks using the SKIR</text>
<text top="622" left="108" width="155" height="16" font="0">just-in-time compiler.</text>
<text top="694" left="151" width="659" height="16" font="0">Figure 7.4 gives a more detailed view of the data shown in Figure 7.2 with respect to the</text>
<text top="730" left="108" width="702" height="16" font="0">performance improvement obtained using the dynamic fusion optimization. The ﬁgure does not</text>
<text top="766" left="108" width="702" height="16" font="0">show results for fft and channel vocoder. Due to extensive use of skir.peek operations, these</text>
<text top="802" left="108" width="702" height="16" font="0">benchmarks receive no beneﬁt from fusion as we do not yet implement fusion of peeking kernels.</text>
<text top="838" left="108" width="22" height="15" font="0">dct</text>
<text top="838" left="136" width="674" height="16" font="0">sees the biggest gains from fusion at roughly 10-15%, depending on the number of threads</text>
<text top="874" left="108" width="702" height="16" font="0">used. We also see a general trend that fusion is more useful when more threads are used. This is</text>
<text top="910" left="108" width="702" height="16" font="0">likely due to the fact that fusion reduces parallelization overheads that are also reduced by simply</text>
<text top="946" left="108" width="702" height="16" font="0">running with a smaller number of threads. All of the results are statistically signiﬁcant except for</text>
<text top="982" left="108" width="88" height="15" font="0">beamformer</text>
<text top="982" left="200" width="404" height="16" font="0">with one and two threads and ﬁlterbank with one thread.</text>
<text top="1018" left="151" width="659" height="16" font="0">Interestingly, only two fusions are ever performed when running dct. They are the fusion</text>
<text top="1054" left="108" width="702" height="16" font="0">of two type conversion ﬁlters (e.g. int to float) with their neighbors in the stream graph.</text>
</page>
<page number="141" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">127</text>
<text top="128" left="108" width="702" height="16" font="0">From a programming perspective this type of ﬁlter boosts productivity by avoiding the need to</text>
<text top="164" left="108" width="702" height="16" font="0">modify existing components (e.g. by not rewriting a ﬁlter to use float instead of int). From</text>
<text top="200" left="108" width="702" height="16" font="0">a computation perspective these ﬁlters are essentially a noop and having them in a graph may be</text>
<text top="236" left="108" width="702" height="16" font="0">of little concern when using a static scheduling scheme. However, the results for SKIR show that</text>
<text top="272" left="108" width="702" height="16" font="0">from a dynamic scheduling perspective these types of ﬁlters can sometimes add a huge amount of</text>
<text top="308" left="108" width="702" height="16" font="0">scheduling overhead. This observation supports the claim made by this thesis that an optimizable</text>
<text top="344" left="108" width="572" height="16" font="0">representation of stream parallelism is useful when dynamic scheduling is used.</text>
<text top="380" left="151" width="659" height="16" font="0">We also compare the performance of the SKIR dynamic scheduler to the performance of two</text>
<text top="416" left="108" width="702" height="16" font="0">mature stream processing systems: StreamIt and GNU Radio. We use a version of StreamIt pulled</text>
<text top="452" left="108" width="702" height="16" font="0">from a mirror the StreamIt code repository [14] with a last commit date of September 2, 2011. We</text>
<text top="488" left="108" width="702" height="16" font="0">use the SMP StreamIt backend which performs aggressive fusion followed by ﬁssion with a width</text>
<text top="524" left="108" width="702" height="16" font="0">equal to the number of threads. This scheduling transformation is described in [33]. The StreamIt</text>
<text top="560" left="108" width="702" height="16" font="0">compiler generates a statically scheduled stream graph as multithreaded C code. Our porting of the</text>
<text top="596" left="108" width="702" height="16" font="0">StreamIt benchmarks to GNU Radio was discussed above. GNU Radio uses a scheduling algorithm</text>
<text top="632" left="108" width="702" height="16" font="0">very similar to the one implemented by Parks to execute KPNs in the Ptolemy framework [48]. It</text>
<text top="668" left="108" width="702" height="16" font="0">uses one operating system thread per kernel. The threads sleep when their kernel is blocked and</text>
<text top="704" left="108" width="422" height="16" font="0">signal sleeping threads when a blocking condition is lifted.</text>
<text top="740" left="151" width="659" height="16" font="0">We compile GNU Radio and the C code generated by StreamIt with llvm-gcc using the</text>
<text top="777" left="108" width="32" height="14" font="0">-03</text>
<text top="776" left="145" width="665" height="16" font="0">optimization ﬂag. Using the LLVM toolchain ensures that the same C frontend and the same</text>
<text top="812" left="108" width="702" height="16" font="0">backend optimization passes are used for SKIR, GNU Radio, and StreamIt. Like we did when run-</text>
<text top="848" left="108" width="702" height="16" font="0">ning the SKIR benchmarks, we pin benchmarks to a subset of available cores using the numactl</text>
<text top="884" left="108" width="702" height="16" font="0">command line tool when targeting a number of threads less than 8. We compile StreamIt pro-</text>
<text top="920" left="108" width="702" height="16" font="0">grams to use the target number of threads. We use the SKIR results from the previous ﬁgures with</text>
<text top="956" left="108" width="424" height="16" font="0">coroutine elimination enabled and without dynamic fusion.</text>
<text top="992" left="151" width="659" height="16" font="0">The results of the comparison of the three schedulers is shown in Figure 7.5. We can see</text>
<text top="1027" left="108" width="702" height="16" font="0">that the performance of SKIR is very competitive with both of the other scheduling schemes. For</text>
<text top="1063" left="108" width="702" height="16" font="0">ﬁve of the benchmarks, SKIR performs the best when targeting 8 threads. GNU Radio performs</text>
</page>
<page number="142" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="32" size="9" family="Times" color="#1a1a1a"/>
<text top="85" left="783" width="27" height="16" font="0">128</text>
<text top="306" left="539" width="6" height="12" font="28">1</text>
<text top="306" left="596" width="6" height="12" font="28">2</text>
<text top="306" left="654" width="6" height="12" font="28">4</text>
<text top="306" left="711" width="6" height="12" font="28">6</text>
<text top="306" left="768" width="6" height="12" font="28">8</text>
<text top="291" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="263" left="489" width="44" height="12" font="28">2.00E+05</text>
<text top="234" left="489" width="44" height="12" font="28">4.00E+05</text>
<text top="206" left="489" width="44" height="12" font="28">6.00E+05</text>
<text top="177" left="489" width="44" height="12" font="28">8.00E+05</text>
<text top="148" left="489" width="44" height="12" font="28">1.00E+06</text>
<text top="120" left="489" width="44" height="12" font="28">1.20E+06</text>
<text top="95" left="563" width="123" height="19" font="11">Channel Vocoder</text>
<text top="346" left="551" width="24" height="12" font="28">SKIR</text>
<text top="346" left="595" width="39" height="12" font="28">StreamIt</text>
<text top="346" left="655" width="54" height="12" font="28">GNU Radio</text>
<text top="323" left="583" width="96" height="13" font="6">number of threads</text>
<text top="261" left="479" width="0" height="13" font="32">sa</text>
<text top="249" left="479" width="0" height="13" font="32">m</text>
<text top="239" left="479" width="0" height="13" font="32">p</text>
<text top="232" left="479" width="0" height="13" font="32">le</text>
<text top="222" left="479" width="0" height="13" font="32">s </text>
<text top="214" left="479" width="0" height="13" font="32">p</text>
<text top="207" left="479" width="0" height="13" font="32">e</text>
<text top="200" left="479" width="0" height="13" font="32">r </text>
<text top="193" left="479" width="0" height="13" font="32">se</text>
<text top="181" left="479" width="0" height="13" font="32">co</text>
<text top="168" left="479" width="0" height="13" font="32">n</text>
<text top="161" left="479" width="0" height="13" font="32">d</text>
<text top="314" left="221" width="6" height="12" font="28">1</text>
<text top="314" left="277" width="6" height="12" font="28">2</text>
<text top="314" left="333" width="6" height="12" font="28">4</text>
<text top="314" left="389" width="6" height="12" font="28">6</text>
<text top="314" left="445" width="6" height="12" font="28">8</text>
<text top="299" left="170" width="44" height="12" font="28">0.00E+00</text>
<text top="276" left="170" width="44" height="12" font="28">5.00E+05</text>
<text top="252" left="170" width="44" height="12" font="28">1.00E+06</text>
<text top="228" left="170" width="44" height="12" font="28">1.50E+06</text>
<text top="204" left="170" width="44" height="12" font="28">2.00E+06</text>
<text top="180" left="170" width="44" height="12" font="28">2.50E+06</text>
<text top="156" left="170" width="44" height="12" font="28">3.00E+06</text>
<text top="132" left="170" width="44" height="12" font="28">3.50E+06</text>
<text top="108" left="170" width="44" height="12" font="28">4.00E+06</text>
<text top="95" left="255" width="89" height="19" font="11">Beamformer</text>
<text top="346" left="227" width="24" height="12" font="28">SKIR</text>
<text top="346" left="270" width="39" height="12" font="28">StreamIt</text>
<text top="346" left="330" width="54" height="12" font="28">GNU Radio</text>
<text top="331" left="263" width="96" height="13" font="6">number of threads</text>
<text top="259" left="161" width="0" height="13" font="32">sa</text>
<text top="247" left="161" width="0" height="13" font="32">m</text>
<text top="237" left="161" width="0" height="13" font="32">p</text>
<text top="230" left="161" width="0" height="13" font="32">le</text>
<text top="221" left="161" width="0" height="13" font="32">s </text>
<text top="212" left="161" width="0" height="13" font="32">p</text>
<text top="205" left="161" width="0" height="13" font="32">e</text>
<text top="198" left="161" width="0" height="13" font="32">r </text>
<text top="192" left="161" width="0" height="13" font="32">se</text>
<text top="179" left="161" width="0" height="13" font="32">co</text>
<text top="167" left="161" width="0" height="13" font="32">n</text>
<text top="160" left="161" width="0" height="13" font="32">d</text>
<text top="585" left="246" width="6" height="12" font="28">1</text>
<text top="585" left="296" width="6" height="12" font="28">2</text>
<text top="585" left="345" width="6" height="12" font="28">4</text>
<text top="585" left="395" width="6" height="12" font="28">6</text>
<text top="585" left="445" width="6" height="12" font="28">8</text>
<text top="570" left="195" width="44" height="12" font="28">0.00E+00</text>
<text top="553" left="195" width="44" height="12" font="28">1.00E+07</text>
<text top="536" left="195" width="44" height="12" font="28">2.00E+07</text>
<text top="518" left="195" width="44" height="12" font="28">3.00E+07</text>
<text top="501" left="195" width="44" height="12" font="28">4.00E+07</text>
<text top="484" left="195" width="44" height="12" font="28">5.00E+07</text>
<text top="467" left="195" width="44" height="12" font="28">6.00E+07</text>
<text top="450" left="195" width="44" height="12" font="28">7.00E+07</text>
<text top="433" left="195" width="44" height="12" font="28">8.00E+07</text>
<text top="416" left="195" width="44" height="12" font="28">9.00E+07</text>
<text top="398" left="195" width="44" height="12" font="28">1.00E+08</text>
<text top="373" left="300" width="33" height="19" font="11">DCT</text>
<text top="625" left="243" width="24" height="12" font="28">SKIR</text>
<text top="625" left="287" width="40" height="12" font="28">StreamIt</text>
<text top="625" left="346" width="54" height="12" font="28">GNU Radio</text>
<text top="602" left="275" width="96" height="13" font="6">number of threads</text>
<text top="540" left="187" width="0" height="13" font="32">sa</text>
<text top="527" left="187" width="0" height="13" font="32">m</text>
<text top="517" left="187" width="0" height="13" font="32">p</text>
<text top="511" left="187" width="0" height="13" font="32">le</text>
<text top="501" left="187" width="0" height="13" font="32">s </text>
<text top="492" left="187" width="0" height="13" font="32">p</text>
<text top="486" left="187" width="0" height="13" font="32">e</text>
<text top="479" left="187" width="0" height="13" font="32">r </text>
<text top="472" left="187" width="0" height="13" font="32">se</text>
<text top="459" left="187" width="0" height="13" font="32">co</text>
<text top="447" left="187" width="0" height="13" font="32">n</text>
<text top="440" left="187" width="0" height="13" font="32">d</text>
<text top="585" left="539" width="6" height="12" font="28">1</text>
<text top="585" left="596" width="6" height="12" font="28">2</text>
<text top="585" left="654" width="6" height="12" font="28">4</text>
<text top="585" left="711" width="6" height="12" font="28">6</text>
<text top="585" left="768" width="6" height="12" font="28">8</text>
<text top="570" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="553" left="489" width="44" height="12" font="28">2.00E+07</text>
<text top="536" left="489" width="44" height="12" font="28">4.00E+07</text>
<text top="519" left="489" width="44" height="12" font="28">6.00E+07</text>
<text top="501" left="489" width="44" height="12" font="28">8.00E+07</text>
<text top="484" left="489" width="44" height="12" font="28">1.00E+08</text>
<text top="467" left="489" width="44" height="12" font="28">1.20E+08</text>
<text top="450" left="489" width="44" height="12" font="28">1.40E+08</text>
<text top="433" left="489" width="44" height="12" font="28">1.60E+08</text>
<text top="416" left="489" width="44" height="12" font="28">1.80E+08</text>
<text top="398" left="489" width="44" height="12" font="28">2.00E+08</text>
<text top="374" left="610" width="30" height="19" font="11">FFT</text>
<text top="625" left="551" width="24" height="12" font="28">SKIR</text>
<text top="625" left="595" width="39" height="12" font="28">StreamIt</text>
<text top="625" left="655" width="54" height="12" font="28">GNU Radio</text>
<text top="602" left="583" width="96" height="13" font="6">number of threads</text>
<text top="540" left="479" width="0" height="13" font="32">sa</text>
<text top="527" left="479" width="0" height="13" font="32">m</text>
<text top="517" left="479" width="0" height="13" font="32">p</text>
<text top="511" left="479" width="0" height="13" font="32">le</text>
<text top="501" left="479" width="0" height="13" font="32">s </text>
<text top="492" left="479" width="0" height="13" font="32">p</text>
<text top="486" left="479" width="0" height="13" font="32">e</text>
<text top="479" left="479" width="0" height="13" font="32">r </text>
<text top="472" left="479" width="0" height="13" font="32">se</text>
<text top="459" left="479" width="0" height="13" font="32">co</text>
<text top="447" left="479" width="0" height="13" font="32">n</text>
<text top="440" left="479" width="0" height="13" font="32">d</text>
<text top="863" left="214" width="6" height="12" font="28">1</text>
<text top="863" left="272" width="6" height="12" font="28">2</text>
<text top="863" left="329" width="6" height="12" font="28">4</text>
<text top="863" left="386" width="6" height="12" font="28">6</text>
<text top="863" left="443" width="6" height="12" font="28">8</text>
<text top="848" left="164" width="44" height="12" font="28">0.00E+00</text>
<text top="824" left="164" width="44" height="12" font="28">2.00E+05</text>
<text top="799" left="164" width="44" height="12" font="28">4.00E+05</text>
<text top="775" left="164" width="44" height="12" font="28">6.00E+05</text>
<text top="750" left="164" width="44" height="12" font="28">8.00E+05</text>
<text top="726" left="164" width="44" height="12" font="28">1.00E+06</text>
<text top="701" left="164" width="44" height="12" font="28">1.20E+06</text>
<text top="677" left="164" width="44" height="12" font="28">1.40E+06</text>
<text top="652" left="260" width="78" height="19" font="11">Filter Bank</text>
<text top="903" left="227" width="24" height="12" font="28">SKIR</text>
<text top="903" left="270" width="39" height="12" font="28">StreamIt</text>
<text top="903" left="330" width="54" height="12" font="28">GNU Radio</text>
<text top="880" left="259" width="96" height="13" font="6">number of threads</text>
<text top="818" left="154" width="0" height="13" font="32">sa</text>
<text top="806" left="154" width="0" height="13" font="32">m</text>
<text top="796" left="154" width="0" height="13" font="32">p</text>
<text top="789" left="154" width="0" height="13" font="32">le</text>
<text top="780" left="154" width="0" height="13" font="32">s </text>
<text top="771" left="154" width="0" height="13" font="32">p</text>
<text top="764" left="154" width="0" height="13" font="32">e</text>
<text top="757" left="154" width="0" height="13" font="32">r </text>
<text top="750" left="154" width="0" height="13" font="32">se</text>
<text top="738" left="154" width="0" height="13" font="32">co</text>
<text top="725" left="154" width="0" height="13" font="32">n</text>
<text top="719" left="154" width="0" height="13" font="32">d</text>
<text top="863" left="539" width="6" height="12" font="28">1</text>
<text top="863" left="596" width="6" height="12" font="28">2</text>
<text top="863" left="654" width="6" height="12" font="28">4</text>
<text top="863" left="711" width="6" height="12" font="28">6</text>
<text top="863" left="768" width="6" height="12" font="28">8</text>
<text top="848" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="824" left="489" width="44" height="12" font="28">5.00E+05</text>
<text top="799" left="489" width="44" height="12" font="28">1.00E+06</text>
<text top="775" left="489" width="44" height="12" font="28">1.50E+06</text>
<text top="750" left="489" width="44" height="12" font="28">2.00E+06</text>
<text top="726" left="489" width="44" height="12" font="28">2.50E+06</text>
<text top="701" left="489" width="44" height="12" font="28">3.00E+06</text>
<text top="677" left="489" width="44" height="12" font="28">3.50E+06</text>
<text top="652" left="590" width="70" height="19" font="11">FM Radio</text>
<text top="903" left="551" width="24" height="12" font="28">SKIR</text>
<text top="903" left="595" width="39" height="12" font="28">StreamIt</text>
<text top="903" left="655" width="54" height="12" font="28">GNU Radio</text>
<text top="880" left="583" width="96" height="13" font="6">number of threads</text>
<text top="818" left="479" width="0" height="13" font="32">sa</text>
<text top="806" left="479" width="0" height="13" font="32">m</text>
<text top="796" left="479" width="0" height="13" font="32">p</text>
<text top="789" left="479" width="0" height="13" font="32">le</text>
<text top="780" left="479" width="0" height="13" font="32">s </text>
<text top="771" left="479" width="0" height="13" font="32">p</text>
<text top="764" left="479" width="0" height="13" font="32">e</text>
<text top="757" left="479" width="0" height="13" font="32">r </text>
<text top="750" left="479" width="0" height="13" font="32">se</text>
<text top="738" left="479" width="0" height="13" font="32">co</text>
<text top="725" left="479" width="0" height="13" font="32">n</text>
<text top="719" left="479" width="0" height="13" font="32">d</text>
<text top="942" left="108" width="702" height="16" font="0">Figure 7.5: Throughput obtained by the SKIR dynamic scheduler, the StreamIt static scheduler,</text>
<text top="963" left="108" width="702" height="16" font="0">and the GNU Radio dynamic scheduler for the StreamIt benchmarks using a varying number of</text>
<text top="985" left="108" width="366" height="16" font="0">threads. Error bars indicate one standard deviation.</text>
</page>
<page number="143" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">129</text>
<text top="128" left="108" width="702" height="16" font="0">the worst except for ﬁlterbank where StreamIt performs poorly. This experiment validates our</text>
<text top="164" left="108" width="702" height="16" font="0">assertion that dynamic scheduling with support for SDF style optimization can perform as well as</text>
<text top="200" left="108" width="702" height="16" font="0">static scheduling for SDF style programs, at least for this set of benchmarks on this 8-core machine.</text>
<text top="236" left="151" width="659" height="16" font="0">The limits of both dynamic and static scheduling are illustrated when we run a similar set of</text>
<text top="272" left="108" width="702" height="16" font="0">experiments on a larger number of cores. Figure 7.6 shows the results of running three different</text>
<text top="308" left="108" width="702" height="16" font="0">versions of each StreamIt benchmark on 1, 6, 12, 18, and 24 cores of a 48-core system containing</text>
<text top="344" left="108" width="702" height="16" font="0">four AMD Opteron 6174 processors. We run the benchmarks using SKIR with coroutine elimi-</text>
<text top="380" left="108" width="702" height="16" font="0">nation but without dynamic fusion or ﬁssion, using the StreamIt compiled executables for eight</text>
<text top="416" left="108" width="702" height="16" font="0">threads from the previous experiments, and using StreamIt compiled executables targeting the ac-</text>
<text top="452" left="108" width="702" height="16" font="0">tual number of threads. As in the previous experiments, we restrict the worker threads to the</text>
<text top="488" left="108" width="702" height="16" font="0">minimum number of multi-core processors and physical sockets using the Linux numactl utility.</text>
<text top="524" left="108" width="702" height="16" font="0">In this system, there are two six core processors per die for a total of twelve processors per socket.</text>
<text top="560" left="151" width="659" height="16" font="0">The ﬁrst thing to notice in Figure 7.6 is the lack of portability seen in the executables com-</text>
<text top="596" left="108" width="702" height="16" font="0">piled by the StreamIt compiler targeting eight threads. Not only does the measured throughput</text>
<text top="632" left="108" width="702" height="16" font="0">plateau after the number of available processors exceeds eight, the performance under performs</text>
<text top="668" left="108" width="702" height="16" font="0">the executable compiled to target the actual number of threads in all but one case. As one would</text>
<text top="704" left="108" width="702" height="16" font="0">expect from a dynamic scheduler, SKIR generally outperforms StreamIt when the actual number</text>
<text top="740" left="108" width="702" height="16" font="0">of threads is different from the number of threads targeted at compile time. As in the previous</text>
<text top="776" left="108" width="529" height="16" font="0">experiments, the StreamIt compiled versions of ﬁlterbank perform poorly.</text>
<text top="812" left="151" width="659" height="16" font="0">The SKIR results in Figure 7.6 show the limits of dynamic scheduling without kernel fusion</text>
<text top="848" left="108" width="702" height="16" font="0">or kernel ﬁssion when compared to the StreamIt static scheduling algorithm. As shown in Table</text>
<text top="884" left="108" width="702" height="16" font="0">7.1, the fm benchmark is dominated by 13 kernels. Thus a system without kernel ﬁssion cannot</text>
<text top="920" left="108" width="702" height="16" font="0">scale much beyond 13 threads and this is clearly seen in the ﬁgure. A similar effect is seen in</text>
<text top="956" left="108" width="702" height="16" font="0">the fft results, where the total number of kernels is 17. When we force SKIR to use 24 threads</text>
<text top="992" left="108" width="702" height="16" font="0">for this benchmark, the result is excessive work stealing overhead from TBB. Of course in a more</text>
<text top="1027" left="108" width="702" height="16" font="0">realistic scenario, the number of threads would not be allowed to grow beyond the number of active</text>
<text top="1063" left="108" width="702" height="16" font="0">kernels. For the dct benchmark, Table 7.1 shows that the benchmark contains 32 kernels large</text>
</page>
<page number="144" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">130</text>
<text top="315" left="221" width="6" height="12" font="28">1</text>
<text top="315" left="276" width="6" height="12" font="28">6</text>
<text top="315" left="329" width="12" height="12" font="28">12</text>
<text top="315" left="385" width="12" height="12" font="28">18</text>
<text top="315" left="440" width="12" height="12" font="28">24</text>
<text top="300" left="170" width="44" height="12" font="28">0.00E+00</text>
<text top="279" left="170" width="44" height="12" font="28">5.00E+05</text>
<text top="257" left="170" width="44" height="12" font="28">1.00E+06</text>
<text top="236" left="170" width="44" height="12" font="28">1.50E+06</text>
<text top="215" left="170" width="44" height="12" font="28">2.00E+06</text>
<text top="193" left="170" width="44" height="12" font="28">2.50E+06</text>
<text top="172" left="170" width="44" height="12" font="28">3.00E+06</text>
<text top="151" left="170" width="44" height="12" font="28">3.50E+06</text>
<text top="129" left="170" width="44" height="12" font="28">4.00E+06</text>
<text top="108" left="170" width="44" height="12" font="28">4.50E+06</text>
<text top="95" left="255" width="89" height="19" font="11">Beamformer</text>
<text top="347" left="230" width="24" height="12" font="28">SKIR</text>
<text top="347" left="274" width="40" height="12" font="28">StreamIt</text>
<text top="347" left="333" width="48" height="12" font="28">StreamIt 8</text>
<text top="332" left="263" width="96" height="13" font="6">number of threads</text>
<text top="260" left="161" width="0" height="13" font="32">sa</text>
<text top="247" left="161" width="0" height="13" font="32">m</text>
<text top="237" left="161" width="0" height="13" font="32">p</text>
<text top="231" left="161" width="0" height="13" font="32">le</text>
<text top="221" left="161" width="0" height="13" font="32">s </text>
<text top="212" left="161" width="0" height="13" font="32">p</text>
<text top="206" left="161" width="0" height="13" font="32">e</text>
<text top="199" left="161" width="0" height="13" font="32">r </text>
<text top="192" left="161" width="0" height="13" font="32">se</text>
<text top="179" left="161" width="0" height="13" font="32">co</text>
<text top="167" left="161" width="0" height="13" font="32">n</text>
<text top="160" left="161" width="0" height="13" font="32">d</text>
<text top="307" left="540" width="6" height="12" font="28">1</text>
<text top="307" left="597" width="6" height="12" font="28">6</text>
<text top="307" left="650" width="12" height="12" font="28">12</text>
<text top="307" left="707" width="12" height="12" font="28">18</text>
<text top="307" left="764" width="12" height="12" font="28">24</text>
<text top="292" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="273" left="489" width="44" height="12" font="28">2.00E+05</text>
<text top="254" left="489" width="44" height="12" font="28">4.00E+05</text>
<text top="234" left="489" width="44" height="12" font="28">6.00E+05</text>
<text top="215" left="489" width="44" height="12" font="28">8.00E+05</text>
<text top="196" left="489" width="44" height="12" font="28">1.00E+06</text>
<text top="177" left="489" width="44" height="12" font="28">1.20E+06</text>
<text top="158" left="489" width="44" height="12" font="28">1.40E+06</text>
<text top="139" left="489" width="44" height="12" font="28">1.60E+06</text>
<text top="120" left="489" width="44" height="12" font="28">1.80E+06</text>
<text top="95" left="564" width="124" height="19" font="11">Channel Vocoder</text>
<text top="347" left="555" width="24" height="12" font="28">SKIR</text>
<text top="347" left="599" width="40" height="12" font="28">StreamIt</text>
<text top="347" left="659" width="48" height="12" font="28">StreamIt 8</text>
<text top="324" left="584" width="96" height="13" font="6">number of threads</text>
<text top="261" left="480" width="0" height="13" font="32">sa</text>
<text top="249" left="480" width="0" height="13" font="32">m</text>
<text top="239" left="480" width="0" height="13" font="32">p</text>
<text top="232" left="480" width="0" height="13" font="32">le</text>
<text top="223" left="480" width="0" height="13" font="32">s </text>
<text top="214" left="480" width="0" height="13" font="32">p</text>
<text top="207" left="480" width="0" height="13" font="32">e</text>
<text top="200" left="480" width="0" height="13" font="32">r </text>
<text top="194" left="480" width="0" height="13" font="32">se</text>
<text top="181" left="480" width="0" height="13" font="32">co</text>
<text top="168" left="480" width="0" height="13" font="32">n</text>
<text top="162" left="480" width="0" height="13" font="32">d</text>
<text top="586" left="215" width="6" height="12" font="28">1</text>
<text top="586" left="271" width="6" height="12" font="28">6</text>
<text top="586" left="325" width="12" height="12" font="28">12</text>
<text top="586" left="381" width="12" height="12" font="28">18</text>
<text top="586" left="438" width="12" height="12" font="28">24</text>
<text top="571" left="164" width="44" height="12" font="28">0.00E+00</text>
<text top="546" left="164" width="44" height="12" font="28">1.00E+07</text>
<text top="522" left="164" width="44" height="12" font="28">2.00E+07</text>
<text top="497" left="164" width="44" height="12" font="28">3.00E+07</text>
<text top="473" left="164" width="44" height="12" font="28">4.00E+07</text>
<text top="448" left="164" width="44" height="12" font="28">5.00E+07</text>
<text top="424" left="164" width="44" height="12" font="28">6.00E+07</text>
<text top="399" left="164" width="44" height="12" font="28">7.00E+07</text>
<text top="374" left="283" width="33" height="19" font="11">DCT</text>
<text top="626" left="230" width="24" height="12" font="28">SKIR</text>
<text top="626" left="274" width="40" height="12" font="28">StreamIt</text>
<text top="626" left="333" width="48" height="12" font="28">StreamIt 8</text>
<text top="603" left="259" width="96" height="13" font="6">number of threads</text>
<text top="541" left="154" width="0" height="13" font="32">sa</text>
<text top="528" left="154" width="0" height="13" font="32">m</text>
<text top="518" left="154" width="0" height="13" font="32">p</text>
<text top="512" left="154" width="0" height="13" font="32">le</text>
<text top="502" left="154" width="0" height="13" font="32">s </text>
<text top="493" left="154" width="0" height="13" font="32">p</text>
<text top="486" left="154" width="0" height="13" font="32">e</text>
<text top="479" left="154" width="0" height="13" font="32">r </text>
<text top="473" left="154" width="0" height="13" font="32">se</text>
<text top="460" left="154" width="0" height="13" font="32">co</text>
<text top="448" left="154" width="0" height="13" font="32">n</text>
<text top="441" left="154" width="0" height="13" font="32">d</text>
<text top="586" left="540" width="6" height="12" font="28">1</text>
<text top="586" left="597" width="6" height="12" font="28">6</text>
<text top="586" left="650" width="12" height="12" font="28">12</text>
<text top="586" left="707" width="12" height="12" font="28">18</text>
<text top="586" left="764" width="12" height="12" font="28">24</text>
<text top="571" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="546" left="489" width="44" height="12" font="28">1.00E+07</text>
<text top="522" left="489" width="44" height="12" font="28">2.00E+07</text>
<text top="497" left="489" width="44" height="12" font="28">3.00E+07</text>
<text top="473" left="489" width="44" height="12" font="28">4.00E+07</text>
<text top="448" left="489" width="44" height="12" font="28">5.00E+07</text>
<text top="424" left="489" width="44" height="12" font="28">6.00E+07</text>
<text top="399" left="489" width="44" height="12" font="28">7.00E+07</text>
<text top="374" left="611" width="30" height="19" font="11">FFT</text>
<text top="625" left="555" width="24" height="12" font="28">SKIR</text>
<text top="625" left="599" width="40" height="12" font="28">StreamIt</text>
<text top="625" left="659" width="48" height="12" font="28">StreamIt 8</text>
<text top="603" left="584" width="96" height="13" font="6">number of threads</text>
<text top="541" left="480" width="0" height="13" font="32">sa</text>
<text top="528" left="480" width="0" height="13" font="32">m</text>
<text top="518" left="480" width="0" height="13" font="32">p</text>
<text top="512" left="480" width="0" height="13" font="32">le</text>
<text top="502" left="480" width="0" height="13" font="32">s </text>
<text top="493" left="480" width="0" height="13" font="32">p</text>
<text top="486" left="480" width="0" height="13" font="32">e</text>
<text top="479" left="480" width="0" height="13" font="32">r </text>
<text top="473" left="480" width="0" height="13" font="32">se</text>
<text top="460" left="480" width="0" height="13" font="32">co</text>
<text top="448" left="480" width="0" height="13" font="32">n</text>
<text top="441" left="480" width="0" height="13" font="32">d</text>
<text top="865" left="215" width="6" height="12" font="28">1</text>
<text top="865" left="271" width="6" height="12" font="28">6</text>
<text top="865" left="325" width="12" height="12" font="28">12</text>
<text top="865" left="381" width="12" height="12" font="28">18</text>
<text top="865" left="438" width="12" height="12" font="28">24</text>
<text top="850" left="164" width="44" height="12" font="28">0.00E+00</text>
<text top="821" left="164" width="44" height="12" font="28">5.00E+05</text>
<text top="793" left="164" width="44" height="12" font="28">1.00E+06</text>
<text top="764" left="164" width="44" height="12" font="28">1.50E+06</text>
<text top="735" left="164" width="44" height="12" font="28">2.00E+06</text>
<text top="707" left="164" width="44" height="12" font="28">2.50E+06</text>
<text top="678" left="164" width="44" height="12" font="28">3.00E+06</text>
<text top="653" left="261" width="78" height="19" font="11">Filter Bank</text>
<text top="905" left="230" width="24" height="12" font="28">SKIR</text>
<text top="905" left="274" width="40" height="12" font="28">StreamIt</text>
<text top="905" left="333" width="48" height="12" font="28">StreamIt 8</text>
<text top="882" left="259" width="96" height="13" font="6">number of threads</text>
<text top="820" left="154" width="0" height="13" font="32">sa</text>
<text top="807" left="154" width="0" height="13" font="32">m</text>
<text top="797" left="154" width="0" height="13" font="32">p</text>
<text top="791" left="154" width="0" height="13" font="32">le</text>
<text top="781" left="154" width="0" height="13" font="32">s </text>
<text top="772" left="154" width="0" height="13" font="32">p</text>
<text top="765" left="154" width="0" height="13" font="32">e</text>
<text top="759" left="154" width="0" height="13" font="32">r </text>
<text top="752" left="154" width="0" height="13" font="32">se</text>
<text top="739" left="154" width="0" height="13" font="32">co</text>
<text top="727" left="154" width="0" height="13" font="32">n</text>
<text top="720" left="154" width="0" height="13" font="32">d</text>
<text top="865" left="540" width="6" height="12" font="28">1</text>
<text top="865" left="597" width="6" height="12" font="28">6</text>
<text top="865" left="650" width="12" height="12" font="28">12</text>
<text top="865" left="707" width="12" height="12" font="28">18</text>
<text top="865" left="764" width="12" height="12" font="28">24</text>
<text top="850" left="489" width="44" height="12" font="28">0.00E+00</text>
<text top="821" left="489" width="44" height="12" font="28">1.00E+06</text>
<text top="793" left="489" width="44" height="12" font="28">2.00E+06</text>
<text top="764" left="489" width="44" height="12" font="28">3.00E+06</text>
<text top="735" left="489" width="44" height="12" font="28">4.00E+06</text>
<text top="707" left="489" width="44" height="12" font="28">5.00E+06</text>
<text top="678" left="489" width="44" height="12" font="28">6.00E+06</text>
<text top="653" left="591" width="70" height="19" font="11">FM Radio</text>
<text top="905" left="555" width="24" height="12" font="28">SKIR</text>
<text top="905" left="599" width="40" height="12" font="28">StreamIt</text>
<text top="905" left="659" width="48" height="12" font="28">StreamIt 8</text>
<text top="882" left="584" width="96" height="13" font="6">number of threads</text>
<text top="820" left="480" width="0" height="13" font="32">sa</text>
<text top="807" left="480" width="0" height="13" font="32">m</text>
<text top="797" left="480" width="0" height="13" font="32">p</text>
<text top="791" left="480" width="0" height="13" font="32">le</text>
<text top="781" left="480" width="0" height="13" font="32">s </text>
<text top="772" left="480" width="0" height="13" font="32">p</text>
<text top="765" left="480" width="0" height="13" font="32">e</text>
<text top="759" left="480" width="0" height="13" font="32">r </text>
<text top="752" left="480" width="0" height="13" font="32">se</text>
<text top="739" left="480" width="0" height="13" font="32">co</text>
<text top="727" left="480" width="0" height="13" font="32">n</text>
<text top="720" left="480" width="0" height="13" font="32">d</text>
<text top="943" left="108" width="702" height="16" font="0">Figure 7.6: Throughput obtained by the SKIR dynamic scheduler, the StreamIt compiler targeting</text>
<text top="965" left="108" width="702" height="16" font="0">8 threads, and the StreamIt compiler targeting the actual number of threads. Error bars indicate</text>
<text top="987" left="108" width="166" height="16" font="0">one standard deviation.</text>
</page>
<page number="145" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">131</text>
<text top="128" left="108" width="702" height="16" font="0">enough that we might expect reasonable scaling. However, this number does not capture the fact</text>
<text top="164" left="108" width="702" height="16" font="0">that each invocation of the kernel work function produces and consumes 16 data items on the input</text>
<text top="200" left="108" width="702" height="16" font="0">and output streams. This fact along with two 16-wide split-joins leads to high communication</text>
<text top="236" left="108" width="702" height="16" font="0">to computation requirements in a dynamic scheduling scheme. On our AMD Opteron system,</text>
<text top="272" left="108" width="702" height="16" font="0">this communication requirement leads to poor scaling beyond a single multi-core processor and</text>
<text top="308" left="108" width="702" height="16" font="0">performance losses beyond a single processor socket. In contrast, the static scheduling algorithm</text>
<text top="344" left="108" width="702" height="16" font="0">of StreamIt transforms the dct computation into a single split-join using aggressive static ﬁssion</text>
<text top="380" left="108" width="702" height="16" font="0">and fusion [33]. This reduces communication requirements by at least 50% compared to a dynamic</text>
<text top="416" left="108" width="67" height="16" font="0">schedule.</text>
<text top="452" left="151" width="659" height="16" font="0">The results for dct in Figure 7.6 indicate a need for further research into dynamic opti-</text>
<text top="488" left="108" width="702" height="16" font="0">mization of very ﬁne grained programs when dynamic scheduling is used with a large number of</text>
<text top="524" left="108" width="702" height="16" font="0">processing cores. We have already shown that a simple dynamic fusion optimization is useful for</text>
<text top="560" left="108" width="702" height="16" font="0">reducing communication and scheduling overhead when the number of kernels is larger than the</text>
<text top="596" left="108" width="702" height="16" font="0">number of cores. And, for benchmarks like fm, we can apply similar techniques involving kernel</text>
<text top="632" left="108" width="702" height="16" font="0">ﬁssion to increase program granularity. The performance of simple forms of manual and automatic</text>
<text top="668" left="108" width="702" height="16" font="0">ﬁssion is described below. For the benchmark dct, however, it appears that a combination of fusion</text>
<text top="704" left="108" width="702" height="16" font="0">and ﬁssion is more effective. That is, perform fusion to create a single data parallel kernel, then</text>
<text top="740" left="108" width="702" height="16" font="0">employ data parallel execution using kernel ﬁssion or other means to regain granularity without</text>
<text top="776" left="108" width="612" height="16" font="0">requiring all of the communication present in the original form of the program graph.</text>
<text top="812" left="151" width="659" height="16" font="0">We evaluate the performance of black-scholes, dedup, and swps3 against their original par-</text>
<text top="848" left="108" width="702" height="16" font="0">allelization using TBB, Pthreads, and FastFlow, respectively. We run the programs using 1, 2, 4,</text>
<text top="884" left="108" width="702" height="16" font="0">6, and 8 threads. For each benchmark, we match the thread allocation strategy used in the original</text>
<text top="920" left="108" width="702" height="16" font="0">non-SKIR version. In each case, this means simply using the number of available processors as the</text>
<text top="956" left="108" width="702" height="16" font="0">ﬁssion width. For dedup, dynamic ﬁssion is run on the two most compute intense kernels. For the</text>
<text top="992" left="108" width="702" height="16" font="0">other benchmarks, manual ﬁssion is used on the single compute intense kernel. The results of this</text>
<text top="1027" left="108" width="702" height="16" font="0">evaluation are shown in Figure 7.7. Results are normalized to the single threaded execution time</text>
<text top="1063" left="108" width="702" height="16" font="0">of the original benchmark. Execution time is obtained by running the programs with the Linux</text>
</page>
<page number="146" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">132</text>
<text top="402" left="258" width="74" height="13" font="22">BlackScholes</text>
<text top="402" left="404" width="36" height="13" font="22">Dedup</text>
<text top="402" left="530" width="37" height="13" font="22">Swps3</text>
<text top="388" left="218" width="7" height="13" font="22">0</text>
<text top="354" left="218" width="7" height="13" font="22">1</text>
<text top="321" left="218" width="7" height="13" font="22">2</text>
<text top="287" left="218" width="7" height="13" font="22">3</text>
<text top="253" left="218" width="7" height="13" font="22">4</text>
<text top="219" left="218" width="7" height="13" font="22">5</text>
<text top="185" left="218" width="7" height="13" font="22">6</text>
<text top="151" left="218" width="7" height="13" font="22">7</text>
<text top="117" left="218" width="7" height="13" font="22">8</text>
<text top="95" left="380" width="163" height="15" font="2">Coarse Grained Benchmarks</text>
<text top="202" left="640" width="73" height="11" font="28">1 Thread – SKIR</text>
<text top="216" left="640" width="83" height="11" font="28">1 Thread – Original</text>
<text top="229" left="640" width="73" height="11" font="28">2 Thread – SKIR</text>
<text top="242" left="640" width="83" height="11" font="28">2 Thread – Original</text>
<text top="256" left="640" width="73" height="11" font="28">4 Thread – SKIR</text>
<text top="269" left="640" width="83" height="11" font="28">4 Thread – Original</text>
<text top="282" left="640" width="73" height="11" font="28">6 Thread – SKIR</text>
<text top="296" left="640" width="83" height="11" font="28">6 Thread – Original</text>
<text top="309" left="640" width="73" height="11" font="28">8 Thread – SKIR</text>
<text top="322" left="640" width="83" height="11" font="28">8 Thread – Original</text>
<text top="422" left="385" width="61" height="13" font="22">Benchmark</text>
<text top="280" left="205" width="0" height="13" font="29">S</text>
<text top="271" left="205" width="0" height="13" font="29">p</text>
<text top="265" left="205" width="0" height="13" font="29">e</text>
<text top="258" left="205" width="0" height="13" font="29">e</text>
<text top="251" left="205" width="0" height="13" font="29">d</text>
<text top="244" left="205" width="0" height="13" font="29">u</text>
<text top="238" left="205" width="0" height="13" font="29">p</text>
<text top="458" left="108" width="702" height="16" font="0">Figure 7.7: A comparison of SKIR performance to the performance of coarse-grained pipeline</text>
<text top="479" left="108" width="702" height="16" font="0">parallel applications parallelized using Pthreads, TBB, and FastFlow. Performance is measured as</text>
<text top="501" left="108" width="110" height="16" font="0">execution time.</text>
<text top="590" left="108" width="43" height="14" font="0">time</text>
<text top="589" left="157" width="653" height="16" font="0">command. Thus the SKIR results include JIT compilation overhead. The mean of seven</text>
<text top="625" left="108" width="702" height="16" font="0">runs is reported. The variance of these results is very small, with standard deviations less than</text>
<text top="661" left="108" width="702" height="16" font="0">one half of one percent of execution time for all swps3 and black-scholes experiments. For dedup</text>
<text top="697" left="108" width="702" height="16" font="0">more variance is seen, with standard deviations of less than one percent of running time in almost</text>
<text top="733" left="108" width="702" height="16" font="0">all cases. In no case is the variance large enough to statistically impact the conclusions described</text>
<text top="769" left="108" width="47" height="16" font="0">below.</text>
<text top="805" left="151" width="659" height="16" font="0">The biggest difference in performance is seen for dedup. SKIR performs better than the</text>
<text top="841" left="108" width="702" height="16" font="0">Pthreads implementation for all but the two thread conﬁguration. The performance difference is</text>
<text top="877" left="108" width="702" height="16" font="0">2% for one and two threads and roughly 8%, 18%, and 11% percent for four, six, and eight threads,</text>
<text top="913" left="108" width="702" height="16" font="0">respectively. This benchmark shows how, for even a simple 5 stage pipeline passing packets of</text>
<text top="949" left="108" width="702" height="16" font="0">information, using a stream parallelism framework can be beneﬁcial. Not only did porting this</text>
<text top="985" left="108" width="702" height="16" font="0">benchmark to SKIR simplify the implementation by removing custom code related to queue and</text>
<text top="1021" left="108" width="702" height="16" font="0">thread management, it also improved performance by using a scheduler speciﬁcally designed for</text>
<text top="1057" left="108" width="215" height="16" font="0">pipeline parallel computation.</text>
</page>
<page number="147" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">133</text>
<text top="128" left="151" width="659" height="16" font="0">One would expect the performance of black-scholes on SKIR to be very similar to the per-</text>
<text top="164" left="108" width="702" height="16" font="0">formance running with TBB since SKIR is implemented on top the TBB scheduler and indeed this</text>
<text top="200" left="108" width="702" height="16" font="0">is the case. SKIR was 0-1% faster than TBB for black-scholes using 1, 2, 4, or 8 threads. For 6</text>
<text top="236" left="108" width="702" height="16" font="0">threads, SKIR was 11% faster than TBB. While the exact reason for the difference in this last case</text>
<text top="272" left="108" width="702" height="16" font="0">is unclear, it may be due to imbalance in the division of work among tasks. In TBB this division</text>
<text top="308" left="108" width="702" height="16" font="0">is done by recursively splitting the iteration space of the data parallel kernel using a parallel for</text>
<text top="344" left="108" width="702" height="16" font="0">loop. In SKIR this same division is done using split-join, which emits much ﬁner grained chunks</text>
<text top="380" left="108" width="314" height="16" font="0">of work than the recursive splitting of TBB.</text>
<text top="416" left="151" width="659" height="16" font="0">SKIR is 0-2% slower than FastFlow for swps3. Most of the computation in this benchmark is</text>
<text top="452" left="108" width="702" height="16" font="0">performed by hand written SIMD assembly routines running millions of cycles per kernel iteration</text>
<text top="488" left="108" width="702" height="16" font="0">(Table 7.1). Thus the difference in performance is almost completely due to JIT compilation over-</text>
<text top="524" left="108" width="702" height="16" font="0">head and differences in scheduling and communication. Using detailed proﬁling, we can attribute</text>
<text top="560" left="108" width="702" height="16" font="0">about half of the performance difference to ﬁxed JIT compilation costs. We can also observe that</text>
<text top="596" left="108" width="702" height="16" font="0">as the runtime of the benchmark increases due to increased input size or decreased parallelism,</text>
<text top="632" left="108" width="702" height="16" font="0">this cost approaches zero as a percentage of execution time. The remainder of the difference is in</text>
<text top="668" left="108" width="702" height="16" font="0">scheduling and communication costs. FastFlow has a scheduler and stream communication opti-</text>
<text top="704" left="108" width="702" height="16" font="0">mized to use only the split-join pattern (called a Farm pattern in [19]). In SKIR, runtime ﬁssion</text>
<text top="740" left="108" width="702" height="16" font="0">maps the same pattern onto a much more general scheduler using a compiler library of split and</text>
<text top="776" left="108" width="702" height="16" font="0">join kernels. The lack of specialization in SKIR for this speciﬁc pattern likely causes the remainder</text>
<text top="812" left="108" width="218" height="16" font="0">of the performance difference.</text>
<text top="848" left="151" width="659" height="16" font="0">We evaluate our OpenCL backend using nbody. We run the benchmark with the compute</text>
<text top="884" left="108" width="702" height="16" font="0">intense kernel executing on a GPU using the OpenCL backend and compare the results with ordi-</text>
<text top="920" left="108" width="702" height="16" font="0">nary kernel ﬁssion using 1, 2, and 4 threads. The CPU for this experiment is a 4-core Intel i7 920</text>
<text top="956" left="108" width="702" height="16" font="0">processor and the GPU is an AMD Radeon HD 5750. The results are shown in Figure 7.8. The</text>
<text top="992" left="108" width="702" height="16" font="0">benchmark reports the performance of the simulation in GFLOPS. The program scales well with</text>
<text top="1027" left="108" width="702" height="16" font="0">kernel ﬁssion using 1-4 cores but performance increases signiﬁcantly when the kernel is moved</text>
<text top="1063" left="108" width="702" height="16" font="0">onto the GPU. The kernel contains manual loop unrolling (as does the original NVIDIA version),</text>
</page>
<page number="148" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">134</text>
<text top="128" left="108" width="702" height="16" font="0">but our OpenCL backend does not perform any other optimizations speciﬁc to the GPU. Based on</text>
<text top="164" left="108" width="702" height="16" font="0">the performance of a hand tuned OpenCL kernel, it appears that the performance could be increased</text>
<text top="200" left="108" width="702" height="16" font="0">another 2x, based largely on GPU-centric memory optimization. The results also suggest that we</text>
<text top="236" left="108" width="667" height="16" font="0">are leaving performance on the table in the CPU version, largely due to lack of vectorization.</text>
<text top="418" left="129" width="74" height="20" font="20">1 Thread</text>
<text top="374" left="126" width="77" height="20" font="20">2 threads</text>
<text top="330" left="126" width="77" height="20" font="20">4 threads</text>
<text top="286" left="134" width="70" height="20" font="20">OpenCL</text>
<text top="458" left="209" width="9" height="17" font="7">0</text>
<text top="458" left="276" width="17" height="17" font="7">10</text>
<text top="458" left="347" width="17" height="17" font="7">20</text>
<text top="458" left="418" width="17" height="17" font="7">30</text>
<text top="458" left="489" width="17" height="17" font="7">40</text>
<text top="458" left="561" width="17" height="17" font="7">50</text>
<text top="458" left="632" width="17" height="17" font="7">60</text>
<text top="458" left="703" width="17" height="17" font="7">70</text>
<text top="458" left="775" width="17" height="17" font="7">80</text>
<text top="421" left="228" width="24" height="14" font="22">1.64</text>
<text top="377" left="240" width="24" height="14" font="22">3.27</text>
<text top="333" left="262" width="24" height="14" font="22">6.41</text>
<text top="289" left="760" width="31" height="14" font="22">76.19</text>
<text top="480" left="428" width="62" height="17" font="7">GFLOPS</text>
<text top="519" left="108" width="702" height="16" font="0">Figure 7.8: Performance of the nbody benchmark running on SKIR using kernel ﬁssion on the</text>
<text top="540" left="108" width="225" height="16" font="0">CPU and OpenCL on the GPU.</text>
<text top="634" left="112" width="22" height="16" font="0">7.3</text>
<text top="634" left="170" width="46" height="16" font="0">Sluice</text>
<text top="689" left="151" width="659" height="16" font="0">In this section we evaluate the characteristics and performance of our Sluice JavaScript ac-</text>
<text top="725" left="108" width="702" height="16" font="0">celeration system built on top of SKIR. We use compute intense JavaScript benchmarks that can be</text>
<text top="761" left="108" width="702" height="16" font="0">expressed in the stream parallel model. Four of the benchmarks are taken from the Pixastic library</text>
<text top="797" left="108" width="702" height="16" font="0">of image processing routines [10]. We also include a nbody benchmark adapted from the SKIR</text>
<text top="833" left="108" width="702" height="16" font="0">version of the CUDA benchmarks mentioned above. This benchmark is similar to code that might</text>
<text top="869" left="108" width="194" height="16" font="0">be found in a game engine.</text>
<text top="904" left="151" width="659" height="16" font="0">As written, the code found in the Pixastic library is already very close to the form required by</text>
<text top="940" left="108" width="702" height="16" font="0">Sluice. We must perform only a few modiﬁcations to turn the image processing routines into Sluice</text>
<text top="976" left="108" width="702" height="16" font="0">kernel objects. Because these routines operate at the granularity of an entire image, we identify</text>
<text top="1012" left="108" width="702" height="16" font="0">parameters that only change between images, such as the image itself. These parameters are re-</text>
<text top="1048" left="108" width="702" height="16" font="0">written as kernel state that is initialized when the kernel is constructed. The rest of the function</text>
</page>
<page number="149" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">135</text>
<text top="128" left="108" width="702" height="16" font="0">body is placed within a kernel work function. Because the Pixastic functions operate on an image</text>
<text top="164" left="108" width="702" height="16" font="0">at a time, there is little need for stream communication in these benchmarks. Nevertheless, SKIR</text>
<text top="200" left="108" width="702" height="16" font="0">requires that a kernel has at least one input or output stream. We fulﬁll this requirement by passing</text>
<text top="236" left="108" width="396" height="16" font="0">the image width and height to the kernel using streams.</text>
<text top="272" left="151" width="659" height="16" font="0">An example from Pixastic is shown in Figure 7.9. In this ﬁgure, the original Pixastic code as</text>
<text top="308" left="108" width="702" height="16" font="0">well as the Sluice version are shown for the invert routine. We run all of the Pixastic benchmarks</text>
<text top="344" left="108" width="702" height="16" font="0">on image data that is read from disk into memory before timing begins. All images are in RGBA</text>
<text top="380" left="108" width="392" height="16" font="0">format with dimensions of 2592x1944 (5 Megapixels).</text>
<text top="446" left="108" width="244" height="9" font="3">function invert_pixastic(params) {</text>
<text top="460" left="122" width="287" height="9" font="3">var data = Pixastic.prepareData(params);</text>
<text top="474" left="122" width="280" height="9" font="3">var invertAlpha = !!params.invertAlpha;</text>
<text top="488" left="122" width="222" height="9" font="3">var rect = params.options.rect;</text>
<text top="517" left="122" width="237" height="11" font="3">var p = rect.width * rect.height;</text>
<text top="531" left="122" width="201" height="11" font="3">var pix = p*4, pix1 = pix+1;</text>
<text top="545" left="122" width="222" height="9" font="3">var pix2 = pix+2, pix3 = pix+3;</text>
<text top="574" left="122" width="93" height="9" font="3">while (p--) {</text>
<text top="588" left="137" width="222" height="9" font="3">data[pix-=4] = 255 - data[pix];</text>
<text top="602" left="137" width="237" height="9" font="3">data[pix1-=4] = 255 - data[pix1];</text>
<text top="616" left="137" width="237" height="9" font="3">data[pix2-=4] = 255 - data[pix2];</text>
<text top="630" left="137" width="115" height="9" font="3">if (invertAlpha)</text>
<text top="645" left="151" width="237" height="9" font="3">data[pix3-=4] = 255 - data[pix3];</text>
<text top="659" left="122" width="7" height="9" font="3">}</text>
<text top="673" left="122" width="86" height="9" font="3">return true;</text>
<text top="687" left="108" width="7" height="9" font="3">}</text>
<text top="417" left="449" width="316" height="9" font="3">function invert_sluice(data, invert_alpha) {</text>
<text top="432" left="464" width="122" height="9" font="3">this.data = data;</text>
<text top="446" left="464" width="230" height="9" font="3">this.invertAlpha = invert_alpha;</text>
<text top="474" left="464" width="179" height="9" font="3">this.work = function () {</text>
<text top="488" left="478" width="136" height="9" font="3">var w = this.pop();</text>
<text top="503" left="478" width="136" height="9" font="3">var h = this.pop();</text>
<text top="517" left="478" width="100" height="11" font="3">var p = w * h;</text>
<text top="531" left="478" width="215" height="11" font="3">var pix = p*4, pix1 = pix + 1;</text>
<text top="545" left="478" width="251" height="9" font="3">var pix2 = pix + 2, pix3 = pix + 3;</text>
<text top="574" left="478" width="93" height="9" font="3">while (p--) {</text>
<text top="588" left="492" width="280" height="9" font="3">this.data[pix-=4] = 255-this.data[pix];</text>
<text top="602" left="492" width="294" height="9" font="3">this.data[pix1-=4] = 255-this.data[pix1];</text>
<text top="616" left="492" width="294" height="9" font="3">this.data[pix2-=4] = 255-this.data[pix2];</text>
<text top="630" left="492" width="151" height="9" font="3">if (this.invertAlpha)</text>
<text top="645" left="507" width="280" height="9" font="3">this.data[pix3-=4]=255-this.data[pix3];</text>
<text top="659" left="478" width="7" height="9" font="3">}</text>
<text top="673" left="478" width="194" height="9" font="3">this.push(w); this.push(h);</text>
<text top="687" left="478" width="93" height="9" font="3">return false;</text>
<text top="701" left="464" width="14" height="9" font="3">};</text>
<text top="716" left="449" width="7" height="9" font="3">}</text>
<text top="741" left="108" width="702" height="16" font="0">Figure 7.9: Comparison of Pixastic code (left) with the same code ported to Sluice (right). The</text>
<text top="763" left="108" width="373" height="16" font="0">code that is shown inverts all the pixels in an image.</text>
<text top="834" left="151" width="659" height="16" font="0">The nbody physics benchmark is written as a three stage pipeline. Almost all the computa-</text>
<text top="870" left="108" width="702" height="16" font="0">tion takes place in the middle stage, shown in Figure 7.10. Each execution of this stage’s kernel</text>
<text top="906" left="108" width="702" height="16" font="0">work function computes the forces on single particle due to all other particles in the system. The</text>
<text top="942" left="108" width="702" height="16" font="0">computed forces are pushed to the output stream. Each execution of the entire three stage pipeline</text>
<text top="978" left="108" width="702" height="16" font="0">corresponds to a single iteration of the nbody simulation. That is, it computes the force and updates</text>
<text top="1014" left="108" width="574" height="16" font="0">the positions and velocities (in the third stage) for all the particles in the system.</text>
<text top="1050" left="151" width="659" height="16" font="0">We run our implementation of Sluice on node.js, a non-browser JavaScript environment</text>
</page>
<page number="150" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">136</text>
<text top="98" left="208" width="373" height="9" font="3">function CalculateForces(pos_rd, softeningSquared) {</text>
<text top="112" left="237" width="165" height="9" font="3">this.m_pos_rd = pos_rd;</text>
<text top="126" left="237" width="308" height="9" font="3">this.m_softeningSquared = softeningSquared;</text>
<text top="140" left="237" width="179" height="9" font="3">this.work = function () {</text>
<text top="154" left="266" width="187" height="9" font="3">var force = [0.0,0.0,0.0];</text>
<text top="169" left="266" width="151" height="11" font="3">var i = this.pop()*4;</text>
<text top="183" left="266" width="151" height="11" font="3">var N = this.pop()*4;</text>
<text top="197" left="266" width="187" height="9" font="3">for (var j=0; j&lt;N; j+=4) {</text>
<text top="211" left="295" width="108" height="9" font="3">var r0, r1, r2;</text>
<text top="225" left="295" width="323" height="9" font="3">r0 = this.m_pos_rd[j+0] - this.m_pos_rd[i+0];</text>
<text top="240" left="295" width="323" height="9" font="3">r1 = this.m_pos_rd[j+1] - this.m_pos_rd[i+1];</text>
<text top="254" left="295" width="323" height="9" font="3">r2 = this.m_pos_rd[j+2] - this.m_pos_rd[i+2];</text>
<text top="268" left="295" width="344" height="11" font="3">var distSqr = (r0 * r0) + (r1 * r1) + (r2 * r2);</text>
<text top="282" left="295" width="251" height="9" font="3">distSqr += this.m_softeningSquared;</text>
<text top="296" left="295" width="265" height="9" font="3">var invDist = 1 / Math.sqrt(distSqr);</text>
<text top="311" left="295" width="122" height="9" font="3">var invDistCube =</text>
<text top="311" left="431" width="172" height="11" font="3">invDist*invDist*invDist;</text>
<text top="325" left="295" width="294" height="11" font="3">var s = this.m_pos_rd[i+3] * invDistCube;</text>
<text top="339" left="295" width="151" height="11" font="3">force[0] += (r0 * s);</text>
<text top="353" left="295" width="151" height="11" font="3">force[1] += (r1 * s);</text>
<text top="367" left="295" width="151" height="11" font="3">force[2] += (r2 * s);</text>
<text top="382" left="266" width="7" height="9" font="3">}</text>
<text top="396" left="266" width="86" height="9" font="3">var f = i/4;</text>
<text top="410" left="266" width="93" height="9" font="3">this.push(f);</text>
<text top="424" left="266" width="143" height="9" font="3">this.push(force[0]);</text>
<text top="438" left="266" width="143" height="9" font="3">this.push(force[1]);</text>
<text top="453" left="266" width="143" height="9" font="3">this.push(force[2]);</text>
<text top="467" left="266" width="93" height="9" font="3">return false;</text>
<text top="481" left="237" width="14" height="9" font="3">};</text>
<text top="495" left="208" width="7" height="9" font="3">}</text>
<text top="521" left="108" width="702" height="16" font="0">Figure 7.10: The CalculateForces kernel found in the nbody benchmark. Ported from the SKIR</text>
<text top="542" left="108" width="371" height="16" font="0">C++ version of the benchmark shown in Figure 7.1.</text>
<text top="634" left="108" width="702" height="16" font="0">build on top of the V8 JavaScript execution engine. Node is typically used in the development</text>
<text top="670" left="108" width="702" height="16" font="0">of network applications. The single threaded scheduling algorithm implemented by Sluice also</text>
<text top="706" left="108" width="702" height="16" font="0">makes use of node-ﬁbers [9], a package providing ﬁbers/coroutines for node.js. This is necessary</text>
<text top="742" left="108" width="702" height="16" font="0">because generators (i.e. yield) are not yet in the language. All experiments are run on a four</text>
<text top="778" left="108" width="345" height="16" font="0">core Intel i7-920 processor under Ubuntu 10.10.</text>
<text top="840" left="112" width="36" height="16" font="0">7.3.1</text>
<text top="840" left="182" width="188" height="16" font="0">Single Threaded Ofﬂoad</text>
<text top="888" left="151" width="659" height="16" font="0">We ﬁrst evaluate the performance of our system when ofﬂoading a Sluice kernel to a single</text>
<text top="924" left="108" width="702" height="16" font="0">threaded SKIR runtime. Because the Sluice and SKIR layers run as separate processes, the of-</text>
<text top="960" left="108" width="702" height="16" font="0">ﬂoaded kernel still runs in parallel with the rest of the Sluice program, but we do not attempt to</text>
<text top="996" left="108" width="702" height="16" font="0">further parallelize the ofﬂoaded kernel. The results of this experiment for the Pixastic kernels can</text>
<text top="1032" left="108" width="702" height="16" font="0">be seen in Figure 7.11. We measure three cases: ref shows the performance of the original image</text>
<text top="1068" left="108" width="702" height="16" font="0">processing routine called as an ordinary JavaScript function whereas skir cold and skir warm show</text>
</page>
<page number="151" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">137</text>
<text top="443" left="263" width="34" height="15" font="2">invert</text>
<text top="443" left="373" width="33" height="15" font="2">sepia</text>
<text top="443" left="475" width="49" height="15" font="2">sharpen</text>
<text top="443" left="590" width="38" height="15" font="2">edges</text>
<text top="428" left="209" width="8" height="15" font="2">0</text>
<text top="391" left="194" width="23" height="15" font="2">200</text>
<text top="354" left="194" width="23" height="15" font="2">400</text>
<text top="317" left="194" width="23" height="15" font="2">600</text>
<text top="280" left="194" width="23" height="15" font="2">800</text>
<text top="243" left="186" width="31" height="15" font="2">1000</text>
<text top="206" left="186" width="31" height="15" font="2">1200</text>
<text top="169" left="186" width="31" height="15" font="2">1400</text>
<text top="132" left="186" width="31" height="15" font="2">1600</text>
<text top="95" left="186" width="31" height="15" font="2">1800</text>
<text top="266" left="700" width="16" height="15" font="2">ref</text>
<text top="283" left="700" width="50" height="15" font="2">skir cold</text>
<text top="301" left="700" width="58" height="15" font="2">skir warm</text>
<text top="466" left="391" width="67" height="15" font="2">benchmark</text>
<text top="323" left="171" width="0" height="15" font="31">e</text>
<text top="316" left="171" width="0" height="15" font="31">xe</text>
<text top="301" left="171" width="0" height="15" font="31">cu</text>
<text top="287" left="171" width="0" height="15" font="31">tio</text>
<text top="272" left="171" width="0" height="15" font="31">n</text>
<text top="264" left="171" width="0" height="15" font="31"> ti</text>
<text top="254" left="171" width="0" height="15" font="31">m</text>
<text top="243" left="171" width="0" height="15" font="31">e</text>
<text top="235" left="171" width="0" height="15" font="31"> (</text>
<text top="228" left="171" width="0" height="15" font="31">m</text>
<text top="217" left="171" width="0" height="15" font="31">s)</text>
<text top="503" left="108" width="702" height="16" font="0">Figure 7.11: Performance of Pixastic image processing routines coded as ordinary JavaScript com-</text>
<text top="525" left="108" width="694" height="16" font="0">pared to the performance of the same routines running as Sluice kernels using the SKIR runtime.</text>
<text top="617" left="108" width="702" height="16" font="0">the performance when executing the image processing routine as a Sluice kernel using the SKIR</text>
<text top="653" left="108" width="702" height="16" font="0">runtime. The cold version is when the kernel has never been seen by the SKIR runtime while the</text>
<text top="689" left="108" width="702" height="16" font="0">warm version is when the SKIR runtime has already seen, processed, and cached the kernel. We</text>
<text top="725" left="108" width="702" height="16" font="0">see good performance improvements for all but the smallest kernel, invert. In this case, the</text>
<text top="761" left="108" width="702" height="16" font="0">overhead of acceleration is greater than the beneﬁt. For the other benchmarks, we see signiﬁcant</text>
<text top="797" left="108" width="475" height="16" font="0">performance improvement due to our specialized code generation.</text>
<text top="833" left="151" width="659" height="16" font="0">The results of this experiment for the nbody benchmark can be seen in Figure 7.12. The</text>
<text top="869" left="108" width="702" height="16" font="0">Figure shows the average time per simulation iteration when using a procedural JavaScript ver-</text>
<text top="904" left="108" width="702" height="16" font="0">sion of the benchmark, the three stage pipeline Sluice version, and the Sluice version with the</text>
<text top="941" left="108" width="161" height="14" font="0">CalculateForces</text>
<text top="940" left="275" width="535" height="16" font="0">kernel ofﬂoaded to SKIR. The results are similar to those for the Pixastic</text>
<text top="976" left="108" width="702" height="16" font="0">benchmark, with signiﬁcant performance improvements due to our specialized code generation</text>
<text top="1012" left="108" width="702" height="16" font="0">in most cases. For the smallest test, a system of only 100 particles, the overhead of acceleration</text>
<text top="1048" left="108" width="171" height="16" font="0">overwhelms the beneﬁt.</text>
</page>
<page number="152" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">138</text>
<text top="443" left="264" width="23" height="15" font="2">100</text>
<text top="443" left="382" width="23" height="15" font="2">500</text>
<text top="443" left="495" width="31" height="15" font="2">1000</text>
<text top="443" left="612" width="31" height="15" font="2">1500</text>
<text top="428" left="201" width="8" height="15" font="2">0</text>
<text top="372" left="186" width="23" height="15" font="2">100</text>
<text top="317" left="186" width="23" height="15" font="2">200</text>
<text top="262" left="186" width="23" height="15" font="2">300</text>
<text top="206" left="186" width="23" height="15" font="2">400</text>
<text top="151" left="186" width="23" height="15" font="2">500</text>
<text top="95" left="186" width="23" height="15" font="2">600</text>
<text top="266" left="722" width="16" height="15" font="2">ref</text>
<text top="283" left="722" width="36" height="15" font="2">sluice</text>
<text top="301" left="722" width="22" height="15" font="2">skir</text>
<text top="466" left="384" width="105" height="15" font="2">number of bodies</text>
<text top="330" left="171" width="0" height="15" font="31">tim</text>
<text top="312" left="171" width="0" height="15" font="31">e</text>
<text top="304" left="171" width="0" height="15" font="31"> p</text>
<text top="293" left="171" width="0" height="15" font="31">e</text>
<text top="285" left="171" width="0" height="15" font="31">r </text>
<text top="278" left="171" width="0" height="15" font="31">ite</text>
<text top="263" left="171" width="0" height="15" font="31">ra</text>
<text top="251" left="171" width="0" height="15" font="31">tio</text>
<text top="237" left="171" width="0" height="15" font="31">n</text>
<text top="229" left="171" width="0" height="15" font="31"> (</text>
<text top="221" left="171" width="0" height="15" font="31">m</text>
<text top="210" left="171" width="0" height="15" font="31">s)</text>
<text top="503" left="108" width="702" height="16" font="0">Figure 7.12: Performance of the nbody benchmark implemented as procedural JavaScript, as Sluice</text>
<text top="525" left="108" width="574" height="16" font="0">code, and as Sluice code with CalculateForces kernel running on SKIR runtime.</text>
<text top="617" left="112" width="36" height="16" font="0">7.3.2</text>
<text top="617" left="182" width="181" height="16" font="0">Task Parallel Execution</text>
<text top="665" left="151" width="659" height="16" font="0">Although we did not parallelize the Pixastic benchmarks internally, we can still execute</text>
<text top="701" left="108" width="702" height="16" font="0">multiple instances of a particular kernel in parallel. This is the simplest form of task parallelism</text>
<text top="737" left="108" width="702" height="16" font="0">exposed by Sluice programs. To test this, we created a Sluice program that sequentially (because</text>
<text top="773" left="108" width="702" height="16" font="0">JavaScript is single threaded) creates, compiles, and executes a varying number of image kernels</text>
<text top="809" left="108" width="702" height="16" font="0">using the SKIR runtime. We give the runtime 8 worker threads (equal to the number of hardware</text>
<text top="845" left="108" width="702" height="16" font="0">threads) to run the kernels, so up to 8 kernel instances can run in parallel. This scenario is similar</text>
<text top="881" left="108" width="615" height="16" font="0">to what might be encountered in a compute intense server-side JavaScript application.</text>
<text top="917" left="151" width="659" height="16" font="0">Figure 7.13 shows the results of running a varying number of Pixastic kernels on different</text>
<text top="953" left="108" width="702" height="16" font="0">images concurrently using Sluice task parallelism. It shows the mean time required to process a</text>
<text top="989" left="108" width="702" height="16" font="0">single image. We observe that as the number of executing kernel instances increases, the system</text>
<text top="1025" left="108" width="702" height="16" font="0">starts to effectively mask much of the overhead associated with running Sluice kernels under SKIR.</text>
<text top="1060" left="108" width="702" height="16" font="0">Eventually, however, the lines on the graph ﬂatten, because the system cannot go faster than the</text>
</page>
<page number="153" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">139</text>
<text top="399" left="242" width="7" height="13" font="6">1</text>
<text top="399" left="321" width="7" height="13" font="6">2</text>
<text top="399" left="400" width="7" height="13" font="6">4</text>
<text top="399" left="479" width="7" height="13" font="6">6</text>
<text top="399" left="558" width="7" height="13" font="6">8</text>
<text top="399" left="634" width="13" height="13" font="6">10</text>
<text top="385" left="232" width="7" height="13" font="6">0</text>
<text top="337" left="218" width="20" height="13" font="6">100</text>
<text top="289" left="218" width="20" height="13" font="6">200</text>
<text top="240" left="218" width="20" height="13" font="6">300</text>
<text top="192" left="218" width="20" height="13" font="6">400</text>
<text top="144" left="218" width="20" height="13" font="6">500</text>
<text top="95" left="218" width="20" height="13" font="6">600</text>
<text top="237" left="679" width="33" height="13" font="6">edges</text>
<text top="252" left="679" width="43" height="13" font="6">sharpen</text>
<text top="267" left="679" width="29" height="13" font="6">sepia</text>
<text top="282" left="679" width="30" height="13" font="6">invert</text>
<text top="419" left="385" width="95" height="13" font="6">number of images</text>
<text top="295" left="205" width="0" height="13" font="32">tim</text>
<text top="280" left="205" width="0" height="13" font="32">e</text>
<text top="273" left="205" width="0" height="13" font="32"> p</text>
<text top="263" left="205" width="0" height="13" font="32">e</text>
<text top="256" left="205" width="0" height="13" font="32">r </text>
<text top="250" left="205" width="0" height="13" font="32">im</text>
<text top="237" left="205" width="0" height="13" font="32">a</text>
<text top="230" left="205" width="0" height="13" font="32">g</text>
<text top="224" left="205" width="0" height="13" font="32">e</text>
<text top="217" left="205" width="0" height="13" font="32"> (</text>
<text top="210" left="205" width="0" height="13" font="32">m</text>
<text top="200" left="205" width="0" height="13" font="32">s)</text>
<text top="457" left="108" width="702" height="16" font="0">Figure 7.13: Per image processing time for the Pixastic benchmarks implemented when a varying</text>
<text top="479" left="108" width="446" height="16" font="0">number of images are processed using Sluice task parallelism.</text>
<text top="571" left="108" width="702" height="16" font="0">sequential parts of the program (the individual kernels and the Sluice runtime). The larger edge</text>
<text top="607" left="108" width="702" height="16" font="0">detection and sharpen kernels show the best results as they contain the most computation to</text>
<text top="643" left="108" width="702" height="16" font="0">overlap with other work. Likewise, invert and sepia show the worst improvement, because</text>
<text top="679" left="108" width="377" height="16" font="0">their execution is dominated by sequential overhead.</text>
<text top="741" left="112" width="36" height="16" font="0">7.3.3</text>
<text top="741" left="182" width="182" height="16" font="0">Data Parallel Execution</text>
<text top="789" left="151" width="659" height="16" font="0">Stream program kernels are often written so that they read, but do not modify, their internal</text>
<text top="825" left="108" width="702" height="16" font="0">state. When this is true – as it is for the CalculateForces kernel in the nbody benchmark –</text>
<text top="861" left="108" width="702" height="16" font="0">it may be proﬁtable to run multiple copies of a single kernel instance on different portions of the</text>
<text top="897" left="108" width="597" height="16" font="0">input stream. This is how the stream programming model exposes data parallelism.</text>
<text top="933" left="151" width="677" height="16" font="0">Figure 7.14 shows the results of executing the nbody benchmark with the CalculateForces</text>
<text top="969" left="108" width="702" height="16" font="0">kernel ofﬂoaded and with data parallelism enabled in the SKIR runtime. The ﬁgure shows results</text>
<text top="1005" left="108" width="702" height="16" font="0">for 1024, 2048, 3072, and 4096 particles in the simulated system while using 2, 4, or 8 worker</text>
<text top="1041" left="108" width="702" height="16" font="0">threads in the SKIR runtime. The benchmark runs several hundred iterations of the simulation</text>
</page>
<page number="154" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">140</text>
<text top="401" left="229" width="7" height="13" font="22">2</text>
<text top="401" left="447" width="7" height="13" font="22">4</text>
<text top="401" left="666" width="7" height="13" font="22">8</text>
<text top="388" left="218" width="7" height="13" font="22">1</text>
<text top="242" left="218" width="7" height="13" font="22">2</text>
<text top="95" left="218" width="7" height="13" font="22">3</text>
<text top="242" left="701" width="21" height="11" font="28">4096</text>
<text top="255" left="701" width="21" height="11" font="28">3072</text>
<text top="269" left="701" width="21" height="11" font="28">2048</text>
<text top="282" left="701" width="21" height="11" font="28">1024</text>
<text top="421" left="397" width="96" height="13" font="22">number of threads</text>
<text top="267" left="205" width="0" height="13" font="29">sp</text>
<text top="255" left="205" width="0" height="13" font="29">e</text>
<text top="248" left="205" width="0" height="13" font="29">e</text>
<text top="241" left="205" width="0" height="13" font="29">d</text>
<text top="234" left="205" width="0" height="13" font="29">u</text>
<text top="228" left="205" width="0" height="13" font="29">p</text>
<text top="457" left="108" width="702" height="16" font="0">Figure 7.14: Speedup of the nbody benchmark due to data parallelism when the CalculateForces</text>
<text top="479" left="108" width="702" height="16" font="0">kernel is run on a multi-threaded SKIR runtime compared to the same benchmark using a single-</text>
<text top="500" left="108" width="172" height="16" font="0">threaded SKIR runtime.</text>
<text top="589" left="108" width="702" height="16" font="0">and reports mean time per iteration. The speedup versus using a single threaded SKIR runtime is</text>
<text top="625" left="108" width="702" height="16" font="0">shown. All of the simulation sizes show performance improvement of 2-2.5x due to parallelism</text>
<text top="661" left="108" width="702" height="16" font="0">when utilizing the entire test machine. We point out that because JavaScript fully utilizes one of</text>
<text top="697" left="108" width="702" height="16" font="0">the cores in our four core test machine, and because this experiment measures scaling in the non-</text>
<text top="732" left="108" width="702" height="16" font="0">JavaScript portion of execution, we don’t expect that the best case speedup is much greater than</text>
<text top="768" left="108" width="22" height="16" font="0">3x.</text>
</page>
<page number="155" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 8</text>
<text top="292" left="406" width="107" height="16" font="0">Related Work</text>
<text top="401" left="112" width="22" height="16" font="0">8.1</text>
<text top="401" left="170" width="378" height="16" font="0">Compiler Representations for Stream Parallelism</text>
<text top="456" left="151" width="659" height="16" font="0">There is little existing work in the area of source language and target architecture independent</text>
<text top="492" left="108" width="702" height="16" font="0">program representations for stream parallelism. However, there have been at least three variations</text>
<text top="528" left="108" width="702" height="16" font="0">of the Stream Virtual Machine (SVM) proposed [35][42][45]. The general goal of SVM is sim-</text>
<text top="564" left="108" width="702" height="16" font="0">ilar to one of SKIR’s goals: to provide an architecture independent target for high level stream</text>
<text top="600" left="108" width="702" height="16" font="0">programming languages such as Brook and StreamIt. As in SKIR, a two-level approach to com-</text>
<text top="636" left="108" width="702" height="16" font="0">pilation is used. First, a high level compiler (HLC) generates a SVM program from a high level</text>
<text top="672" left="108" width="702" height="16" font="0">stream parallel language. Then, a low level compiler (LLC) lowers the program to machine code.</text>
<text top="708" left="108" width="702" height="16" font="0">The virtual machine model consists of local memories for storing stream data, kernel processors</text>
<text top="744" left="108" width="702" height="16" font="0">for executing kernels, DMA engines for data transfer, and a control processor to control the entire</text>
<text top="780" left="108" width="702" height="16" font="0">machine. In all of the proposals the SVM language targeted by the HLC consists of C plus a ver-</text>
<text top="816" left="108" width="702" height="16" font="0">sion of the SVM API. SVM programs are structured as a single thread of control which calls the</text>
<text top="852" left="108" width="702" height="16" font="0">SVM API to issue kernel execution, memory movement, and dependency description operations</text>
<text top="888" left="108" width="702" height="16" font="0">to virtualized stream parallel hardware. An example of SVM-C pseudo code from [35] is shown</text>
<text top="923" left="108" width="702" height="16" font="0">in Figure 8.1. For each iteration of the inner loop in the ﬁgure, the program must issue loads and</text>
<text top="959" left="108" width="702" height="16" font="0">stores for chunks of stream data, spawn two executions of kernel work functions, and describe to</text>
<text top="995" left="108" width="399" height="16" font="0">the runtime the dependencies between these operations.</text>
<text top="1031" left="151" width="659" height="16" font="0">It should be clear from the ﬁgure that the division of responsibility between the high level</text>
<text top="1067" left="108" width="702" height="16" font="0">and low level compilers are very different in SKIR and SVM. In the SVM model of Labonte et.</text>
</page>
<page number="156" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">142</text>
<text top="97" left="214" width="359" height="12" font="1">for (ns = 0; ns &lt; NUM_STRIPS; ns += 2) {</text>
<text top="115" left="232" width="403" height="12" font="1">for (i = 0; i &lt; 2; i++ ) { //Double buffering</text>
<text top="133" left="250" width="484" height="12" font="1">streamLoad (as[i], a, start_idx, Ns, sizeof (Type a));</text>
<text top="151" left="250" width="484" height="12" font="1">streamLoad (idxs[i], idx, start_idx, Ns, sizeof(int));</text>
<text top="187" left="250" width="233" height="12" font="1">addDep (Gcs[i], Lidxs[i]);</text>
<text top="205" left="250" width="484" height="12" font="1">streamGather (cs[i], c, idxs[i], Ns, sizeof (Type c));</text>
<text top="241" left="250" width="341" height="12" font="1">addDep (K1, Las[i], Lidxs[i], Gcs[i]);</text>
<text top="259" left="250" width="332" height="12" font="1">kernelCall (K1, as[i], cs[i], ds[i]);</text>
<text top="295" left="250" width="484" height="12" font="1">streamLoad (xs[i], x, start_idx, Ns, sizeof (Type x));</text>
<text top="330" left="250" width="403" height="12" font="1">// K2 depends on K1, loads to as[i] and xs[i]</text>
<text top="348" left="250" width="287" height="12" font="1">addDep (K2, K1, Las[i], Lxs[i]);</text>
<text top="366" left="250" width="395" height="12" font="1">kernelCall (K2, ds[i], as[i], xs[i], zs[i]);</text>
<text top="402" left="250" width="179" height="12" font="1">addDep (Szs[i], K2);</text>
<text top="420" left="250" width="493" height="12" font="1">streamStore (zs[i], z, start_idx, Ns, sizeof (Type z));</text>
<text top="438" left="250" width="143" height="12" font="1">start_idx += Ns;</text>
<text top="456" left="232" width="9" height="12" font="1">}</text>
<text top="474" left="214" width="9" height="12" font="1">}</text>
<text top="501" left="284" width="350" height="16" font="0">Figure 8.1: An example of SVM-C pseudo code.</text>
<text top="593" left="108" width="702" height="16" font="0">al. [42] and Mattson et. al. [45], the HLC is responsible for parallelism detection, load balancing,</text>
<text top="629" left="108" width="702" height="16" font="0">coarse-grained scheduling of kernels, and memory management of streams while the LLC is only</text>
<text top="665" left="108" width="702" height="16" font="0">responsible for code generation and optimization within kernels. The Streamware SVM imple-</text>
<text top="701" left="108" width="702" height="16" font="0">mentation adds another layer of abstraction [35]. The high-level compiler still performs stream</text>
<text top="737" left="108" width="702" height="16" font="0">parallel transformations but leaves the emitted C code in a parameterized form. The run-time sys-</text>
<text top="773" left="108" width="702" height="16" font="0">tem ﬁlls in the appropriate values based on the architecture on which the program is executing.</text>
<text top="809" left="108" width="702" height="16" font="0">This gives slightly better portability than previous instances of SVM. The SVM approach is to</text>
<text top="845" left="108" width="702" height="16" font="0">separate compilation related to the stream parallel model from traditional compiler functionality</text>
<text top="881" left="108" width="535" height="16" font="0">whereas in SKIR the goal is to handle both in the same low level compiler.</text>
<text top="917" left="151" width="659" height="16" font="0">Similar to the SVM, the Multicore Streaming Layer (MSL) was introduced in [55] as a</text>
<text top="953" left="108" width="702" height="16" font="0">stream processing runtime for the Cell processor. Like with the SVM, the MSL is used as a C API</text>
<text top="989" left="108" width="702" height="16" font="0">to abstract away the details of data movement and kernel execution. A modiﬁed backend for the</text>
<text top="1025" left="108" width="702" height="16" font="0">the StreamIt compiler was designed to generate stream programs targeting the MSL and the kernel</text>
<text top="1061" left="108" width="702" height="16" font="0">work emited were compiled with the Cell GCC backend. The resulting compiler stack was used to</text>
</page>
<page number="157" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">143</text>
<text top="128" left="108" width="702" height="16" font="0">evaluate static and dynamic scheduling schemes for the Cell. As one might expect, they found that</text>
<text top="164" left="108" width="702" height="16" font="0">the dynamic scheduler was more general (e.g. it can handle unpredictable stream programs), but in</text>
<text top="200" left="108" width="702" height="16" font="0">their case carried a higher overhead than a the static scheduler. With SKIR we show how dynamic</text>
<text top="236" left="108" width="702" height="16" font="0">scheduling overheads can be reduced to be competitive with static scheduling while maintaining</text>
<text top="272" left="108" width="73" height="16" font="0">ﬂexibility.</text>
<text top="308" left="151" width="659" height="16" font="0">The design of the Erbium system [47] is much closer to the design philosophy of SKIR than</text>
<text top="344" left="108" width="702" height="16" font="0">SVM. Like SKIR, the intermediate representation designed for Erbium can be used by compiler</text>
<text top="380" left="108" width="702" height="16" font="0">front-ends and by low level programmers. The key difference between SKIR and the Erbium</text>
<text top="416" left="108" width="702" height="16" font="0">IR is that in the Erbium IR the data structure implementing stream communication is purposely</text>
<text top="452" left="108" width="702" height="16" font="0">exposed to the program through a rich API. The stated reasons for this are to provide peek and poke</text>
<text top="488" left="108" width="702" height="16" font="0">operations as well as multiple producers and consumers. In SKIR, the implementation of stream</text>
<text top="524" left="108" width="702" height="16" font="0">communication is purposely hidden to promote compiler ﬂexibility and portability. This means</text>
<text top="560" left="108" width="702" height="16" font="0">that the semantics of SKIR stream operations would not need to change if multiple producers and</text>
<text top="596" left="108" width="702" height="16" font="0">consumers were desired. The way similar functionality is provided in SKIR today is with split-</text>
<text top="632" left="108" width="702" height="16" font="0">joins. At one time SKIR supported poke operations but we did not ﬁnd a need for them and they</text>
<text top="668" left="108" width="106" height="16" font="0">were removed.</text>
<text top="725" left="112" width="22" height="16" font="0">8.2</text>
<text top="725" left="170" width="328" height="16" font="0">Dynamic Scheduling of Stream Parallelism</text>
<text top="780" left="151" width="659" height="16" font="0">Dynamic scheduling for process networks in the Ptolemy system is implemented using</text>
<text top="816" left="108" width="702" height="16" font="0">bounded FIFO buffers, POSIX threads, monitors, and condition variables [48]. The operation</text>
<text top="852" left="108" width="702" height="16" font="0">of the scheduler is quite simple. For each kernel, a POSIX thread is created. The main procedure</text>
<text top="888" left="108" width="702" height="16" font="0">of the thread repeatedly executes the kernel work function. Whenever a blocking read or write is</text>
<text top="924" left="108" width="702" height="16" font="0">encountered, the thread is put to sleep. When data or space becomes available, the thread is woken</text>
<text top="960" left="108" width="702" height="16" font="0">up. This is also the basic scheduling algorithm used in the GNU Radio system [4]. We compare</text>
<text top="996" left="108" width="388" height="16" font="0">the performance of SKIR to GNU Radio in Chapter 7.</text>
<text top="1032" left="151" width="659" height="16" font="0">The authors of Streamware also describe a dynamic task queuing scheduler that is quite</text>
<text top="1068" left="108" width="702" height="16" font="0">different than the SKIR dynamic scheduler [35]. Because of the design of SVM, the Streamware</text>
</page>
<page number="158" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">144</text>
<text top="128" left="108" width="702" height="16" font="0">scheduler relies on the high level stream language compiler to decompose the execution of a stream</text>
<text top="164" left="108" width="702" height="16" font="0">program into a long series of kernel execution operations, dependency description operations, and</text>
<text top="200" left="108" width="702" height="16" font="0">data movement operations, whereas in SKIR the front-end compiler leaves kernels intact, maintains</text>
<text top="236" left="108" width="702" height="16" font="0">dependency information in its original form (as edges in the stream graph), and uses demand/data</text>
<text top="272" left="108" width="702" height="16" font="0">driven execution. Streamware also uses a stream parallelism speciﬁc queuing scheme with a ded-</text>
<text top="308" left="108" width="702" height="16" font="0">icated kernel execution queue and a dedicated data movement queue whereas SKIR is built on a</text>
<text top="344" left="108" width="613" height="16" font="0">general purpose work stealing scheme and kernels perform their own data movement.</text>
<text top="380" left="151" width="659" height="16" font="0">A stream speciﬁc queuing system more closely related to the SKIR dynamic scheduler is</text>
<text top="416" left="108" width="702" height="16" font="0">found in the GRAMPS scheduler [50]. The GRAMPS scheduler uses fairly complex task stealing</text>
<text top="452" left="108" width="702" height="16" font="0">system speciﬁc to stream parallelism with per-kernel task queues of varying priority on each worker</text>
<text top="488" left="108" width="702" height="16" font="0">thread and an explicit backpressure mechanism. In contrast, our simpler scheduling algorithm uses</text>
<text top="524" left="108" width="702" height="16" font="0">an implicit backpressure mechanism and runs on a general purpose task stealing system (TBB)</text>
<text top="560" left="108" width="702" height="16" font="0">with only minor modiﬁcation to support targeted task stealing (about 40 lines of code). This is</text>
<text top="596" left="108" width="702" height="16" font="0">important because programs may contain forms of parallelism other than stream parallelism and</text>
<text top="632" left="108" width="702" height="16" font="0">using a common scheduling infrastructure is desirable to avoid interference and over-subscription.</text>
<text top="668" left="108" width="702" height="16" font="0">TBB itself contains mechanisms to handle these situations by fairly allocating work threads among</text>
<text top="704" left="108" width="406" height="16" font="0">different parallel contexts executing in the same process.</text>
<text top="740" left="151" width="659" height="16" font="0">The Flextream system [37] provides a small amount of dynamic adaptation by using an ap-</text>
<text top="776" left="108" width="702" height="16" font="0">proach similar to SVM. At compile time, a static compiler ﬁnds an optimal schedule for virtualized</text>
<text top="812" left="108" width="702" height="16" font="0">stream parallel hardware which is a superset of the target hardware. At runtime, the schedule can</text>
<text top="848" left="108" width="702" height="16" font="0">be reﬁned for more constrained hardware or when available hardware resources change. The mo-</text>
<text top="884" left="108" width="702" height="16" font="0">tivation for Flextream is that static scheduling algorithms are too slow for runtime re-compilation.</text>
<text top="920" left="108" width="634" height="16" font="0">This is also a motivation for exploring a fully dynamic scheduling mechanism for SKIR.</text>
<text top="956" left="151" width="659" height="16" font="0">Two other recent dynamic scheduling work related to SKIR are DoPE and FDP [49][51].</text>
<text top="992" left="108" width="702" height="16" font="0">These are high level software frameworks built in C++. The primary goal of these systems is to</text>
<text top="1027" left="108" width="702" height="16" font="0">choose the best allocation of threads to data parallel kernels found in pipeline parallel programs</text>
<text top="1063" left="108" width="702" height="16" font="0">given a certain goal. This programming pattern is a subset of stream parallelism. In FDP the goal is</text>
</page>
<page number="159" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">145</text>
<text top="128" left="108" width="702" height="16" font="0">power reduction while the authors of DoPE provide APIs to build schedulers with different goals.</text>
<text top="164" left="108" width="702" height="16" font="0">Both of these works are orthogonal to the dynamic ﬁssion performed for SKIR (Section 6.6.2) and</text>
<text top="200" left="108" width="308" height="16" font="0">could be used to help choose ﬁssion width.</text>
<text top="258" left="112" width="22" height="16" font="0">8.3</text>
<text top="258" left="170" width="374" height="16" font="0">Stream Parallelism for Heterogeneous Hardware</text>
<text top="313" left="151" width="659" height="16" font="0">This thesis describes one way SKIR can be compiled to execute on graphics hardware. This</text>
<text top="349" left="108" width="702" height="16" font="0">functionality is motivated by a large amount of prior work showing that stream parallelism in</text>
<text top="385" left="108" width="702" height="16" font="0">general and the SDF model speciﬁcally are appropriate programming models for heterogeneous</text>
<text top="421" left="108" width="702" height="16" font="0">computing. Any number of techniques could be taken from the existing literature on the subject</text>
<text top="457" left="108" width="375" height="16" font="0">and applied to static regions of SKIR stream graphs.</text>
<text top="493" left="151" width="659" height="16" font="0">The Brook language [23] described in Chapter 2 as well as the related CUDA and OpenCL</text>
<text top="529" left="108" width="702" height="16" font="0">frameworks are speciﬁcally designed to execute on data parallel hardware such as GPUs. Hor-</text>
<text top="565" left="108" width="702" height="16" font="0">mati, et. al. [38] describe techniques to generate optimized CUDA code from StreamIt kernels.</text>
<text top="600" left="108" width="702" height="16" font="0">These techniques could be used to extend the methodology described for SKIR. Udupa et. al.</text>
<text top="636" left="108" width="702" height="16" font="0">[54] describe a more comprehensive approach to statically dividing the work of a StreamIt pro-</text>
<text top="672" left="108" width="702" height="16" font="0">gram between a GPU and CPU using an Integer Linear Program formulation. Approximations of</text>
<text top="708" left="108" width="702" height="16" font="0">such methods could be used to perform runtime work partitioning in a dynamic system with load</text>
<text top="744" left="108" width="176" height="16" font="0">balancing such as SKIR.</text>
</page>
<page number="160" position="absolute" top="0" left="0" height="1188" width="918">
<text top="233" left="418" width="82" height="16" font="0">Chapter 9</text>
<text top="292" left="416" width="86" height="16" font="0">Conclusion</text>
<text top="408" left="151" width="659" height="16" font="0">This thesis extends the state of the art in stream parallelism by unifying static and dynamic</text>
<text top="444" left="108" width="702" height="16" font="0">approaches to the construction, compilation, and scheduling of stream parallel computation. Pre-</text>
<text top="479" left="108" width="702" height="16" font="0">vious work in the area of static compilation and scheduling has shown the power of restricted</text>
<text top="515" left="108" width="702" height="16" font="0">stream parallel models such as Synchronous Dataﬂow. Using these models compilers can compute</text>
<text top="551" left="108" width="702" height="16" font="0">efﬁcient static schedules, target a variety of hardware types, and perform sophisticated transfor-</text>
<text top="587" left="108" width="702" height="16" font="0">mations of stream graphs. But, because past work relies on specialized languages and restricted</text>
<text top="623" left="108" width="702" height="16" font="0">programming models, few of these techniques apply to parallel programing in general purpose</text>
<text top="659" left="108" width="702" height="16" font="0">languages. Previous systems for stream parallelism in general purpose languages can implement</text>
<text top="695" left="108" width="702" height="16" font="0">efﬁcient dynamic scheduling but lack the ability to apply the aggressive optimization available to</text>
<text top="731" left="108" width="186" height="16" font="0">stream parallel compilers.</text>
<text top="767" left="151" width="659" height="16" font="0">The Stream and Kernel Intermediate Representation (SKIR) addresses these issues by pro-</text>
<text top="803" left="108" width="702" height="16" font="0">viding a compiler level representation for stream parallel computation. It is a general representa-</text>
<text top="839" left="108" width="702" height="16" font="0">tion which can be used to express arbitrary stream graphs containing pipeline and data parallelism.</text>
<text top="875" left="108" width="702" height="16" font="0">Chapter 4 explored four different uses for SKIR as a compilation target: as low level primitives</text>
<text top="911" left="108" width="594" height="16" font="0">for C; as an implementation language for object oriented stream parallelism in C</text>
<text top="911" left="700" width="17" height="13" font="1">++</text>
<text top="911" left="723" width="87" height="16" font="0">; as a target</text>
<text top="947" left="108" width="702" height="16" font="0">for the specialized stream parallel language StreamIt; and as an acceleration layer for the dynamic</text>
<text top="983" left="108" width="148" height="16" font="0">JavaScript language.</text>
<text top="1019" left="151" width="659" height="16" font="0">This thesis also introduced several techniques to support efﬁcient execution of SKIR pro-</text>
<text top="1055" left="108" width="702" height="16" font="0">grams. In Chapter 5 simple dynamic scheduling and stream communication mechanisms for par-</text>
</page>
<page number="161" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">147</text>
<text top="128" left="108" width="702" height="16" font="0">allel execution of SKIR kernels were described. Chapter 6 showed how we can perform compiler</text>
<text top="164" left="108" width="702" height="16" font="0">optimizations in support of these scheduling and communication mechanisms both in general and</text>
<text top="200" left="108" width="702" height="16" font="0">when program kernels conform to stricter stream parallel models. Chapter 6 also demonstrated</text>
<text top="236" left="108" width="702" height="16" font="0">the ability to perform stream graph level optimizations on SKIR program graphs by describing</text>
<text top="272" left="108" width="702" height="16" font="0">dynamic kernel fusion and ﬁssion transformations and by describing a SKIR to OpenCL backend.</text>
<text top="308" left="108" width="94" height="16" font="0">Compiling C</text>
<text top="308" left="200" width="17" height="13" font="1">++</text>
<text top="308" left="223" width="587" height="16" font="0">to run on a GPU is not an easy task, but this was shown to be feasible using the</text>
<text top="344" left="108" width="135" height="16" font="0">SKIR abstractions.</text>
<text top="380" left="151" width="659" height="16" font="0">In Chapter 7, we showed that the SKIR program representation combined with our schedul-</text>
<text top="416" left="108" width="702" height="16" font="0">ing and compilation techniques obtains performance competitive with mature systems for stream</text>
<text top="452" left="108" width="702" height="16" font="0">parallelism. Our ﬁne-grained SDF-style StreamIt benchmarks generally perform equal to or better</text>
<text top="488" left="108" width="702" height="16" font="0">than the same code compiled by the StreamIt compiler or running under the GNU Radio dynamic</text>
<text top="524" left="108" width="702" height="16" font="0">scheduler. For coarse grained data and pipeline parallel programs, the SKIR system again per-</text>
<text top="560" left="108" width="702" height="16" font="0">forms at or beyond the level of existing systems. The SKIR compiler and runtime achieves this</text>
<text top="596" left="108" width="591" height="16" font="0">performance while allowing far more ﬂexibility and portability than prior systems.</text>
<text top="632" left="151" width="659" height="16" font="0">This thesis demonstrates that the SKIR program representation along with dynamic schedul-</text>
<text top="668" left="108" width="702" height="16" font="0">ing and compilation is a useful tool for implementing stream parallel programming tools. In the</text>
<text top="704" left="108" width="702" height="16" font="0">future we look forward to using the SKIR platform to explore more optimization and code trans-</text>
<text top="740" left="108" width="465" height="16" font="0">formations opportunities for heterogeneous multi-core hardware.</text>
</page>
<page number="162" position="absolute" top="0" left="0" height="1188" width="918">
<text top="252" left="409" width="100" height="16" font="0">Bibliography</text>
<text top="367" left="117" width="405" height="16" font="0">[1] Apache couchdb project. http://couchdb.apache.org.</text>
<text top="404" left="117" width="210" height="16" font="0">[2] Basho. http://basho.com.</text>
<text top="441" left="117" width="270" height="16" font="0">[3] Commonjs. http://commonjs.org.</text>
<text top="477" left="117" width="252" height="16" font="0">[4] Gnu radio. http://gnuradio.org.</text>
<text top="514" left="117" width="501" height="16" font="0">[5] Go language sieve example. http://golang.org/doc/progs/sieve.go.</text>
<text top="550" left="117" width="546" height="16" font="0">[6] Intel thread building blocks (tbb). http://www.threadbuildingblocks.org.</text>
<text top="587" left="117" width="632" height="16" font="0">[7] Low level virtual machine (llvm) language reference. http://llvm.org/LangRef.html.</text>
<text top="624" left="117" width="202" height="16" font="0">[8] Node. http://nodejs.org.</text>
<text top="660" left="117" width="397" height="16" font="0">[9] node-ﬁbers. http://github.com/laverdet/node-ﬁbers.</text>
<text top="697" left="108" width="287" height="16" font="0">[10] Pixastic. http://www.pixastic.com.</text>
<text top="733" left="108" width="415" height="16" font="0">[11] Protocol buffers. http://code.google.com/p/protobuf.</text>
<text top="770" left="108" width="409" height="16" font="0">[12] Rivertrail. https://github.com/RiverTrail/RiverTrail.</text>
<text top="807" left="108" width="363" height="16" font="0">[13] Storm. https://github.com/nathanmarz/storm.</text>
<text top="843" left="108" width="378" height="16" font="0">[14] Streamit svn. https://svn.csail.mit.edu/streamit.</text>
<text top="880" left="108" width="404" height="16" font="0">[15] V8 javascript engine. http://code.google.com/p/v8.</text>
<text top="917" left="108" width="100" height="16" font="0">[16] Streamit</text>
<text top="917" left="225" width="75" height="16" font="0">cookbook,</text>
<text top="917" left="321" width="40" height="16" font="0">2006.</text>
<text top="917" left="409" width="401" height="16" font="0">http://groups.csail.mit.edu/cag/streamit/papers/streamit-</text>
<text top="938" left="147" width="104" height="16" font="0">cookbook.pdf.</text>
<text top="975" left="108" width="702" height="16" font="0">[17] Atul Adya, Jon Howell, Marvin Theimer, William J. Bolosky, and John R. Douceur. Coop-</text>
<text top="996" left="147" width="663" height="16" font="0">erative task management without manual stack management. In Proceedings of the General</text>
<text top="1018" left="147" width="663" height="16" font="0">Track of the annual conference on USENIX Annual Technical Conference, pages 289–302,</text>
<text top="1040" left="147" width="355" height="16" font="0">Berkeley, CA, USA, 2002. USENIX Association.</text>
</page>
<page number="163" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">149</text>
<text top="128" left="108" width="702" height="16" font="0">[18] Marco Aldinucci, Massimiliano Meneghin, and Massimo Torquati. Efﬁcient smith-waterman</text>
<text top="150" left="147" width="663" height="16" font="0">on multi-core with fastﬂow. In Marco Danelutto, Tom Gross, and Julien Bourgeois, editors,</text>
<text top="172" left="147" width="663" height="16" font="0">Proc. of Intl. Euromicro PDP 2010: Parallel Distributed and network-based Processing, Pisa,</text>
<text top="193" left="147" width="198" height="16" font="0">Italy, February 2010. IEEE.</text>
<text top="230" left="108" width="702" height="16" font="0">[19] Marco Aldinucci, Massimo Torquati, and Massimiliano Meneghin. Fastﬂow: Efﬁcient paral-</text>
<text top="252" left="147" width="505" height="16" font="0">lel streaming applications on multi-core. CoRR, abs/0909.1187, 2009.</text>
<text top="288" left="108" width="702" height="16" font="0">[20] Gregory E. Allen, Paul E. Zucknick, and Brian L. Evans. A distributed deadlock detection and</text>
<text top="310" left="147" width="663" height="16" font="0">resolution algorithm for process networks. In IEEE International Conference on Acoustics,</text>
<text top="331" left="147" width="423" height="16" font="0">Speech and Signal Processing, 2007. ICASSP 2007., 2007.</text>
<text top="368" left="108" width="702" height="16" font="0">[21] Christian Bienia and Kai Li. Parsec 2.0: A new benchmark suite for chip-multiprocessors. In</text>
<text top="390" left="147" width="663" height="16" font="0">Proceedings of the 5th Annual Workshop on Modeling, Benchmarking and Simulation, June</text>
<text top="411" left="147" width="40" height="16" font="0">2009.</text>
<text top="448" left="108" width="702" height="16" font="0">[22] Ian Buck. Brook speciﬁcation v0.2. Technical Report CSTR 2003-04 10/31/03 12/5/03,</text>
<text top="470" left="147" width="189" height="16" font="0">Stanford University, 2003.</text>
<text top="506" left="108" width="702" height="16" font="0">[23] Ian Buck, Tim Foley, Daniel Horn, Jeremy Sugerman, Kayvon Fatahalian, Mike Houston,</text>
<text top="528" left="147" width="663" height="16" font="0">and Pat Hanrahan. Brook for gpus: stream computing on graphics hardware. ACM Trans.</text>
<text top="550" left="147" width="214" height="16" font="0">Graph., 23(3):777–786, 2004.</text>
<text top="586" left="108" width="702" height="16" font="0">[24] Michael Butts, Anthony Mark Jones, and Paul Wasson. A structural object programming</text>
<text top="608" left="147" width="663" height="16" font="0">model, architecture, chip and tools for reconﬁgurable computing. In FCCM ’07: Proceedings</text>
<text top="630" left="147" width="663" height="16" font="0">of the 15th Annual IEEE Symposium on Field-Programmable Custom Computing Machines,</text>
<text top="651" left="147" width="494" height="16" font="0">pages 55–64, Washington, DC, USA, 2007. IEEE Computer Society.</text>
<text top="688" left="108" width="702" height="16" font="0">[25] Eylon Caspi, Michael Chu, Randy Huang, Joseph Yeh, John Wawrzynek, and Andr´e</text>
<text top="710" left="147" width="56" height="16" font="0">DeHon.</text>
<text top="710" left="222" width="515" height="16" font="0">Stream computations organized for reconﬁgurable execution (score).</text>
<text top="710" left="756" width="54" height="16" font="0">In FPL</text>
<text top="731" left="147" width="663" height="16" font="0">’00: Proceedings of the The Roadmap to Reconﬁgurable Computing, 10th International</text>
<text top="753" left="147" width="663" height="16" font="0">Workshop on Field-Programmable Logic and Applications, pages 605–614, London, UK,</text>
<text top="775" left="147" width="163" height="16" font="0">2000. Springer-Verlag.</text>
<text top="811" left="108" width="702" height="16" font="0">[26] Bryan Catanzaro, Michael Garland, and Kurt Keutzer. Copperhead: compiling an embed-</text>
<text top="833" left="147" width="663" height="16" font="0">ded data parallel language. In Proceedings of the 16th ACM symposium on Principles and</text>
<text top="855" left="147" width="663" height="16" font="0">practice of parallel programming, PPoPP ’11, pages 47–56, New York, NY, USA, 2011.</text>
<text top="876" left="147" width="45" height="16" font="0">ACM.</text>
<text top="913" left="108" width="305" height="16" font="0">[27] Jeffrey Fiﬁeld and Dirk Grunwald.</text>
<text top="913" left="433" width="377" height="16" font="0">A methodology for ﬁne-grained parallelization of</text>
<text top="934" left="147" width="663" height="16" font="0">javascript applications. In The 24th International Workshop on Languages and Compilers</text>
<text top="956" left="147" width="397" height="16" font="0">for Parallel Computing (LCPC 2011), September 2011.</text>
<text top="993" left="108" width="702" height="16" font="0">[28] Andreas Gal, Brendan Eich, Mike Shaver, David Anderson, David Mandelin, Mohammad R.</text>
<text top="1014" left="147" width="663" height="16" font="0">Haghighat, Blake Kaplan, Graydon Hoare, Boris Zbarsky, Jason Orendorff, Jesse Ruder-</text>
<text top="1036" left="147" width="663" height="16" font="0">man, Edwin W. Smith, Rick Reitmaier, Michael Bebenita, Mason Chang, and Michael Franz.</text>
<text top="1058" left="147" width="663" height="16" font="0">Trace-based just-in-time type specialization for dynamic languages. In Proceedings of the</text>
</page>
<page number="164" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">150</text>
<text top="128" left="147" width="663" height="16" font="0">2009 ACM SIGPLAN conference on Programming language design and implementation,</text>
<text top="150" left="147" width="443" height="16" font="0">PLDI ’09, pages 465–478, New York, NY, USA, 2009. ACM.</text>
<text top="187" left="108" width="702" height="16" font="0">[29] Anwar Ghuloum, Terry Smith, Gansha Wu, Xin Zhou, Jesse Fang, Peng Guo, Byoungro So,</text>
<text top="208" left="147" width="663" height="16" font="0">Mohan Rajagopalan, Yongjian Chen, and Biao Chen. Future-proof data parallel algorithms</text>
<text top="230" left="147" width="638" height="16" font="0">and software on intel multi-core architecture. Intel Technology Journal, November 2007.</text>
<text top="266" left="108" width="702" height="16" font="0">[30] John Giacomoni, Tipp Moseley, and Manish Vachharajani. Fastforward for efﬁcient pipeline</text>
<text top="288" left="147" width="663" height="16" font="0">parallelism: a cache-optimized concurrent lock-free queue. In PPoPP ’08: Proceedings of</text>
<text top="310" left="147" width="663" height="16" font="0">the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming,</text>
<text top="331" left="147" width="348" height="16" font="0">pages 43–52, New York, NY, USA, 2008. ACM.</text>
<text top="368" left="108" width="702" height="16" font="0">[31] Maya B. Gokhale, Janice M. Stone, Jeff Arnold, and Mirek Kalinowski. Stream-oriented fpga</text>
<text top="390" left="147" width="663" height="16" font="0">computing in the streams-c high level language. In FCCM ’00: Proceedings of the 2000 IEEE</text>
<text top="411" left="147" width="663" height="16" font="0">Symposium on Field-Programmable Custom Computing Machines, page 49, Washington,</text>
<text top="433" left="147" width="300" height="16" font="0">DC, USA, 2000. IEEE Computer Society.</text>
<text top="470" left="108" width="702" height="16" font="0">[32] Michael I. Gordon. Compiler Techniques for Scalable Performance of Stream Programs on</text>
<text top="491" left="147" width="663" height="16" font="0">Multicore Architectures. Ph.d. thesis, Massachusetts Institute of Technology, Cambridge,</text>
<text top="513" left="147" width="116" height="16" font="0">MA, May 2010.</text>
<text top="550" left="108" width="702" height="16" font="0">[33] Michael I. Gordon, William Thies, and Saman Amarasinghe. Exploiting coarse-grained task,</text>
<text top="571" left="147" width="663" height="16" font="0">data, and pipeline parallelism in stream programs. In ASPLOS-XII: Proceedings of the 12th</text>
<text top="593" left="147" width="663" height="16" font="0">international conference on Architectural support for programming languages and operating</text>
<text top="615" left="147" width="431" height="16" font="0">systems, pages 151–162, New York, NY, USA, 2006. ACM.</text>
<text top="651" left="108" width="702" height="16" font="0">[34] Michael I. Gordon, William Thies, Michal Karczmarek, Jasper Lin, Ali S. Meli, Andrew A.</text>
<text top="673" left="147" width="663" height="16" font="0">Lamb, Chris Leger, Jeremy Wong, Henry Hoffmann, David Maze, and Saman Amarasinghe.</text>
<text top="695" left="147" width="663" height="16" font="0">A stream compiler for communication-exposed architectures. SIGOPS Oper. Syst. Rev.,</text>
<text top="716" left="147" width="156" height="16" font="0">36(5):291–303, 2002.</text>
<text top="753" left="108" width="702" height="16" font="0">[35] Jayanth Gummaraju, Joel Coburn, Yoshio Turner, and Mendel Rosenblum. Streamware:</text>
<text top="775" left="147" width="504" height="16" font="0">programming general-purpose multicore processors using streams.</text>
<text top="775" left="673" width="137" height="16" font="0">In ASPLOS XIII:</text>
<text top="796" left="147" width="663" height="16" font="0">Proceedings of the 13th international conference on Architectural support for programming</text>
<text top="818" left="147" width="610" height="16" font="0">languages and operating systems, pages 297–307, New York, NY, USA, 2008. ACM.</text>
<text top="855" left="108" width="702" height="16" font="0">[36] Amir Hormati, Manjunath Kudlur, Scott Mahlke, David Bacon, and Rodric Rabbah. Op-</text>
<text top="876" left="147" width="663" height="16" font="0">timus: efﬁcient realization of streaming applications on fpgas. In Proceedings of the 2008</text>
<text top="898" left="147" width="663" height="16" font="0">international conference on Compilers, architectures and synthesis for embedded systems,</text>
<text top="920" left="147" width="441" height="16" font="0">CASES ’08, pages 41–50, New York, NY, USA, 2008. ACM.</text>
<text top="956" left="108" width="702" height="16" font="0">[37] Amir H. Hormati, Yoonseo Choi, Manjunath Kudlur, Rodric Rabbah, Trevor Mudge, and</text>
<text top="978" left="147" width="663" height="16" font="0">Scott Mahlke. Flextream: Adaptive compilation of streaming applications for heterogeneous</text>
<text top="999" left="147" width="626" height="16" font="0">architectures. In In PACT 09: Parallel Architecture and Compilation Techniques, 2009.</text>
<text top="1036" left="108" width="702" height="16" font="0">[38] Amir H. Hormati, Mehrzad Samadi, Mark Woh, Trevor Mudge, and Scott Mahlke. Sponge:</text>
<text top="1058" left="147" width="393" height="16" font="0">portable stream programming on graphics engines.</text>
<text top="1058" left="565" width="245" height="16" font="0">In Proceedings of the sixteenth</text>
</page>
<page number="165" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">151</text>
<text top="128" left="147" width="663" height="16" font="0">international conference on Architectural support for programming languages and operating</text>
<text top="150" left="147" width="535" height="16" font="0">systems, ASPLOS ’11, pages 381–392, New York, NY, USA, 2011. ACM.</text>
<text top="187" left="108" width="702" height="16" font="0">[39] Gilles Kahn. The semantics of a simple language for parallel programming. In Information</text>
<text top="208" left="147" width="507" height="16" font="0">processing 74, pages 471–475. North Holland, Amsterdam, Aug 1974.</text>
<text top="245" left="108" width="702" height="16" font="0">[40] Gilles Kahn and David B. Macqueen. Coroutines and networks of parallel processes. In</text>
<text top="266" left="147" width="562" height="16" font="0">Information Processing 77, pages 993–998. North Holland, Amsterdam, 1977.</text>
<text top="303" left="108" width="702" height="16" font="0">[41] Ujval J. Kapasi, William J. Dally, Scott Rixner, John D. Owens, and Brucek Khailany. Pro-</text>
<text top="325" left="147" width="483" height="16" font="0">grammable stream processors. IEEE Computer, 36:282–288, 2003.</text>
<text top="361" left="108" width="702" height="16" font="0">[42] Francois Labonte, Peter Mattson, William Thies, Ian Buck, Christos Kozyrakis, and Mark</text>
<text top="383" left="147" width="663" height="16" font="0">Horowitz. The stream virtual machine. In PACT ’04: Proceedings of the 13th International</text>
<text top="405" left="147" width="663" height="16" font="0">Conference on Parallel Architectures and Compilation Techniques, pages 267–277, Wash-</text>
<text top="426" left="147" width="355" height="16" font="0">ington, DC, USA, 2004. IEEE Computer Society.</text>
<text top="463" left="108" width="702" height="16" font="0">[43] E. A. Lee and D. G. Messerschmitt. Synchronous data ﬂow. Proceedings of the IEEE,</text>
<text top="485" left="147" width="174" height="16" font="0">75(9):1235–1245, 1987.</text>
<text top="521" left="108" width="702" height="16" font="0">[44] Shih-Wei Liao, Zhaohui Du, Gansha Wu, and Guei-Yuan Lueh. Data and computation trans-</text>
<text top="543" left="147" width="663" height="16" font="0">formations for brook streaming applications on multiprocessors. In CGO ’06: Proceedings of</text>
<text top="565" left="147" width="663" height="16" font="0">the International Symposium on Code Generation and Optimization, pages 196–207, Wash-</text>
<text top="586" left="147" width="355" height="16" font="0">ington, DC, USA, 2006. IEEE Computer Society.</text>
<text top="623" left="108" width="702" height="16" font="0">[45] Peter Mattson, Bill Thies, Lance Hammond, and Michael Vahey. Streaming virtual machine</text>
<text top="645" left="147" width="260" height="16" font="0">speciﬁcation version 1.0. July 2004.</text>
<text top="681" left="108" width="702" height="16" font="0">[46] M. Douglas Mcllroy. Squinting at power series. Softw. Pract. Exper., 20:661–683, July 1990.</text>
<text top="718" left="108" width="702" height="16" font="0">[47] Cupertino Miranda, Antoniu Pop, Philippe Dumont, Albert Cohen, and Marc Duranton. Er-</text>
<text top="739" left="147" width="663" height="16" font="0">bium: a deterministic, concurrent intermediate representation to map data-ﬂow tasks to scal-</text>
<text top="761" left="147" width="663" height="16" font="0">able, persistent streaming processes. In Proceedings of the 2010 international conference</text>
<text top="783" left="147" width="663" height="16" font="0">on Compilers, architectures and synthesis for embedded systems, CASES ’10, pages 11–20,</text>
<text top="804" left="147" width="249" height="16" font="0">New York, NY, USA, 2010. ACM.</text>
<text top="841" left="108" width="702" height="16" font="0">[48] Thomas M. Parks. Bounded Scheduling of Process Networks. PhD thesis, EECS Department,</text>
<text top="863" left="147" width="293" height="16" font="0">University of California, Berkeley, 1995.</text>
<text top="899" left="108" width="702" height="16" font="0">[49] Arun Raman, Hanjun Kim, Taewook Oh, Jae W. Lee, , and David I. August. Parallelism</text>
<text top="921" left="147" width="663" height="16" font="0">orchestration using dope: the degree of parallelism executive. In Proceedings of the 32nd</text>
<text top="943" left="147" width="663" height="16" font="0">ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),</text>
<text top="964" left="147" width="78" height="16" font="0">June 2011.</text>
<text top="1001" left="108" width="702" height="16" font="0">[50] Daniel Sanchez, David Lo, Jeremy Sugerman, Richard M. Yoo, and Christos Kozyrakis.</text>
<text top="1023" left="147" width="663" height="16" font="0">Dynamic ﬁne-grain scheduling of pipeline parallelism. In PACT ’11: Proceedings of the</text>
<text top="1044" left="147" width="663" height="16" font="0">20th International Conference on Parallel Architecture and Compilation Techniques, October</text>
<text top="1066" left="147" width="40" height="16" font="0">2011.</text>
</page>
<page number="166" position="absolute" top="0" left="0" height="1188" width="918">
<text top="85" left="783" width="27" height="16" font="0">152</text>
<text top="128" left="108" width="702" height="16" font="0">[51] M. Aater Suleman, Moinuddin K. Qureshi, Khubaib, and Yale N. Patt. Feedback-directed</text>
<text top="150" left="147" width="151" height="16" font="0">pipeline parallelism.</text>
<text top="150" left="321" width="489" height="16" font="0">In Proceedings of the 19th international conference on Parallel</text>
<text top="172" left="147" width="663" height="16" font="0">architectures and compilation techniques, PACT ’10, pages 147–156, New York, NY, USA,</text>
<text top="193" left="147" width="89" height="16" font="0">2010. ACM.</text>
<text top="230" left="108" width="702" height="16" font="0">[52] William Thies. Language and Compiler Support for Stream Programs. Ph.d. thesis, Mas-</text>
<text top="252" left="147" width="450" height="16" font="0">sachusetts Institute of Technology, Cambridge, MA, Feb 2009.</text>
<text top="288" left="108" width="702" height="16" font="0">[53] William Thies, Michal Karczmarek, Janis Sermulins, Rodric Rabbah, and Saman Amaras-</text>
<text top="310" left="147" width="663" height="16" font="0">inghe. Teleport messaging for distributed stream programs. In Symposium on Principles and</text>
<text top="331" left="147" width="447" height="16" font="0">Practice of Parallel Programming, Chicago, Illinois, Jun 2005.</text>
<text top="368" left="108" width="702" height="16" font="0">[54] Abhishek Udupa, R. Govindarajan, and Matthew J. Thazhuthaveetil. Synergistic execu-</text>
<text top="390" left="147" width="663" height="16" font="0">tion of stream programs on multicores with accelerators. In Proceedings of the 2009 ACM</text>
<text top="411" left="147" width="663" height="16" font="0">SIGPLAN/SIGBED conference on Languages, compilers, and tools for embedded systems,</text>
<text top="433" left="147" width="449" height="16" font="0">LCTES ’09, pages 99–108, New York, NY, USA, 2009. ACM.</text>
<text top="470" left="108" width="702" height="16" font="0">[55] Xin David Zhang, Qiuyuan J. Li, Rodric Rabbah, and Saman Amarasinghe. A lightweight</text>
<text top="491" left="147" width="310" height="16" font="0">streaming layer for multicore execution.</text>
<text top="491" left="481" width="329" height="16" font="0">In Workshop on Design, Architecture and</text>
<text top="513" left="147" width="487" height="16" font="0">Simulation of Chip Multi-Processors, Chicago, IL, December 2007.</text>
</page>
</pdf2xml>
